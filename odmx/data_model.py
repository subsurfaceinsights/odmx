"""
Autogenerated python classes for database tables
Generated on 2023-05-14 20:29:40.720730 by db module
"""
import dataclasses
import datetime
from beartype.typing import Optional, Generator, List, ClassVar, Type, Dict, Any
import beartype
import odmx.support.db as db

def beartype_wrap_init(cls):
    assert dataclasses.is_dataclass(cls)
    cls.__init__ = beartype.beartype(cls.__init__)
    return cls

@beartype_wrap_init
@dataclasses.dataclass
class CategoricalResultValueAnnotations:
    """
    Annotations for Categorical ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['CategoricalResultValues']:
        return read_categorical_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_categorical_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a CategoricalResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CategoricalResultValueAnnotations(**json_obj)


@beartype.beartype
def write_categorical_result_value_annotations_obj(con: db.Connection, obj: CategoricalResultValueAnnotations) -> int:
    """
    Write a CategoricalResultValueAnnotations object to the database
    @param con: database connection
    @param obj: CategoricalResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'categorical_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_categorical_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the categorical_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'categorical_result_value_annotations', data)

@beartype.beartype
def write_categorical_result_value_annotations_many(con: db.Connection, objs: List[CategoricalResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of CategoricalResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of CategoricalResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'categorical_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_categorical_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the categorical_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'categorical_result_value_annotations', data)

@beartype.beartype
def read_categorical_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[CategoricalResultValueAnnotations, None, None]:
    """
    Read from the categorical_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of CategoricalResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'categorical_result_value_annotations', data)
    for row in result:
        yield CategoricalResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_categorical_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[CategoricalResultValueAnnotations, None, None]:
    """
    Read from the categorical_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of CategoricalResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'categorical_result_value_annotations', data)
    for row in result:
        yield CategoricalResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_categorical_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[CategoricalResultValueAnnotations, None, None]:
    """
    Read from the categorical_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of CategoricalResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'categorical_result_value_annotations', data)
    for row in result:
        yield CategoricalResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_categorical_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[CategoricalResultValueAnnotations]:
    """
    Read from the categorical_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'categorical_result_value_annotations', data)
    if result is None:
        return None
    return CategoricalResultValueAnnotations(**result)

@beartype.beartype
def read_categorical_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> CategoricalResultValueAnnotations:
    """
    Read from the categorical_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'categorical_result_value_annotations', data)
    return CategoricalResultValueAnnotations(**result)

@beartype.beartype
def read_categorical_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[CategoricalResultValueAnnotations]:
    """
    Read from the categorical_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'categorical_result_value_annotations', data)
    return [CategoricalResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_categorical_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[CategoricalResultValueAnnotations]:
    result = db.query_one(con, 'categorical_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return CategoricalResultValueAnnotations(**result)

@beartype.beartype
def delete_categorical_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'categorical_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
CategoricalResultValueAnnotations.create_from_json_dict = create_categorical_result_value_annotations_from_json_dict
CategoricalResultValueAnnotations.write = write_categorical_result_value_annotations
CategoricalResultValueAnnotations.update = update_categorical_result_value_annotations
CategoricalResultValueAnnotations.write_many = write_categorical_result_value_annotations_many
CategoricalResultValueAnnotations.read = read_categorical_result_value_annotations
CategoricalResultValueAnnotations.read_fuzzy = read_categorical_result_value_annotations_fuzzy
CategoricalResultValueAnnotations.read_any = read_categorical_result_value_annotations_any
CategoricalResultValueAnnotations.read_one = read_categorical_result_value_annotations_one
CategoricalResultValueAnnotations.read_one_or_none = read_categorical_result_value_annotations_one_or_none
CategoricalResultValueAnnotations.read_all = read_categorical_result_value_annotations_all
CategoricalResultValueAnnotations.delete = delete_categorical_result_value_annotations_by_id
CategoricalResultValueAnnotations.read_by_id = read_categorical_result_value_annotations_by_id
CategoricalResultValueAnnotations.delete_by_id = delete_categorical_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ActionAnnotations:
    """
    Notes for or groups of one or more Actions.

    @param bridge_id 
    @param action_id 
    @param annotation_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

@beartype.beartype
def create_action_annotations_from_json_dict(json_obj: dict):
        """
        Create a ActionAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ActionAnnotations(**json_obj)


@beartype.beartype
def write_action_annotations_obj(con: db.Connection, obj: ActionAnnotations) -> int:
    """
    Write a ActionAnnotations object to the database
    @param con: database connection
    @param obj: ActionAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'action_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_action_annotations(
            con: db.Connection,
            action_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the action_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'action_annotations', data)

@beartype.beartype
def write_action_annotations_many(con: db.Connection, objs: List[ActionAnnotations], upsert: bool = False) -> int:
    """
    Write a list of ActionAnnotations objects to the database
    @param con: database connection
    @param objs: list of ActionAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'action_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_action_annotations(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the action_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'action_annotations', data)

@beartype.beartype
def read_action_annotations(
            con: db.Connection,
            action_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ActionAnnotations, None, None]:
    """
    Read from the action_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param annotation_id 
    @return generator of ActionAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'action_annotations', data)
    for row in result:
        yield ActionAnnotations(**row.as_dict())

@beartype.beartype
def read_action_annotations_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ActionAnnotations, None, None]:
    """
    Read from the action_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param annotation_id 
    @return generator of ActionAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'action_annotations', data)
    for row in result:
        yield ActionAnnotations(**row.as_dict())

@beartype.beartype
def read_action_annotations_any(con: db.Connection, action_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ActionAnnotations, None, None]:
    """
    Read from the action_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param annotation_id 
    @return generator of ActionAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'action_annotations', data)
    for row in result:
        yield ActionAnnotations(**row.as_dict())

@beartype.beartype
def read_action_annotations_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ActionAnnotations]:
    """
    Read from the action_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'action_annotations', data)
    if result is None:
        return None
    return ActionAnnotations(**result)

@beartype.beartype
def read_action_annotations_one(con: db.Connection, action_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ActionAnnotations:
    """
    Read from the action_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'action_annotations', data)
    return ActionAnnotations(**result)

@beartype.beartype
def read_action_annotations_all(con: db.Connection, action_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ActionAnnotations]:
    """
    Read from the action_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'action_annotations', data)
    return [ActionAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_action_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[ActionAnnotations]:
    result = db.query_one(con, 'action_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ActionAnnotations(**result)

@beartype.beartype
def delete_action_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'action_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
ActionAnnotations.create_from_json_dict = create_action_annotations_from_json_dict
ActionAnnotations.write = write_action_annotations
ActionAnnotations.update = update_action_annotations
ActionAnnotations.write_many = write_action_annotations_many
ActionAnnotations.read = read_action_annotations
ActionAnnotations.read_fuzzy = read_action_annotations_fuzzy
ActionAnnotations.read_any = read_action_annotations_any
ActionAnnotations.read_one = read_action_annotations_one
ActionAnnotations.read_one_or_none = read_action_annotations_one_or_none
ActionAnnotations.read_all = read_action_annotations_all
ActionAnnotations.delete = delete_action_annotations_by_id
ActionAnnotations.read_by_id = read_action_annotations_by_id
ActionAnnotations.delete_by_id = delete_action_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Annotations:
    """
    Contains text annotations added to one or more records within various ODMX tables.  Annotations can be used to record notes about a particular SamplingFeature, Action, Result, etc. or to create groups of records such as Specimens, Sites, People, etc.

    @param annotation_id 
    @param annotation_type_cv 
    @param annotation_code 
    @param annotation_text 
    @param annotation_date_time 
    @param annotation_utc_offset 
    @param annotation_link 
    @param annotator_id 
    @param citation_id 

    This is an automatically generated class
    """
    annotation_type_cv: str # annotation_type_cv character varying (default: )
    annotation_text: str # annotation_text character varying (default: )
    annotation_id: Optional[int] = None # annotation_id integer (default: )
    annotation_code: Optional[str] = None # annotation_code character varying (default: )
    annotation_date_time: Optional[datetime.datetime] = None # annotation_date_time timestamp without time zone (default: )
    annotation_utc_offset: Optional[int] = None # annotation_utc_offset integer (default: )
    annotation_link: Optional[str] = None # annotation_link character varying (default: )
    annotator_id: Optional[int] = None # annotator_id integer (default: )
    citation_id: Optional[int] = None # citation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'annotation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.annotation_date_time is not None:
            obj['annotation_date_time'] = self.annotation_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_annotation_type_cv(self, con: db.Connection) -> Optional['CvAnnotationType']:
        return read_cv_annotation_type_one_or_none(con, term=self.annotation_type_cv)

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_annotator(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.annotator_id)

@beartype.beartype
def create_annotations_from_json_dict(json_obj: dict):
        """
        Create a Annotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'annotation_date_time' in json_obj and json_obj['annotation_date_time'] is not None:
            json_obj['annotation_date_time'] = datetime.datetime.fromisoformat(json_obj['annotation_date_time'])
        return Annotations(**json_obj)


@beartype.beartype
def write_annotations_obj(con: db.Connection, obj: Annotations) -> int:
    """
    Write a Annotations object to the database
    @param con: database connection
    @param obj: Annotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_annotations(
            con: db.Connection,
            annotation_type_cv: str,
            annotation_text: str,
            annotation_id: Optional[int] = None,
            annotation_code: Optional[str] = None,
            annotation_date_time: Optional[datetime.datetime] = None,
            annotation_utc_offset: Optional[int] = None,
            annotation_link: Optional[str] = None,
            annotator_id: Optional[int] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Write to the annotations table in the database
    @param con: database connection
    @param annotation_id 
    @param annotation_type_cv 
    @param annotation_code 
    @param annotation_text 
    @param annotation_date_time 
    @param annotation_utc_offset 
    @param annotation_link 
    @param annotator_id 
    @param citation_id 
    @return id of the inserted/updated row
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    return db.upsert(con, 'annotations', data)

@beartype.beartype
def write_annotations_many(con: db.Connection, objs: List[Annotations], upsert: bool = False) -> int:
    """
    Write a list of Annotations objects to the database
    @param con: database connection
    @param objs: list of Annotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_annotations(con: db.Connection, annotation_id: int,
            annotation_type_cv: Optional[str] = None,
            annotation_text: Optional[str] = None,
            annotation_code: Optional[str] = None,
            annotation_date_time: Optional[datetime.datetime] = None,
            annotation_utc_offset: Optional[int] = None,
            annotation_link: Optional[str] = None,
            annotator_id: Optional[int] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Update a row in the annotations table in the database
    @param con: database connection
    @param annotation_id 
    @param annotation_type_cv 
    @param annotation_code 
    @param annotation_text 
    @param annotation_date_time 
    @param annotation_utc_offset 
    @param annotation_link 
    @param annotator_id 
    @param citation_id 
    @return The number of rows updated
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    return db.update(con, 'annotations', data)

@beartype.beartype
def read_annotations(
            con: db.Connection,
            annotation_type_cv: Optional[str] = None,
             annotation_text: Optional[str] = None,
             annotation_id: Optional[int] = None,
             annotation_code: Optional[str] = None,
             annotation_date_time: Optional[datetime.datetime] = None,
             annotation_utc_offset: Optional[int] = None,
             annotation_link: Optional[str] = None,
             annotator_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Generator[Annotations, None, None]:
    """
    Read from the annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param annotation_id 
    @param annotation_type_cv 
    @param annotation_code 
    @param annotation_text 
    @param annotation_date_time 
    @param annotation_utc_offset 
    @param annotation_link 
    @param annotator_id 
    @param citation_id 
    @return generator of Annotations objects
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    result = db.query(con, 'annotations', data)
    for row in result:
        yield Annotations(**row.as_dict())

@beartype.beartype
def read_annotations_fuzzy(con: db.Connection, annotation_type_cv: Optional[str] = None,
             annotation_text: Optional[str] = None,
             annotation_id: Optional[int] = None,
             annotation_code: Optional[str] = None,
             annotation_date_time: Optional[datetime.datetime] = None,
             annotation_utc_offset: Optional[int] = None,
             annotation_link: Optional[str] = None,
             annotator_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Generator[Annotations, None, None]:
    """
    Read from the annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param annotation_id 
    @param annotation_type_cv 
    @param annotation_code 
    @param annotation_text 
    @param annotation_date_time 
    @param annotation_utc_offset 
    @param annotation_link 
    @param annotator_id 
    @param citation_id 
    @return generator of Annotations objects
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    result = db.query_fuzzy(con, 'annotations', data)
    for row in result:
        yield Annotations(**row.as_dict())

@beartype.beartype
def read_annotations_any(con: db.Connection, annotation_type_cv: Optional[List[str]] = None,
             annotation_text: Optional[List[str]] = None,
             annotation_id: Optional[List[int]] = None,
             annotation_code: Optional[List[str]] = None,
             annotation_date_time: Optional[List[datetime.datetime]] = None,
             annotation_utc_offset: Optional[List[int]] = None,
             annotation_link: Optional[List[str]] = None,
             annotator_id: Optional[List[int]] = None,
             citation_id: Optional[List[int]] = None) -> Generator[Annotations, None, None]:
    """
    Read from the annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param annotation_id 
    @param annotation_type_cv 
    @param annotation_code 
    @param annotation_text 
    @param annotation_date_time 
    @param annotation_utc_offset 
    @param annotation_link 
    @param annotator_id 
    @param citation_id 
    @return generator of Annotations objects
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    result = db.query_any(con, 'annotations', data)
    for row in result:
        yield Annotations(**row.as_dict())

@beartype.beartype
def read_annotations_one_or_none(con: db.Connection, annotation_type_cv: Optional[str] = None,
             annotation_text: Optional[str] = None,
             annotation_id: Optional[int] = None,
             annotation_code: Optional[str] = None,
             annotation_date_time: Optional[datetime.datetime] = None,
             annotation_utc_offset: Optional[int] = None,
             annotation_link: Optional[str] = None,
             annotator_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Optional[Annotations]:
    """
    Read from the annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    result = db.query_one_or_none(con, 'annotations', data)
    if result is None:
        return None
    return Annotations(**result)

@beartype.beartype
def read_annotations_one(con: db.Connection, annotation_type_cv: Optional[str] = None,
             annotation_text: Optional[str] = None,
             annotation_id: Optional[int] = None,
             annotation_code: Optional[str] = None,
             annotation_date_time: Optional[datetime.datetime] = None,
             annotation_utc_offset: Optional[int] = None,
             annotation_link: Optional[str] = None,
             annotator_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Annotations:
    """
    Read from the annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    result = db.query_one(con, 'annotations', data)
    return Annotations(**result)

@beartype.beartype
def read_annotations_all(con: db.Connection, annotation_type_cv: Optional[str] = None,
             annotation_text: Optional[str] = None,
             annotation_id: Optional[int] = None,
             annotation_code: Optional[str] = None,
             annotation_date_time: Optional[datetime.datetime] = None,
             annotation_utc_offset: Optional[int] = None,
             annotation_link: Optional[str] = None,
             annotator_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> List[Annotations]:
    """
    Read from the annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'annotation_id': annotation_id,
        'annotation_type_cv': annotation_type_cv,
        'annotation_code': annotation_code,
        'annotation_text': annotation_text,
        'annotation_date_time': annotation_date_time,
        'annotation_utc_offset': annotation_utc_offset,
        'annotation_link': annotation_link,
        'annotator_id': annotator_id,
        'citation_id': citation_id,
    }
    result = db.query(con, 'annotations', data)
    return [Annotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_annotations_by_id(con: db.Connection, annotation_id: int) -> Optional[Annotations]:
    result = db.query_one(con, 'annotations', {'annotation_id': annotation_id})
    if result is None:
        return None
    return Annotations(**result)

@beartype.beartype
def delete_annotations_by_id(con: db.Connection, annotation_id: int):
    db.delete(con, 'annotations', {'annotation_id': annotation_id})
# Associate the functions with the class
Annotations.create_from_json_dict = create_annotations_from_json_dict
Annotations.write = write_annotations
Annotations.update = update_annotations
Annotations.write_many = write_annotations_many
Annotations.read = read_annotations
Annotations.read_fuzzy = read_annotations_fuzzy
Annotations.read_any = read_annotations_any
Annotations.read_one = read_annotations_one
Annotations.read_one_or_none = read_annotations_one_or_none
Annotations.read_all = read_annotations_all
Annotations.delete = delete_annotations_by_id
Annotations.read_by_id = read_annotations_by_id
Annotations.delete_by_id = delete_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class EquipmentAnnotations:
    """
    Bridge table linking Annotations to Equipment

    @param bridge_id 
    @param equipment_id 
    @param annotation_id 

    This is an automatically generated class
    """
    equipment_id: int # equipment_id integer (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

@beartype.beartype
def create_equipment_annotations_from_json_dict(json_obj: dict):
        """
        Create a EquipmentAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return EquipmentAnnotations(**json_obj)


@beartype.beartype
def write_equipment_annotations_obj(con: db.Connection, obj: EquipmentAnnotations) -> int:
    """
    Write a EquipmentAnnotations object to the database
    @param con: database connection
    @param obj: EquipmentAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'equipment_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_equipment_annotations(
            con: db.Connection,
            equipment_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the equipment_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'equipment_annotations', data)

@beartype.beartype
def write_equipment_annotations_many(con: db.Connection, objs: List[EquipmentAnnotations], upsert: bool = False) -> int:
    """
    Write a list of EquipmentAnnotations objects to the database
    @param con: database connection
    @param objs: list of EquipmentAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'equipment_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_equipment_annotations(con: db.Connection, bridge_id: int,
            equipment_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the equipment_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'equipment_annotations', data)

@beartype.beartype
def read_equipment_annotations(
            con: db.Connection,
            equipment_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[EquipmentAnnotations, None, None]:
    """
    Read from the equipment_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param annotation_id 
    @return generator of EquipmentAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'equipment_annotations', data)
    for row in result:
        yield EquipmentAnnotations(**row.as_dict())

@beartype.beartype
def read_equipment_annotations_fuzzy(con: db.Connection, equipment_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[EquipmentAnnotations, None, None]:
    """
    Read from the equipment_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param annotation_id 
    @return generator of EquipmentAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'equipment_annotations', data)
    for row in result:
        yield EquipmentAnnotations(**row.as_dict())

@beartype.beartype
def read_equipment_annotations_any(con: db.Connection, equipment_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[EquipmentAnnotations, None, None]:
    """
    Read from the equipment_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param annotation_id 
    @return generator of EquipmentAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'equipment_annotations', data)
    for row in result:
        yield EquipmentAnnotations(**row.as_dict())

@beartype.beartype
def read_equipment_annotations_one_or_none(con: db.Connection, equipment_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[EquipmentAnnotations]:
    """
    Read from the equipment_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'equipment_annotations', data)
    if result is None:
        return None
    return EquipmentAnnotations(**result)

@beartype.beartype
def read_equipment_annotations_one(con: db.Connection, equipment_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> EquipmentAnnotations:
    """
    Read from the equipment_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'equipment_annotations', data)
    return EquipmentAnnotations(**result)

@beartype.beartype
def read_equipment_annotations_all(con: db.Connection, equipment_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[EquipmentAnnotations]:
    """
    Read from the equipment_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'equipment_annotations', data)
    return [EquipmentAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_equipment_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[EquipmentAnnotations]:
    result = db.query_one(con, 'equipment_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return EquipmentAnnotations(**result)

@beartype.beartype
def delete_equipment_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'equipment_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
EquipmentAnnotations.create_from_json_dict = create_equipment_annotations_from_json_dict
EquipmentAnnotations.write = write_equipment_annotations
EquipmentAnnotations.update = update_equipment_annotations
EquipmentAnnotations.write_many = write_equipment_annotations_many
EquipmentAnnotations.read = read_equipment_annotations
EquipmentAnnotations.read_fuzzy = read_equipment_annotations_fuzzy
EquipmentAnnotations.read_any = read_equipment_annotations_any
EquipmentAnnotations.read_one = read_equipment_annotations_one
EquipmentAnnotations.read_one_or_none = read_equipment_annotations_one_or_none
EquipmentAnnotations.read_all = read_equipment_annotations_all
EquipmentAnnotations.delete = delete_equipment_annotations_by_id
EquipmentAnnotations.read_by_id = read_equipment_annotations_by_id
EquipmentAnnotations.delete_by_id = delete_equipment_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MeasurementResultValueAnnotations:
    """
    Annotations for Measurement ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['MeasurementResultValues']:
        return read_measurement_result_values_one_or_none(con, value_id=self.value_id)

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

@beartype.beartype
def create_measurement_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a MeasurementResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MeasurementResultValueAnnotations(**json_obj)


@beartype.beartype
def write_measurement_result_value_annotations_obj(con: db.Connection, obj: MeasurementResultValueAnnotations) -> int:
    """
    Write a MeasurementResultValueAnnotations object to the database
    @param con: database connection
    @param obj: MeasurementResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'measurement_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_measurement_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the measurement_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'measurement_result_value_annotations', data)

@beartype.beartype
def write_measurement_result_value_annotations_many(con: db.Connection, objs: List[MeasurementResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of MeasurementResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of MeasurementResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'measurement_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_measurement_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the measurement_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'measurement_result_value_annotations', data)

@beartype.beartype
def read_measurement_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[MeasurementResultValueAnnotations, None, None]:
    """
    Read from the measurement_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of MeasurementResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'measurement_result_value_annotations', data)
    for row in result:
        yield MeasurementResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_measurement_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[MeasurementResultValueAnnotations, None, None]:
    """
    Read from the measurement_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of MeasurementResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'measurement_result_value_annotations', data)
    for row in result:
        yield MeasurementResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_measurement_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[MeasurementResultValueAnnotations, None, None]:
    """
    Read from the measurement_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of MeasurementResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'measurement_result_value_annotations', data)
    for row in result:
        yield MeasurementResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_measurement_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[MeasurementResultValueAnnotations]:
    """
    Read from the measurement_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'measurement_result_value_annotations', data)
    if result is None:
        return None
    return MeasurementResultValueAnnotations(**result)

@beartype.beartype
def read_measurement_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> MeasurementResultValueAnnotations:
    """
    Read from the measurement_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'measurement_result_value_annotations', data)
    return MeasurementResultValueAnnotations(**result)

@beartype.beartype
def read_measurement_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[MeasurementResultValueAnnotations]:
    """
    Read from the measurement_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'measurement_result_value_annotations', data)
    return [MeasurementResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_measurement_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[MeasurementResultValueAnnotations]:
    result = db.query_one(con, 'measurement_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return MeasurementResultValueAnnotations(**result)

@beartype.beartype
def delete_measurement_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'measurement_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
MeasurementResultValueAnnotations.create_from_json_dict = create_measurement_result_value_annotations_from_json_dict
MeasurementResultValueAnnotations.write = write_measurement_result_value_annotations
MeasurementResultValueAnnotations.update = update_measurement_result_value_annotations
MeasurementResultValueAnnotations.write_many = write_measurement_result_value_annotations_many
MeasurementResultValueAnnotations.read = read_measurement_result_value_annotations
MeasurementResultValueAnnotations.read_fuzzy = read_measurement_result_value_annotations_fuzzy
MeasurementResultValueAnnotations.read_any = read_measurement_result_value_annotations_any
MeasurementResultValueAnnotations.read_one = read_measurement_result_value_annotations_one
MeasurementResultValueAnnotations.read_one_or_none = read_measurement_result_value_annotations_one_or_none
MeasurementResultValueAnnotations.read_all = read_measurement_result_value_annotations_all
MeasurementResultValueAnnotations.delete = delete_measurement_result_value_annotations_by_id
MeasurementResultValueAnnotations.read_by_id = read_measurement_result_value_annotations_by_id
MeasurementResultValueAnnotations.delete_by_id = delete_measurement_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MethodAnnotations:
    """
    Notes for or groups of one or more Methods.

    @param bridge_id 
    @param method_id 
    @param annotation_id 

    This is an automatically generated class
    """
    method_id: int # method_id integer (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_method(self, con: db.Connection) -> Optional['Methods']:
        return read_methods_one_or_none(con, method_id=self.method_id)

@beartype.beartype
def create_method_annotations_from_json_dict(json_obj: dict):
        """
        Create a MethodAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MethodAnnotations(**json_obj)


@beartype.beartype
def write_method_annotations_obj(con: db.Connection, obj: MethodAnnotations) -> int:
    """
    Write a MethodAnnotations object to the database
    @param con: database connection
    @param obj: MethodAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'method_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_method_annotations(
            con: db.Connection,
            method_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the method_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'method_annotations', data)

@beartype.beartype
def write_method_annotations_many(con: db.Connection, objs: List[MethodAnnotations], upsert: bool = False) -> int:
    """
    Write a list of MethodAnnotations objects to the database
    @param con: database connection
    @param objs: list of MethodAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'method_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_method_annotations(con: db.Connection, bridge_id: int,
            method_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the method_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'method_annotations', data)

@beartype.beartype
def read_method_annotations(
            con: db.Connection,
            method_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[MethodAnnotations, None, None]:
    """
    Read from the method_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param annotation_id 
    @return generator of MethodAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'method_annotations', data)
    for row in result:
        yield MethodAnnotations(**row.as_dict())

@beartype.beartype
def read_method_annotations_fuzzy(con: db.Connection, method_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[MethodAnnotations, None, None]:
    """
    Read from the method_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param annotation_id 
    @return generator of MethodAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'method_annotations', data)
    for row in result:
        yield MethodAnnotations(**row.as_dict())

@beartype.beartype
def read_method_annotations_any(con: db.Connection, method_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[MethodAnnotations, None, None]:
    """
    Read from the method_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param annotation_id 
    @return generator of MethodAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'method_annotations', data)
    for row in result:
        yield MethodAnnotations(**row.as_dict())

@beartype.beartype
def read_method_annotations_one_or_none(con: db.Connection, method_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[MethodAnnotations]:
    """
    Read from the method_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'method_annotations', data)
    if result is None:
        return None
    return MethodAnnotations(**result)

@beartype.beartype
def read_method_annotations_one(con: db.Connection, method_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> MethodAnnotations:
    """
    Read from the method_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'method_annotations', data)
    return MethodAnnotations(**result)

@beartype.beartype
def read_method_annotations_all(con: db.Connection, method_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[MethodAnnotations]:
    """
    Read from the method_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'method_annotations', data)
    return [MethodAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_method_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[MethodAnnotations]:
    result = db.query_one(con, 'method_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return MethodAnnotations(**result)

@beartype.beartype
def delete_method_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'method_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
MethodAnnotations.create_from_json_dict = create_method_annotations_from_json_dict
MethodAnnotations.write = write_method_annotations
MethodAnnotations.update = update_method_annotations
MethodAnnotations.write_many = write_method_annotations_many
MethodAnnotations.read = read_method_annotations
MethodAnnotations.read_fuzzy = read_method_annotations_fuzzy
MethodAnnotations.read_any = read_method_annotations_any
MethodAnnotations.read_one = read_method_annotations_one
MethodAnnotations.read_one_or_none = read_method_annotations_one_or_none
MethodAnnotations.read_all = read_method_annotations_all
MethodAnnotations.delete = delete_method_annotations_by_id
MethodAnnotations.read_by_id = read_method_annotations_by_id
MethodAnnotations.delete_by_id = delete_method_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PointCoverageResultValueAnnotations:
    """
    Annotations for Point Coverage ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['PointCoverageResultValues']:
        return read_point_coverage_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_point_coverage_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a PointCoverageResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return PointCoverageResultValueAnnotations(**json_obj)


@beartype.beartype
def write_point_coverage_result_value_annotations_obj(con: db.Connection, obj: PointCoverageResultValueAnnotations) -> int:
    """
    Write a PointCoverageResultValueAnnotations object to the database
    @param con: database connection
    @param obj: PointCoverageResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'point_coverage_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_point_coverage_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the point_coverage_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'point_coverage_result_value_annotations', data)

@beartype.beartype
def write_point_coverage_result_value_annotations_many(con: db.Connection, objs: List[PointCoverageResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of PointCoverageResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of PointCoverageResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'point_coverage_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_point_coverage_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the point_coverage_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'point_coverage_result_value_annotations', data)

@beartype.beartype
def read_point_coverage_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[PointCoverageResultValueAnnotations, None, None]:
    """
    Read from the point_coverage_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of PointCoverageResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'point_coverage_result_value_annotations', data)
    for row in result:
        yield PointCoverageResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_point_coverage_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[PointCoverageResultValueAnnotations, None, None]:
    """
    Read from the point_coverage_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of PointCoverageResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'point_coverage_result_value_annotations', data)
    for row in result:
        yield PointCoverageResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_point_coverage_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[PointCoverageResultValueAnnotations, None, None]:
    """
    Read from the point_coverage_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of PointCoverageResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'point_coverage_result_value_annotations', data)
    for row in result:
        yield PointCoverageResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_point_coverage_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[PointCoverageResultValueAnnotations]:
    """
    Read from the point_coverage_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'point_coverage_result_value_annotations', data)
    if result is None:
        return None
    return PointCoverageResultValueAnnotations(**result)

@beartype.beartype
def read_point_coverage_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> PointCoverageResultValueAnnotations:
    """
    Read from the point_coverage_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'point_coverage_result_value_annotations', data)
    return PointCoverageResultValueAnnotations(**result)

@beartype.beartype
def read_point_coverage_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[PointCoverageResultValueAnnotations]:
    """
    Read from the point_coverage_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'point_coverage_result_value_annotations', data)
    return [PointCoverageResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_point_coverage_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[PointCoverageResultValueAnnotations]:
    result = db.query_one(con, 'point_coverage_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return PointCoverageResultValueAnnotations(**result)

@beartype.beartype
def delete_point_coverage_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'point_coverage_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
PointCoverageResultValueAnnotations.create_from_json_dict = create_point_coverage_result_value_annotations_from_json_dict
PointCoverageResultValueAnnotations.write = write_point_coverage_result_value_annotations
PointCoverageResultValueAnnotations.update = update_point_coverage_result_value_annotations
PointCoverageResultValueAnnotations.write_many = write_point_coverage_result_value_annotations_many
PointCoverageResultValueAnnotations.read = read_point_coverage_result_value_annotations
PointCoverageResultValueAnnotations.read_fuzzy = read_point_coverage_result_value_annotations_fuzzy
PointCoverageResultValueAnnotations.read_any = read_point_coverage_result_value_annotations_any
PointCoverageResultValueAnnotations.read_one = read_point_coverage_result_value_annotations_one
PointCoverageResultValueAnnotations.read_one_or_none = read_point_coverage_result_value_annotations_one_or_none
PointCoverageResultValueAnnotations.read_all = read_point_coverage_result_value_annotations_all
PointCoverageResultValueAnnotations.delete = delete_point_coverage_result_value_annotations_by_id
PointCoverageResultValueAnnotations.read_by_id = read_point_coverage_result_value_annotations_by_id
PointCoverageResultValueAnnotations.delete_by_id = delete_point_coverage_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ProfileResultValueAnnotations:
    """
    Annotations for Profile ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['ProfileResultValues']:
        return read_profile_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_profile_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a ProfileResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ProfileResultValueAnnotations(**json_obj)


@beartype.beartype
def write_profile_result_value_annotations_obj(con: db.Connection, obj: ProfileResultValueAnnotations) -> int:
    """
    Write a ProfileResultValueAnnotations object to the database
    @param con: database connection
    @param obj: ProfileResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'profile_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_profile_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the profile_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'profile_result_value_annotations', data)

@beartype.beartype
def write_profile_result_value_annotations_many(con: db.Connection, objs: List[ProfileResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of ProfileResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of ProfileResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'profile_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_profile_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the profile_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'profile_result_value_annotations', data)

@beartype.beartype
def read_profile_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ProfileResultValueAnnotations, None, None]:
    """
    Read from the profile_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of ProfileResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'profile_result_value_annotations', data)
    for row in result:
        yield ProfileResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_profile_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ProfileResultValueAnnotations, None, None]:
    """
    Read from the profile_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of ProfileResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'profile_result_value_annotations', data)
    for row in result:
        yield ProfileResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_profile_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ProfileResultValueAnnotations, None, None]:
    """
    Read from the profile_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of ProfileResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'profile_result_value_annotations', data)
    for row in result:
        yield ProfileResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_profile_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ProfileResultValueAnnotations]:
    """
    Read from the profile_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'profile_result_value_annotations', data)
    if result is None:
        return None
    return ProfileResultValueAnnotations(**result)

@beartype.beartype
def read_profile_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ProfileResultValueAnnotations:
    """
    Read from the profile_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'profile_result_value_annotations', data)
    return ProfileResultValueAnnotations(**result)

@beartype.beartype
def read_profile_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ProfileResultValueAnnotations]:
    """
    Read from the profile_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'profile_result_value_annotations', data)
    return [ProfileResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_profile_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[ProfileResultValueAnnotations]:
    result = db.query_one(con, 'profile_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ProfileResultValueAnnotations(**result)

@beartype.beartype
def delete_profile_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'profile_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
ProfileResultValueAnnotations.create_from_json_dict = create_profile_result_value_annotations_from_json_dict
ProfileResultValueAnnotations.write = write_profile_result_value_annotations
ProfileResultValueAnnotations.update = update_profile_result_value_annotations
ProfileResultValueAnnotations.write_many = write_profile_result_value_annotations_many
ProfileResultValueAnnotations.read = read_profile_result_value_annotations
ProfileResultValueAnnotations.read_fuzzy = read_profile_result_value_annotations_fuzzy
ProfileResultValueAnnotations.read_any = read_profile_result_value_annotations_any
ProfileResultValueAnnotations.read_one = read_profile_result_value_annotations_one
ProfileResultValueAnnotations.read_one_or_none = read_profile_result_value_annotations_one_or_none
ProfileResultValueAnnotations.read_all = read_profile_result_value_annotations_all
ProfileResultValueAnnotations.delete = delete_profile_result_value_annotations_by_id
ProfileResultValueAnnotations.read_by_id = read_profile_result_value_annotations_by_id
ProfileResultValueAnnotations.delete_by_id = delete_profile_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ResultAnnotations:
    """
    Notes for or groups of one or more Results [sets].

    @param bridge_id 
    @param result_id 
    @param annotation_id 
    @param begin_date_time 
    @param end_date_time 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    begin_date_time: datetime.datetime # begin_date_time timestamp without time zone (default: )
    end_date_time: datetime.datetime # end_date_time timestamp without time zone (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['begin_date_time'] = self.begin_date_time.isoformat()
        obj['end_date_time'] = self.end_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_result_annotations_from_json_dict(json_obj: dict):
        """
        Create a ResultAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['begin_date_time'] = datetime.datetime.fromisoformat(json_obj['begin_date_time'])
        json_obj['end_date_time'] = datetime.datetime.fromisoformat(json_obj['end_date_time'])
        return ResultAnnotations(**json_obj)


@beartype.beartype
def write_result_annotations_obj(con: db.Connection, obj: ResultAnnotations) -> int:
    """
    Write a ResultAnnotations object to the database
    @param con: database connection
    @param obj: ResultAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'result_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_result_annotations(
            con: db.Connection,
            result_id: int,
            annotation_id: int,
            begin_date_time: datetime.datetime,
            end_date_time: datetime.datetime,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the result_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param annotation_id 
    @param begin_date_time 
    @param end_date_time 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    return db.upsert(con, 'result_annotations', data)

@beartype.beartype
def write_result_annotations_many(con: db.Connection, objs: List[ResultAnnotations], upsert: bool = False) -> int:
    """
    Write a list of ResultAnnotations objects to the database
    @param con: database connection
    @param objs: list of ResultAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'result_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_result_annotations(con: db.Connection, bridge_id: int,
            result_id: Optional[int] = None,
            annotation_id: Optional[int] = None,
            begin_date_time: Optional[datetime.datetime] = None,
            end_date_time: Optional[datetime.datetime] = None) -> int:
    """
    Update a row in the result_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param annotation_id 
    @param begin_date_time 
    @param end_date_time 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    return db.update(con, 'result_annotations', data)

@beartype.beartype
def read_result_annotations(
            con: db.Connection,
            result_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             end_date_time: Optional[datetime.datetime] = None,
             bridge_id: Optional[int] = None) -> Generator[ResultAnnotations, None, None]:
    """
    Read from the result_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param annotation_id 
    @param begin_date_time 
    @param end_date_time 
    @return generator of ResultAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    result = db.query(con, 'result_annotations', data)
    for row in result:
        yield ResultAnnotations(**row.as_dict())

@beartype.beartype
def read_result_annotations_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             end_date_time: Optional[datetime.datetime] = None,
             bridge_id: Optional[int] = None) -> Generator[ResultAnnotations, None, None]:
    """
    Read from the result_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param annotation_id 
    @param begin_date_time 
    @param end_date_time 
    @return generator of ResultAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    result = db.query_fuzzy(con, 'result_annotations', data)
    for row in result:
        yield ResultAnnotations(**row.as_dict())

@beartype.beartype
def read_result_annotations_any(con: db.Connection, result_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             begin_date_time: Optional[List[datetime.datetime]] = None,
             end_date_time: Optional[List[datetime.datetime]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ResultAnnotations, None, None]:
    """
    Read from the result_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param annotation_id 
    @param begin_date_time 
    @param end_date_time 
    @return generator of ResultAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    result = db.query_any(con, 'result_annotations', data)
    for row in result:
        yield ResultAnnotations(**row.as_dict())

@beartype.beartype
def read_result_annotations_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             end_date_time: Optional[datetime.datetime] = None,
             bridge_id: Optional[int] = None) -> Optional[ResultAnnotations]:
    """
    Read from the result_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    result = db.query_one_or_none(con, 'result_annotations', data)
    if result is None:
        return None
    return ResultAnnotations(**result)

@beartype.beartype
def read_result_annotations_one(con: db.Connection, result_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             end_date_time: Optional[datetime.datetime] = None,
             bridge_id: Optional[int] = None) -> ResultAnnotations:
    """
    Read from the result_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    result = db.query_one(con, 'result_annotations', data)
    return ResultAnnotations(**result)

@beartype.beartype
def read_result_annotations_all(con: db.Connection, result_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             end_date_time: Optional[datetime.datetime] = None,
             bridge_id: Optional[int] = None) -> List[ResultAnnotations]:
    """
    Read from the result_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'annotation_id': annotation_id,
        'begin_date_time': begin_date_time,
        'end_date_time': end_date_time,
    }
    result = db.query(con, 'result_annotations', data)
    return [ResultAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_result_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[ResultAnnotations]:
    result = db.query_one(con, 'result_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ResultAnnotations(**result)

@beartype.beartype
def delete_result_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'result_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
ResultAnnotations.create_from_json_dict = create_result_annotations_from_json_dict
ResultAnnotations.write = write_result_annotations
ResultAnnotations.update = update_result_annotations
ResultAnnotations.write_many = write_result_annotations_many
ResultAnnotations.read = read_result_annotations
ResultAnnotations.read_fuzzy = read_result_annotations_fuzzy
ResultAnnotations.read_any = read_result_annotations_any
ResultAnnotations.read_one = read_result_annotations_one
ResultAnnotations.read_one_or_none = read_result_annotations_one_or_none
ResultAnnotations.read_all = read_result_annotations_all
ResultAnnotations.delete = delete_result_annotations_by_id
ResultAnnotations.read_by_id = read_result_annotations_by_id
ResultAnnotations.delete_by_id = delete_result_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SamplingFeatureAnnotations:
    """
    Notes for or groups of one or more Sampling Features.

    @param bridge_id 
    @param sampling_feature_id 
    @param annotation_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_sampling_feature_annotations_from_json_dict(json_obj: dict):
        """
        Create a SamplingFeatureAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SamplingFeatureAnnotations(**json_obj)


@beartype.beartype
def write_sampling_feature_annotations_obj(con: db.Connection, obj: SamplingFeatureAnnotations) -> int:
    """
    Write a SamplingFeatureAnnotations object to the database
    @param con: database connection
    @param obj: SamplingFeatureAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampling_feature_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_sampling_feature_annotations(
            con: db.Connection,
            sampling_feature_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the sampling_feature_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'sampling_feature_annotations', data)

@beartype.beartype
def write_sampling_feature_annotations_many(con: db.Connection, objs: List[SamplingFeatureAnnotations], upsert: bool = False) -> int:
    """
    Write a list of SamplingFeatureAnnotations objects to the database
    @param con: database connection
    @param objs: list of SamplingFeatureAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampling_feature_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampling_feature_annotations(con: db.Connection, bridge_id: int,
            sampling_feature_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the sampling_feature_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'sampling_feature_annotations', data)

@beartype.beartype
def read_sampling_feature_annotations(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[SamplingFeatureAnnotations, None, None]:
    """
    Read from the sampling_feature_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param annotation_id 
    @return generator of SamplingFeatureAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'sampling_feature_annotations', data)
    for row in result:
        yield SamplingFeatureAnnotations(**row.as_dict())

@beartype.beartype
def read_sampling_feature_annotations_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[SamplingFeatureAnnotations, None, None]:
    """
    Read from the sampling_feature_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param annotation_id 
    @return generator of SamplingFeatureAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'sampling_feature_annotations', data)
    for row in result:
        yield SamplingFeatureAnnotations(**row.as_dict())

@beartype.beartype
def read_sampling_feature_annotations_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[SamplingFeatureAnnotations, None, None]:
    """
    Read from the sampling_feature_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param annotation_id 
    @return generator of SamplingFeatureAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'sampling_feature_annotations', data)
    for row in result:
        yield SamplingFeatureAnnotations(**row.as_dict())

@beartype.beartype
def read_sampling_feature_annotations_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[SamplingFeatureAnnotations]:
    """
    Read from the sampling_feature_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'sampling_feature_annotations', data)
    if result is None:
        return None
    return SamplingFeatureAnnotations(**result)

@beartype.beartype
def read_sampling_feature_annotations_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> SamplingFeatureAnnotations:
    """
    Read from the sampling_feature_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'sampling_feature_annotations', data)
    return SamplingFeatureAnnotations(**result)

@beartype.beartype
def read_sampling_feature_annotations_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[SamplingFeatureAnnotations]:
    """
    Read from the sampling_feature_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'sampling_feature_annotations', data)
    return [SamplingFeatureAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampling_feature_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[SamplingFeatureAnnotations]:
    result = db.query_one(con, 'sampling_feature_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SamplingFeatureAnnotations(**result)

@beartype.beartype
def delete_sampling_feature_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'sampling_feature_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
SamplingFeatureAnnotations.create_from_json_dict = create_sampling_feature_annotations_from_json_dict
SamplingFeatureAnnotations.write = write_sampling_feature_annotations
SamplingFeatureAnnotations.update = update_sampling_feature_annotations
SamplingFeatureAnnotations.write_many = write_sampling_feature_annotations_many
SamplingFeatureAnnotations.read = read_sampling_feature_annotations
SamplingFeatureAnnotations.read_fuzzy = read_sampling_feature_annotations_fuzzy
SamplingFeatureAnnotations.read_any = read_sampling_feature_annotations_any
SamplingFeatureAnnotations.read_one = read_sampling_feature_annotations_one
SamplingFeatureAnnotations.read_one_or_none = read_sampling_feature_annotations_one_or_none
SamplingFeatureAnnotations.read_all = read_sampling_feature_annotations_all
SamplingFeatureAnnotations.delete = delete_sampling_feature_annotations_by_id
SamplingFeatureAnnotations.read_by_id = read_sampling_feature_annotations_by_id
SamplingFeatureAnnotations.delete_by_id = delete_sampling_feature_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SectionResultValueAnnotations:
    """
    Annotations for Section ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['SectionResultValues']:
        return read_section_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_section_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a SectionResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SectionResultValueAnnotations(**json_obj)


@beartype.beartype
def write_section_result_value_annotations_obj(con: db.Connection, obj: SectionResultValueAnnotations) -> int:
    """
    Write a SectionResultValueAnnotations object to the database
    @param con: database connection
    @param obj: SectionResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'section_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_section_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the section_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'section_result_value_annotations', data)

@beartype.beartype
def write_section_result_value_annotations_many(con: db.Connection, objs: List[SectionResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of SectionResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of SectionResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'section_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_section_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the section_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'section_result_value_annotations', data)

@beartype.beartype
def read_section_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[SectionResultValueAnnotations, None, None]:
    """
    Read from the section_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of SectionResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'section_result_value_annotations', data)
    for row in result:
        yield SectionResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_section_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[SectionResultValueAnnotations, None, None]:
    """
    Read from the section_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of SectionResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'section_result_value_annotations', data)
    for row in result:
        yield SectionResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_section_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[SectionResultValueAnnotations, None, None]:
    """
    Read from the section_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of SectionResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'section_result_value_annotations', data)
    for row in result:
        yield SectionResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_section_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[SectionResultValueAnnotations]:
    """
    Read from the section_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'section_result_value_annotations', data)
    if result is None:
        return None
    return SectionResultValueAnnotations(**result)

@beartype.beartype
def read_section_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> SectionResultValueAnnotations:
    """
    Read from the section_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'section_result_value_annotations', data)
    return SectionResultValueAnnotations(**result)

@beartype.beartype
def read_section_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[SectionResultValueAnnotations]:
    """
    Read from the section_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'section_result_value_annotations', data)
    return [SectionResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_section_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[SectionResultValueAnnotations]:
    result = db.query_one(con, 'section_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SectionResultValueAnnotations(**result)

@beartype.beartype
def delete_section_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'section_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
SectionResultValueAnnotations.create_from_json_dict = create_section_result_value_annotations_from_json_dict
SectionResultValueAnnotations.write = write_section_result_value_annotations
SectionResultValueAnnotations.update = update_section_result_value_annotations
SectionResultValueAnnotations.write_many = write_section_result_value_annotations_many
SectionResultValueAnnotations.read = read_section_result_value_annotations
SectionResultValueAnnotations.read_fuzzy = read_section_result_value_annotations_fuzzy
SectionResultValueAnnotations.read_any = read_section_result_value_annotations_any
SectionResultValueAnnotations.read_one = read_section_result_value_annotations_one
SectionResultValueAnnotations.read_one_or_none = read_section_result_value_annotations_one_or_none
SectionResultValueAnnotations.read_all = read_section_result_value_annotations_all
SectionResultValueAnnotations.delete = delete_section_result_value_annotations_by_id
SectionResultValueAnnotations.read_by_id = read_section_result_value_annotations_by_id
SectionResultValueAnnotations.delete_by_id = delete_section_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpectraResultValueAnnotations:
    """
    Annotations for Spectra ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['SpectraResultValues']:
        return read_spectra_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_spectra_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a SpectraResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpectraResultValueAnnotations(**json_obj)


@beartype.beartype
def write_spectra_result_value_annotations_obj(con: db.Connection, obj: SpectraResultValueAnnotations) -> int:
    """
    Write a SpectraResultValueAnnotations object to the database
    @param con: database connection
    @param obj: SpectraResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'spectra_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_spectra_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the spectra_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'spectra_result_value_annotations', data)

@beartype.beartype
def write_spectra_result_value_annotations_many(con: db.Connection, objs: List[SpectraResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of SpectraResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of SpectraResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'spectra_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_spectra_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the spectra_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'spectra_result_value_annotations', data)

@beartype.beartype
def read_spectra_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[SpectraResultValueAnnotations, None, None]:
    """
    Read from the spectra_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of SpectraResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'spectra_result_value_annotations', data)
    for row in result:
        yield SpectraResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_spectra_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[SpectraResultValueAnnotations, None, None]:
    """
    Read from the spectra_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of SpectraResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'spectra_result_value_annotations', data)
    for row in result:
        yield SpectraResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_spectra_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[SpectraResultValueAnnotations, None, None]:
    """
    Read from the spectra_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of SpectraResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'spectra_result_value_annotations', data)
    for row in result:
        yield SpectraResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_spectra_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[SpectraResultValueAnnotations]:
    """
    Read from the spectra_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'spectra_result_value_annotations', data)
    if result is None:
        return None
    return SpectraResultValueAnnotations(**result)

@beartype.beartype
def read_spectra_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> SpectraResultValueAnnotations:
    """
    Read from the spectra_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'spectra_result_value_annotations', data)
    return SpectraResultValueAnnotations(**result)

@beartype.beartype
def read_spectra_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[SpectraResultValueAnnotations]:
    """
    Read from the spectra_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'spectra_result_value_annotations', data)
    return [SpectraResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_spectra_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[SpectraResultValueAnnotations]:
    result = db.query_one(con, 'spectra_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SpectraResultValueAnnotations(**result)

@beartype.beartype
def delete_spectra_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'spectra_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
SpectraResultValueAnnotations.create_from_json_dict = create_spectra_result_value_annotations_from_json_dict
SpectraResultValueAnnotations.write = write_spectra_result_value_annotations
SpectraResultValueAnnotations.update = update_spectra_result_value_annotations
SpectraResultValueAnnotations.write_many = write_spectra_result_value_annotations_many
SpectraResultValueAnnotations.read = read_spectra_result_value_annotations
SpectraResultValueAnnotations.read_fuzzy = read_spectra_result_value_annotations_fuzzy
SpectraResultValueAnnotations.read_any = read_spectra_result_value_annotations_any
SpectraResultValueAnnotations.read_one = read_spectra_result_value_annotations_one
SpectraResultValueAnnotations.read_one_or_none = read_spectra_result_value_annotations_one_or_none
SpectraResultValueAnnotations.read_all = read_spectra_result_value_annotations_all
SpectraResultValueAnnotations.delete = delete_spectra_result_value_annotations_by_id
SpectraResultValueAnnotations.read_by_id = read_spectra_result_value_annotations_by_id
SpectraResultValueAnnotations.delete_by_id = delete_spectra_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TimeseriesResultValueAnnotations:
    """
    Annotations for Time Series ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['TimeseriesResultValues']:
        return read_timeseries_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_timeseries_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a TimeseriesResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TimeseriesResultValueAnnotations(**json_obj)


@beartype.beartype
def write_timeseries_result_value_annotations_obj(con: db.Connection, obj: TimeseriesResultValueAnnotations) -> int:
    """
    Write a TimeseriesResultValueAnnotations object to the database
    @param con: database connection
    @param obj: TimeseriesResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'timeseries_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_timeseries_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the timeseries_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'timeseries_result_value_annotations', data)

@beartype.beartype
def write_timeseries_result_value_annotations_many(con: db.Connection, objs: List[TimeseriesResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of TimeseriesResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of TimeseriesResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'timeseries_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_timeseries_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the timeseries_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'timeseries_result_value_annotations', data)

@beartype.beartype
def read_timeseries_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[TimeseriesResultValueAnnotations, None, None]:
    """
    Read from the timeseries_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TimeseriesResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'timeseries_result_value_annotations', data)
    for row in result:
        yield TimeseriesResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_timeseries_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[TimeseriesResultValueAnnotations, None, None]:
    """
    Read from the timeseries_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TimeseriesResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'timeseries_result_value_annotations', data)
    for row in result:
        yield TimeseriesResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_timeseries_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[TimeseriesResultValueAnnotations, None, None]:
    """
    Read from the timeseries_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TimeseriesResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'timeseries_result_value_annotations', data)
    for row in result:
        yield TimeseriesResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_timeseries_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[TimeseriesResultValueAnnotations]:
    """
    Read from the timeseries_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'timeseries_result_value_annotations', data)
    if result is None:
        return None
    return TimeseriesResultValueAnnotations(**result)

@beartype.beartype
def read_timeseries_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> TimeseriesResultValueAnnotations:
    """
    Read from the timeseries_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'timeseries_result_value_annotations', data)
    return TimeseriesResultValueAnnotations(**result)

@beartype.beartype
def read_timeseries_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[TimeseriesResultValueAnnotations]:
    """
    Read from the timeseries_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'timeseries_result_value_annotations', data)
    return [TimeseriesResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_timeseries_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[TimeseriesResultValueAnnotations]:
    result = db.query_one(con, 'timeseries_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return TimeseriesResultValueAnnotations(**result)

@beartype.beartype
def delete_timeseries_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'timeseries_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
TimeseriesResultValueAnnotations.create_from_json_dict = create_timeseries_result_value_annotations_from_json_dict
TimeseriesResultValueAnnotations.write = write_timeseries_result_value_annotations
TimeseriesResultValueAnnotations.update = update_timeseries_result_value_annotations
TimeseriesResultValueAnnotations.write_many = write_timeseries_result_value_annotations_many
TimeseriesResultValueAnnotations.read = read_timeseries_result_value_annotations
TimeseriesResultValueAnnotations.read_fuzzy = read_timeseries_result_value_annotations_fuzzy
TimeseriesResultValueAnnotations.read_any = read_timeseries_result_value_annotations_any
TimeseriesResultValueAnnotations.read_one = read_timeseries_result_value_annotations_one
TimeseriesResultValueAnnotations.read_one_or_none = read_timeseries_result_value_annotations_one_or_none
TimeseriesResultValueAnnotations.read_all = read_timeseries_result_value_annotations_all
TimeseriesResultValueAnnotations.delete = delete_timeseries_result_value_annotations_by_id
TimeseriesResultValueAnnotations.read_by_id = read_timeseries_result_value_annotations_by_id
TimeseriesResultValueAnnotations.delete_by_id = delete_timeseries_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TrajectoryResultValueAnnotations:
    """
    Annotations for Trajectory ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['TrajectoryResultValues']:
        return read_trajectory_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_trajectory_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a TrajectoryResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TrajectoryResultValueAnnotations(**json_obj)


@beartype.beartype
def write_trajectory_result_value_annotations_obj(con: db.Connection, obj: TrajectoryResultValueAnnotations) -> int:
    """
    Write a TrajectoryResultValueAnnotations object to the database
    @param con: database connection
    @param obj: TrajectoryResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'trajectory_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_trajectory_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the trajectory_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'trajectory_result_value_annotations', data)

@beartype.beartype
def write_trajectory_result_value_annotations_many(con: db.Connection, objs: List[TrajectoryResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of TrajectoryResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of TrajectoryResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'trajectory_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_trajectory_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the trajectory_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'trajectory_result_value_annotations', data)

@beartype.beartype
def read_trajectory_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[TrajectoryResultValueAnnotations, None, None]:
    """
    Read from the trajectory_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TrajectoryResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'trajectory_result_value_annotations', data)
    for row in result:
        yield TrajectoryResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_trajectory_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[TrajectoryResultValueAnnotations, None, None]:
    """
    Read from the trajectory_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TrajectoryResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'trajectory_result_value_annotations', data)
    for row in result:
        yield TrajectoryResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_trajectory_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[TrajectoryResultValueAnnotations, None, None]:
    """
    Read from the trajectory_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TrajectoryResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'trajectory_result_value_annotations', data)
    for row in result:
        yield TrajectoryResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_trajectory_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[TrajectoryResultValueAnnotations]:
    """
    Read from the trajectory_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'trajectory_result_value_annotations', data)
    if result is None:
        return None
    return TrajectoryResultValueAnnotations(**result)

@beartype.beartype
def read_trajectory_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> TrajectoryResultValueAnnotations:
    """
    Read from the trajectory_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'trajectory_result_value_annotations', data)
    return TrajectoryResultValueAnnotations(**result)

@beartype.beartype
def read_trajectory_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[TrajectoryResultValueAnnotations]:
    """
    Read from the trajectory_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'trajectory_result_value_annotations', data)
    return [TrajectoryResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_trajectory_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[TrajectoryResultValueAnnotations]:
    result = db.query_one(con, 'trajectory_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return TrajectoryResultValueAnnotations(**result)

@beartype.beartype
def delete_trajectory_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'trajectory_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
TrajectoryResultValueAnnotations.create_from_json_dict = create_trajectory_result_value_annotations_from_json_dict
TrajectoryResultValueAnnotations.write = write_trajectory_result_value_annotations
TrajectoryResultValueAnnotations.update = update_trajectory_result_value_annotations
TrajectoryResultValueAnnotations.write_many = write_trajectory_result_value_annotations_many
TrajectoryResultValueAnnotations.read = read_trajectory_result_value_annotations
TrajectoryResultValueAnnotations.read_fuzzy = read_trajectory_result_value_annotations_fuzzy
TrajectoryResultValueAnnotations.read_any = read_trajectory_result_value_annotations_any
TrajectoryResultValueAnnotations.read_one = read_trajectory_result_value_annotations_one
TrajectoryResultValueAnnotations.read_one_or_none = read_trajectory_result_value_annotations_one_or_none
TrajectoryResultValueAnnotations.read_all = read_trajectory_result_value_annotations_all
TrajectoryResultValueAnnotations.delete = delete_trajectory_result_value_annotations_by_id
TrajectoryResultValueAnnotations.read_by_id = read_trajectory_result_value_annotations_by_id
TrajectoryResultValueAnnotations.delete_by_id = delete_trajectory_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TransectResultValueAnnotations:
    """
    Annotations for Transect ResultValues

    @param bridge_id 
    @param value_id 
    @param annotation_id 

    This is an automatically generated class
    """
    value_id: int # value_id bigint (default: )
    annotation_id: int # annotation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_value(self, con: db.Connection) -> Optional['TransectResultValues']:
        return read_transect_result_values_one_or_none(con, value_id=self.value_id)

@beartype.beartype
def create_transect_result_value_annotations_from_json_dict(json_obj: dict):
        """
        Create a TransectResultValueAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TransectResultValueAnnotations(**json_obj)


@beartype.beartype
def write_transect_result_value_annotations_obj(con: db.Connection, obj: TransectResultValueAnnotations) -> int:
    """
    Write a TransectResultValueAnnotations object to the database
    @param con: database connection
    @param obj: TransectResultValueAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'transect_result_value_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_transect_result_value_annotations(
            con: db.Connection,
            value_id: int,
            annotation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the transect_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.upsert(con, 'transect_result_value_annotations', data)

@beartype.beartype
def write_transect_result_value_annotations_many(con: db.Connection, objs: List[TransectResultValueAnnotations], upsert: bool = False) -> int:
    """
    Write a list of TransectResultValueAnnotations objects to the database
    @param con: database connection
    @param objs: list of TransectResultValueAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'transect_result_value_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_transect_result_value_annotations(con: db.Connection, bridge_id: int,
            value_id: Optional[int] = None,
            annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the transect_result_value_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    return db.update(con, 'transect_result_value_annotations', data)

@beartype.beartype
def read_transect_result_value_annotations(
            con: db.Connection,
            value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[TransectResultValueAnnotations, None, None]:
    """
    Read from the transect_result_value_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TransectResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'transect_result_value_annotations', data)
    for row in result:
        yield TransectResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_transect_result_value_annotations_fuzzy(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[TransectResultValueAnnotations, None, None]:
    """
    Read from the transect_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TransectResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_fuzzy(con, 'transect_result_value_annotations', data)
    for row in result:
        yield TransectResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_transect_result_value_annotations_any(con: db.Connection, value_id: Optional[List[int]] = None,
             annotation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[TransectResultValueAnnotations, None, None]:
    """
    Read from the transect_result_value_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param value_id 
    @param annotation_id 
    @return generator of TransectResultValueAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_any(con, 'transect_result_value_annotations', data)
    for row in result:
        yield TransectResultValueAnnotations(**row.as_dict())

@beartype.beartype
def read_transect_result_value_annotations_one_or_none(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[TransectResultValueAnnotations]:
    """
    Read from the transect_result_value_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one_or_none(con, 'transect_result_value_annotations', data)
    if result is None:
        return None
    return TransectResultValueAnnotations(**result)

@beartype.beartype
def read_transect_result_value_annotations_one(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> TransectResultValueAnnotations:
    """
    Read from the transect_result_value_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query_one(con, 'transect_result_value_annotations', data)
    return TransectResultValueAnnotations(**result)

@beartype.beartype
def read_transect_result_value_annotations_all(con: db.Connection, value_id: Optional[int] = None,
             annotation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[TransectResultValueAnnotations]:
    """
    Read from the transect_result_value_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'value_id': value_id,
        'annotation_id': annotation_id,
    }
    result = db.query(con, 'transect_result_value_annotations', data)
    return [TransectResultValueAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_transect_result_value_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[TransectResultValueAnnotations]:
    result = db.query_one(con, 'transect_result_value_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return TransectResultValueAnnotations(**result)

@beartype.beartype
def delete_transect_result_value_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'transect_result_value_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
TransectResultValueAnnotations.create_from_json_dict = create_transect_result_value_annotations_from_json_dict
TransectResultValueAnnotations.write = write_transect_result_value_annotations
TransectResultValueAnnotations.update = update_transect_result_value_annotations
TransectResultValueAnnotations.write_many = write_transect_result_value_annotations_many
TransectResultValueAnnotations.read = read_transect_result_value_annotations
TransectResultValueAnnotations.read_fuzzy = read_transect_result_value_annotations_fuzzy
TransectResultValueAnnotations.read_any = read_transect_result_value_annotations_any
TransectResultValueAnnotations.read_one = read_transect_result_value_annotations_one
TransectResultValueAnnotations.read_one_or_none = read_transect_result_value_annotations_one_or_none
TransectResultValueAnnotations.read_all = read_transect_result_value_annotations_all
TransectResultValueAnnotations.delete = delete_transect_result_value_annotations_by_id
TransectResultValueAnnotations.read_by_id = read_transect_result_value_annotations_by_id
TransectResultValueAnnotations.delete_by_id = delete_transect_result_value_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvCensorCode:
    """
    Table containing terms used in the CensorCode controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_censor_code_from_json_dict(json_obj: dict):
        """
        Create a CvCensorCode from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvCensorCode(**json_obj)


@beartype.beartype
def write_cv_censor_code_obj(con: db.Connection, obj: CvCensorCode) -> str:
    """
    Write a CvCensorCode object to the database
    @param con: database connection
    @param obj: CvCensorCode object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_censor_code', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_censor_code(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_censor_code table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_censor_code', data)

@beartype.beartype
def write_cv_censor_code_many(con: db.Connection, objs: List[CvCensorCode], upsert: bool = False) -> int:
    """
    Write a list of CvCensorCode objects to the database
    @param con: database connection
    @param objs: list of CvCensorCode objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_censor_code', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_censor_code(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_censor_code table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_censor_code', data)

@beartype.beartype
def read_cv_censor_code(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvCensorCode, None, None]:
    """
    Read from the cv_censor_code table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvCensorCode objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_censor_code', data)
    for row in result:
        yield CvCensorCode(**row.as_dict())

@beartype.beartype
def read_cv_censor_code_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvCensorCode, None, None]:
    """
    Read from the cv_censor_code table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvCensorCode objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_censor_code', data)
    for row in result:
        yield CvCensorCode(**row.as_dict())

@beartype.beartype
def read_cv_censor_code_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvCensorCode, None, None]:
    """
    Read from the cv_censor_code table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvCensorCode objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_censor_code', data)
    for row in result:
        yield CvCensorCode(**row.as_dict())

@beartype.beartype
def read_cv_censor_code_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvCensorCode]:
    """
    Read from the cv_censor_code table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_censor_code', data)
    if result is None:
        return None
    return CvCensorCode(**result)

@beartype.beartype
def read_cv_censor_code_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvCensorCode:
    """
    Read from the cv_censor_code table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_censor_code', data)
    return CvCensorCode(**result)

@beartype.beartype
def read_cv_censor_code_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvCensorCode]:
    """
    Read from the cv_censor_code table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_censor_code', data)
    return [CvCensorCode(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_censor_code_by_id(con: db.Connection, term: str) -> Optional[CvCensorCode]:
    result = db.query_one(con, 'cv_censor_code', {'term': term})
    if result is None:
        return None
    return CvCensorCode(**result)

@beartype.beartype
def delete_cv_censor_code_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_censor_code', {'term': term})
# Associate the functions with the class
CvCensorCode.create_from_json_dict = create_cv_censor_code_from_json_dict
CvCensorCode.write = write_cv_censor_code
CvCensorCode.update = update_cv_censor_code
CvCensorCode.write_many = write_cv_censor_code_many
CvCensorCode.read = read_cv_censor_code
CvCensorCode.read_fuzzy = read_cv_censor_code_fuzzy
CvCensorCode.read_any = read_cv_censor_code_any
CvCensorCode.read_one = read_cv_censor_code_one
CvCensorCode.read_one_or_none = read_cv_censor_code_one_or_none
CvCensorCode.read_all = read_cv_censor_code_all
CvCensorCode.delete = delete_cv_censor_code_by_id
CvCensorCode.read_by_id = read_cv_censor_code_by_id
CvCensorCode.delete_by_id = delete_cv_censor_code_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvAnnotationSource:
    """
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_annotation_source_from_json_dict(json_obj: dict):
        """
        Create a CvAnnotationSource from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvAnnotationSource(**json_obj)


@beartype.beartype
def write_cv_annotation_source_obj(con: db.Connection, obj: CvAnnotationSource) -> str:
    """
    Write a CvAnnotationSource object to the database
    @param con: database connection
    @param obj: CvAnnotationSource object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_annotation_source', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_annotation_source(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_annotation_source table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_annotation_source', data)

@beartype.beartype
def write_cv_annotation_source_many(con: db.Connection, objs: List[CvAnnotationSource], upsert: bool = False) -> int:
    """
    Write a list of CvAnnotationSource objects to the database
    @param con: database connection
    @param objs: list of CvAnnotationSource objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_annotation_source', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_annotation_source(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_annotation_source table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_annotation_source', data)

@beartype.beartype
def read_cv_annotation_source(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvAnnotationSource, None, None]:
    """
    Read from the cv_annotation_source table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAnnotationSource objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_annotation_source', data)
    for row in result:
        yield CvAnnotationSource(**row.as_dict())

@beartype.beartype
def read_cv_annotation_source_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvAnnotationSource, None, None]:
    """
    Read from the cv_annotation_source table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAnnotationSource objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_annotation_source', data)
    for row in result:
        yield CvAnnotationSource(**row.as_dict())

@beartype.beartype
def read_cv_annotation_source_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvAnnotationSource, None, None]:
    """
    Read from the cv_annotation_source table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAnnotationSource objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_annotation_source', data)
    for row in result:
        yield CvAnnotationSource(**row.as_dict())

@beartype.beartype
def read_cv_annotation_source_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvAnnotationSource]:
    """
    Read from the cv_annotation_source table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_annotation_source', data)
    if result is None:
        return None
    return CvAnnotationSource(**result)

@beartype.beartype
def read_cv_annotation_source_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvAnnotationSource:
    """
    Read from the cv_annotation_source table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_annotation_source', data)
    return CvAnnotationSource(**result)

@beartype.beartype
def read_cv_annotation_source_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvAnnotationSource]:
    """
    Read from the cv_annotation_source table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_annotation_source', data)
    return [CvAnnotationSource(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_annotation_source_by_id(con: db.Connection, term: str) -> Optional[CvAnnotationSource]:
    result = db.query_one(con, 'cv_annotation_source', {'term': term})
    if result is None:
        return None
    return CvAnnotationSource(**result)

@beartype.beartype
def delete_cv_annotation_source_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_annotation_source', {'term': term})
# Associate the functions with the class
CvAnnotationSource.create_from_json_dict = create_cv_annotation_source_from_json_dict
CvAnnotationSource.write = write_cv_annotation_source
CvAnnotationSource.update = update_cv_annotation_source
CvAnnotationSource.write_many = write_cv_annotation_source_many
CvAnnotationSource.read = read_cv_annotation_source
CvAnnotationSource.read_fuzzy = read_cv_annotation_source_fuzzy
CvAnnotationSource.read_any = read_cv_annotation_source_any
CvAnnotationSource.read_one = read_cv_annotation_source_one
CvAnnotationSource.read_one_or_none = read_cv_annotation_source_one_or_none
CvAnnotationSource.read_all = read_cv_annotation_source_all
CvAnnotationSource.delete = delete_cv_annotation_source_by_id
CvAnnotationSource.read_by_id = read_cv_annotation_source_by_id
CvAnnotationSource.delete_by_id = delete_cv_annotation_source_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvActionType:
    """
    Table containing terms used in the ActionType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param produces_result 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    produces_result: Optional[bool] = None # produces_result boolean (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_action_type_from_json_dict(json_obj: dict):
        """
        Create a CvActionType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvActionType(**json_obj)


@beartype.beartype
def write_cv_action_type_obj(con: db.Connection, obj: CvActionType) -> str:
    """
    Write a CvActionType object to the database
    @param con: database connection
    @param obj: CvActionType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_action_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_action_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            produces_result: Optional[bool] = None) -> str:
    """
    Write to the cv_action_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param produces_result 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    return db.upsert(con, 'cv_action_type', data)

@beartype.beartype
def write_cv_action_type_many(con: db.Connection, objs: List[CvActionType], upsert: bool = False) -> int:
    """
    Write a list of CvActionType objects to the database
    @param con: database connection
    @param objs: list of CvActionType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_action_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_action_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            produces_result: Optional[bool] = None) -> int:
    """
    Update a row in the cv_action_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param produces_result 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    return db.update(con, 'cv_action_type', data)

@beartype.beartype
def read_cv_action_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             produces_result: Optional[bool] = None) -> Generator[CvActionType, None, None]:
    """
    Read from the cv_action_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param produces_result 
    @return generator of CvActionType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    result = db.query(con, 'cv_action_type', data)
    for row in result:
        yield CvActionType(**row.as_dict())

@beartype.beartype
def read_cv_action_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             produces_result: Optional[bool] = None) -> Generator[CvActionType, None, None]:
    """
    Read from the cv_action_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param produces_result 
    @return generator of CvActionType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    result = db.query_fuzzy(con, 'cv_action_type', data)
    for row in result:
        yield CvActionType(**row.as_dict())

@beartype.beartype
def read_cv_action_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None,
             produces_result: Optional[List[bool]] = None) -> Generator[CvActionType, None, None]:
    """
    Read from the cv_action_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param produces_result 
    @return generator of CvActionType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    result = db.query_any(con, 'cv_action_type', data)
    for row in result:
        yield CvActionType(**row.as_dict())

@beartype.beartype
def read_cv_action_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             produces_result: Optional[bool] = None) -> Optional[CvActionType]:
    """
    Read from the cv_action_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    result = db.query_one_or_none(con, 'cv_action_type', data)
    if result is None:
        return None
    return CvActionType(**result)

@beartype.beartype
def read_cv_action_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             produces_result: Optional[bool] = None) -> CvActionType:
    """
    Read from the cv_action_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    result = db.query_one(con, 'cv_action_type', data)
    return CvActionType(**result)

@beartype.beartype
def read_cv_action_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             produces_result: Optional[bool] = None) -> List[CvActionType]:
    """
    Read from the cv_action_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'produces_result': produces_result,
    }
    result = db.query(con, 'cv_action_type', data)
    return [CvActionType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_action_type_by_id(con: db.Connection, term: str) -> Optional[CvActionType]:
    result = db.query_one(con, 'cv_action_type', {'term': term})
    if result is None:
        return None
    return CvActionType(**result)

@beartype.beartype
def delete_cv_action_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_action_type', {'term': term})
# Associate the functions with the class
CvActionType.create_from_json_dict = create_cv_action_type_from_json_dict
CvActionType.write = write_cv_action_type
CvActionType.update = update_cv_action_type
CvActionType.write_many = write_cv_action_type_many
CvActionType.read = read_cv_action_type
CvActionType.read_fuzzy = read_cv_action_type_fuzzy
CvActionType.read_any = read_cv_action_type_any
CvActionType.read_one = read_cv_action_type_one
CvActionType.read_one_or_none = read_cv_action_type_one_or_none
CvActionType.read_all = read_cv_action_type_all
CvActionType.delete = delete_cv_action_type_by_id
CvActionType.read_by_id = read_cv_action_type_by_id
CvActionType.delete_by_id = delete_cv_action_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDatastreamAccessLevel:
    """
    Table containing terms used in the VariableDomain controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_datastream_access_level_from_json_dict(json_obj: dict):
        """
        Create a CvDatastreamAccessLevel from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDatastreamAccessLevel(**json_obj)


@beartype.beartype
def write_cv_datastream_access_level_obj(con: db.Connection, obj: CvDatastreamAccessLevel) -> str:
    """
    Write a CvDatastreamAccessLevel object to the database
    @param con: database connection
    @param obj: CvDatastreamAccessLevel object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_datastream_access_level', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_datastream_access_level(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_datastream_access_level table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_datastream_access_level', data)

@beartype.beartype
def write_cv_datastream_access_level_many(con: db.Connection, objs: List[CvDatastreamAccessLevel], upsert: bool = False) -> int:
    """
    Write a list of CvDatastreamAccessLevel objects to the database
    @param con: database connection
    @param objs: list of CvDatastreamAccessLevel objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_datastream_access_level', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_datastream_access_level(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_datastream_access_level table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_datastream_access_level', data)

@beartype.beartype
def read_cv_datastream_access_level(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamAccessLevel, None, None]:
    """
    Read from the cv_datastream_access_level table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamAccessLevel objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_access_level', data)
    for row in result:
        yield CvDatastreamAccessLevel(**row.as_dict())

@beartype.beartype
def read_cv_datastream_access_level_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamAccessLevel, None, None]:
    """
    Read from the cv_datastream_access_level table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamAccessLevel objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_datastream_access_level', data)
    for row in result:
        yield CvDatastreamAccessLevel(**row.as_dict())

@beartype.beartype
def read_cv_datastream_access_level_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDatastreamAccessLevel, None, None]:
    """
    Read from the cv_datastream_access_level table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamAccessLevel objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_datastream_access_level', data)
    for row in result:
        yield CvDatastreamAccessLevel(**row.as_dict())

@beartype.beartype
def read_cv_datastream_access_level_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDatastreamAccessLevel]:
    """
    Read from the cv_datastream_access_level table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_datastream_access_level', data)
    if result is None:
        return None
    return CvDatastreamAccessLevel(**result)

@beartype.beartype
def read_cv_datastream_access_level_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDatastreamAccessLevel:
    """
    Read from the cv_datastream_access_level table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_datastream_access_level', data)
    return CvDatastreamAccessLevel(**result)

@beartype.beartype
def read_cv_datastream_access_level_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDatastreamAccessLevel]:
    """
    Read from the cv_datastream_access_level table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_access_level', data)
    return [CvDatastreamAccessLevel(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_datastream_access_level_by_id(con: db.Connection, term: str) -> Optional[CvDatastreamAccessLevel]:
    result = db.query_one(con, 'cv_datastream_access_level', {'term': term})
    if result is None:
        return None
    return CvDatastreamAccessLevel(**result)

@beartype.beartype
def delete_cv_datastream_access_level_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_datastream_access_level', {'term': term})
# Associate the functions with the class
CvDatastreamAccessLevel.create_from_json_dict = create_cv_datastream_access_level_from_json_dict
CvDatastreamAccessLevel.write = write_cv_datastream_access_level
CvDatastreamAccessLevel.update = update_cv_datastream_access_level
CvDatastreamAccessLevel.write_many = write_cv_datastream_access_level_many
CvDatastreamAccessLevel.read = read_cv_datastream_access_level
CvDatastreamAccessLevel.read_fuzzy = read_cv_datastream_access_level_fuzzy
CvDatastreamAccessLevel.read_any = read_cv_datastream_access_level_any
CvDatastreamAccessLevel.read_one = read_cv_datastream_access_level_one
CvDatastreamAccessLevel.read_one_or_none = read_cv_datastream_access_level_one_or_none
CvDatastreamAccessLevel.read_all = read_cv_datastream_access_level_all
CvDatastreamAccessLevel.delete = delete_cv_datastream_access_level_by_id
CvDatastreamAccessLevel.read_by_id = read_cv_datastream_access_level_by_id
CvDatastreamAccessLevel.delete_by_id = delete_cv_datastream_access_level_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvAggregationStatistic:
    """
    Table containing terms used in the AggregationStatistic controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_aggregation_statistic_from_json_dict(json_obj: dict):
        """
        Create a CvAggregationStatistic from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvAggregationStatistic(**json_obj)


@beartype.beartype
def write_cv_aggregation_statistic_obj(con: db.Connection, obj: CvAggregationStatistic) -> str:
    """
    Write a CvAggregationStatistic object to the database
    @param con: database connection
    @param obj: CvAggregationStatistic object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_aggregation_statistic', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_aggregation_statistic(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_aggregation_statistic table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_aggregation_statistic', data)

@beartype.beartype
def write_cv_aggregation_statistic_many(con: db.Connection, objs: List[CvAggregationStatistic], upsert: bool = False) -> int:
    """
    Write a list of CvAggregationStatistic objects to the database
    @param con: database connection
    @param objs: list of CvAggregationStatistic objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_aggregation_statistic', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_aggregation_statistic(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_aggregation_statistic table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_aggregation_statistic', data)

@beartype.beartype
def read_cv_aggregation_statistic(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvAggregationStatistic, None, None]:
    """
    Read from the cv_aggregation_statistic table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAggregationStatistic objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_aggregation_statistic', data)
    for row in result:
        yield CvAggregationStatistic(**row.as_dict())

@beartype.beartype
def read_cv_aggregation_statistic_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvAggregationStatistic, None, None]:
    """
    Read from the cv_aggregation_statistic table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAggregationStatistic objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_aggregation_statistic', data)
    for row in result:
        yield CvAggregationStatistic(**row.as_dict())

@beartype.beartype
def read_cv_aggregation_statistic_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvAggregationStatistic, None, None]:
    """
    Read from the cv_aggregation_statistic table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAggregationStatistic objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_aggregation_statistic', data)
    for row in result:
        yield CvAggregationStatistic(**row.as_dict())

@beartype.beartype
def read_cv_aggregation_statistic_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvAggregationStatistic]:
    """
    Read from the cv_aggregation_statistic table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_aggregation_statistic', data)
    if result is None:
        return None
    return CvAggregationStatistic(**result)

@beartype.beartype
def read_cv_aggregation_statistic_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvAggregationStatistic:
    """
    Read from the cv_aggregation_statistic table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_aggregation_statistic', data)
    return CvAggregationStatistic(**result)

@beartype.beartype
def read_cv_aggregation_statistic_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvAggregationStatistic]:
    """
    Read from the cv_aggregation_statistic table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_aggregation_statistic', data)
    return [CvAggregationStatistic(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_aggregation_statistic_by_id(con: db.Connection, term: str) -> Optional[CvAggregationStatistic]:
    result = db.query_one(con, 'cv_aggregation_statistic', {'term': term})
    if result is None:
        return None
    return CvAggregationStatistic(**result)

@beartype.beartype
def delete_cv_aggregation_statistic_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_aggregation_statistic', {'term': term})
# Associate the functions with the class
CvAggregationStatistic.create_from_json_dict = create_cv_aggregation_statistic_from_json_dict
CvAggregationStatistic.write = write_cv_aggregation_statistic
CvAggregationStatistic.update = update_cv_aggregation_statistic
CvAggregationStatistic.write_many = write_cv_aggregation_statistic_many
CvAggregationStatistic.read = read_cv_aggregation_statistic
CvAggregationStatistic.read_fuzzy = read_cv_aggregation_statistic_fuzzy
CvAggregationStatistic.read_any = read_cv_aggregation_statistic_any
CvAggregationStatistic.read_one = read_cv_aggregation_statistic_one
CvAggregationStatistic.read_one_or_none = read_cv_aggregation_statistic_one_or_none
CvAggregationStatistic.read_all = read_cv_aggregation_statistic_all
CvAggregationStatistic.delete = delete_cv_aggregation_statistic_by_id
CvAggregationStatistic.read_by_id = read_cv_aggregation_statistic_by_id
CvAggregationStatistic.delete_by_id = delete_cv_aggregation_statistic_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDataQualityType:
    """
    Table containing terms used in the DataQualityType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_data_quality_type_from_json_dict(json_obj: dict):
        """
        Create a CvDataQualityType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDataQualityType(**json_obj)


@beartype.beartype
def write_cv_data_quality_type_obj(con: db.Connection, obj: CvDataQualityType) -> str:
    """
    Write a CvDataQualityType object to the database
    @param con: database connection
    @param obj: CvDataQualityType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_data_quality_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_data_quality_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_data_quality_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_data_quality_type', data)

@beartype.beartype
def write_cv_data_quality_type_many(con: db.Connection, objs: List[CvDataQualityType], upsert: bool = False) -> int:
    """
    Write a list of CvDataQualityType objects to the database
    @param con: database connection
    @param objs: list of CvDataQualityType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_data_quality_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_data_quality_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_data_quality_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_data_quality_type', data)

@beartype.beartype
def read_cv_data_quality_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDataQualityType, None, None]:
    """
    Read from the cv_data_quality_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDataQualityType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_data_quality_type', data)
    for row in result:
        yield CvDataQualityType(**row.as_dict())

@beartype.beartype
def read_cv_data_quality_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDataQualityType, None, None]:
    """
    Read from the cv_data_quality_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDataQualityType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_data_quality_type', data)
    for row in result:
        yield CvDataQualityType(**row.as_dict())

@beartype.beartype
def read_cv_data_quality_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDataQualityType, None, None]:
    """
    Read from the cv_data_quality_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDataQualityType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_data_quality_type', data)
    for row in result:
        yield CvDataQualityType(**row.as_dict())

@beartype.beartype
def read_cv_data_quality_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDataQualityType]:
    """
    Read from the cv_data_quality_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_data_quality_type', data)
    if result is None:
        return None
    return CvDataQualityType(**result)

@beartype.beartype
def read_cv_data_quality_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDataQualityType:
    """
    Read from the cv_data_quality_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_data_quality_type', data)
    return CvDataQualityType(**result)

@beartype.beartype
def read_cv_data_quality_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDataQualityType]:
    """
    Read from the cv_data_quality_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_data_quality_type', data)
    return [CvDataQualityType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_data_quality_type_by_id(con: db.Connection, term: str) -> Optional[CvDataQualityType]:
    result = db.query_one(con, 'cv_data_quality_type', {'term': term})
    if result is None:
        return None
    return CvDataQualityType(**result)

@beartype.beartype
def delete_cv_data_quality_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_data_quality_type', {'term': term})
# Associate the functions with the class
CvDataQualityType.create_from_json_dict = create_cv_data_quality_type_from_json_dict
CvDataQualityType.write = write_cv_data_quality_type
CvDataQualityType.update = update_cv_data_quality_type
CvDataQualityType.write_many = write_cv_data_quality_type_many
CvDataQualityType.read = read_cv_data_quality_type
CvDataQualityType.read_fuzzy = read_cv_data_quality_type_fuzzy
CvDataQualityType.read_any = read_cv_data_quality_type_any
CvDataQualityType.read_one = read_cv_data_quality_type_one
CvDataQualityType.read_one_or_none = read_cv_data_quality_type_one_or_none
CvDataQualityType.read_all = read_cv_data_quality_type_all
CvDataQualityType.delete = delete_cv_data_quality_type_by_id
CvDataQualityType.read_by_id = read_cv_data_quality_type_by_id
CvDataQualityType.delete_by_id = delete_cv_data_quality_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDatastreamClassifier:
    """
    Table containing terms used in the VariableDomain controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_datastream_classifier_from_json_dict(json_obj: dict):
        """
        Create a CvDatastreamClassifier from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDatastreamClassifier(**json_obj)


@beartype.beartype
def write_cv_datastream_classifier_obj(con: db.Connection, obj: CvDatastreamClassifier) -> str:
    """
    Write a CvDatastreamClassifier object to the database
    @param con: database connection
    @param obj: CvDatastreamClassifier object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_datastream_classifier', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_datastream_classifier(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_datastream_classifier table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_datastream_classifier', data)

@beartype.beartype
def write_cv_datastream_classifier_many(con: db.Connection, objs: List[CvDatastreamClassifier], upsert: bool = False) -> int:
    """
    Write a list of CvDatastreamClassifier objects to the database
    @param con: database connection
    @param objs: list of CvDatastreamClassifier objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_datastream_classifier', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_datastream_classifier(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_datastream_classifier table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_datastream_classifier', data)

@beartype.beartype
def read_cv_datastream_classifier(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamClassifier, None, None]:
    """
    Read from the cv_datastream_classifier table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamClassifier objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_classifier', data)
    for row in result:
        yield CvDatastreamClassifier(**row.as_dict())

@beartype.beartype
def read_cv_datastream_classifier_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamClassifier, None, None]:
    """
    Read from the cv_datastream_classifier table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamClassifier objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_datastream_classifier', data)
    for row in result:
        yield CvDatastreamClassifier(**row.as_dict())

@beartype.beartype
def read_cv_datastream_classifier_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDatastreamClassifier, None, None]:
    """
    Read from the cv_datastream_classifier table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamClassifier objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_datastream_classifier', data)
    for row in result:
        yield CvDatastreamClassifier(**row.as_dict())

@beartype.beartype
def read_cv_datastream_classifier_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDatastreamClassifier]:
    """
    Read from the cv_datastream_classifier table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_datastream_classifier', data)
    if result is None:
        return None
    return CvDatastreamClassifier(**result)

@beartype.beartype
def read_cv_datastream_classifier_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDatastreamClassifier:
    """
    Read from the cv_datastream_classifier table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_datastream_classifier', data)
    return CvDatastreamClassifier(**result)

@beartype.beartype
def read_cv_datastream_classifier_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDatastreamClassifier]:
    """
    Read from the cv_datastream_classifier table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_classifier', data)
    return [CvDatastreamClassifier(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_datastream_classifier_by_id(con: db.Connection, term: str) -> Optional[CvDatastreamClassifier]:
    result = db.query_one(con, 'cv_datastream_classifier', {'term': term})
    if result is None:
        return None
    return CvDatastreamClassifier(**result)

@beartype.beartype
def delete_cv_datastream_classifier_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_datastream_classifier', {'term': term})
# Associate the functions with the class
CvDatastreamClassifier.create_from_json_dict = create_cv_datastream_classifier_from_json_dict
CvDatastreamClassifier.write = write_cv_datastream_classifier
CvDatastreamClassifier.update = update_cv_datastream_classifier
CvDatastreamClassifier.write_many = write_cv_datastream_classifier_many
CvDatastreamClassifier.read = read_cv_datastream_classifier
CvDatastreamClassifier.read_fuzzy = read_cv_datastream_classifier_fuzzy
CvDatastreamClassifier.read_any = read_cv_datastream_classifier_any
CvDatastreamClassifier.read_one = read_cv_datastream_classifier_one
CvDatastreamClassifier.read_one_or_none = read_cv_datastream_classifier_one_or_none
CvDatastreamClassifier.read_all = read_cv_datastream_classifier_all
CvDatastreamClassifier.delete = delete_cv_datastream_classifier_by_id
CvDatastreamClassifier.read_by_id = read_cv_datastream_classifier_by_id
CvDatastreamClassifier.delete_by_id = delete_cv_datastream_classifier_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDatastreamSourceCategory:
    """
    Table containing terms used in the VariableDomain controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_datastream_source_category_from_json_dict(json_obj: dict):
        """
        Create a CvDatastreamSourceCategory from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDatastreamSourceCategory(**json_obj)


@beartype.beartype
def write_cv_datastream_source_category_obj(con: db.Connection, obj: CvDatastreamSourceCategory) -> str:
    """
    Write a CvDatastreamSourceCategory object to the database
    @param con: database connection
    @param obj: CvDatastreamSourceCategory object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_datastream_source_category', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_datastream_source_category(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_datastream_source_category table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_datastream_source_category', data)

@beartype.beartype
def write_cv_datastream_source_category_many(con: db.Connection, objs: List[CvDatastreamSourceCategory], upsert: bool = False) -> int:
    """
    Write a list of CvDatastreamSourceCategory objects to the database
    @param con: database connection
    @param objs: list of CvDatastreamSourceCategory objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_datastream_source_category', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_datastream_source_category(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_datastream_source_category table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_datastream_source_category', data)

@beartype.beartype
def read_cv_datastream_source_category(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamSourceCategory, None, None]:
    """
    Read from the cv_datastream_source_category table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamSourceCategory objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_source_category', data)
    for row in result:
        yield CvDatastreamSourceCategory(**row.as_dict())

@beartype.beartype
def read_cv_datastream_source_category_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamSourceCategory, None, None]:
    """
    Read from the cv_datastream_source_category table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamSourceCategory objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_datastream_source_category', data)
    for row in result:
        yield CvDatastreamSourceCategory(**row.as_dict())

@beartype.beartype
def read_cv_datastream_source_category_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDatastreamSourceCategory, None, None]:
    """
    Read from the cv_datastream_source_category table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamSourceCategory objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_datastream_source_category', data)
    for row in result:
        yield CvDatastreamSourceCategory(**row.as_dict())

@beartype.beartype
def read_cv_datastream_source_category_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDatastreamSourceCategory]:
    """
    Read from the cv_datastream_source_category table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_datastream_source_category', data)
    if result is None:
        return None
    return CvDatastreamSourceCategory(**result)

@beartype.beartype
def read_cv_datastream_source_category_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDatastreamSourceCategory:
    """
    Read from the cv_datastream_source_category table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_datastream_source_category', data)
    return CvDatastreamSourceCategory(**result)

@beartype.beartype
def read_cv_datastream_source_category_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDatastreamSourceCategory]:
    """
    Read from the cv_datastream_source_category table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_source_category', data)
    return [CvDatastreamSourceCategory(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_datastream_source_category_by_id(con: db.Connection, term: str) -> Optional[CvDatastreamSourceCategory]:
    result = db.query_one(con, 'cv_datastream_source_category', {'term': term})
    if result is None:
        return None
    return CvDatastreamSourceCategory(**result)

@beartype.beartype
def delete_cv_datastream_source_category_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_datastream_source_category', {'term': term})
# Associate the functions with the class
CvDatastreamSourceCategory.create_from_json_dict = create_cv_datastream_source_category_from_json_dict
CvDatastreamSourceCategory.write = write_cv_datastream_source_category
CvDatastreamSourceCategory.update = update_cv_datastream_source_category
CvDatastreamSourceCategory.write_many = write_cv_datastream_source_category_many
CvDatastreamSourceCategory.read = read_cv_datastream_source_category
CvDatastreamSourceCategory.read_fuzzy = read_cv_datastream_source_category_fuzzy
CvDatastreamSourceCategory.read_any = read_cv_datastream_source_category_any
CvDatastreamSourceCategory.read_one = read_cv_datastream_source_category_one
CvDatastreamSourceCategory.read_one_or_none = read_cv_datastream_source_category_one_or_none
CvDatastreamSourceCategory.read_all = read_cv_datastream_source_category_all
CvDatastreamSourceCategory.delete = delete_cv_datastream_source_category_by_id
CvDatastreamSourceCategory.read_by_id = read_cv_datastream_source_category_by_id
CvDatastreamSourceCategory.delete_by_id = delete_cv_datastream_source_category_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDatastreamType:
    """
    Table containing terms used in the DatasetType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_datastream_type_from_json_dict(json_obj: dict):
        """
        Create a CvDatastreamType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDatastreamType(**json_obj)


@beartype.beartype
def write_cv_datastream_type_obj(con: db.Connection, obj: CvDatastreamType) -> str:
    """
    Write a CvDatastreamType object to the database
    @param con: database connection
    @param obj: CvDatastreamType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_datastream_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_datastream_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_datastream_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_datastream_type', data)

@beartype.beartype
def write_cv_datastream_type_many(con: db.Connection, objs: List[CvDatastreamType], upsert: bool = False) -> int:
    """
    Write a list of CvDatastreamType objects to the database
    @param con: database connection
    @param objs: list of CvDatastreamType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_datastream_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_datastream_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_datastream_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_datastream_type', data)

@beartype.beartype
def read_cv_datastream_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamType, None, None]:
    """
    Read from the cv_datastream_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_type', data)
    for row in result:
        yield CvDatastreamType(**row.as_dict())

@beartype.beartype
def read_cv_datastream_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatastreamType, None, None]:
    """
    Read from the cv_datastream_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_datastream_type', data)
    for row in result:
        yield CvDatastreamType(**row.as_dict())

@beartype.beartype
def read_cv_datastream_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDatastreamType, None, None]:
    """
    Read from the cv_datastream_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatastreamType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_datastream_type', data)
    for row in result:
        yield CvDatastreamType(**row.as_dict())

@beartype.beartype
def read_cv_datastream_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDatastreamType]:
    """
    Read from the cv_datastream_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_datastream_type', data)
    if result is None:
        return None
    return CvDatastreamType(**result)

@beartype.beartype
def read_cv_datastream_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDatastreamType:
    """
    Read from the cv_datastream_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_datastream_type', data)
    return CvDatastreamType(**result)

@beartype.beartype
def read_cv_datastream_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDatastreamType]:
    """
    Read from the cv_datastream_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_datastream_type', data)
    return [CvDatastreamType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_datastream_type_by_id(con: db.Connection, term: str) -> Optional[CvDatastreamType]:
    result = db.query_one(con, 'cv_datastream_type', {'term': term})
    if result is None:
        return None
    return CvDatastreamType(**result)

@beartype.beartype
def delete_cv_datastream_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_datastream_type', {'term': term})
# Associate the functions with the class
CvDatastreamType.create_from_json_dict = create_cv_datastream_type_from_json_dict
CvDatastreamType.write = write_cv_datastream_type
CvDatastreamType.update = update_cv_datastream_type
CvDatastreamType.write_many = write_cv_datastream_type_many
CvDatastreamType.read = read_cv_datastream_type
CvDatastreamType.read_fuzzy = read_cv_datastream_type_fuzzy
CvDatastreamType.read_any = read_cv_datastream_type_any
CvDatastreamType.read_one = read_cv_datastream_type_one
CvDatastreamType.read_one_or_none = read_cv_datastream_type_one_or_none
CvDatastreamType.read_all = read_cv_datastream_type_all
CvDatastreamType.delete = delete_cv_datastream_type_by_id
CvDatastreamType.read_by_id = read_cv_datastream_type_by_id
CvDatastreamType.delete_by_id = delete_cv_datastream_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvAnnotationType:
    """
    Table containing terms used in the AnnotationType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_annotation_type_from_json_dict(json_obj: dict):
        """
        Create a CvAnnotationType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvAnnotationType(**json_obj)


@beartype.beartype
def write_cv_annotation_type_obj(con: db.Connection, obj: CvAnnotationType) -> str:
    """
    Write a CvAnnotationType object to the database
    @param con: database connection
    @param obj: CvAnnotationType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_annotation_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_annotation_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_annotation_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_annotation_type', data)

@beartype.beartype
def write_cv_annotation_type_many(con: db.Connection, objs: List[CvAnnotationType], upsert: bool = False) -> int:
    """
    Write a list of CvAnnotationType objects to the database
    @param con: database connection
    @param objs: list of CvAnnotationType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_annotation_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_annotation_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_annotation_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_annotation_type', data)

@beartype.beartype
def read_cv_annotation_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvAnnotationType, None, None]:
    """
    Read from the cv_annotation_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAnnotationType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_annotation_type', data)
    for row in result:
        yield CvAnnotationType(**row.as_dict())

@beartype.beartype
def read_cv_annotation_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvAnnotationType, None, None]:
    """
    Read from the cv_annotation_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAnnotationType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_annotation_type', data)
    for row in result:
        yield CvAnnotationType(**row.as_dict())

@beartype.beartype
def read_cv_annotation_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvAnnotationType, None, None]:
    """
    Read from the cv_annotation_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvAnnotationType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_annotation_type', data)
    for row in result:
        yield CvAnnotationType(**row.as_dict())

@beartype.beartype
def read_cv_annotation_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvAnnotationType]:
    """
    Read from the cv_annotation_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_annotation_type', data)
    if result is None:
        return None
    return CvAnnotationType(**result)

@beartype.beartype
def read_cv_annotation_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvAnnotationType:
    """
    Read from the cv_annotation_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_annotation_type', data)
    return CvAnnotationType(**result)

@beartype.beartype
def read_cv_annotation_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvAnnotationType]:
    """
    Read from the cv_annotation_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_annotation_type', data)
    return [CvAnnotationType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_annotation_type_by_id(con: db.Connection, term: str) -> Optional[CvAnnotationType]:
    result = db.query_one(con, 'cv_annotation_type', {'term': term})
    if result is None:
        return None
    return CvAnnotationType(**result)

@beartype.beartype
def delete_cv_annotation_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_annotation_type', {'term': term})
# Associate the functions with the class
CvAnnotationType.create_from_json_dict = create_cv_annotation_type_from_json_dict
CvAnnotationType.write = write_cv_annotation_type
CvAnnotationType.update = update_cv_annotation_type
CvAnnotationType.write_many = write_cv_annotation_type_many
CvAnnotationType.read = read_cv_annotation_type
CvAnnotationType.read_fuzzy = read_cv_annotation_type_fuzzy
CvAnnotationType.read_any = read_cv_annotation_type_any
CvAnnotationType.read_one = read_cv_annotation_type_one
CvAnnotationType.read_one_or_none = read_cv_annotation_type_one_or_none
CvAnnotationType.read_all = read_cv_annotation_type_all
CvAnnotationType.delete = delete_cv_annotation_type_by_id
CvAnnotationType.read_by_id = read_cv_annotation_type_by_id
CvAnnotationType.delete_by_id = delete_cv_annotation_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDatasetType:
    """
    Table containing terms used in the DatasetType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_dataset_type_from_json_dict(json_obj: dict):
        """
        Create a CvDatasetType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDatasetType(**json_obj)


@beartype.beartype
def write_cv_dataset_type_obj(con: db.Connection, obj: CvDatasetType) -> str:
    """
    Write a CvDatasetType object to the database
    @param con: database connection
    @param obj: CvDatasetType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_dataset_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_dataset_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_dataset_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_dataset_type', data)

@beartype.beartype
def write_cv_dataset_type_many(con: db.Connection, objs: List[CvDatasetType], upsert: bool = False) -> int:
    """
    Write a list of CvDatasetType objects to the database
    @param con: database connection
    @param objs: list of CvDatasetType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_dataset_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_dataset_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_dataset_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_dataset_type', data)

@beartype.beartype
def read_cv_dataset_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatasetType, None, None]:
    """
    Read from the cv_dataset_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatasetType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_dataset_type', data)
    for row in result:
        yield CvDatasetType(**row.as_dict())

@beartype.beartype
def read_cv_dataset_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDatasetType, None, None]:
    """
    Read from the cv_dataset_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatasetType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_dataset_type', data)
    for row in result:
        yield CvDatasetType(**row.as_dict())

@beartype.beartype
def read_cv_dataset_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDatasetType, None, None]:
    """
    Read from the cv_dataset_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDatasetType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_dataset_type', data)
    for row in result:
        yield CvDatasetType(**row.as_dict())

@beartype.beartype
def read_cv_dataset_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDatasetType]:
    """
    Read from the cv_dataset_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_dataset_type', data)
    if result is None:
        return None
    return CvDatasetType(**result)

@beartype.beartype
def read_cv_dataset_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDatasetType:
    """
    Read from the cv_dataset_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_dataset_type', data)
    return CvDatasetType(**result)

@beartype.beartype
def read_cv_dataset_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDatasetType]:
    """
    Read from the cv_dataset_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_dataset_type', data)
    return [CvDatasetType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_dataset_type_by_id(con: db.Connection, term: str) -> Optional[CvDatasetType]:
    result = db.query_one(con, 'cv_dataset_type', {'term': term})
    if result is None:
        return None
    return CvDatasetType(**result)

@beartype.beartype
def delete_cv_dataset_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_dataset_type', {'term': term})
# Associate the functions with the class
CvDatasetType.create_from_json_dict = create_cv_dataset_type_from_json_dict
CvDatasetType.write = write_cv_dataset_type
CvDatasetType.update = update_cv_dataset_type
CvDatasetType.write_many = write_cv_dataset_type_many
CvDatasetType.read = read_cv_dataset_type
CvDatasetType.read_fuzzy = read_cv_dataset_type_fuzzy
CvDatasetType.read_any = read_cv_dataset_type_any
CvDatasetType.read_one = read_cv_dataset_type_one
CvDatasetType.read_one_or_none = read_cv_dataset_type_one_or_none
CvDatasetType.read_all = read_cv_dataset_type_all
CvDatasetType.delete = delete_cv_dataset_type_by_id
CvDatasetType.read_by_id = read_cv_dataset_type_by_id
CvDatasetType.delete_by_id = delete_cv_dataset_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvMedium:
    """
    Table containing terms used in the Medium controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_medium_from_json_dict(json_obj: dict):
        """
        Create a CvMedium from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvMedium(**json_obj)


@beartype.beartype
def write_cv_medium_obj(con: db.Connection, obj: CvMedium) -> str:
    """
    Write a CvMedium object to the database
    @param con: database connection
    @param obj: CvMedium object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_medium', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_medium(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_medium table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_medium', data)

@beartype.beartype
def write_cv_medium_many(con: db.Connection, objs: List[CvMedium], upsert: bool = False) -> int:
    """
    Write a list of CvMedium objects to the database
    @param con: database connection
    @param objs: list of CvMedium objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_medium', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_medium(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_medium table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_medium', data)

@beartype.beartype
def read_cv_medium(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvMedium, None, None]:
    """
    Read from the cv_medium table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvMedium objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_medium', data)
    for row in result:
        yield CvMedium(**row.as_dict())

@beartype.beartype
def read_cv_medium_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvMedium, None, None]:
    """
    Read from the cv_medium table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvMedium objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_medium', data)
    for row in result:
        yield CvMedium(**row.as_dict())

@beartype.beartype
def read_cv_medium_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvMedium, None, None]:
    """
    Read from the cv_medium table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvMedium objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_medium', data)
    for row in result:
        yield CvMedium(**row.as_dict())

@beartype.beartype
def read_cv_medium_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvMedium]:
    """
    Read from the cv_medium table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_medium', data)
    if result is None:
        return None
    return CvMedium(**result)

@beartype.beartype
def read_cv_medium_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvMedium:
    """
    Read from the cv_medium table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_medium', data)
    return CvMedium(**result)

@beartype.beartype
def read_cv_medium_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvMedium]:
    """
    Read from the cv_medium table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_medium', data)
    return [CvMedium(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_medium_by_id(con: db.Connection, term: str) -> Optional[CvMedium]:
    result = db.query_one(con, 'cv_medium', {'term': term})
    if result is None:
        return None
    return CvMedium(**result)

@beartype.beartype
def delete_cv_medium_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_medium', {'term': term})
# Associate the functions with the class
CvMedium.create_from_json_dict = create_cv_medium_from_json_dict
CvMedium.write = write_cv_medium
CvMedium.update = update_cv_medium
CvMedium.write_many = write_cv_medium_many
CvMedium.read = read_cv_medium
CvMedium.read_fuzzy = read_cv_medium_fuzzy
CvMedium.read_any = read_cv_medium_any
CvMedium.read_one = read_cv_medium_one
CvMedium.read_one_or_none = read_cv_medium_one_or_none
CvMedium.read_all = read_cv_medium_all
CvMedium.delete = delete_cv_medium_by_id
CvMedium.read_by_id = read_cv_medium_by_id
CvMedium.delete_by_id = delete_cv_medium_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvPropertyDataType:
    """
    Table containing terms used in the PropertyDataType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_property_data_type_from_json_dict(json_obj: dict):
        """
        Create a CvPropertyDataType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvPropertyDataType(**json_obj)


@beartype.beartype
def write_cv_property_data_type_obj(con: db.Connection, obj: CvPropertyDataType) -> str:
    """
    Write a CvPropertyDataType object to the database
    @param con: database connection
    @param obj: CvPropertyDataType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_property_data_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_property_data_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_property_data_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_property_data_type', data)

@beartype.beartype
def write_cv_property_data_type_many(con: db.Connection, objs: List[CvPropertyDataType], upsert: bool = False) -> int:
    """
    Write a list of CvPropertyDataType objects to the database
    @param con: database connection
    @param objs: list of CvPropertyDataType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_property_data_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_property_data_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_property_data_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_property_data_type', data)

@beartype.beartype
def read_cv_property_data_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvPropertyDataType, None, None]:
    """
    Read from the cv_property_data_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvPropertyDataType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_property_data_type', data)
    for row in result:
        yield CvPropertyDataType(**row.as_dict())

@beartype.beartype
def read_cv_property_data_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvPropertyDataType, None, None]:
    """
    Read from the cv_property_data_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvPropertyDataType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_property_data_type', data)
    for row in result:
        yield CvPropertyDataType(**row.as_dict())

@beartype.beartype
def read_cv_property_data_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvPropertyDataType, None, None]:
    """
    Read from the cv_property_data_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvPropertyDataType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_property_data_type', data)
    for row in result:
        yield CvPropertyDataType(**row.as_dict())

@beartype.beartype
def read_cv_property_data_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvPropertyDataType]:
    """
    Read from the cv_property_data_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_property_data_type', data)
    if result is None:
        return None
    return CvPropertyDataType(**result)

@beartype.beartype
def read_cv_property_data_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvPropertyDataType:
    """
    Read from the cv_property_data_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_property_data_type', data)
    return CvPropertyDataType(**result)

@beartype.beartype
def read_cv_property_data_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvPropertyDataType]:
    """
    Read from the cv_property_data_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_property_data_type', data)
    return [CvPropertyDataType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_property_data_type_by_id(con: db.Connection, term: str) -> Optional[CvPropertyDataType]:
    result = db.query_one(con, 'cv_property_data_type', {'term': term})
    if result is None:
        return None
    return CvPropertyDataType(**result)

@beartype.beartype
def delete_cv_property_data_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_property_data_type', {'term': term})
# Associate the functions with the class
CvPropertyDataType.create_from_json_dict = create_cv_property_data_type_from_json_dict
CvPropertyDataType.write = write_cv_property_data_type
CvPropertyDataType.update = update_cv_property_data_type
CvPropertyDataType.write_many = write_cv_property_data_type_many
CvPropertyDataType.read = read_cv_property_data_type
CvPropertyDataType.read_fuzzy = read_cv_property_data_type_fuzzy
CvPropertyDataType.read_any = read_cv_property_data_type_any
CvPropertyDataType.read_one = read_cv_property_data_type_one
CvPropertyDataType.read_one_or_none = read_cv_property_data_type_one_or_none
CvPropertyDataType.read_all = read_cv_property_data_type_all
CvPropertyDataType.delete = delete_cv_property_data_type_by_id
CvPropertyDataType.read_by_id = read_cv_property_data_type_by_id
CvPropertyDataType.delete_by_id = delete_cv_property_data_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvPersonsRole:
    """
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_persons_role_from_json_dict(json_obj: dict):
        """
        Create a CvPersonsRole from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvPersonsRole(**json_obj)


@beartype.beartype
def write_cv_persons_role_obj(con: db.Connection, obj: CvPersonsRole) -> str:
    """
    Write a CvPersonsRole object to the database
    @param con: database connection
    @param obj: CvPersonsRole object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_persons_role', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_persons_role(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_persons_role table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_persons_role', data)

@beartype.beartype
def write_cv_persons_role_many(con: db.Connection, objs: List[CvPersonsRole], upsert: bool = False) -> int:
    """
    Write a list of CvPersonsRole objects to the database
    @param con: database connection
    @param objs: list of CvPersonsRole objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_persons_role', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_persons_role(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_persons_role table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_persons_role', data)

@beartype.beartype
def read_cv_persons_role(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvPersonsRole, None, None]:
    """
    Read from the cv_persons_role table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvPersonsRole objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_persons_role', data)
    for row in result:
        yield CvPersonsRole(**row.as_dict())

@beartype.beartype
def read_cv_persons_role_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvPersonsRole, None, None]:
    """
    Read from the cv_persons_role table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvPersonsRole objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_persons_role', data)
    for row in result:
        yield CvPersonsRole(**row.as_dict())

@beartype.beartype
def read_cv_persons_role_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvPersonsRole, None, None]:
    """
    Read from the cv_persons_role table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvPersonsRole objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_persons_role', data)
    for row in result:
        yield CvPersonsRole(**row.as_dict())

@beartype.beartype
def read_cv_persons_role_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvPersonsRole]:
    """
    Read from the cv_persons_role table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_persons_role', data)
    if result is None:
        return None
    return CvPersonsRole(**result)

@beartype.beartype
def read_cv_persons_role_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvPersonsRole:
    """
    Read from the cv_persons_role table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_persons_role', data)
    return CvPersonsRole(**result)

@beartype.beartype
def read_cv_persons_role_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvPersonsRole]:
    """
    Read from the cv_persons_role table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_persons_role', data)
    return [CvPersonsRole(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_persons_role_by_id(con: db.Connection, term: str) -> Optional[CvPersonsRole]:
    result = db.query_one(con, 'cv_persons_role', {'term': term})
    if result is None:
        return None
    return CvPersonsRole(**result)

@beartype.beartype
def delete_cv_persons_role_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_persons_role', {'term': term})
# Associate the functions with the class
CvPersonsRole.create_from_json_dict = create_cv_persons_role_from_json_dict
CvPersonsRole.write = write_cv_persons_role
CvPersonsRole.update = update_cv_persons_role
CvPersonsRole.write_many = write_cv_persons_role_many
CvPersonsRole.read = read_cv_persons_role
CvPersonsRole.read_fuzzy = read_cv_persons_role_fuzzy
CvPersonsRole.read_any = read_cv_persons_role_any
CvPersonsRole.read_one = read_cv_persons_role_one
CvPersonsRole.read_one_or_none = read_cv_persons_role_one_or_none
CvPersonsRole.read_all = read_cv_persons_role_all
CvPersonsRole.delete = delete_cv_persons_role_by_id
CvPersonsRole.read_by_id = read_cv_persons_role_by_id
CvPersonsRole.delete_by_id = delete_cv_persons_role_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvImageChannel:
    """
    Table containing terms used in the Image Channel controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_image_channel_from_json_dict(json_obj: dict):
        """
        Create a CvImageChannel from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvImageChannel(**json_obj)


@beartype.beartype
def write_cv_image_channel_obj(con: db.Connection, obj: CvImageChannel) -> str:
    """
    Write a CvImageChannel object to the database
    @param con: database connection
    @param obj: CvImageChannel object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_image_channel', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_image_channel(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_image_channel table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_image_channel', data)

@beartype.beartype
def write_cv_image_channel_many(con: db.Connection, objs: List[CvImageChannel], upsert: bool = False) -> int:
    """
    Write a list of CvImageChannel objects to the database
    @param con: database connection
    @param objs: list of CvImageChannel objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_image_channel', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_image_channel(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_image_channel table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_image_channel', data)

@beartype.beartype
def read_cv_image_channel(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvImageChannel, None, None]:
    """
    Read from the cv_image_channel table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvImageChannel objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_image_channel', data)
    for row in result:
        yield CvImageChannel(**row.as_dict())

@beartype.beartype
def read_cv_image_channel_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvImageChannel, None, None]:
    """
    Read from the cv_image_channel table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvImageChannel objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_image_channel', data)
    for row in result:
        yield CvImageChannel(**row.as_dict())

@beartype.beartype
def read_cv_image_channel_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvImageChannel, None, None]:
    """
    Read from the cv_image_channel table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvImageChannel objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_image_channel', data)
    for row in result:
        yield CvImageChannel(**row.as_dict())

@beartype.beartype
def read_cv_image_channel_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvImageChannel]:
    """
    Read from the cv_image_channel table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_image_channel', data)
    if result is None:
        return None
    return CvImageChannel(**result)

@beartype.beartype
def read_cv_image_channel_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvImageChannel:
    """
    Read from the cv_image_channel table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_image_channel', data)
    return CvImageChannel(**result)

@beartype.beartype
def read_cv_image_channel_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvImageChannel]:
    """
    Read from the cv_image_channel table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_image_channel', data)
    return [CvImageChannel(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_image_channel_by_id(con: db.Connection, term: str) -> Optional[CvImageChannel]:
    result = db.query_one(con, 'cv_image_channel', {'term': term})
    if result is None:
        return None
    return CvImageChannel(**result)

@beartype.beartype
def delete_cv_image_channel_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_image_channel', {'term': term})
# Associate the functions with the class
CvImageChannel.create_from_json_dict = create_cv_image_channel_from_json_dict
CvImageChannel.write = write_cv_image_channel
CvImageChannel.update = update_cv_image_channel
CvImageChannel.write_many = write_cv_image_channel_many
CvImageChannel.read = read_cv_image_channel
CvImageChannel.read_fuzzy = read_cv_image_channel_fuzzy
CvImageChannel.read_any = read_cv_image_channel_any
CvImageChannel.read_one = read_cv_image_channel_one
CvImageChannel.read_one_or_none = read_cv_image_channel_one_or_none
CvImageChannel.read_all = read_cv_image_channel_all
CvImageChannel.delete = delete_cv_image_channel_by_id
CvImageChannel.read_by_id = read_cv_image_channel_by_id
CvImageChannel.delete_by_id = delete_cv_image_channel_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvEquipmentType:
    """
    Table containing terms used in the EquipmentType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_equipment_type_from_json_dict(json_obj: dict):
        """
        Create a CvEquipmentType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvEquipmentType(**json_obj)


@beartype.beartype
def write_cv_equipment_type_obj(con: db.Connection, obj: CvEquipmentType) -> str:
    """
    Write a CvEquipmentType object to the database
    @param con: database connection
    @param obj: CvEquipmentType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_equipment_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_equipment_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_equipment_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_equipment_type', data)

@beartype.beartype
def write_cv_equipment_type_many(con: db.Connection, objs: List[CvEquipmentType], upsert: bool = False) -> int:
    """
    Write a list of CvEquipmentType objects to the database
    @param con: database connection
    @param objs: list of CvEquipmentType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_equipment_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_equipment_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_equipment_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_equipment_type', data)

@beartype.beartype
def read_cv_equipment_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvEquipmentType, None, None]:
    """
    Read from the cv_equipment_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvEquipmentType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_equipment_type', data)
    for row in result:
        yield CvEquipmentType(**row.as_dict())

@beartype.beartype
def read_cv_equipment_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvEquipmentType, None, None]:
    """
    Read from the cv_equipment_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvEquipmentType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_equipment_type', data)
    for row in result:
        yield CvEquipmentType(**row.as_dict())

@beartype.beartype
def read_cv_equipment_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvEquipmentType, None, None]:
    """
    Read from the cv_equipment_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvEquipmentType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_equipment_type', data)
    for row in result:
        yield CvEquipmentType(**row.as_dict())

@beartype.beartype
def read_cv_equipment_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvEquipmentType]:
    """
    Read from the cv_equipment_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_equipment_type', data)
    if result is None:
        return None
    return CvEquipmentType(**result)

@beartype.beartype
def read_cv_equipment_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvEquipmentType:
    """
    Read from the cv_equipment_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_equipment_type', data)
    return CvEquipmentType(**result)

@beartype.beartype
def read_cv_equipment_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvEquipmentType]:
    """
    Read from the cv_equipment_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_equipment_type', data)
    return [CvEquipmentType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_equipment_type_by_id(con: db.Connection, term: str) -> Optional[CvEquipmentType]:
    result = db.query_one(con, 'cv_equipment_type', {'term': term})
    if result is None:
        return None
    return CvEquipmentType(**result)

@beartype.beartype
def delete_cv_equipment_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_equipment_type', {'term': term})
# Associate the functions with the class
CvEquipmentType.create_from_json_dict = create_cv_equipment_type_from_json_dict
CvEquipmentType.write = write_cv_equipment_type
CvEquipmentType.update = update_cv_equipment_type
CvEquipmentType.write_many = write_cv_equipment_type_many
CvEquipmentType.read = read_cv_equipment_type
CvEquipmentType.read_fuzzy = read_cv_equipment_type_fuzzy
CvEquipmentType.read_any = read_cv_equipment_type_any
CvEquipmentType.read_one = read_cv_equipment_type_one
CvEquipmentType.read_one_or_none = read_cv_equipment_type_one_or_none
CvEquipmentType.read_all = read_cv_equipment_type_all
CvEquipmentType.delete = delete_cv_equipment_type_by_id
CvEquipmentType.read_by_id = read_cv_equipment_type_by_id
CvEquipmentType.delete_by_id = delete_cv_equipment_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvOrganizationType:
    """
    Table containing terms used in the OrganizationType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_organization_type_from_json_dict(json_obj: dict):
        """
        Create a CvOrganizationType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvOrganizationType(**json_obj)


@beartype.beartype
def write_cv_organization_type_obj(con: db.Connection, obj: CvOrganizationType) -> str:
    """
    Write a CvOrganizationType object to the database
    @param con: database connection
    @param obj: CvOrganizationType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_organization_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_organization_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_organization_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_organization_type', data)

@beartype.beartype
def write_cv_organization_type_many(con: db.Connection, objs: List[CvOrganizationType], upsert: bool = False) -> int:
    """
    Write a list of CvOrganizationType objects to the database
    @param con: database connection
    @param objs: list of CvOrganizationType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_organization_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_organization_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_organization_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_organization_type', data)

@beartype.beartype
def read_cv_organization_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvOrganizationType, None, None]:
    """
    Read from the cv_organization_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvOrganizationType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_organization_type', data)
    for row in result:
        yield CvOrganizationType(**row.as_dict())

@beartype.beartype
def read_cv_organization_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvOrganizationType, None, None]:
    """
    Read from the cv_organization_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvOrganizationType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_organization_type', data)
    for row in result:
        yield CvOrganizationType(**row.as_dict())

@beartype.beartype
def read_cv_organization_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvOrganizationType, None, None]:
    """
    Read from the cv_organization_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvOrganizationType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_organization_type', data)
    for row in result:
        yield CvOrganizationType(**row.as_dict())

@beartype.beartype
def read_cv_organization_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvOrganizationType]:
    """
    Read from the cv_organization_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_organization_type', data)
    if result is None:
        return None
    return CvOrganizationType(**result)

@beartype.beartype
def read_cv_organization_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvOrganizationType:
    """
    Read from the cv_organization_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_organization_type', data)
    return CvOrganizationType(**result)

@beartype.beartype
def read_cv_organization_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvOrganizationType]:
    """
    Read from the cv_organization_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_organization_type', data)
    return [CvOrganizationType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_organization_type_by_id(con: db.Connection, term: str) -> Optional[CvOrganizationType]:
    result = db.query_one(con, 'cv_organization_type', {'term': term})
    if result is None:
        return None
    return CvOrganizationType(**result)

@beartype.beartype
def delete_cv_organization_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_organization_type', {'term': term})
# Associate the functions with the class
CvOrganizationType.create_from_json_dict = create_cv_organization_type_from_json_dict
CvOrganizationType.write = write_cv_organization_type
CvOrganizationType.update = update_cv_organization_type
CvOrganizationType.write_many = write_cv_organization_type_many
CvOrganizationType.read = read_cv_organization_type
CvOrganizationType.read_fuzzy = read_cv_organization_type_fuzzy
CvOrganizationType.read_any = read_cv_organization_type_any
CvOrganizationType.read_one = read_cv_organization_type_one
CvOrganizationType.read_one_or_none = read_cv_organization_type_one_or_none
CvOrganizationType.read_all = read_cv_organization_type_all
CvOrganizationType.delete = delete_cv_organization_type_by_id
CvOrganizationType.read_by_id = read_cv_organization_type_by_id
CvOrganizationType.delete_by_id = delete_cv_organization_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvElevationDatum:
    """
    Table containing terms used in the ElevationDatum controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_elevation_datum_from_json_dict(json_obj: dict):
        """
        Create a CvElevationDatum from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvElevationDatum(**json_obj)


@beartype.beartype
def write_cv_elevation_datum_obj(con: db.Connection, obj: CvElevationDatum) -> str:
    """
    Write a CvElevationDatum object to the database
    @param con: database connection
    @param obj: CvElevationDatum object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_elevation_datum', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_elevation_datum(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_elevation_datum table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_elevation_datum', data)

@beartype.beartype
def write_cv_elevation_datum_many(con: db.Connection, objs: List[CvElevationDatum], upsert: bool = False) -> int:
    """
    Write a list of CvElevationDatum objects to the database
    @param con: database connection
    @param objs: list of CvElevationDatum objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_elevation_datum', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_elevation_datum(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_elevation_datum table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_elevation_datum', data)

@beartype.beartype
def read_cv_elevation_datum(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvElevationDatum, None, None]:
    """
    Read from the cv_elevation_datum table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvElevationDatum objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_elevation_datum', data)
    for row in result:
        yield CvElevationDatum(**row.as_dict())

@beartype.beartype
def read_cv_elevation_datum_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvElevationDatum, None, None]:
    """
    Read from the cv_elevation_datum table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvElevationDatum objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_elevation_datum', data)
    for row in result:
        yield CvElevationDatum(**row.as_dict())

@beartype.beartype
def read_cv_elevation_datum_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvElevationDatum, None, None]:
    """
    Read from the cv_elevation_datum table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvElevationDatum objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_elevation_datum', data)
    for row in result:
        yield CvElevationDatum(**row.as_dict())

@beartype.beartype
def read_cv_elevation_datum_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvElevationDatum]:
    """
    Read from the cv_elevation_datum table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_elevation_datum', data)
    if result is None:
        return None
    return CvElevationDatum(**result)

@beartype.beartype
def read_cv_elevation_datum_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvElevationDatum:
    """
    Read from the cv_elevation_datum table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_elevation_datum', data)
    return CvElevationDatum(**result)

@beartype.beartype
def read_cv_elevation_datum_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvElevationDatum]:
    """
    Read from the cv_elevation_datum table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_elevation_datum', data)
    return [CvElevationDatum(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_elevation_datum_by_id(con: db.Connection, term: str) -> Optional[CvElevationDatum]:
    result = db.query_one(con, 'cv_elevation_datum', {'term': term})
    if result is None:
        return None
    return CvElevationDatum(**result)

@beartype.beartype
def delete_cv_elevation_datum_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_elevation_datum', {'term': term})
# Associate the functions with the class
CvElevationDatum.create_from_json_dict = create_cv_elevation_datum_from_json_dict
CvElevationDatum.write = write_cv_elevation_datum
CvElevationDatum.update = update_cv_elevation_datum
CvElevationDatum.write_many = write_cv_elevation_datum_many
CvElevationDatum.read = read_cv_elevation_datum
CvElevationDatum.read_fuzzy = read_cv_elevation_datum_fuzzy
CvElevationDatum.read_any = read_cv_elevation_datum_any
CvElevationDatum.read_one = read_cv_elevation_datum_one
CvElevationDatum.read_one_or_none = read_cv_elevation_datum_one_or_none
CvElevationDatum.read_all = read_cv_elevation_datum_all
CvElevationDatum.delete = delete_cv_elevation_datum_by_id
CvElevationDatum.read_by_id = read_cv_elevation_datum_by_id
CvElevationDatum.delete_by_id = delete_cv_elevation_datum_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvEquipmentStatus:
    """
    Table containing terms used in the ElevationDatum controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_equipment_status_from_json_dict(json_obj: dict):
        """
        Create a CvEquipmentStatus from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvEquipmentStatus(**json_obj)


@beartype.beartype
def write_cv_equipment_status_obj(con: db.Connection, obj: CvEquipmentStatus) -> str:
    """
    Write a CvEquipmentStatus object to the database
    @param con: database connection
    @param obj: CvEquipmentStatus object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_equipment_status', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_equipment_status(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_equipment_status table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_equipment_status', data)

@beartype.beartype
def write_cv_equipment_status_many(con: db.Connection, objs: List[CvEquipmentStatus], upsert: bool = False) -> int:
    """
    Write a list of CvEquipmentStatus objects to the database
    @param con: database connection
    @param objs: list of CvEquipmentStatus objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_equipment_status', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_equipment_status(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_equipment_status table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_equipment_status', data)

@beartype.beartype
def read_cv_equipment_status(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvEquipmentStatus, None, None]:
    """
    Read from the cv_equipment_status table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvEquipmentStatus objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_equipment_status', data)
    for row in result:
        yield CvEquipmentStatus(**row.as_dict())

@beartype.beartype
def read_cv_equipment_status_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvEquipmentStatus, None, None]:
    """
    Read from the cv_equipment_status table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvEquipmentStatus objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_equipment_status', data)
    for row in result:
        yield CvEquipmentStatus(**row.as_dict())

@beartype.beartype
def read_cv_equipment_status_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvEquipmentStatus, None, None]:
    """
    Read from the cv_equipment_status table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvEquipmentStatus objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_equipment_status', data)
    for row in result:
        yield CvEquipmentStatus(**row.as_dict())

@beartype.beartype
def read_cv_equipment_status_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvEquipmentStatus]:
    """
    Read from the cv_equipment_status table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_equipment_status', data)
    if result is None:
        return None
    return CvEquipmentStatus(**result)

@beartype.beartype
def read_cv_equipment_status_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvEquipmentStatus:
    """
    Read from the cv_equipment_status table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_equipment_status', data)
    return CvEquipmentStatus(**result)

@beartype.beartype
def read_cv_equipment_status_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvEquipmentStatus]:
    """
    Read from the cv_equipment_status table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_equipment_status', data)
    return [CvEquipmentStatus(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_equipment_status_by_id(con: db.Connection, term: str) -> Optional[CvEquipmentStatus]:
    result = db.query_one(con, 'cv_equipment_status', {'term': term})
    if result is None:
        return None
    return CvEquipmentStatus(**result)

@beartype.beartype
def delete_cv_equipment_status_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_equipment_status', {'term': term})
# Associate the functions with the class
CvEquipmentStatus.create_from_json_dict = create_cv_equipment_status_from_json_dict
CvEquipmentStatus.write = write_cv_equipment_status
CvEquipmentStatus.update = update_cv_equipment_status
CvEquipmentStatus.write_many = write_cv_equipment_status_many
CvEquipmentStatus.read = read_cv_equipment_status
CvEquipmentStatus.read_fuzzy = read_cv_equipment_status_fuzzy
CvEquipmentStatus.read_any = read_cv_equipment_status_any
CvEquipmentStatus.read_one = read_cv_equipment_status_one
CvEquipmentStatus.read_one_or_none = read_cv_equipment_status_one_or_none
CvEquipmentStatus.read_all = read_cv_equipment_status_all
CvEquipmentStatus.delete = delete_cv_equipment_status_by_id
CvEquipmentStatus.read_by_id = read_cv_equipment_status_by_id
CvEquipmentStatus.delete_by_id = delete_cv_equipment_status_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvDirectiveType:
    """
    Table containing terms used in the DirectiveType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_directive_type_from_json_dict(json_obj: dict):
        """
        Create a CvDirectiveType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvDirectiveType(**json_obj)


@beartype.beartype
def write_cv_directive_type_obj(con: db.Connection, obj: CvDirectiveType) -> str:
    """
    Write a CvDirectiveType object to the database
    @param con: database connection
    @param obj: CvDirectiveType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_directive_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_directive_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_directive_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_directive_type', data)

@beartype.beartype
def write_cv_directive_type_many(con: db.Connection, objs: List[CvDirectiveType], upsert: bool = False) -> int:
    """
    Write a list of CvDirectiveType objects to the database
    @param con: database connection
    @param objs: list of CvDirectiveType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_directive_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_directive_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_directive_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_directive_type', data)

@beartype.beartype
def read_cv_directive_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDirectiveType, None, None]:
    """
    Read from the cv_directive_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDirectiveType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_directive_type', data)
    for row in result:
        yield CvDirectiveType(**row.as_dict())

@beartype.beartype
def read_cv_directive_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvDirectiveType, None, None]:
    """
    Read from the cv_directive_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDirectiveType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_directive_type', data)
    for row in result:
        yield CvDirectiveType(**row.as_dict())

@beartype.beartype
def read_cv_directive_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvDirectiveType, None, None]:
    """
    Read from the cv_directive_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvDirectiveType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_directive_type', data)
    for row in result:
        yield CvDirectiveType(**row.as_dict())

@beartype.beartype
def read_cv_directive_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvDirectiveType]:
    """
    Read from the cv_directive_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_directive_type', data)
    if result is None:
        return None
    return CvDirectiveType(**result)

@beartype.beartype
def read_cv_directive_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvDirectiveType:
    """
    Read from the cv_directive_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_directive_type', data)
    return CvDirectiveType(**result)

@beartype.beartype
def read_cv_directive_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvDirectiveType]:
    """
    Read from the cv_directive_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_directive_type', data)
    return [CvDirectiveType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_directive_type_by_id(con: db.Connection, term: str) -> Optional[CvDirectiveType]:
    result = db.query_one(con, 'cv_directive_type', {'term': term})
    if result is None:
        return None
    return CvDirectiveType(**result)

@beartype.beartype
def delete_cv_directive_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_directive_type', {'term': term})
# Associate the functions with the class
CvDirectiveType.create_from_json_dict = create_cv_directive_type_from_json_dict
CvDirectiveType.write = write_cv_directive_type
CvDirectiveType.update = update_cv_directive_type
CvDirectiveType.write_many = write_cv_directive_type_many
CvDirectiveType.read = read_cv_directive_type
CvDirectiveType.read_fuzzy = read_cv_directive_type_fuzzy
CvDirectiveType.read_any = read_cv_directive_type_any
CvDirectiveType.read_one = read_cv_directive_type_one
CvDirectiveType.read_one_or_none = read_cv_directive_type_one_or_none
CvDirectiveType.read_all = read_cv_directive_type_all
CvDirectiveType.delete = delete_cv_directive_type_by_id
CvDirectiveType.read_by_id = read_cv_directive_type_by_id
CvDirectiveType.delete_by_id = delete_cv_directive_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvMethodType:
    """
    Table containing terms used in the MethodType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_method_type_from_json_dict(json_obj: dict):
        """
        Create a CvMethodType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvMethodType(**json_obj)


@beartype.beartype
def write_cv_method_type_obj(con: db.Connection, obj: CvMethodType) -> str:
    """
    Write a CvMethodType object to the database
    @param con: database connection
    @param obj: CvMethodType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_method_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_method_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_method_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_method_type', data)

@beartype.beartype
def write_cv_method_type_many(con: db.Connection, objs: List[CvMethodType], upsert: bool = False) -> int:
    """
    Write a list of CvMethodType objects to the database
    @param con: database connection
    @param objs: list of CvMethodType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_method_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_method_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_method_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_method_type', data)

@beartype.beartype
def read_cv_method_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvMethodType, None, None]:
    """
    Read from the cv_method_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvMethodType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_method_type', data)
    for row in result:
        yield CvMethodType(**row.as_dict())

@beartype.beartype
def read_cv_method_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvMethodType, None, None]:
    """
    Read from the cv_method_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvMethodType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_method_type', data)
    for row in result:
        yield CvMethodType(**row.as_dict())

@beartype.beartype
def read_cv_method_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvMethodType, None, None]:
    """
    Read from the cv_method_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvMethodType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_method_type', data)
    for row in result:
        yield CvMethodType(**row.as_dict())

@beartype.beartype
def read_cv_method_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvMethodType]:
    """
    Read from the cv_method_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_method_type', data)
    if result is None:
        return None
    return CvMethodType(**result)

@beartype.beartype
def read_cv_method_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvMethodType:
    """
    Read from the cv_method_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_method_type', data)
    return CvMethodType(**result)

@beartype.beartype
def read_cv_method_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvMethodType]:
    """
    Read from the cv_method_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_method_type', data)
    return [CvMethodType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_method_type_by_id(con: db.Connection, term: str) -> Optional[CvMethodType]:
    result = db.query_one(con, 'cv_method_type', {'term': term})
    if result is None:
        return None
    return CvMethodType(**result)

@beartype.beartype
def delete_cv_method_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_method_type', {'term': term})
# Associate the functions with the class
CvMethodType.create_from_json_dict = create_cv_method_type_from_json_dict
CvMethodType.write = write_cv_method_type
CvMethodType.update = update_cv_method_type
CvMethodType.write_many = write_cv_method_type_many
CvMethodType.read = read_cv_method_type
CvMethodType.read_fuzzy = read_cv_method_type_fuzzy
CvMethodType.read_any = read_cv_method_type_any
CvMethodType.read_one = read_cv_method_type_one
CvMethodType.read_one_or_none = read_cv_method_type_one_or_none
CvMethodType.read_all = read_cv_method_type_all
CvMethodType.delete = delete_cv_method_type_by_id
CvMethodType.read_by_id = read_cv_method_type_by_id
CvMethodType.delete_by_id = delete_cv_method_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvFeaturesOfInterestType:
    """
    Table containing terms used in the FeatureOfInterestType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_features_of_interest_type_from_json_dict(json_obj: dict):
        """
        Create a CvFeaturesOfInterestType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvFeaturesOfInterestType(**json_obj)


@beartype.beartype
def write_cv_features_of_interest_type_obj(con: db.Connection, obj: CvFeaturesOfInterestType) -> str:
    """
    Write a CvFeaturesOfInterestType object to the database
    @param con: database connection
    @param obj: CvFeaturesOfInterestType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_features_of_interest_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_features_of_interest_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_features_of_interest_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_features_of_interest_type', data)

@beartype.beartype
def write_cv_features_of_interest_type_many(con: db.Connection, objs: List[CvFeaturesOfInterestType], upsert: bool = False) -> int:
    """
    Write a list of CvFeaturesOfInterestType objects to the database
    @param con: database connection
    @param objs: list of CvFeaturesOfInterestType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_features_of_interest_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_features_of_interest_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_features_of_interest_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_features_of_interest_type', data)

@beartype.beartype
def read_cv_features_of_interest_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvFeaturesOfInterestType, None, None]:
    """
    Read from the cv_features_of_interest_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvFeaturesOfInterestType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_features_of_interest_type', data)
    for row in result:
        yield CvFeaturesOfInterestType(**row.as_dict())

@beartype.beartype
def read_cv_features_of_interest_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvFeaturesOfInterestType, None, None]:
    """
    Read from the cv_features_of_interest_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvFeaturesOfInterestType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_features_of_interest_type', data)
    for row in result:
        yield CvFeaturesOfInterestType(**row.as_dict())

@beartype.beartype
def read_cv_features_of_interest_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvFeaturesOfInterestType, None, None]:
    """
    Read from the cv_features_of_interest_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvFeaturesOfInterestType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_features_of_interest_type', data)
    for row in result:
        yield CvFeaturesOfInterestType(**row.as_dict())

@beartype.beartype
def read_cv_features_of_interest_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvFeaturesOfInterestType]:
    """
    Read from the cv_features_of_interest_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_features_of_interest_type', data)
    if result is None:
        return None
    return CvFeaturesOfInterestType(**result)

@beartype.beartype
def read_cv_features_of_interest_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvFeaturesOfInterestType:
    """
    Read from the cv_features_of_interest_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_features_of_interest_type', data)
    return CvFeaturesOfInterestType(**result)

@beartype.beartype
def read_cv_features_of_interest_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvFeaturesOfInterestType]:
    """
    Read from the cv_features_of_interest_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_features_of_interest_type', data)
    return [CvFeaturesOfInterestType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_features_of_interest_type_by_id(con: db.Connection, term: str) -> Optional[CvFeaturesOfInterestType]:
    result = db.query_one(con, 'cv_features_of_interest_type', {'term': term})
    if result is None:
        return None
    return CvFeaturesOfInterestType(**result)

@beartype.beartype
def delete_cv_features_of_interest_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_features_of_interest_type', {'term': term})
# Associate the functions with the class
CvFeaturesOfInterestType.create_from_json_dict = create_cv_features_of_interest_type_from_json_dict
CvFeaturesOfInterestType.write = write_cv_features_of_interest_type
CvFeaturesOfInterestType.update = update_cv_features_of_interest_type
CvFeaturesOfInterestType.write_many = write_cv_features_of_interest_type_many
CvFeaturesOfInterestType.read = read_cv_features_of_interest_type
CvFeaturesOfInterestType.read_fuzzy = read_cv_features_of_interest_type_fuzzy
CvFeaturesOfInterestType.read_any = read_cv_features_of_interest_type_any
CvFeaturesOfInterestType.read_one = read_cv_features_of_interest_type_one
CvFeaturesOfInterestType.read_one_or_none = read_cv_features_of_interest_type_one_or_none
CvFeaturesOfInterestType.read_all = read_cv_features_of_interest_type_all
CvFeaturesOfInterestType.delete = delete_cv_features_of_interest_type_by_id
CvFeaturesOfInterestType.read_by_id = read_cv_features_of_interest_type_by_id
CvFeaturesOfInterestType.delete_by_id = delete_cv_features_of_interest_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvRelationshipType:
    """
    Table containing terms used in the RelationshipType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_relationship_type_from_json_dict(json_obj: dict):
        """
        Create a CvRelationshipType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvRelationshipType(**json_obj)


@beartype.beartype
def write_cv_relationship_type_obj(con: db.Connection, obj: CvRelationshipType) -> str:
    """
    Write a CvRelationshipType object to the database
    @param con: database connection
    @param obj: CvRelationshipType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_relationship_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_relationship_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_relationship_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_relationship_type', data)

@beartype.beartype
def write_cv_relationship_type_many(con: db.Connection, objs: List[CvRelationshipType], upsert: bool = False) -> int:
    """
    Write a list of CvRelationshipType objects to the database
    @param con: database connection
    @param objs: list of CvRelationshipType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_relationship_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_relationship_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_relationship_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_relationship_type', data)

@beartype.beartype
def read_cv_relationship_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvRelationshipType, None, None]:
    """
    Read from the cv_relationship_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvRelationshipType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_relationship_type', data)
    for row in result:
        yield CvRelationshipType(**row.as_dict())

@beartype.beartype
def read_cv_relationship_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvRelationshipType, None, None]:
    """
    Read from the cv_relationship_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvRelationshipType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_relationship_type', data)
    for row in result:
        yield CvRelationshipType(**row.as_dict())

@beartype.beartype
def read_cv_relationship_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvRelationshipType, None, None]:
    """
    Read from the cv_relationship_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvRelationshipType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_relationship_type', data)
    for row in result:
        yield CvRelationshipType(**row.as_dict())

@beartype.beartype
def read_cv_relationship_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvRelationshipType]:
    """
    Read from the cv_relationship_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_relationship_type', data)
    if result is None:
        return None
    return CvRelationshipType(**result)

@beartype.beartype
def read_cv_relationship_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvRelationshipType:
    """
    Read from the cv_relationship_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_relationship_type', data)
    return CvRelationshipType(**result)

@beartype.beartype
def read_cv_relationship_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvRelationshipType]:
    """
    Read from the cv_relationship_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_relationship_type', data)
    return [CvRelationshipType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_relationship_type_by_id(con: db.Connection, term: str) -> Optional[CvRelationshipType]:
    result = db.query_one(con, 'cv_relationship_type', {'term': term})
    if result is None:
        return None
    return CvRelationshipType(**result)

@beartype.beartype
def delete_cv_relationship_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_relationship_type', {'term': term})
# Associate the functions with the class
CvRelationshipType.create_from_json_dict = create_cv_relationship_type_from_json_dict
CvRelationshipType.write = write_cv_relationship_type
CvRelationshipType.update = update_cv_relationship_type
CvRelationshipType.write_many = write_cv_relationship_type_many
CvRelationshipType.read = read_cv_relationship_type
CvRelationshipType.read_fuzzy = read_cv_relationship_type_fuzzy
CvRelationshipType.read_any = read_cv_relationship_type_any
CvRelationshipType.read_one = read_cv_relationship_type_one
CvRelationshipType.read_one_or_none = read_cv_relationship_type_one_or_none
CvRelationshipType.read_all = read_cv_relationship_type_all
CvRelationshipType.delete = delete_cv_relationship_type_by_id
CvRelationshipType.read_by_id = read_cv_relationship_type_by_id
CvRelationshipType.delete_by_id = delete_cv_relationship_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvResultType:
    """
    Table containing terms used in the ResultType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_result_type_from_json_dict(json_obj: dict):
        """
        Create a CvResultType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvResultType(**json_obj)


@beartype.beartype
def write_cv_result_type_obj(con: db.Connection, obj: CvResultType) -> str:
    """
    Write a CvResultType object to the database
    @param con: database connection
    @param obj: CvResultType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_result_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_result_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_result_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_result_type', data)

@beartype.beartype
def write_cv_result_type_many(con: db.Connection, objs: List[CvResultType], upsert: bool = False) -> int:
    """
    Write a list of CvResultType objects to the database
    @param con: database connection
    @param objs: list of CvResultType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_result_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_result_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_result_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_result_type', data)

@beartype.beartype
def read_cv_result_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvResultType, None, None]:
    """
    Read from the cv_result_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvResultType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_result_type', data)
    for row in result:
        yield CvResultType(**row.as_dict())

@beartype.beartype
def read_cv_result_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvResultType, None, None]:
    """
    Read from the cv_result_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvResultType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_result_type', data)
    for row in result:
        yield CvResultType(**row.as_dict())

@beartype.beartype
def read_cv_result_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvResultType, None, None]:
    """
    Read from the cv_result_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvResultType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_result_type', data)
    for row in result:
        yield CvResultType(**row.as_dict())

@beartype.beartype
def read_cv_result_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvResultType]:
    """
    Read from the cv_result_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_result_type', data)
    if result is None:
        return None
    return CvResultType(**result)

@beartype.beartype
def read_cv_result_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvResultType:
    """
    Read from the cv_result_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_result_type', data)
    return CvResultType(**result)

@beartype.beartype
def read_cv_result_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvResultType]:
    """
    Read from the cv_result_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_result_type', data)
    return [CvResultType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_result_type_by_id(con: db.Connection, term: str) -> Optional[CvResultType]:
    result = db.query_one(con, 'cv_result_type', {'term': term})
    if result is None:
        return None
    return CvResultType(**result)

@beartype.beartype
def delete_cv_result_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_result_type', {'term': term})
# Associate the functions with the class
CvResultType.create_from_json_dict = create_cv_result_type_from_json_dict
CvResultType.write = write_cv_result_type
CvResultType.update = update_cv_result_type
CvResultType.write_many = write_cv_result_type_many
CvResultType.read = read_cv_result_type
CvResultType.read_fuzzy = read_cv_result_type_fuzzy
CvResultType.read_any = read_cv_result_type_any
CvResultType.read_one = read_cv_result_type_one
CvResultType.read_one_or_none = read_cv_result_type_one_or_none
CvResultType.read_all = read_cv_result_type_all
CvResultType.delete = delete_cv_result_type_by_id
CvResultType.read_by_id = read_cv_result_type_by_id
CvResultType.delete_by_id = delete_cv_result_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvStatus:
    """
    Table containing terms used in the Status controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_status_from_json_dict(json_obj: dict):
        """
        Create a CvStatus from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvStatus(**json_obj)


@beartype.beartype
def write_cv_status_obj(con: db.Connection, obj: CvStatus) -> str:
    """
    Write a CvStatus object to the database
    @param con: database connection
    @param obj: CvStatus object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_status', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_status(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_status table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_status', data)

@beartype.beartype
def write_cv_status_many(con: db.Connection, objs: List[CvStatus], upsert: bool = False) -> int:
    """
    Write a list of CvStatus objects to the database
    @param con: database connection
    @param objs: list of CvStatus objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_status', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_status(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_status table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_status', data)

@beartype.beartype
def read_cv_status(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvStatus, None, None]:
    """
    Read from the cv_status table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvStatus objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_status', data)
    for row in result:
        yield CvStatus(**row.as_dict())

@beartype.beartype
def read_cv_status_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvStatus, None, None]:
    """
    Read from the cv_status table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvStatus objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_status', data)
    for row in result:
        yield CvStatus(**row.as_dict())

@beartype.beartype
def read_cv_status_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvStatus, None, None]:
    """
    Read from the cv_status table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvStatus objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_status', data)
    for row in result:
        yield CvStatus(**row.as_dict())

@beartype.beartype
def read_cv_status_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvStatus]:
    """
    Read from the cv_status table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_status', data)
    if result is None:
        return None
    return CvStatus(**result)

@beartype.beartype
def read_cv_status_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvStatus:
    """
    Read from the cv_status table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_status', data)
    return CvStatus(**result)

@beartype.beartype
def read_cv_status_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvStatus]:
    """
    Read from the cv_status table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_status', data)
    return [CvStatus(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_status_by_id(con: db.Connection, term: str) -> Optional[CvStatus]:
    result = db.query_one(con, 'cv_status', {'term': term})
    if result is None:
        return None
    return CvStatus(**result)

@beartype.beartype
def delete_cv_status_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_status', {'term': term})
# Associate the functions with the class
CvStatus.create_from_json_dict = create_cv_status_from_json_dict
CvStatus.write = write_cv_status
CvStatus.update = update_cv_status
CvStatus.write_many = write_cv_status_many
CvStatus.read = read_cv_status
CvStatus.read_fuzzy = read_cv_status_fuzzy
CvStatus.read_any = read_cv_status_any
CvStatus.read_one = read_cv_status_one
CvStatus.read_one_or_none = read_cv_status_one_or_none
CvStatus.read_all = read_cv_status_all
CvStatus.delete = delete_cv_status_by_id
CvStatus.read_by_id = read_cv_status_by_id
CvStatus.delete_by_id = delete_cv_status_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvSamplingFeatureType:
    """
    Table containing terms used in the SamplingFeatureType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param dimensionality 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    dimensionality: Optional[str] = None # dimensionality character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_sampling_feature_type_from_json_dict(json_obj: dict):
        """
        Create a CvSamplingFeatureType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvSamplingFeatureType(**json_obj)


@beartype.beartype
def write_cv_sampling_feature_type_obj(con: db.Connection, obj: CvSamplingFeatureType) -> str:
    """
    Write a CvSamplingFeatureType object to the database
    @param con: database connection
    @param obj: CvSamplingFeatureType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_sampling_feature_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_sampling_feature_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            dimensionality: Optional[str] = None) -> str:
    """
    Write to the cv_sampling_feature_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param dimensionality 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    return db.upsert(con, 'cv_sampling_feature_type', data)

@beartype.beartype
def write_cv_sampling_feature_type_many(con: db.Connection, objs: List[CvSamplingFeatureType], upsert: bool = False) -> int:
    """
    Write a list of CvSamplingFeatureType objects to the database
    @param con: database connection
    @param objs: list of CvSamplingFeatureType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_sampling_feature_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_sampling_feature_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            dimensionality: Optional[str] = None) -> int:
    """
    Update a row in the cv_sampling_feature_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param dimensionality 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    return db.update(con, 'cv_sampling_feature_type', data)

@beartype.beartype
def read_cv_sampling_feature_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             dimensionality: Optional[str] = None) -> Generator[CvSamplingFeatureType, None, None]:
    """
    Read from the cv_sampling_feature_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param dimensionality 
    @return generator of CvSamplingFeatureType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    result = db.query(con, 'cv_sampling_feature_type', data)
    for row in result:
        yield CvSamplingFeatureType(**row.as_dict())

@beartype.beartype
def read_cv_sampling_feature_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             dimensionality: Optional[str] = None) -> Generator[CvSamplingFeatureType, None, None]:
    """
    Read from the cv_sampling_feature_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param dimensionality 
    @return generator of CvSamplingFeatureType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    result = db.query_fuzzy(con, 'cv_sampling_feature_type', data)
    for row in result:
        yield CvSamplingFeatureType(**row.as_dict())

@beartype.beartype
def read_cv_sampling_feature_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None,
             dimensionality: Optional[List[str]] = None) -> Generator[CvSamplingFeatureType, None, None]:
    """
    Read from the cv_sampling_feature_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param dimensionality 
    @return generator of CvSamplingFeatureType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    result = db.query_any(con, 'cv_sampling_feature_type', data)
    for row in result:
        yield CvSamplingFeatureType(**row.as_dict())

@beartype.beartype
def read_cv_sampling_feature_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             dimensionality: Optional[str] = None) -> Optional[CvSamplingFeatureType]:
    """
    Read from the cv_sampling_feature_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    result = db.query_one_or_none(con, 'cv_sampling_feature_type', data)
    if result is None:
        return None
    return CvSamplingFeatureType(**result)

@beartype.beartype
def read_cv_sampling_feature_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             dimensionality: Optional[str] = None) -> CvSamplingFeatureType:
    """
    Read from the cv_sampling_feature_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    result = db.query_one(con, 'cv_sampling_feature_type', data)
    return CvSamplingFeatureType(**result)

@beartype.beartype
def read_cv_sampling_feature_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             dimensionality: Optional[str] = None) -> List[CvSamplingFeatureType]:
    """
    Read from the cv_sampling_feature_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'dimensionality': dimensionality,
    }
    result = db.query(con, 'cv_sampling_feature_type', data)
    return [CvSamplingFeatureType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_sampling_feature_type_by_id(con: db.Connection, term: str) -> Optional[CvSamplingFeatureType]:
    result = db.query_one(con, 'cv_sampling_feature_type', {'term': term})
    if result is None:
        return None
    return CvSamplingFeatureType(**result)

@beartype.beartype
def delete_cv_sampling_feature_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_sampling_feature_type', {'term': term})
# Associate the functions with the class
CvSamplingFeatureType.create_from_json_dict = create_cv_sampling_feature_type_from_json_dict
CvSamplingFeatureType.write = write_cv_sampling_feature_type
CvSamplingFeatureType.update = update_cv_sampling_feature_type
CvSamplingFeatureType.write_many = write_cv_sampling_feature_type_many
CvSamplingFeatureType.read = read_cv_sampling_feature_type
CvSamplingFeatureType.read_fuzzy = read_cv_sampling_feature_type_fuzzy
CvSamplingFeatureType.read_any = read_cv_sampling_feature_type_any
CvSamplingFeatureType.read_one = read_cv_sampling_feature_type_one
CvSamplingFeatureType.read_one_or_none = read_cv_sampling_feature_type_one_or_none
CvSamplingFeatureType.read_all = read_cv_sampling_feature_type_all
CvSamplingFeatureType.delete = delete_cv_sampling_feature_type_by_id
CvSamplingFeatureType.read_by_id = read_cv_sampling_feature_type_by_id
CvSamplingFeatureType.delete_by_id = delete_cv_sampling_feature_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvTaxonomicClassifierDomain:
    """
    Table containing terms used in the TaxonomicClassifierDomain controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_taxonomic_classifier_domain_from_json_dict(json_obj: dict):
        """
        Create a CvTaxonomicClassifierDomain from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvTaxonomicClassifierDomain(**json_obj)


@beartype.beartype
def write_cv_taxonomic_classifier_domain_obj(con: db.Connection, obj: CvTaxonomicClassifierDomain) -> str:
    """
    Write a CvTaxonomicClassifierDomain object to the database
    @param con: database connection
    @param obj: CvTaxonomicClassifierDomain object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_taxonomic_classifier_domain', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_taxonomic_classifier_domain(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_taxonomic_classifier_domain table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_taxonomic_classifier_domain', data)

@beartype.beartype
def write_cv_taxonomic_classifier_domain_many(con: db.Connection, objs: List[CvTaxonomicClassifierDomain], upsert: bool = False) -> int:
    """
    Write a list of CvTaxonomicClassifierDomain objects to the database
    @param con: database connection
    @param objs: list of CvTaxonomicClassifierDomain objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_taxonomic_classifier_domain', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_taxonomic_classifier_domain(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_taxonomic_classifier_domain table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_taxonomic_classifier_domain', data)

@beartype.beartype
def read_cv_taxonomic_classifier_domain(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvTaxonomicClassifierDomain, None, None]:
    """
    Read from the cv_taxonomic_classifier_domain table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvTaxonomicClassifierDomain objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_taxonomic_classifier_domain', data)
    for row in result:
        yield CvTaxonomicClassifierDomain(**row.as_dict())

@beartype.beartype
def read_cv_taxonomic_classifier_domain_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvTaxonomicClassifierDomain, None, None]:
    """
    Read from the cv_taxonomic_classifier_domain table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvTaxonomicClassifierDomain objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_taxonomic_classifier_domain', data)
    for row in result:
        yield CvTaxonomicClassifierDomain(**row.as_dict())

@beartype.beartype
def read_cv_taxonomic_classifier_domain_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvTaxonomicClassifierDomain, None, None]:
    """
    Read from the cv_taxonomic_classifier_domain table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvTaxonomicClassifierDomain objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_taxonomic_classifier_domain', data)
    for row in result:
        yield CvTaxonomicClassifierDomain(**row.as_dict())

@beartype.beartype
def read_cv_taxonomic_classifier_domain_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvTaxonomicClassifierDomain]:
    """
    Read from the cv_taxonomic_classifier_domain table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_taxonomic_classifier_domain', data)
    if result is None:
        return None
    return CvTaxonomicClassifierDomain(**result)

@beartype.beartype
def read_cv_taxonomic_classifier_domain_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvTaxonomicClassifierDomain:
    """
    Read from the cv_taxonomic_classifier_domain table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_taxonomic_classifier_domain', data)
    return CvTaxonomicClassifierDomain(**result)

@beartype.beartype
def read_cv_taxonomic_classifier_domain_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvTaxonomicClassifierDomain]:
    """
    Read from the cv_taxonomic_classifier_domain table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_taxonomic_classifier_domain', data)
    return [CvTaxonomicClassifierDomain(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_taxonomic_classifier_domain_by_id(con: db.Connection, term: str) -> Optional[CvTaxonomicClassifierDomain]:
    result = db.query_one(con, 'cv_taxonomic_classifier_domain', {'term': term})
    if result is None:
        return None
    return CvTaxonomicClassifierDomain(**result)

@beartype.beartype
def delete_cv_taxonomic_classifier_domain_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_taxonomic_classifier_domain', {'term': term})
# Associate the functions with the class
CvTaxonomicClassifierDomain.create_from_json_dict = create_cv_taxonomic_classifier_domain_from_json_dict
CvTaxonomicClassifierDomain.write = write_cv_taxonomic_classifier_domain
CvTaxonomicClassifierDomain.update = update_cv_taxonomic_classifier_domain
CvTaxonomicClassifierDomain.write_many = write_cv_taxonomic_classifier_domain_many
CvTaxonomicClassifierDomain.read = read_cv_taxonomic_classifier_domain
CvTaxonomicClassifierDomain.read_fuzzy = read_cv_taxonomic_classifier_domain_fuzzy
CvTaxonomicClassifierDomain.read_any = read_cv_taxonomic_classifier_domain_any
CvTaxonomicClassifierDomain.read_one = read_cv_taxonomic_classifier_domain_one
CvTaxonomicClassifierDomain.read_one_or_none = read_cv_taxonomic_classifier_domain_one_or_none
CvTaxonomicClassifierDomain.read_all = read_cv_taxonomic_classifier_domain_all
CvTaxonomicClassifierDomain.delete = delete_cv_taxonomic_classifier_domain_by_id
CvTaxonomicClassifierDomain.read_by_id = read_cv_taxonomic_classifier_domain_by_id
CvTaxonomicClassifierDomain.delete_by_id = delete_cv_taxonomic_classifier_domain_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvSpecimenCollection:
    """
    Table containing terms used in the Specimen Collection controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_specimen_collection_from_json_dict(json_obj: dict):
        """
        Create a CvSpecimenCollection from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvSpecimenCollection(**json_obj)


@beartype.beartype
def write_cv_specimen_collection_obj(con: db.Connection, obj: CvSpecimenCollection) -> str:
    """
    Write a CvSpecimenCollection object to the database
    @param con: database connection
    @param obj: CvSpecimenCollection object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_specimen_collection', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_specimen_collection(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_specimen_collection table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_specimen_collection', data)

@beartype.beartype
def write_cv_specimen_collection_many(con: db.Connection, objs: List[CvSpecimenCollection], upsert: bool = False) -> int:
    """
    Write a list of CvSpecimenCollection objects to the database
    @param con: database connection
    @param objs: list of CvSpecimenCollection objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_specimen_collection', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_specimen_collection(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_specimen_collection table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_specimen_collection', data)

@beartype.beartype
def read_cv_specimen_collection(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvSpecimenCollection, None, None]:
    """
    Read from the cv_specimen_collection table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSpecimenCollection objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_specimen_collection', data)
    for row in result:
        yield CvSpecimenCollection(**row.as_dict())

@beartype.beartype
def read_cv_specimen_collection_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvSpecimenCollection, None, None]:
    """
    Read from the cv_specimen_collection table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSpecimenCollection objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_specimen_collection', data)
    for row in result:
        yield CvSpecimenCollection(**row.as_dict())

@beartype.beartype
def read_cv_specimen_collection_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvSpecimenCollection, None, None]:
    """
    Read from the cv_specimen_collection table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSpecimenCollection objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_specimen_collection', data)
    for row in result:
        yield CvSpecimenCollection(**row.as_dict())

@beartype.beartype
def read_cv_specimen_collection_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvSpecimenCollection]:
    """
    Read from the cv_specimen_collection table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_specimen_collection', data)
    if result is None:
        return None
    return CvSpecimenCollection(**result)

@beartype.beartype
def read_cv_specimen_collection_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvSpecimenCollection:
    """
    Read from the cv_specimen_collection table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_specimen_collection', data)
    return CvSpecimenCollection(**result)

@beartype.beartype
def read_cv_specimen_collection_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvSpecimenCollection]:
    """
    Read from the cv_specimen_collection table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_specimen_collection', data)
    return [CvSpecimenCollection(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_specimen_collection_by_id(con: db.Connection, term: str) -> Optional[CvSpecimenCollection]:
    result = db.query_one(con, 'cv_specimen_collection', {'term': term})
    if result is None:
        return None
    return CvSpecimenCollection(**result)

@beartype.beartype
def delete_cv_specimen_collection_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_specimen_collection', {'term': term})
# Associate the functions with the class
CvSpecimenCollection.create_from_json_dict = create_cv_specimen_collection_from_json_dict
CvSpecimenCollection.write = write_cv_specimen_collection
CvSpecimenCollection.update = update_cv_specimen_collection
CvSpecimenCollection.write_many = write_cv_specimen_collection_many
CvSpecimenCollection.read = read_cv_specimen_collection
CvSpecimenCollection.read_fuzzy = read_cv_specimen_collection_fuzzy
CvSpecimenCollection.read_any = read_cv_specimen_collection_any
CvSpecimenCollection.read_one = read_cv_specimen_collection_one
CvSpecimenCollection.read_one_or_none = read_cv_specimen_collection_one_or_none
CvSpecimenCollection.read_all = read_cv_specimen_collection_all
CvSpecimenCollection.delete = delete_cv_specimen_collection_by_id
CvSpecimenCollection.read_by_id = read_cv_specimen_collection_by_id
CvSpecimenCollection.delete_by_id = delete_cv_specimen_collection_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvSpecimenType:
    """
    Table containing terms used in the SpecimenType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_specimen_type_from_json_dict(json_obj: dict):
        """
        Create a CvSpecimenType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvSpecimenType(**json_obj)


@beartype.beartype
def write_cv_specimen_type_obj(con: db.Connection, obj: CvSpecimenType) -> str:
    """
    Write a CvSpecimenType object to the database
    @param con: database connection
    @param obj: CvSpecimenType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_specimen_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_specimen_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_specimen_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_specimen_type', data)

@beartype.beartype
def write_cv_specimen_type_many(con: db.Connection, objs: List[CvSpecimenType], upsert: bool = False) -> int:
    """
    Write a list of CvSpecimenType objects to the database
    @param con: database connection
    @param objs: list of CvSpecimenType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_specimen_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_specimen_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_specimen_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_specimen_type', data)

@beartype.beartype
def read_cv_specimen_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvSpecimenType, None, None]:
    """
    Read from the cv_specimen_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSpecimenType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_specimen_type', data)
    for row in result:
        yield CvSpecimenType(**row.as_dict())

@beartype.beartype
def read_cv_specimen_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvSpecimenType, None, None]:
    """
    Read from the cv_specimen_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSpecimenType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_specimen_type', data)
    for row in result:
        yield CvSpecimenType(**row.as_dict())

@beartype.beartype
def read_cv_specimen_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvSpecimenType, None, None]:
    """
    Read from the cv_specimen_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSpecimenType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_specimen_type', data)
    for row in result:
        yield CvSpecimenType(**row.as_dict())

@beartype.beartype
def read_cv_specimen_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvSpecimenType]:
    """
    Read from the cv_specimen_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_specimen_type', data)
    if result is None:
        return None
    return CvSpecimenType(**result)

@beartype.beartype
def read_cv_specimen_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvSpecimenType:
    """
    Read from the cv_specimen_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_specimen_type', data)
    return CvSpecimenType(**result)

@beartype.beartype
def read_cv_specimen_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvSpecimenType]:
    """
    Read from the cv_specimen_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_specimen_type', data)
    return [CvSpecimenType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_specimen_type_by_id(con: db.Connection, term: str) -> Optional[CvSpecimenType]:
    result = db.query_one(con, 'cv_specimen_type', {'term': term})
    if result is None:
        return None
    return CvSpecimenType(**result)

@beartype.beartype
def delete_cv_specimen_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_specimen_type', {'term': term})
# Associate the functions with the class
CvSpecimenType.create_from_json_dict = create_cv_specimen_type_from_json_dict
CvSpecimenType.write = write_cv_specimen_type
CvSpecimenType.update = update_cv_specimen_type
CvSpecimenType.write_many = write_cv_specimen_type_many
CvSpecimenType.read = read_cv_specimen_type
CvSpecimenType.read_fuzzy = read_cv_specimen_type_fuzzy
CvSpecimenType.read_any = read_cv_specimen_type_any
CvSpecimenType.read_one = read_cv_specimen_type_one
CvSpecimenType.read_one_or_none = read_cv_specimen_type_one_or_none
CvSpecimenType.read_all = read_cv_specimen_type_all
CvSpecimenType.delete = delete_cv_specimen_type_by_id
CvSpecimenType.read_by_id = read_cv_specimen_type_by_id
CvSpecimenType.delete_by_id = delete_cv_specimen_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvSamplingFeatureGeoType:
    """
    Table containing terms used in the SamplingFeatureGeoType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_sampling_feature_geo_type_from_json_dict(json_obj: dict):
        """
        Create a CvSamplingFeatureGeoType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvSamplingFeatureGeoType(**json_obj)


@beartype.beartype
def write_cv_sampling_feature_geo_type_obj(con: db.Connection, obj: CvSamplingFeatureGeoType) -> str:
    """
    Write a CvSamplingFeatureGeoType object to the database
    @param con: database connection
    @param obj: CvSamplingFeatureGeoType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_sampling_feature_geo_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_sampling_feature_geo_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_sampling_feature_geo_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_sampling_feature_geo_type', data)

@beartype.beartype
def write_cv_sampling_feature_geo_type_many(con: db.Connection, objs: List[CvSamplingFeatureGeoType], upsert: bool = False) -> int:
    """
    Write a list of CvSamplingFeatureGeoType objects to the database
    @param con: database connection
    @param objs: list of CvSamplingFeatureGeoType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_sampling_feature_geo_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_sampling_feature_geo_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_sampling_feature_geo_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_sampling_feature_geo_type', data)

@beartype.beartype
def read_cv_sampling_feature_geo_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvSamplingFeatureGeoType, None, None]:
    """
    Read from the cv_sampling_feature_geo_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSamplingFeatureGeoType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_sampling_feature_geo_type', data)
    for row in result:
        yield CvSamplingFeatureGeoType(**row.as_dict())

@beartype.beartype
def read_cv_sampling_feature_geo_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvSamplingFeatureGeoType, None, None]:
    """
    Read from the cv_sampling_feature_geo_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSamplingFeatureGeoType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_sampling_feature_geo_type', data)
    for row in result:
        yield CvSamplingFeatureGeoType(**row.as_dict())

@beartype.beartype
def read_cv_sampling_feature_geo_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvSamplingFeatureGeoType, None, None]:
    """
    Read from the cv_sampling_feature_geo_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvSamplingFeatureGeoType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_sampling_feature_geo_type', data)
    for row in result:
        yield CvSamplingFeatureGeoType(**row.as_dict())

@beartype.beartype
def read_cv_sampling_feature_geo_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvSamplingFeatureGeoType]:
    """
    Read from the cv_sampling_feature_geo_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_sampling_feature_geo_type', data)
    if result is None:
        return None
    return CvSamplingFeatureGeoType(**result)

@beartype.beartype
def read_cv_sampling_feature_geo_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvSamplingFeatureGeoType:
    """
    Read from the cv_sampling_feature_geo_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_sampling_feature_geo_type', data)
    return CvSamplingFeatureGeoType(**result)

@beartype.beartype
def read_cv_sampling_feature_geo_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvSamplingFeatureGeoType]:
    """
    Read from the cv_sampling_feature_geo_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_sampling_feature_geo_type', data)
    return [CvSamplingFeatureGeoType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_sampling_feature_geo_type_by_id(con: db.Connection, term: str) -> Optional[CvSamplingFeatureGeoType]:
    result = db.query_one(con, 'cv_sampling_feature_geo_type', {'term': term})
    if result is None:
        return None
    return CvSamplingFeatureGeoType(**result)

@beartype.beartype
def delete_cv_sampling_feature_geo_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_sampling_feature_geo_type', {'term': term})
# Associate the functions with the class
CvSamplingFeatureGeoType.create_from_json_dict = create_cv_sampling_feature_geo_type_from_json_dict
CvSamplingFeatureGeoType.write = write_cv_sampling_feature_geo_type
CvSamplingFeatureGeoType.update = update_cv_sampling_feature_geo_type
CvSamplingFeatureGeoType.write_many = write_cv_sampling_feature_geo_type_many
CvSamplingFeatureGeoType.read = read_cv_sampling_feature_geo_type
CvSamplingFeatureGeoType.read_fuzzy = read_cv_sampling_feature_geo_type_fuzzy
CvSamplingFeatureGeoType.read_any = read_cv_sampling_feature_geo_type_any
CvSamplingFeatureGeoType.read_one = read_cv_sampling_feature_geo_type_one
CvSamplingFeatureGeoType.read_one_or_none = read_cv_sampling_feature_geo_type_one_or_none
CvSamplingFeatureGeoType.read_all = read_cv_sampling_feature_geo_type_all
CvSamplingFeatureGeoType.delete = delete_cv_sampling_feature_geo_type_by_id
CvSamplingFeatureGeoType.read_by_id = read_cv_sampling_feature_geo_type_by_id
CvSamplingFeatureGeoType.delete_by_id = delete_cv_sampling_feature_geo_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvQualityCode:
    """
    Table containing terms used in the QualityCode controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param qa_flag 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: str # definition character varying (default: )
    qa_flag: str # qa_flag character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_quality_code_from_json_dict(json_obj: dict):
        """
        Create a CvQualityCode from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvQualityCode(**json_obj)


@beartype.beartype
def write_cv_quality_code_obj(con: db.Connection, obj: CvQualityCode) -> str:
    """
    Write a CvQualityCode object to the database
    @param con: database connection
    @param obj: CvQualityCode object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_quality_code', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_quality_code(
            con: db.Connection,
            term: str,
            name: str,
            definition: str,
            qa_flag: str,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_quality_code table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param qa_flag 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    return db.upsert(con, 'cv_quality_code', data)

@beartype.beartype
def write_cv_quality_code_many(con: db.Connection, objs: List[CvQualityCode], upsert: bool = False) -> int:
    """
    Write a list of CvQualityCode objects to the database
    @param con: database connection
    @param objs: list of CvQualityCode objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_quality_code', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_quality_code(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            qa_flag: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_quality_code table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param qa_flag 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    return db.update(con, 'cv_quality_code', data)

@beartype.beartype
def read_cv_quality_code(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             qa_flag: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvQualityCode, None, None]:
    """
    Read from the cv_quality_code table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param qa_flag 
    @return generator of CvQualityCode objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    result = db.query(con, 'cv_quality_code', data)
    for row in result:
        yield CvQualityCode(**row.as_dict())

@beartype.beartype
def read_cv_quality_code_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             qa_flag: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvQualityCode, None, None]:
    """
    Read from the cv_quality_code table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param qa_flag 
    @return generator of CvQualityCode objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    result = db.query_fuzzy(con, 'cv_quality_code', data)
    for row in result:
        yield CvQualityCode(**row.as_dict())

@beartype.beartype
def read_cv_quality_code_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             qa_flag: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvQualityCode, None, None]:
    """
    Read from the cv_quality_code table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param qa_flag 
    @return generator of CvQualityCode objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    result = db.query_any(con, 'cv_quality_code', data)
    for row in result:
        yield CvQualityCode(**row.as_dict())

@beartype.beartype
def read_cv_quality_code_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             qa_flag: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvQualityCode]:
    """
    Read from the cv_quality_code table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    result = db.query_one_or_none(con, 'cv_quality_code', data)
    if result is None:
        return None
    return CvQualityCode(**result)

@beartype.beartype
def read_cv_quality_code_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             qa_flag: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvQualityCode:
    """
    Read from the cv_quality_code table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    result = db.query_one(con, 'cv_quality_code', data)
    return CvQualityCode(**result)

@beartype.beartype
def read_cv_quality_code_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             qa_flag: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvQualityCode]:
    """
    Read from the cv_quality_code table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'qa_flag': qa_flag,
    }
    result = db.query(con, 'cv_quality_code', data)
    return [CvQualityCode(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_quality_code_by_id(con: db.Connection, term: str) -> Optional[CvQualityCode]:
    result = db.query_one(con, 'cv_quality_code', {'term': term})
    if result is None:
        return None
    return CvQualityCode(**result)

@beartype.beartype
def delete_cv_quality_code_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_quality_code', {'term': term})
# Associate the functions with the class
CvQualityCode.create_from_json_dict = create_cv_quality_code_from_json_dict
CvQualityCode.write = write_cv_quality_code
CvQualityCode.update = update_cv_quality_code
CvQualityCode.write_many = write_cv_quality_code_many
CvQualityCode.read = read_cv_quality_code
CvQualityCode.read_fuzzy = read_cv_quality_code_fuzzy
CvQualityCode.read_any = read_cv_quality_code_any
CvQualityCode.read_one = read_cv_quality_code_one
CvQualityCode.read_one_or_none = read_cv_quality_code_one_or_none
CvQualityCode.read_all = read_cv_quality_code_all
CvQualityCode.delete = delete_cv_quality_code_by_id
CvQualityCode.read_by_id = read_cv_quality_code_by_id
CvQualityCode.delete_by_id = delete_cv_quality_code_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvQuantityKind:
    """
    Table containing terms used in the QuantityKind  controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param default_unit 
    @param default_unit_abbreviation 
    @param dimension_symbol 
    @param dimension_unitless 
    @param dimension_length 
    @param dimension_mass 
    @param dimension_time 
    @param dimension_current 
    @param dimension_temperature 
    @param dimension_amount 
    @param dimension_light 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    dimension_unitless: int # dimension_unitless integer (default: )
    dimension_length: int # dimension_length integer (default: )
    dimension_mass: int # dimension_mass integer (default: )
    dimension_time: int # dimension_time integer (default: )
    dimension_current: int # dimension_current integer (default: )
    dimension_temperature: int # dimension_temperature integer (default: )
    dimension_amount: int # dimension_amount integer (default: )
    dimension_light: int # dimension_light integer (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    default_unit: Optional[str] = None # default_unit character varying (default: )
    default_unit_abbreviation: Optional[str] = None # default_unit_abbreviation character varying (default: )
    dimension_symbol: Optional[str] = None # dimension_symbol character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_quantity_kind_from_json_dict(json_obj: dict):
        """
        Create a CvQuantityKind from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvQuantityKind(**json_obj)


@beartype.beartype
def write_cv_quantity_kind_obj(con: db.Connection, obj: CvQuantityKind) -> str:
    """
    Write a CvQuantityKind object to the database
    @param con: database connection
    @param obj: CvQuantityKind object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_quantity_kind', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_quantity_kind(
            con: db.Connection,
            term: str,
            name: str,
            dimension_unitless: int,
            dimension_length: int,
            dimension_mass: int,
            dimension_time: int,
            dimension_current: int,
            dimension_temperature: int,
            dimension_amount: int,
            dimension_light: int,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            default_unit: Optional[str] = None,
            default_unit_abbreviation: Optional[str] = None,
            dimension_symbol: Optional[str] = None) -> str:
    """
    Write to the cv_quantity_kind table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param default_unit 
    @param default_unit_abbreviation 
    @param dimension_symbol 
    @param dimension_unitless 
    @param dimension_length 
    @param dimension_mass 
    @param dimension_time 
    @param dimension_current 
    @param dimension_temperature 
    @param dimension_amount 
    @param dimension_light 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    return db.upsert(con, 'cv_quantity_kind', data)

@beartype.beartype
def write_cv_quantity_kind_many(con: db.Connection, objs: List[CvQuantityKind], upsert: bool = False) -> int:
    """
    Write a list of CvQuantityKind objects to the database
    @param con: database connection
    @param objs: list of CvQuantityKind objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_quantity_kind', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_quantity_kind(con: db.Connection, term: str,
            name: Optional[str] = None,
            dimension_unitless: Optional[int] = None,
            dimension_length: Optional[int] = None,
            dimension_mass: Optional[int] = None,
            dimension_time: Optional[int] = None,
            dimension_current: Optional[int] = None,
            dimension_temperature: Optional[int] = None,
            dimension_amount: Optional[int] = None,
            dimension_light: Optional[int] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            default_unit: Optional[str] = None,
            default_unit_abbreviation: Optional[str] = None,
            dimension_symbol: Optional[str] = None) -> int:
    """
    Update a row in the cv_quantity_kind table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param default_unit 
    @param default_unit_abbreviation 
    @param dimension_symbol 
    @param dimension_unitless 
    @param dimension_length 
    @param dimension_mass 
    @param dimension_time 
    @param dimension_current 
    @param dimension_temperature 
    @param dimension_amount 
    @param dimension_light 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    return db.update(con, 'cv_quantity_kind', data)

@beartype.beartype
def read_cv_quantity_kind(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             dimension_unitless: Optional[int] = None,
             dimension_length: Optional[int] = None,
             dimension_mass: Optional[int] = None,
             dimension_time: Optional[int] = None,
             dimension_current: Optional[int] = None,
             dimension_temperature: Optional[int] = None,
             dimension_amount: Optional[int] = None,
             dimension_light: Optional[int] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             default_unit: Optional[str] = None,
             default_unit_abbreviation: Optional[str] = None,
             dimension_symbol: Optional[str] = None) -> Generator[CvQuantityKind, None, None]:
    """
    Read from the cv_quantity_kind table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param default_unit 
    @param default_unit_abbreviation 
    @param dimension_symbol 
    @param dimension_unitless 
    @param dimension_length 
    @param dimension_mass 
    @param dimension_time 
    @param dimension_current 
    @param dimension_temperature 
    @param dimension_amount 
    @param dimension_light 
    @return generator of CvQuantityKind objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    result = db.query(con, 'cv_quantity_kind', data)
    for row in result:
        yield CvQuantityKind(**row.as_dict())

@beartype.beartype
def read_cv_quantity_kind_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             dimension_unitless: Optional[int] = None,
             dimension_length: Optional[int] = None,
             dimension_mass: Optional[int] = None,
             dimension_time: Optional[int] = None,
             dimension_current: Optional[int] = None,
             dimension_temperature: Optional[int] = None,
             dimension_amount: Optional[int] = None,
             dimension_light: Optional[int] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             default_unit: Optional[str] = None,
             default_unit_abbreviation: Optional[str] = None,
             dimension_symbol: Optional[str] = None) -> Generator[CvQuantityKind, None, None]:
    """
    Read from the cv_quantity_kind table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param default_unit 
    @param default_unit_abbreviation 
    @param dimension_symbol 
    @param dimension_unitless 
    @param dimension_length 
    @param dimension_mass 
    @param dimension_time 
    @param dimension_current 
    @param dimension_temperature 
    @param dimension_amount 
    @param dimension_light 
    @return generator of CvQuantityKind objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    result = db.query_fuzzy(con, 'cv_quantity_kind', data)
    for row in result:
        yield CvQuantityKind(**row.as_dict())

@beartype.beartype
def read_cv_quantity_kind_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             dimension_unitless: Optional[List[int]] = None,
             dimension_length: Optional[List[int]] = None,
             dimension_mass: Optional[List[int]] = None,
             dimension_time: Optional[List[int]] = None,
             dimension_current: Optional[List[int]] = None,
             dimension_temperature: Optional[List[int]] = None,
             dimension_amount: Optional[List[int]] = None,
             dimension_light: Optional[List[int]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None,
             default_unit: Optional[List[str]] = None,
             default_unit_abbreviation: Optional[List[str]] = None,
             dimension_symbol: Optional[List[str]] = None) -> Generator[CvQuantityKind, None, None]:
    """
    Read from the cv_quantity_kind table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param default_unit 
    @param default_unit_abbreviation 
    @param dimension_symbol 
    @param dimension_unitless 
    @param dimension_length 
    @param dimension_mass 
    @param dimension_time 
    @param dimension_current 
    @param dimension_temperature 
    @param dimension_amount 
    @param dimension_light 
    @return generator of CvQuantityKind objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    result = db.query_any(con, 'cv_quantity_kind', data)
    for row in result:
        yield CvQuantityKind(**row.as_dict())

@beartype.beartype
def read_cv_quantity_kind_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             dimension_unitless: Optional[int] = None,
             dimension_length: Optional[int] = None,
             dimension_mass: Optional[int] = None,
             dimension_time: Optional[int] = None,
             dimension_current: Optional[int] = None,
             dimension_temperature: Optional[int] = None,
             dimension_amount: Optional[int] = None,
             dimension_light: Optional[int] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             default_unit: Optional[str] = None,
             default_unit_abbreviation: Optional[str] = None,
             dimension_symbol: Optional[str] = None) -> Optional[CvQuantityKind]:
    """
    Read from the cv_quantity_kind table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    result = db.query_one_or_none(con, 'cv_quantity_kind', data)
    if result is None:
        return None
    return CvQuantityKind(**result)

@beartype.beartype
def read_cv_quantity_kind_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             dimension_unitless: Optional[int] = None,
             dimension_length: Optional[int] = None,
             dimension_mass: Optional[int] = None,
             dimension_time: Optional[int] = None,
             dimension_current: Optional[int] = None,
             dimension_temperature: Optional[int] = None,
             dimension_amount: Optional[int] = None,
             dimension_light: Optional[int] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             default_unit: Optional[str] = None,
             default_unit_abbreviation: Optional[str] = None,
             dimension_symbol: Optional[str] = None) -> CvQuantityKind:
    """
    Read from the cv_quantity_kind table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    result = db.query_one(con, 'cv_quantity_kind', data)
    return CvQuantityKind(**result)

@beartype.beartype
def read_cv_quantity_kind_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             dimension_unitless: Optional[int] = None,
             dimension_length: Optional[int] = None,
             dimension_mass: Optional[int] = None,
             dimension_time: Optional[int] = None,
             dimension_current: Optional[int] = None,
             dimension_temperature: Optional[int] = None,
             dimension_amount: Optional[int] = None,
             dimension_light: Optional[int] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             default_unit: Optional[str] = None,
             default_unit_abbreviation: Optional[str] = None,
             dimension_symbol: Optional[str] = None) -> List[CvQuantityKind]:
    """
    Read from the cv_quantity_kind table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'default_unit': default_unit,
        'default_unit_abbreviation': default_unit_abbreviation,
        'dimension_symbol': dimension_symbol,
        'dimension_unitless': dimension_unitless,
        'dimension_length': dimension_length,
        'dimension_mass': dimension_mass,
        'dimension_time': dimension_time,
        'dimension_current': dimension_current,
        'dimension_temperature': dimension_temperature,
        'dimension_amount': dimension_amount,
        'dimension_light': dimension_light,
    }
    result = db.query(con, 'cv_quantity_kind', data)
    return [CvQuantityKind(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_quantity_kind_by_id(con: db.Connection, term: str) -> Optional[CvQuantityKind]:
    result = db.query_one(con, 'cv_quantity_kind', {'term': term})
    if result is None:
        return None
    return CvQuantityKind(**result)

@beartype.beartype
def delete_cv_quantity_kind_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_quantity_kind', {'term': term})
# Associate the functions with the class
CvQuantityKind.create_from_json_dict = create_cv_quantity_kind_from_json_dict
CvQuantityKind.write = write_cv_quantity_kind
CvQuantityKind.update = update_cv_quantity_kind
CvQuantityKind.write_many = write_cv_quantity_kind_many
CvQuantityKind.read = read_cv_quantity_kind
CvQuantityKind.read_fuzzy = read_cv_quantity_kind_fuzzy
CvQuantityKind.read_any = read_cv_quantity_kind_any
CvQuantityKind.read_one = read_cv_quantity_kind_one
CvQuantityKind.read_one_or_none = read_cv_quantity_kind_one_or_none
CvQuantityKind.read_all = read_cv_quantity_kind_all
CvQuantityKind.delete = delete_cv_quantity_kind_by_id
CvQuantityKind.read_by_id = read_cv_quantity_kind_by_id
CvQuantityKind.delete_by_id = delete_cv_quantity_kind_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvSpatialOffsetType:
    """
    Table containing terms used in the SpatialOffsetType controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param offset1 
    @param offset2 
    @param offset3 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    offset1: Optional[str] = None # offset1 character varying (default: )
    offset2: Optional[str] = None # offset2 character varying (default: )
    offset3: Optional[str] = None # offset3 character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_spatial_offset_type_from_json_dict(json_obj: dict):
        """
        Create a CvSpatialOffsetType from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvSpatialOffsetType(**json_obj)


@beartype.beartype
def write_cv_spatial_offset_type_obj(con: db.Connection, obj: CvSpatialOffsetType) -> str:
    """
    Write a CvSpatialOffsetType object to the database
    @param con: database connection
    @param obj: CvSpatialOffsetType object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_spatial_offset_type', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_spatial_offset_type(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            offset1: Optional[str] = None,
            offset2: Optional[str] = None,
            offset3: Optional[str] = None) -> str:
    """
    Write to the cv_spatial_offset_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param offset1 
    @param offset2 
    @param offset3 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    return db.upsert(con, 'cv_spatial_offset_type', data)

@beartype.beartype
def write_cv_spatial_offset_type_many(con: db.Connection, objs: List[CvSpatialOffsetType], upsert: bool = False) -> int:
    """
    Write a list of CvSpatialOffsetType objects to the database
    @param con: database connection
    @param objs: list of CvSpatialOffsetType objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_spatial_offset_type', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_spatial_offset_type(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None,
            offset1: Optional[str] = None,
            offset2: Optional[str] = None,
            offset3: Optional[str] = None) -> int:
    """
    Update a row in the cv_spatial_offset_type table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param offset1 
    @param offset2 
    @param offset3 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    return db.update(con, 'cv_spatial_offset_type', data)

@beartype.beartype
def read_cv_spatial_offset_type(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             offset1: Optional[str] = None,
             offset2: Optional[str] = None,
             offset3: Optional[str] = None) -> Generator[CvSpatialOffsetType, None, None]:
    """
    Read from the cv_spatial_offset_type table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param offset1 
    @param offset2 
    @param offset3 
    @return generator of CvSpatialOffsetType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    result = db.query(con, 'cv_spatial_offset_type', data)
    for row in result:
        yield CvSpatialOffsetType(**row.as_dict())

@beartype.beartype
def read_cv_spatial_offset_type_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             offset1: Optional[str] = None,
             offset2: Optional[str] = None,
             offset3: Optional[str] = None) -> Generator[CvSpatialOffsetType, None, None]:
    """
    Read from the cv_spatial_offset_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param offset1 
    @param offset2 
    @param offset3 
    @return generator of CvSpatialOffsetType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    result = db.query_fuzzy(con, 'cv_spatial_offset_type', data)
    for row in result:
        yield CvSpatialOffsetType(**row.as_dict())

@beartype.beartype
def read_cv_spatial_offset_type_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None,
             offset1: Optional[List[str]] = None,
             offset2: Optional[List[str]] = None,
             offset3: Optional[List[str]] = None) -> Generator[CvSpatialOffsetType, None, None]:
    """
    Read from the cv_spatial_offset_type table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @param offset1 
    @param offset2 
    @param offset3 
    @return generator of CvSpatialOffsetType objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    result = db.query_any(con, 'cv_spatial_offset_type', data)
    for row in result:
        yield CvSpatialOffsetType(**row.as_dict())

@beartype.beartype
def read_cv_spatial_offset_type_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             offset1: Optional[str] = None,
             offset2: Optional[str] = None,
             offset3: Optional[str] = None) -> Optional[CvSpatialOffsetType]:
    """
    Read from the cv_spatial_offset_type table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    result = db.query_one_or_none(con, 'cv_spatial_offset_type', data)
    if result is None:
        return None
    return CvSpatialOffsetType(**result)

@beartype.beartype
def read_cv_spatial_offset_type_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             offset1: Optional[str] = None,
             offset2: Optional[str] = None,
             offset3: Optional[str] = None) -> CvSpatialOffsetType:
    """
    Read from the cv_spatial_offset_type table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    result = db.query_one(con, 'cv_spatial_offset_type', data)
    return CvSpatialOffsetType(**result)

@beartype.beartype
def read_cv_spatial_offset_type_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None,
             offset1: Optional[str] = None,
             offset2: Optional[str] = None,
             offset3: Optional[str] = None) -> List[CvSpatialOffsetType]:
    """
    Read from the cv_spatial_offset_type table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
        'offset1': offset1,
        'offset2': offset2,
        'offset3': offset3,
    }
    result = db.query(con, 'cv_spatial_offset_type', data)
    return [CvSpatialOffsetType(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_spatial_offset_type_by_id(con: db.Connection, term: str) -> Optional[CvSpatialOffsetType]:
    result = db.query_one(con, 'cv_spatial_offset_type', {'term': term})
    if result is None:
        return None
    return CvSpatialOffsetType(**result)

@beartype.beartype
def delete_cv_spatial_offset_type_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_spatial_offset_type', {'term': term})
# Associate the functions with the class
CvSpatialOffsetType.create_from_json_dict = create_cv_spatial_offset_type_from_json_dict
CvSpatialOffsetType.write = write_cv_spatial_offset_type
CvSpatialOffsetType.update = update_cv_spatial_offset_type
CvSpatialOffsetType.write_many = write_cv_spatial_offset_type_many
CvSpatialOffsetType.read = read_cv_spatial_offset_type
CvSpatialOffsetType.read_fuzzy = read_cv_spatial_offset_type_fuzzy
CvSpatialOffsetType.read_any = read_cv_spatial_offset_type_any
CvSpatialOffsetType.read_one = read_cv_spatial_offset_type_one
CvSpatialOffsetType.read_one_or_none = read_cv_spatial_offset_type_one_or_none
CvSpatialOffsetType.read_all = read_cv_spatial_offset_type_all
CvSpatialOffsetType.delete = delete_cv_spatial_offset_type_by_id
CvSpatialOffsetType.read_by_id = read_cv_spatial_offset_type_by_id
CvSpatialOffsetType.delete_by_id = delete_cv_spatial_offset_type_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvUnits:
    """
    Table containing terms used in the VariableName controlled vocabulary.

    @param units_id 
    @param term 
    @param units_name 
    @param quantity_kind_cv 
    @param units_abbreviation 
    @param units_link 
    @param conversion_multiplier 
    @param conversion_offset 
    @param definition 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    units_name: str # units_name character varying (default: )
    quantity_kind_cv: str # quantity_kind_cv character varying (default: )
    conversion_multiplier: float # conversion_multiplier double precision (default: )
    conversion_offset: float # conversion_offset double precision (default: )
    units_id: Optional[int] = None # units_id integer (default: )
    units_abbreviation: Optional[str] = None # units_abbreviation character varying (default: )
    units_link: Optional[str] = None # units_link character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'units_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_units_from_json_dict(json_obj: dict):
        """
        Create a CvUnits from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvUnits(**json_obj)


@beartype.beartype
def write_cv_units_obj(con: db.Connection, obj: CvUnits) -> int:
    """
    Write a CvUnits object to the database
    @param con: database connection
    @param obj: CvUnits object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_units', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_units(
            con: db.Connection,
            term: str,
            units_name: str,
            quantity_kind_cv: str,
            conversion_multiplier: float,
            conversion_offset: float,
            units_id: Optional[int] = None,
            units_abbreviation: Optional[str] = None,
            units_link: Optional[str] = None,
            definition: Optional[str] = None) -> int:
    """
    Write to the cv_units table in the database
    @param con: database connection
    @param units_id 
    @param term 
    @param units_name 
    @param quantity_kind_cv 
    @param units_abbreviation 
    @param units_link 
    @param conversion_multiplier 
    @param conversion_offset 
    @param definition 
    @return id of the inserted/updated row
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    return db.upsert(con, 'cv_units', data)

@beartype.beartype
def write_cv_units_many(con: db.Connection, objs: List[CvUnits], upsert: bool = False) -> int:
    """
    Write a list of CvUnits objects to the database
    @param con: database connection
    @param objs: list of CvUnits objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_units', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_units(con: db.Connection, units_id: int,
            term: Optional[str] = None,
            units_name: Optional[str] = None,
            quantity_kind_cv: Optional[str] = None,
            conversion_multiplier: Optional[float] = None,
            conversion_offset: Optional[float] = None,
            units_abbreviation: Optional[str] = None,
            units_link: Optional[str] = None,
            definition: Optional[str] = None) -> int:
    """
    Update a row in the cv_units table in the database
    @param con: database connection
    @param units_id 
    @param term 
    @param units_name 
    @param quantity_kind_cv 
    @param units_abbreviation 
    @param units_link 
    @param conversion_multiplier 
    @param conversion_offset 
    @param definition 
    @return The number of rows updated
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    return db.update(con, 'cv_units', data)

@beartype.beartype
def read_cv_units(
            con: db.Connection,
            term: Optional[str] = None,
             units_name: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None,
             units_id: Optional[int] = None,
             units_abbreviation: Optional[str] = None,
             units_link: Optional[str] = None,
             definition: Optional[str] = None) -> Generator[CvUnits, None, None]:
    """
    Read from the cv_units table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param units_id 
    @param term 
    @param units_name 
    @param quantity_kind_cv 
    @param units_abbreviation 
    @param units_link 
    @param conversion_multiplier 
    @param conversion_offset 
    @param definition 
    @return generator of CvUnits objects
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    result = db.query(con, 'cv_units', data)
    for row in result:
        yield CvUnits(**row.as_dict())

@beartype.beartype
def read_cv_units_fuzzy(con: db.Connection, term: Optional[str] = None,
             units_name: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None,
             units_id: Optional[int] = None,
             units_abbreviation: Optional[str] = None,
             units_link: Optional[str] = None,
             definition: Optional[str] = None) -> Generator[CvUnits, None, None]:
    """
    Read from the cv_units table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param units_id 
    @param term 
    @param units_name 
    @param quantity_kind_cv 
    @param units_abbreviation 
    @param units_link 
    @param conversion_multiplier 
    @param conversion_offset 
    @param definition 
    @return generator of CvUnits objects
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    result = db.query_fuzzy(con, 'cv_units', data)
    for row in result:
        yield CvUnits(**row.as_dict())

@beartype.beartype
def read_cv_units_any(con: db.Connection, term: Optional[List[str]] = None,
             units_name: Optional[List[str]] = None,
             quantity_kind_cv: Optional[List[str]] = None,
             conversion_multiplier: Optional[List[float]] = None,
             conversion_offset: Optional[List[float]] = None,
             units_id: Optional[List[int]] = None,
             units_abbreviation: Optional[List[str]] = None,
             units_link: Optional[List[str]] = None,
             definition: Optional[List[str]] = None) -> Generator[CvUnits, None, None]:
    """
    Read from the cv_units table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param units_id 
    @param term 
    @param units_name 
    @param quantity_kind_cv 
    @param units_abbreviation 
    @param units_link 
    @param conversion_multiplier 
    @param conversion_offset 
    @param definition 
    @return generator of CvUnits objects
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    result = db.query_any(con, 'cv_units', data)
    for row in result:
        yield CvUnits(**row.as_dict())

@beartype.beartype
def read_cv_units_one_or_none(con: db.Connection, term: Optional[str] = None,
             units_name: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None,
             units_id: Optional[int] = None,
             units_abbreviation: Optional[str] = None,
             units_link: Optional[str] = None,
             definition: Optional[str] = None) -> Optional[CvUnits]:
    """
    Read from the cv_units table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    result = db.query_one_or_none(con, 'cv_units', data)
    if result is None:
        return None
    return CvUnits(**result)

@beartype.beartype
def read_cv_units_one(con: db.Connection, term: Optional[str] = None,
             units_name: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None,
             units_id: Optional[int] = None,
             units_abbreviation: Optional[str] = None,
             units_link: Optional[str] = None,
             definition: Optional[str] = None) -> CvUnits:
    """
    Read from the cv_units table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    result = db.query_one(con, 'cv_units', data)
    return CvUnits(**result)

@beartype.beartype
def read_cv_units_all(con: db.Connection, term: Optional[str] = None,
             units_name: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None,
             units_id: Optional[int] = None,
             units_abbreviation: Optional[str] = None,
             units_link: Optional[str] = None,
             definition: Optional[str] = None) -> List[CvUnits]:
    """
    Read from the cv_units table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'units_id': units_id,
        'term': term,
        'units_name': units_name,
        'quantity_kind_cv': quantity_kind_cv,
        'units_abbreviation': units_abbreviation,
        'units_link': units_link,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
        'definition': definition,
    }
    result = db.query(con, 'cv_units', data)
    return [CvUnits(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_units_by_id(con: db.Connection, units_id: int) -> Optional[CvUnits]:
    result = db.query_one(con, 'cv_units', {'units_id': units_id})
    if result is None:
        return None
    return CvUnits(**result)

@beartype.beartype
def delete_cv_units_by_id(con: db.Connection, units_id: int):
    db.delete(con, 'cv_units', {'units_id': units_id})
# Associate the functions with the class
CvUnits.create_from_json_dict = create_cv_units_from_json_dict
CvUnits.write = write_cv_units
CvUnits.update = update_cv_units
CvUnits.write_many = write_cv_units_many
CvUnits.read = read_cv_units
CvUnits.read_fuzzy = read_cv_units_fuzzy
CvUnits.read_any = read_cv_units_any
CvUnits.read_one = read_cv_units_one
CvUnits.read_one_or_none = read_cv_units_one_or_none
CvUnits.read_all = read_cv_units_all
CvUnits.delete = delete_cv_units_by_id
CvUnits.read_by_id = read_cv_units_by_id
CvUnits.delete_by_id = delete_cv_units_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Affiliations:
    """
    Describes affiliations of people with organizations.

    @param affiliation_id 
    @param person_id 
    @param organization_id 
    @param is_primary_organization_contact 
    @param affiliation_start_date 
    @param affiliation_end_date 
    @param phone 
    @param email 
    @param address 
    @param city 
    @param state_province 
    @param postal_code 
    @param country 
    @param person_link 
    @param job_title 

    This is an automatically generated class
    """
    person_id: int # person_id integer (default: )
    affiliation_id: Optional[int] = None # affiliation_id integer (default: )
    organization_id: Optional[int] = None # organization_id integer (default: )
    is_primary_organization_contact: Optional[bool] = None # is_primary_organization_contact boolean (default: )
    affiliation_start_date: Optional[datetime.date] = None # affiliation_start_date date (default: )
    affiliation_end_date: Optional[datetime.date] = None # affiliation_end_date date (default: )
    phone: Optional[str] = None # phone character varying (default: )
    email: Optional[str] = None # email character varying (default: )
    address: Optional[str] = None # address character varying (default: )
    city: Optional[str] = None # city character varying (default: )
    state_province: Optional[str] = None # state_province character varying (default: )
    postal_code: Optional[str] = None # postal_code character varying (default: )
    country: Optional[str] = None # country character varying (default: )
    person_link: Optional[str] = None # person_link character varying (default: )
    job_title: Optional[str] = None # job_title character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'affiliation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.affiliation_start_date is not None:
            obj['affiliation_start_date'] = self.affiliation_start_date.isoformat()
        if self.affiliation_end_date is not None:
            obj['affiliation_end_date'] = self.affiliation_end_date.isoformat()
        return obj

    @beartype.beartype
    def get_organization(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.organization_id)

    @beartype.beartype
    def get_person(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.person_id)

@beartype.beartype
def create_affiliations_from_json_dict(json_obj: dict):
        """
        Create a Affiliations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'affiliation_start_date' in json_obj and json_obj['affiliation_start_date'] is not None:
            json_obj['affiliation_start_date'] = datetime.date.fromisoformat(json_obj['affiliation_start_date'])
        if 'affiliation_end_date' in json_obj and json_obj['affiliation_end_date'] is not None:
            json_obj['affiliation_end_date'] = datetime.date.fromisoformat(json_obj['affiliation_end_date'])
        return Affiliations(**json_obj)


@beartype.beartype
def write_affiliations_obj(con: db.Connection, obj: Affiliations) -> int:
    """
    Write a Affiliations object to the database
    @param con: database connection
    @param obj: Affiliations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'affiliations', dataclasses.asdict(obj))

@beartype.beartype
def write_affiliations(
            con: db.Connection,
            person_id: int,
            affiliation_id: Optional[int] = None,
            organization_id: Optional[int] = None,
            is_primary_organization_contact: Optional[bool] = None,
            affiliation_start_date: Optional[datetime.date] = None,
            affiliation_end_date: Optional[datetime.date] = None,
            phone: Optional[str] = None,
            email: Optional[str] = None,
            address: Optional[str] = None,
            city: Optional[str] = None,
            state_province: Optional[str] = None,
            postal_code: Optional[str] = None,
            country: Optional[str] = None,
            person_link: Optional[str] = None,
            job_title: Optional[str] = None) -> int:
    """
    Write to the affiliations table in the database
    @param con: database connection
    @param affiliation_id 
    @param person_id 
    @param organization_id 
    @param is_primary_organization_contact 
    @param affiliation_start_date 
    @param affiliation_end_date 
    @param phone 
    @param email 
    @param address 
    @param city 
    @param state_province 
    @param postal_code 
    @param country 
    @param person_link 
    @param job_title 
    @return id of the inserted/updated row
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    return db.upsert(con, 'affiliations', data)

@beartype.beartype
def write_affiliations_many(con: db.Connection, objs: List[Affiliations], upsert: bool = False) -> int:
    """
    Write a list of Affiliations objects to the database
    @param con: database connection
    @param objs: list of Affiliations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'affiliations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_affiliations(con: db.Connection, affiliation_id: int,
            person_id: Optional[int] = None,
            organization_id: Optional[int] = None,
            is_primary_organization_contact: Optional[bool] = None,
            affiliation_start_date: Optional[datetime.date] = None,
            affiliation_end_date: Optional[datetime.date] = None,
            phone: Optional[str] = None,
            email: Optional[str] = None,
            address: Optional[str] = None,
            city: Optional[str] = None,
            state_province: Optional[str] = None,
            postal_code: Optional[str] = None,
            country: Optional[str] = None,
            person_link: Optional[str] = None,
            job_title: Optional[str] = None) -> int:
    """
    Update a row in the affiliations table in the database
    @param con: database connection
    @param affiliation_id 
    @param person_id 
    @param organization_id 
    @param is_primary_organization_contact 
    @param affiliation_start_date 
    @param affiliation_end_date 
    @param phone 
    @param email 
    @param address 
    @param city 
    @param state_province 
    @param postal_code 
    @param country 
    @param person_link 
    @param job_title 
    @return The number of rows updated
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    return db.update(con, 'affiliations', data)

@beartype.beartype
def read_affiliations(
            con: db.Connection,
            person_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             organization_id: Optional[int] = None,
             is_primary_organization_contact: Optional[bool] = None,
             affiliation_start_date: Optional[datetime.date] = None,
             affiliation_end_date: Optional[datetime.date] = None,
             phone: Optional[str] = None,
             email: Optional[str] = None,
             address: Optional[str] = None,
             city: Optional[str] = None,
             state_province: Optional[str] = None,
             postal_code: Optional[str] = None,
             country: Optional[str] = None,
             person_link: Optional[str] = None,
             job_title: Optional[str] = None) -> Generator[Affiliations, None, None]:
    """
    Read from the affiliations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param affiliation_id 
    @param person_id 
    @param organization_id 
    @param is_primary_organization_contact 
    @param affiliation_start_date 
    @param affiliation_end_date 
    @param phone 
    @param email 
    @param address 
    @param city 
    @param state_province 
    @param postal_code 
    @param country 
    @param person_link 
    @param job_title 
    @return generator of Affiliations objects
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    result = db.query(con, 'affiliations', data)
    for row in result:
        yield Affiliations(**row.as_dict())

@beartype.beartype
def read_affiliations_fuzzy(con: db.Connection, person_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             organization_id: Optional[int] = None,
             is_primary_organization_contact: Optional[bool] = None,
             affiliation_start_date: Optional[datetime.date] = None,
             affiliation_end_date: Optional[datetime.date] = None,
             phone: Optional[str] = None,
             email: Optional[str] = None,
             address: Optional[str] = None,
             city: Optional[str] = None,
             state_province: Optional[str] = None,
             postal_code: Optional[str] = None,
             country: Optional[str] = None,
             person_link: Optional[str] = None,
             job_title: Optional[str] = None) -> Generator[Affiliations, None, None]:
    """
    Read from the affiliations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param affiliation_id 
    @param person_id 
    @param organization_id 
    @param is_primary_organization_contact 
    @param affiliation_start_date 
    @param affiliation_end_date 
    @param phone 
    @param email 
    @param address 
    @param city 
    @param state_province 
    @param postal_code 
    @param country 
    @param person_link 
    @param job_title 
    @return generator of Affiliations objects
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    result = db.query_fuzzy(con, 'affiliations', data)
    for row in result:
        yield Affiliations(**row.as_dict())

@beartype.beartype
def read_affiliations_any(con: db.Connection, person_id: Optional[List[int]] = None,
             affiliation_id: Optional[List[int]] = None,
             organization_id: Optional[List[int]] = None,
             is_primary_organization_contact: Optional[List[bool]] = None,
             affiliation_start_date: Optional[List[datetime.date]] = None,
             affiliation_end_date: Optional[List[datetime.date]] = None,
             phone: Optional[List[str]] = None,
             email: Optional[List[str]] = None,
             address: Optional[List[str]] = None,
             city: Optional[List[str]] = None,
             state_province: Optional[List[str]] = None,
             postal_code: Optional[List[str]] = None,
             country: Optional[List[str]] = None,
             person_link: Optional[List[str]] = None,
             job_title: Optional[List[str]] = None) -> Generator[Affiliations, None, None]:
    """
    Read from the affiliations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param affiliation_id 
    @param person_id 
    @param organization_id 
    @param is_primary_organization_contact 
    @param affiliation_start_date 
    @param affiliation_end_date 
    @param phone 
    @param email 
    @param address 
    @param city 
    @param state_province 
    @param postal_code 
    @param country 
    @param person_link 
    @param job_title 
    @return generator of Affiliations objects
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    result = db.query_any(con, 'affiliations', data)
    for row in result:
        yield Affiliations(**row.as_dict())

@beartype.beartype
def read_affiliations_one_or_none(con: db.Connection, person_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             organization_id: Optional[int] = None,
             is_primary_organization_contact: Optional[bool] = None,
             affiliation_start_date: Optional[datetime.date] = None,
             affiliation_end_date: Optional[datetime.date] = None,
             phone: Optional[str] = None,
             email: Optional[str] = None,
             address: Optional[str] = None,
             city: Optional[str] = None,
             state_province: Optional[str] = None,
             postal_code: Optional[str] = None,
             country: Optional[str] = None,
             person_link: Optional[str] = None,
             job_title: Optional[str] = None) -> Optional[Affiliations]:
    """
    Read from the affiliations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    result = db.query_one_or_none(con, 'affiliations', data)
    if result is None:
        return None
    return Affiliations(**result)

@beartype.beartype
def read_affiliations_one(con: db.Connection, person_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             organization_id: Optional[int] = None,
             is_primary_organization_contact: Optional[bool] = None,
             affiliation_start_date: Optional[datetime.date] = None,
             affiliation_end_date: Optional[datetime.date] = None,
             phone: Optional[str] = None,
             email: Optional[str] = None,
             address: Optional[str] = None,
             city: Optional[str] = None,
             state_province: Optional[str] = None,
             postal_code: Optional[str] = None,
             country: Optional[str] = None,
             person_link: Optional[str] = None,
             job_title: Optional[str] = None) -> Affiliations:
    """
    Read from the affiliations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    result = db.query_one(con, 'affiliations', data)
    return Affiliations(**result)

@beartype.beartype
def read_affiliations_all(con: db.Connection, person_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             organization_id: Optional[int] = None,
             is_primary_organization_contact: Optional[bool] = None,
             affiliation_start_date: Optional[datetime.date] = None,
             affiliation_end_date: Optional[datetime.date] = None,
             phone: Optional[str] = None,
             email: Optional[str] = None,
             address: Optional[str] = None,
             city: Optional[str] = None,
             state_province: Optional[str] = None,
             postal_code: Optional[str] = None,
             country: Optional[str] = None,
             person_link: Optional[str] = None,
             job_title: Optional[str] = None) -> List[Affiliations]:
    """
    Read from the affiliations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'affiliation_id': affiliation_id,
        'person_id': person_id,
        'organization_id': organization_id,
        'is_primary_organization_contact': is_primary_organization_contact,
        'affiliation_start_date': affiliation_start_date,
        'affiliation_end_date': affiliation_end_date,
        'phone': phone,
        'email': email,
        'address': address,
        'city': city,
        'state_province': state_province,
        'postal_code': postal_code,
        'country': country,
        'person_link': person_link,
        'job_title': job_title,
    }
    result = db.query(con, 'affiliations', data)
    return [Affiliations(**row.as_dict()) for row in result]

@beartype.beartype
def read_affiliations_by_id(con: db.Connection, affiliation_id: int) -> Optional[Affiliations]:
    result = db.query_one(con, 'affiliations', {'affiliation_id': affiliation_id})
    if result is None:
        return None
    return Affiliations(**result)

@beartype.beartype
def delete_affiliations_by_id(con: db.Connection, affiliation_id: int):
    db.delete(con, 'affiliations', {'affiliation_id': affiliation_id})
# Associate the functions with the class
Affiliations.create_from_json_dict = create_affiliations_from_json_dict
Affiliations.write = write_affiliations
Affiliations.update = update_affiliations
Affiliations.write_many = write_affiliations_many
Affiliations.read = read_affiliations
Affiliations.read_fuzzy = read_affiliations_fuzzy
Affiliations.read_any = read_affiliations_any
Affiliations.read_one = read_affiliations_one
Affiliations.read_one_or_none = read_affiliations_one_or_none
Affiliations.read_all = read_affiliations_all
Affiliations.delete = delete_affiliations_by_id
Affiliations.read_by_id = read_affiliations_by_id
Affiliations.delete_by_id = delete_affiliations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class UnitsQuantityKindBridge:
    """
    @param bridge_id 
    @param units_id 
    @param term 

    This is an automatically generated class
    """
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    units_id: Optional[int] = None # units_id integer (default: )
    term: Optional[str] = None # term character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_term(self, con: db.Connection) -> Optional['CvQuantityKind']:
        return read_cv_quantity_kind_one_or_none(con, term=self.term)

    @beartype.beartype
    def get_units(self, con: db.Connection) -> Optional['CvUnits']:
        return read_cv_units_one_or_none(con, units_id=self.units_id)

@beartype.beartype
def create_units_quantity_kind_bridge_from_json_dict(json_obj: dict):
        """
        Create a UnitsQuantityKindBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return UnitsQuantityKindBridge(**json_obj)


@beartype.beartype
def write_units_quantity_kind_bridge_obj(con: db.Connection, obj: UnitsQuantityKindBridge) -> int:
    """
    Write a UnitsQuantityKindBridge object to the database
    @param con: database connection
    @param obj: UnitsQuantityKindBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'units_quantity_kind_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_units_quantity_kind_bridge(
            con: db.Connection,
            bridge_id: Optional[int] = None,
            units_id: Optional[int] = None,
            term: Optional[str] = None) -> int:
    """
    Write to the units_quantity_kind_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param units_id 
    @param term 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    return db.upsert(con, 'units_quantity_kind_bridge', data)

@beartype.beartype
def write_units_quantity_kind_bridge_many(con: db.Connection, objs: List[UnitsQuantityKindBridge], upsert: bool = False) -> int:
    """
    Write a list of UnitsQuantityKindBridge objects to the database
    @param con: database connection
    @param objs: list of UnitsQuantityKindBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'units_quantity_kind_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_units_quantity_kind_bridge(con: db.Connection, bridge_id: int,
            units_id: Optional[int] = None,
            term: Optional[str] = None) -> int:
    """
    Update a row in the units_quantity_kind_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param units_id 
    @param term 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    return db.update(con, 'units_quantity_kind_bridge', data)

@beartype.beartype
def read_units_quantity_kind_bridge(
            con: db.Connection,
            bridge_id: Optional[int] = None,
             units_id: Optional[int] = None,
             term: Optional[str] = None) -> Generator[UnitsQuantityKindBridge, None, None]:
    """
    Read from the units_quantity_kind_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param units_id 
    @param term 
    @return generator of UnitsQuantityKindBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    result = db.query(con, 'units_quantity_kind_bridge', data)
    for row in result:
        yield UnitsQuantityKindBridge(**row.as_dict())

@beartype.beartype
def read_units_quantity_kind_bridge_fuzzy(con: db.Connection, bridge_id: Optional[int] = None,
             units_id: Optional[int] = None,
             term: Optional[str] = None) -> Generator[UnitsQuantityKindBridge, None, None]:
    """
    Read from the units_quantity_kind_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param units_id 
    @param term 
    @return generator of UnitsQuantityKindBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    result = db.query_fuzzy(con, 'units_quantity_kind_bridge', data)
    for row in result:
        yield UnitsQuantityKindBridge(**row.as_dict())

@beartype.beartype
def read_units_quantity_kind_bridge_any(con: db.Connection, bridge_id: Optional[List[int]] = None,
             units_id: Optional[List[int]] = None,
             term: Optional[List[str]] = None) -> Generator[UnitsQuantityKindBridge, None, None]:
    """
    Read from the units_quantity_kind_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param units_id 
    @param term 
    @return generator of UnitsQuantityKindBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    result = db.query_any(con, 'units_quantity_kind_bridge', data)
    for row in result:
        yield UnitsQuantityKindBridge(**row.as_dict())

@beartype.beartype
def read_units_quantity_kind_bridge_one_or_none(con: db.Connection, bridge_id: Optional[int] = None,
             units_id: Optional[int] = None,
             term: Optional[str] = None) -> Optional[UnitsQuantityKindBridge]:
    """
    Read from the units_quantity_kind_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    result = db.query_one_or_none(con, 'units_quantity_kind_bridge', data)
    if result is None:
        return None
    return UnitsQuantityKindBridge(**result)

@beartype.beartype
def read_units_quantity_kind_bridge_one(con: db.Connection, bridge_id: Optional[int] = None,
             units_id: Optional[int] = None,
             term: Optional[str] = None) -> UnitsQuantityKindBridge:
    """
    Read from the units_quantity_kind_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    result = db.query_one(con, 'units_quantity_kind_bridge', data)
    return UnitsQuantityKindBridge(**result)

@beartype.beartype
def read_units_quantity_kind_bridge_all(con: db.Connection, bridge_id: Optional[int] = None,
             units_id: Optional[int] = None,
             term: Optional[str] = None) -> List[UnitsQuantityKindBridge]:
    """
    Read from the units_quantity_kind_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'units_id': units_id,
        'term': term,
    }
    result = db.query(con, 'units_quantity_kind_bridge', data)
    return [UnitsQuantityKindBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_units_quantity_kind_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[UnitsQuantityKindBridge]:
    result = db.query_one(con, 'units_quantity_kind_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return UnitsQuantityKindBridge(**result)

@beartype.beartype
def delete_units_quantity_kind_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'units_quantity_kind_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
UnitsQuantityKindBridge.create_from_json_dict = create_units_quantity_kind_bridge_from_json_dict
UnitsQuantityKindBridge.write = write_units_quantity_kind_bridge
UnitsQuantityKindBridge.update = update_units_quantity_kind_bridge
UnitsQuantityKindBridge.write_many = write_units_quantity_kind_bridge_many
UnitsQuantityKindBridge.read = read_units_quantity_kind_bridge
UnitsQuantityKindBridge.read_fuzzy = read_units_quantity_kind_bridge_fuzzy
UnitsQuantityKindBridge.read_any = read_units_quantity_kind_bridge_any
UnitsQuantityKindBridge.read_one = read_units_quantity_kind_bridge_one
UnitsQuantityKindBridge.read_one_or_none = read_units_quantity_kind_bridge_one_or_none
UnitsQuantityKindBridge.read_all = read_units_quantity_kind_bridge_all
UnitsQuantityKindBridge.delete = delete_units_quantity_kind_bridge_by_id
UnitsQuantityKindBridge.read_by_id = read_units_quantity_kind_bridge_by_id
UnitsQuantityKindBridge.delete_by_id = delete_units_quantity_kind_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Datasets:
    """
    Describes groupings of observation results that can be considered datasets

    @param dataset_id 
    @param dataset_uuid 
    @param dataset_type_cv 
    @param dataset_code 
    @param dataset_title 
    @param dataset_abstract 

    This is an automatically generated class
    """
    dataset_uuid: str # dataset_uuid oid (default: )
    dataset_type_cv: str # dataset_type_cv character varying (default: )
    dataset_code: str # dataset_code character varying (default: )
    dataset_title: str # dataset_title character varying (default: )
    dataset_abstract: str # dataset_abstract character varying (default: )
    dataset_id: Optional[int] = None # dataset_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'dataset_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_dataset_type_cv(self, con: db.Connection) -> Optional['CvDatasetType']:
        return read_cv_dataset_type_one_or_none(con, term=self.dataset_type_cv)

@beartype.beartype
def create_datasets_from_json_dict(json_obj: dict):
        """
        Create a Datasets from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Datasets(**json_obj)


@beartype.beartype
def write_datasets_obj(con: db.Connection, obj: Datasets) -> int:
    """
    Write a Datasets object to the database
    @param con: database connection
    @param obj: Datasets object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datasets', dataclasses.asdict(obj))

@beartype.beartype
def write_datasets(
            con: db.Connection,
            dataset_uuid: str,
            dataset_type_cv: str,
            dataset_code: str,
            dataset_title: str,
            dataset_abstract: str,
            dataset_id: Optional[int] = None) -> int:
    """
    Write to the datasets table in the database
    @param con: database connection
    @param dataset_id 
    @param dataset_uuid 
    @param dataset_type_cv 
    @param dataset_code 
    @param dataset_title 
    @param dataset_abstract 
    @return id of the inserted/updated row
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    return db.upsert(con, 'datasets', data)

@beartype.beartype
def write_datasets_many(con: db.Connection, objs: List[Datasets], upsert: bool = False) -> int:
    """
    Write a list of Datasets objects to the database
    @param con: database connection
    @param objs: list of Datasets objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datasets', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datasets(con: db.Connection, dataset_id: int,
            dataset_uuid: Optional[str] = None,
            dataset_type_cv: Optional[str] = None,
            dataset_code: Optional[str] = None,
            dataset_title: Optional[str] = None,
            dataset_abstract: Optional[str] = None) -> int:
    """
    Update a row in the datasets table in the database
    @param con: database connection
    @param dataset_id 
    @param dataset_uuid 
    @param dataset_type_cv 
    @param dataset_code 
    @param dataset_title 
    @param dataset_abstract 
    @return The number of rows updated
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    return db.update(con, 'datasets', data)

@beartype.beartype
def read_datasets(
            con: db.Connection,
            dataset_uuid: Optional[str] = None,
             dataset_type_cv: Optional[str] = None,
             dataset_code: Optional[str] = None,
             dataset_title: Optional[str] = None,
             dataset_abstract: Optional[str] = None,
             dataset_id: Optional[int] = None) -> Generator[Datasets, None, None]:
    """
    Read from the datasets table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param dataset_id 
    @param dataset_uuid 
    @param dataset_type_cv 
    @param dataset_code 
    @param dataset_title 
    @param dataset_abstract 
    @return generator of Datasets objects
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    result = db.query(con, 'datasets', data)
    for row in result:
        yield Datasets(**row.as_dict())

@beartype.beartype
def read_datasets_fuzzy(con: db.Connection, dataset_uuid: Optional[str] = None,
             dataset_type_cv: Optional[str] = None,
             dataset_code: Optional[str] = None,
             dataset_title: Optional[str] = None,
             dataset_abstract: Optional[str] = None,
             dataset_id: Optional[int] = None) -> Generator[Datasets, None, None]:
    """
    Read from the datasets table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param dataset_id 
    @param dataset_uuid 
    @param dataset_type_cv 
    @param dataset_code 
    @param dataset_title 
    @param dataset_abstract 
    @return generator of Datasets objects
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    result = db.query_fuzzy(con, 'datasets', data)
    for row in result:
        yield Datasets(**row.as_dict())

@beartype.beartype
def read_datasets_any(con: db.Connection, dataset_uuid: Optional[List[str]] = None,
             dataset_type_cv: Optional[List[str]] = None,
             dataset_code: Optional[List[str]] = None,
             dataset_title: Optional[List[str]] = None,
             dataset_abstract: Optional[List[str]] = None,
             dataset_id: Optional[List[int]] = None) -> Generator[Datasets, None, None]:
    """
    Read from the datasets table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param dataset_id 
    @param dataset_uuid 
    @param dataset_type_cv 
    @param dataset_code 
    @param dataset_title 
    @param dataset_abstract 
    @return generator of Datasets objects
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    result = db.query_any(con, 'datasets', data)
    for row in result:
        yield Datasets(**row.as_dict())

@beartype.beartype
def read_datasets_one_or_none(con: db.Connection, dataset_uuid: Optional[str] = None,
             dataset_type_cv: Optional[str] = None,
             dataset_code: Optional[str] = None,
             dataset_title: Optional[str] = None,
             dataset_abstract: Optional[str] = None,
             dataset_id: Optional[int] = None) -> Optional[Datasets]:
    """
    Read from the datasets table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    result = db.query_one_or_none(con, 'datasets', data)
    if result is None:
        return None
    return Datasets(**result)

@beartype.beartype
def read_datasets_one(con: db.Connection, dataset_uuid: Optional[str] = None,
             dataset_type_cv: Optional[str] = None,
             dataset_code: Optional[str] = None,
             dataset_title: Optional[str] = None,
             dataset_abstract: Optional[str] = None,
             dataset_id: Optional[int] = None) -> Datasets:
    """
    Read from the datasets table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    result = db.query_one(con, 'datasets', data)
    return Datasets(**result)

@beartype.beartype
def read_datasets_all(con: db.Connection, dataset_uuid: Optional[str] = None,
             dataset_type_cv: Optional[str] = None,
             dataset_code: Optional[str] = None,
             dataset_title: Optional[str] = None,
             dataset_abstract: Optional[str] = None,
             dataset_id: Optional[int] = None) -> List[Datasets]:
    """
    Read from the datasets table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'dataset_id': dataset_id,
        'dataset_uuid': dataset_uuid,
        'dataset_type_cv': dataset_type_cv,
        'dataset_code': dataset_code,
        'dataset_title': dataset_title,
        'dataset_abstract': dataset_abstract,
    }
    result = db.query(con, 'datasets', data)
    return [Datasets(**row.as_dict()) for row in result]

@beartype.beartype
def read_datasets_by_id(con: db.Connection, dataset_id: int) -> Optional[Datasets]:
    result = db.query_one(con, 'datasets', {'dataset_id': dataset_id})
    if result is None:
        return None
    return Datasets(**result)

@beartype.beartype
def delete_datasets_by_id(con: db.Connection, dataset_id: int):
    db.delete(con, 'datasets', {'dataset_id': dataset_id})
# Associate the functions with the class
Datasets.create_from_json_dict = create_datasets_from_json_dict
Datasets.write = write_datasets
Datasets.update = update_datasets
Datasets.write_many = write_datasets_many
Datasets.read = read_datasets
Datasets.read_fuzzy = read_datasets_fuzzy
Datasets.read_any = read_datasets_any
Datasets.read_one = read_datasets_one
Datasets.read_one_or_none = read_datasets_one_or_none
Datasets.read_all = read_datasets_all
Datasets.delete = delete_datasets_by_id
Datasets.read_by_id = read_datasets_by_id
Datasets.delete_by_id = delete_datasets_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DatasetsResults:
    """
    Lists the Results that are grouped into a DataSet

    @param bridge_id 
    @param dataset_id 
    @param result_id 

    This is an automatically generated class
    """
    dataset_id: int # dataset_id integer (default: )
    result_id: int # result_id bigint (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_dataset(self, con: db.Connection) -> Optional['Datasets']:
        return read_datasets_one_or_none(con, dataset_id=self.dataset_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_datasets_results_from_json_dict(json_obj: dict):
        """
        Create a DatasetsResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DatasetsResults(**json_obj)


@beartype.beartype
def write_datasets_results_obj(con: db.Connection, obj: DatasetsResults) -> int:
    """
    Write a DatasetsResults object to the database
    @param con: database connection
    @param obj: DatasetsResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datasets_results', dataclasses.asdict(obj))

@beartype.beartype
def write_datasets_results(
            con: db.Connection,
            dataset_id: int,
            result_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the datasets_results table in the database
    @param con: database connection
    @param bridge_id 
    @param dataset_id 
    @param result_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    return db.upsert(con, 'datasets_results', data)

@beartype.beartype
def write_datasets_results_many(con: db.Connection, objs: List[DatasetsResults], upsert: bool = False) -> int:
    """
    Write a list of DatasetsResults objects to the database
    @param con: database connection
    @param objs: list of DatasetsResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datasets_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datasets_results(con: db.Connection, bridge_id: int,
            dataset_id: Optional[int] = None,
            result_id: Optional[int] = None) -> int:
    """
    Update a row in the datasets_results table in the database
    @param con: database connection
    @param bridge_id 
    @param dataset_id 
    @param result_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    return db.update(con, 'datasets_results', data)

@beartype.beartype
def read_datasets_results(
            con: db.Connection,
            dataset_id: Optional[int] = None,
             result_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[DatasetsResults, None, None]:
    """
    Read from the datasets_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param dataset_id 
    @param result_id 
    @return generator of DatasetsResults objects
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    result = db.query(con, 'datasets_results', data)
    for row in result:
        yield DatasetsResults(**row.as_dict())

@beartype.beartype
def read_datasets_results_fuzzy(con: db.Connection, dataset_id: Optional[int] = None,
             result_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[DatasetsResults, None, None]:
    """
    Read from the datasets_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param dataset_id 
    @param result_id 
    @return generator of DatasetsResults objects
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    result = db.query_fuzzy(con, 'datasets_results', data)
    for row in result:
        yield DatasetsResults(**row.as_dict())

@beartype.beartype
def read_datasets_results_any(con: db.Connection, dataset_id: Optional[List[int]] = None,
             result_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[DatasetsResults, None, None]:
    """
    Read from the datasets_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param dataset_id 
    @param result_id 
    @return generator of DatasetsResults objects
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    result = db.query_any(con, 'datasets_results', data)
    for row in result:
        yield DatasetsResults(**row.as_dict())

@beartype.beartype
def read_datasets_results_one_or_none(con: db.Connection, dataset_id: Optional[int] = None,
             result_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[DatasetsResults]:
    """
    Read from the datasets_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    result = db.query_one_or_none(con, 'datasets_results', data)
    if result is None:
        return None
    return DatasetsResults(**result)

@beartype.beartype
def read_datasets_results_one(con: db.Connection, dataset_id: Optional[int] = None,
             result_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> DatasetsResults:
    """
    Read from the datasets_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    result = db.query_one(con, 'datasets_results', data)
    return DatasetsResults(**result)

@beartype.beartype
def read_datasets_results_all(con: db.Connection, dataset_id: Optional[int] = None,
             result_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[DatasetsResults]:
    """
    Read from the datasets_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'dataset_id': dataset_id,
        'result_id': result_id,
    }
    result = db.query(con, 'datasets_results', data)
    return [DatasetsResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_datasets_results_by_id(con: db.Connection, bridge_id: int) -> Optional[DatasetsResults]:
    result = db.query_one(con, 'datasets_results', {'bridge_id': bridge_id})
    if result is None:
        return None
    return DatasetsResults(**result)

@beartype.beartype
def delete_datasets_results_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'datasets_results', {'bridge_id': bridge_id})
# Associate the functions with the class
DatasetsResults.create_from_json_dict = create_datasets_results_from_json_dict
DatasetsResults.write = write_datasets_results
DatasetsResults.update = update_datasets_results
DatasetsResults.write_many = write_datasets_results_many
DatasetsResults.read = read_datasets_results
DatasetsResults.read_fuzzy = read_datasets_results_fuzzy
DatasetsResults.read_any = read_datasets_results_any
DatasetsResults.read_one = read_datasets_results_one
DatasetsResults.read_one_or_none = read_datasets_results_one_or_none
DatasetsResults.read_all = read_datasets_results_all
DatasetsResults.delete = delete_datasets_results_by_id
DatasetsResults.read_by_id = read_datasets_results_by_id
DatasetsResults.delete_by_id = delete_datasets_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class FeatureActions:
    """
    @param feature_action_id 
    @param sampling_feature_id 
    @param action_id 
    @param related_features_relation_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    action_id: int # action_id integer (default: )
    feature_action_id: Optional[int] = None # feature_action_id integer (default: )
    related_features_relation_id: Optional[int] = None # related_features_relation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'feature_action_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_related_features_relation(self, con: db.Connection) -> Optional['RelatedFeatures']:
        return read_related_features_one_or_none(con, relation_id=self.related_features_relation_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_feature_actions_from_json_dict(json_obj: dict):
        """
        Create a FeatureActions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return FeatureActions(**json_obj)


@beartype.beartype
def write_feature_actions_obj(con: db.Connection, obj: FeatureActions) -> int:
    """
    Write a FeatureActions object to the database
    @param con: database connection
    @param obj: FeatureActions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'feature_actions', dataclasses.asdict(obj))

@beartype.beartype
def write_feature_actions(
            con: db.Connection,
            sampling_feature_id: int,
            action_id: int,
            feature_action_id: Optional[int] = None,
            related_features_relation_id: Optional[int] = None) -> int:
    """
    Write to the feature_actions table in the database
    @param con: database connection
    @param feature_action_id 
    @param sampling_feature_id 
    @param action_id 
    @param related_features_relation_id 
    @return id of the inserted/updated row
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    return db.upsert(con, 'feature_actions', data)

@beartype.beartype
def write_feature_actions_many(con: db.Connection, objs: List[FeatureActions], upsert: bool = False) -> int:
    """
    Write a list of FeatureActions objects to the database
    @param con: database connection
    @param objs: list of FeatureActions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'feature_actions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_feature_actions(con: db.Connection, feature_action_id: int,
            sampling_feature_id: Optional[int] = None,
            action_id: Optional[int] = None,
            related_features_relation_id: Optional[int] = None) -> int:
    """
    Update a row in the feature_actions table in the database
    @param con: database connection
    @param feature_action_id 
    @param sampling_feature_id 
    @param action_id 
    @param related_features_relation_id 
    @return The number of rows updated
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    return db.update(con, 'feature_actions', data)

@beartype.beartype
def read_feature_actions(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             action_id: Optional[int] = None,
             feature_action_id: Optional[int] = None,
             related_features_relation_id: Optional[int] = None) -> Generator[FeatureActions, None, None]:
    """
    Read from the feature_actions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param feature_action_id 
    @param sampling_feature_id 
    @param action_id 
    @param related_features_relation_id 
    @return generator of FeatureActions objects
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    result = db.query(con, 'feature_actions', data)
    for row in result:
        yield FeatureActions(**row.as_dict())

@beartype.beartype
def read_feature_actions_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             action_id: Optional[int] = None,
             feature_action_id: Optional[int] = None,
             related_features_relation_id: Optional[int] = None) -> Generator[FeatureActions, None, None]:
    """
    Read from the feature_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param feature_action_id 
    @param sampling_feature_id 
    @param action_id 
    @param related_features_relation_id 
    @return generator of FeatureActions objects
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    result = db.query_fuzzy(con, 'feature_actions', data)
    for row in result:
        yield FeatureActions(**row.as_dict())

@beartype.beartype
def read_feature_actions_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             action_id: Optional[List[int]] = None,
             feature_action_id: Optional[List[int]] = None,
             related_features_relation_id: Optional[List[int]] = None) -> Generator[FeatureActions, None, None]:
    """
    Read from the feature_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param feature_action_id 
    @param sampling_feature_id 
    @param action_id 
    @param related_features_relation_id 
    @return generator of FeatureActions objects
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    result = db.query_any(con, 'feature_actions', data)
    for row in result:
        yield FeatureActions(**row.as_dict())

@beartype.beartype
def read_feature_actions_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             action_id: Optional[int] = None,
             feature_action_id: Optional[int] = None,
             related_features_relation_id: Optional[int] = None) -> Optional[FeatureActions]:
    """
    Read from the feature_actions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    result = db.query_one_or_none(con, 'feature_actions', data)
    if result is None:
        return None
    return FeatureActions(**result)

@beartype.beartype
def read_feature_actions_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             action_id: Optional[int] = None,
             feature_action_id: Optional[int] = None,
             related_features_relation_id: Optional[int] = None) -> FeatureActions:
    """
    Read from the feature_actions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    result = db.query_one(con, 'feature_actions', data)
    return FeatureActions(**result)

@beartype.beartype
def read_feature_actions_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             action_id: Optional[int] = None,
             feature_action_id: Optional[int] = None,
             related_features_relation_id: Optional[int] = None) -> List[FeatureActions]:
    """
    Read from the feature_actions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'feature_action_id': feature_action_id,
        'sampling_feature_id': sampling_feature_id,
        'action_id': action_id,
        'related_features_relation_id': related_features_relation_id,
    }
    result = db.query(con, 'feature_actions', data)
    return [FeatureActions(**row.as_dict()) for row in result]

@beartype.beartype
def read_feature_actions_by_id(con: db.Connection, feature_action_id: int) -> Optional[FeatureActions]:
    result = db.query_one(con, 'feature_actions', {'feature_action_id': feature_action_id})
    if result is None:
        return None
    return FeatureActions(**result)

@beartype.beartype
def delete_feature_actions_by_id(con: db.Connection, feature_action_id: int):
    db.delete(con, 'feature_actions', {'feature_action_id': feature_action_id})
# Associate the functions with the class
FeatureActions.create_from_json_dict = create_feature_actions_from_json_dict
FeatureActions.write = write_feature_actions
FeatureActions.update = update_feature_actions
FeatureActions.write_many = write_feature_actions_many
FeatureActions.read = read_feature_actions
FeatureActions.read_fuzzy = read_feature_actions_fuzzy
FeatureActions.read_any = read_feature_actions_any
FeatureActions.read_one = read_feature_actions_one
FeatureActions.read_one_or_none = read_feature_actions_one_or_none
FeatureActions.read_all = read_feature_actions_all
FeatureActions.delete = delete_feature_actions_by_id
FeatureActions.read_by_id = read_feature_actions_by_id
FeatureActions.delete_by_id = delete_feature_actions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Actions:
    """
    Describes actions (e.g., observation, sample collection, sample analysis, field visits, field activities, etc.)

    @param action_id 
    @param action_type_cv 
    @param action_name 
    @param action_description 
    @param method_id 
    @param begin_date_time 
    @param begin_date_time_utc_offset 
    @param end_date_time 
    @param end_date_time_utc_offset 
    @param action_file_link 

    This is an automatically generated class
    """
    action_type_cv: str # action_type_cv character varying (default: )
    method_id: int # method_id integer (default: )
    begin_date_time: datetime.datetime # begin_date_time timestamp without time zone (default: )
    begin_date_time_utc_offset: int # begin_date_time_utc_offset integer (default: )
    action_id: Optional[int] = None # action_id integer (default: )
    action_name: Optional[str] = None # action_name character varying (default: )
    action_description: Optional[str] = None # action_description character varying (default: )
    end_date_time: Optional[datetime.datetime] = None # end_date_time timestamp without time zone (default: )
    end_date_time_utc_offset: Optional[int] = None # end_date_time_utc_offset integer (default: )
    action_file_link: Optional[str] = None # action_file_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'action_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['begin_date_time'] = self.begin_date_time.isoformat()
        if self.end_date_time is not None:
            obj['end_date_time'] = self.end_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_action_type_cv(self, con: db.Connection) -> Optional['CvActionType']:
        return read_cv_action_type_one_or_none(con, term=self.action_type_cv)

    @beartype.beartype
    def get_method(self, con: db.Connection) -> Optional['Methods']:
        return read_methods_one_or_none(con, method_id=self.method_id)

@beartype.beartype
def create_actions_from_json_dict(json_obj: dict):
        """
        Create a Actions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['begin_date_time'] = datetime.datetime.fromisoformat(json_obj['begin_date_time'])
        if 'end_date_time' in json_obj and json_obj['end_date_time'] is not None:
            json_obj['end_date_time'] = datetime.datetime.fromisoformat(json_obj['end_date_time'])
        return Actions(**json_obj)


@beartype.beartype
def write_actions_obj(con: db.Connection, obj: Actions) -> int:
    """
    Write a Actions object to the database
    @param con: database connection
    @param obj: Actions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'actions', dataclasses.asdict(obj))

@beartype.beartype
def write_actions(
            con: db.Connection,
            action_type_cv: str,
            method_id: int,
            begin_date_time: datetime.datetime,
            begin_date_time_utc_offset: int,
            action_id: Optional[int] = None,
            action_name: Optional[str] = None,
            action_description: Optional[str] = None,
            end_date_time: Optional[datetime.datetime] = None,
            end_date_time_utc_offset: Optional[int] = None,
            action_file_link: Optional[str] = None) -> int:
    """
    Write to the actions table in the database
    @param con: database connection
    @param action_id 
    @param action_type_cv 
    @param action_name 
    @param action_description 
    @param method_id 
    @param begin_date_time 
    @param begin_date_time_utc_offset 
    @param end_date_time 
    @param end_date_time_utc_offset 
    @param action_file_link 
    @return id of the inserted/updated row
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    return db.upsert(con, 'actions', data)

@beartype.beartype
def write_actions_many(con: db.Connection, objs: List[Actions], upsert: bool = False) -> int:
    """
    Write a list of Actions objects to the database
    @param con: database connection
    @param objs: list of Actions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'actions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_actions(con: db.Connection, action_id: int,
            action_type_cv: Optional[str] = None,
            method_id: Optional[int] = None,
            begin_date_time: Optional[datetime.datetime] = None,
            begin_date_time_utc_offset: Optional[int] = None,
            action_name: Optional[str] = None,
            action_description: Optional[str] = None,
            end_date_time: Optional[datetime.datetime] = None,
            end_date_time_utc_offset: Optional[int] = None,
            action_file_link: Optional[str] = None) -> int:
    """
    Update a row in the actions table in the database
    @param con: database connection
    @param action_id 
    @param action_type_cv 
    @param action_name 
    @param action_description 
    @param method_id 
    @param begin_date_time 
    @param begin_date_time_utc_offset 
    @param end_date_time 
    @param end_date_time_utc_offset 
    @param action_file_link 
    @return The number of rows updated
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    return db.update(con, 'actions', data)

@beartype.beartype
def read_actions(
            con: db.Connection,
            action_type_cv: Optional[str] = None,
             method_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             begin_date_time_utc_offset: Optional[int] = None,
             action_id: Optional[int] = None,
             action_name: Optional[str] = None,
             action_description: Optional[str] = None,
             end_date_time: Optional[datetime.datetime] = None,
             end_date_time_utc_offset: Optional[int] = None,
             action_file_link: Optional[str] = None) -> Generator[Actions, None, None]:
    """
    Read from the actions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param action_type_cv 
    @param action_name 
    @param action_description 
    @param method_id 
    @param begin_date_time 
    @param begin_date_time_utc_offset 
    @param end_date_time 
    @param end_date_time_utc_offset 
    @param action_file_link 
    @return generator of Actions objects
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    result = db.query(con, 'actions', data)
    for row in result:
        yield Actions(**row.as_dict())

@beartype.beartype
def read_actions_fuzzy(con: db.Connection, action_type_cv: Optional[str] = None,
             method_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             begin_date_time_utc_offset: Optional[int] = None,
             action_id: Optional[int] = None,
             action_name: Optional[str] = None,
             action_description: Optional[str] = None,
             end_date_time: Optional[datetime.datetime] = None,
             end_date_time_utc_offset: Optional[int] = None,
             action_file_link: Optional[str] = None) -> Generator[Actions, None, None]:
    """
    Read from the actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param action_type_cv 
    @param action_name 
    @param action_description 
    @param method_id 
    @param begin_date_time 
    @param begin_date_time_utc_offset 
    @param end_date_time 
    @param end_date_time_utc_offset 
    @param action_file_link 
    @return generator of Actions objects
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    result = db.query_fuzzy(con, 'actions', data)
    for row in result:
        yield Actions(**row.as_dict())

@beartype.beartype
def read_actions_any(con: db.Connection, action_type_cv: Optional[List[str]] = None,
             method_id: Optional[List[int]] = None,
             begin_date_time: Optional[List[datetime.datetime]] = None,
             begin_date_time_utc_offset: Optional[List[int]] = None,
             action_id: Optional[List[int]] = None,
             action_name: Optional[List[str]] = None,
             action_description: Optional[List[str]] = None,
             end_date_time: Optional[List[datetime.datetime]] = None,
             end_date_time_utc_offset: Optional[List[int]] = None,
             action_file_link: Optional[List[str]] = None) -> Generator[Actions, None, None]:
    """
    Read from the actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param action_type_cv 
    @param action_name 
    @param action_description 
    @param method_id 
    @param begin_date_time 
    @param begin_date_time_utc_offset 
    @param end_date_time 
    @param end_date_time_utc_offset 
    @param action_file_link 
    @return generator of Actions objects
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    result = db.query_any(con, 'actions', data)
    for row in result:
        yield Actions(**row.as_dict())

@beartype.beartype
def read_actions_one_or_none(con: db.Connection, action_type_cv: Optional[str] = None,
             method_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             begin_date_time_utc_offset: Optional[int] = None,
             action_id: Optional[int] = None,
             action_name: Optional[str] = None,
             action_description: Optional[str] = None,
             end_date_time: Optional[datetime.datetime] = None,
             end_date_time_utc_offset: Optional[int] = None,
             action_file_link: Optional[str] = None) -> Optional[Actions]:
    """
    Read from the actions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    result = db.query_one_or_none(con, 'actions', data)
    if result is None:
        return None
    return Actions(**result)

@beartype.beartype
def read_actions_one(con: db.Connection, action_type_cv: Optional[str] = None,
             method_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             begin_date_time_utc_offset: Optional[int] = None,
             action_id: Optional[int] = None,
             action_name: Optional[str] = None,
             action_description: Optional[str] = None,
             end_date_time: Optional[datetime.datetime] = None,
             end_date_time_utc_offset: Optional[int] = None,
             action_file_link: Optional[str] = None) -> Actions:
    """
    Read from the actions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    result = db.query_one(con, 'actions', data)
    return Actions(**result)

@beartype.beartype
def read_actions_all(con: db.Connection, action_type_cv: Optional[str] = None,
             method_id: Optional[int] = None,
             begin_date_time: Optional[datetime.datetime] = None,
             begin_date_time_utc_offset: Optional[int] = None,
             action_id: Optional[int] = None,
             action_name: Optional[str] = None,
             action_description: Optional[str] = None,
             end_date_time: Optional[datetime.datetime] = None,
             end_date_time_utc_offset: Optional[int] = None,
             action_file_link: Optional[str] = None) -> List[Actions]:
    """
    Read from the actions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'action_type_cv': action_type_cv,
        'action_name': action_name,
        'action_description': action_description,
        'method_id': method_id,
        'begin_date_time': begin_date_time,
        'begin_date_time_utc_offset': begin_date_time_utc_offset,
        'end_date_time': end_date_time,
        'end_date_time_utc_offset': end_date_time_utc_offset,
        'action_file_link': action_file_link,
    }
    result = db.query(con, 'actions', data)
    return [Actions(**row.as_dict()) for row in result]

@beartype.beartype
def read_actions_by_id(con: db.Connection, action_id: int) -> Optional[Actions]:
    result = db.query_one(con, 'actions', {'action_id': action_id})
    if result is None:
        return None
    return Actions(**result)

@beartype.beartype
def delete_actions_by_id(con: db.Connection, action_id: int):
    db.delete(con, 'actions', {'action_id': action_id})
# Associate the functions with the class
Actions.create_from_json_dict = create_actions_from_json_dict
Actions.write = write_actions
Actions.update = update_actions
Actions.write_many = write_actions_many
Actions.read = read_actions
Actions.read_fuzzy = read_actions_fuzzy
Actions.read_any = read_actions_any
Actions.read_one = read_actions_one
Actions.read_one_or_none = read_actions_one_or_none
Actions.read_all = read_actions_all
Actions.delete = delete_actions_by_id
Actions.read_by_id = read_actions_by_id
Actions.delete_by_id = delete_actions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ActionBy:
    """
    Affiliates people with actions and describes thier role in the action.

    @param bridge_id 
    @param action_id 
    @param affiliation_id 
    @param is_action_lead 
    @param role_description 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    affiliation_id: int # affiliation_id integer (default: )
    is_action_lead: bool # is_action_lead boolean (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    role_description: Optional[str] = None # role_description character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_affiliation(self, con: db.Connection) -> Optional['Affiliations']:
        return read_affiliations_one_or_none(con, affiliation_id=self.affiliation_id)

@beartype.beartype
def create_action_by_from_json_dict(json_obj: dict):
        """
        Create a ActionBy from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ActionBy(**json_obj)


@beartype.beartype
def write_action_by_obj(con: db.Connection, obj: ActionBy) -> int:
    """
    Write a ActionBy object to the database
    @param con: database connection
    @param obj: ActionBy object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'action_by', dataclasses.asdict(obj))

@beartype.beartype
def write_action_by(
            con: db.Connection,
            action_id: int,
            affiliation_id: int,
            is_action_lead: bool,
            bridge_id: Optional[int] = None,
            role_description: Optional[str] = None) -> int:
    """
    Write to the action_by table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param affiliation_id 
    @param is_action_lead 
    @param role_description 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    return db.upsert(con, 'action_by', data)

@beartype.beartype
def write_action_by_many(con: db.Connection, objs: List[ActionBy], upsert: bool = False) -> int:
    """
    Write a list of ActionBy objects to the database
    @param con: database connection
    @param objs: list of ActionBy objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'action_by', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_action_by(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            affiliation_id: Optional[int] = None,
            is_action_lead: Optional[bool] = None,
            role_description: Optional[str] = None) -> int:
    """
    Update a row in the action_by table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param affiliation_id 
    @param is_action_lead 
    @param role_description 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    return db.update(con, 'action_by', data)

@beartype.beartype
def read_action_by(
            con: db.Connection,
            action_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             is_action_lead: Optional[bool] = None,
             bridge_id: Optional[int] = None,
             role_description: Optional[str] = None) -> Generator[ActionBy, None, None]:
    """
    Read from the action_by table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param affiliation_id 
    @param is_action_lead 
    @param role_description 
    @return generator of ActionBy objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    result = db.query(con, 'action_by', data)
    for row in result:
        yield ActionBy(**row.as_dict())

@beartype.beartype
def read_action_by_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             is_action_lead: Optional[bool] = None,
             bridge_id: Optional[int] = None,
             role_description: Optional[str] = None) -> Generator[ActionBy, None, None]:
    """
    Read from the action_by table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param affiliation_id 
    @param is_action_lead 
    @param role_description 
    @return generator of ActionBy objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    result = db.query_fuzzy(con, 'action_by', data)
    for row in result:
        yield ActionBy(**row.as_dict())

@beartype.beartype
def read_action_by_any(con: db.Connection, action_id: Optional[List[int]] = None,
             affiliation_id: Optional[List[int]] = None,
             is_action_lead: Optional[List[bool]] = None,
             bridge_id: Optional[List[int]] = None,
             role_description: Optional[List[str]] = None) -> Generator[ActionBy, None, None]:
    """
    Read from the action_by table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param affiliation_id 
    @param is_action_lead 
    @param role_description 
    @return generator of ActionBy objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    result = db.query_any(con, 'action_by', data)
    for row in result:
        yield ActionBy(**row.as_dict())

@beartype.beartype
def read_action_by_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             is_action_lead: Optional[bool] = None,
             bridge_id: Optional[int] = None,
             role_description: Optional[str] = None) -> Optional[ActionBy]:
    """
    Read from the action_by table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    result = db.query_one_or_none(con, 'action_by', data)
    if result is None:
        return None
    return ActionBy(**result)

@beartype.beartype
def read_action_by_one(con: db.Connection, action_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             is_action_lead: Optional[bool] = None,
             bridge_id: Optional[int] = None,
             role_description: Optional[str] = None) -> ActionBy:
    """
    Read from the action_by table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    result = db.query_one(con, 'action_by', data)
    return ActionBy(**result)

@beartype.beartype
def read_action_by_all(con: db.Connection, action_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             is_action_lead: Optional[bool] = None,
             bridge_id: Optional[int] = None,
             role_description: Optional[str] = None) -> List[ActionBy]:
    """
    Read from the action_by table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'affiliation_id': affiliation_id,
        'is_action_lead': is_action_lead,
        'role_description': role_description,
    }
    result = db.query(con, 'action_by', data)
    return [ActionBy(**row.as_dict()) for row in result]

@beartype.beartype
def read_action_by_by_id(con: db.Connection, bridge_id: int) -> Optional[ActionBy]:
    result = db.query_one(con, 'action_by', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ActionBy(**result)

@beartype.beartype
def delete_action_by_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'action_by', {'bridge_id': bridge_id})
# Associate the functions with the class
ActionBy.create_from_json_dict = create_action_by_from_json_dict
ActionBy.write = write_action_by
ActionBy.update = update_action_by
ActionBy.write_many = write_action_by_many
ActionBy.read = read_action_by
ActionBy.read_fuzzy = read_action_by_fuzzy
ActionBy.read_any = read_action_by_any
ActionBy.read_one = read_action_by_one
ActionBy.read_one_or_none = read_action_by_one_or_none
ActionBy.read_all = read_action_by_all
ActionBy.delete = delete_action_by_by_id
ActionBy.read_by_id = read_action_by_by_id
ActionBy.delete_by_id = delete_action_by_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ExternalConnection:
    """
    a table which allows us to link Actions, People and Sampling Features to external data and events

    @param connection_id 
    @param sampling_feature_id 
    @param equipment_id 
    @param action_id 
    @param description 

    This is an automatically generated class
    """
    connection_id: Optional[int] = None # connection_id integer (default: )
    sampling_feature_id: Optional[int] = None # sampling_feature_id integer (default: )
    equipment_id: Optional[int] = None # equipment_id integer (default: )
    action_id: Optional[int] = None # action_id integer (default: )
    description: Optional[str] = None # description character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'connection_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_external_connection_from_json_dict(json_obj: dict):
        """
        Create a ExternalConnection from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ExternalConnection(**json_obj)


@beartype.beartype
def write_external_connection_obj(con: db.Connection, obj: ExternalConnection) -> int:
    """
    Write a ExternalConnection object to the database
    @param con: database connection
    @param obj: ExternalConnection object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'external_connection', dataclasses.asdict(obj))

@beartype.beartype
def write_external_connection(
            con: db.Connection,
            connection_id: Optional[int] = None,
            sampling_feature_id: Optional[int] = None,
            equipment_id: Optional[int] = None,
            action_id: Optional[int] = None,
            description: Optional[str] = None) -> int:
    """
    Write to the external_connection table in the database
    @param con: database connection
    @param connection_id 
    @param sampling_feature_id 
    @param equipment_id 
    @param action_id 
    @param description 
    @return id of the inserted/updated row
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    return db.upsert(con, 'external_connection', data)

@beartype.beartype
def write_external_connection_many(con: db.Connection, objs: List[ExternalConnection], upsert: bool = False) -> int:
    """
    Write a list of ExternalConnection objects to the database
    @param con: database connection
    @param objs: list of ExternalConnection objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'external_connection', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_external_connection(con: db.Connection, connection_id: int,
            sampling_feature_id: Optional[int] = None,
            equipment_id: Optional[int] = None,
            action_id: Optional[int] = None,
            description: Optional[str] = None) -> int:
    """
    Update a row in the external_connection table in the database
    @param con: database connection
    @param connection_id 
    @param sampling_feature_id 
    @param equipment_id 
    @param action_id 
    @param description 
    @return The number of rows updated
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    return db.update(con, 'external_connection', data)

@beartype.beartype
def read_external_connection(
            con: db.Connection,
            connection_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             action_id: Optional[int] = None,
             description: Optional[str] = None) -> Generator[ExternalConnection, None, None]:
    """
    Read from the external_connection table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param connection_id 
    @param sampling_feature_id 
    @param equipment_id 
    @param action_id 
    @param description 
    @return generator of ExternalConnection objects
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    result = db.query(con, 'external_connection', data)
    for row in result:
        yield ExternalConnection(**row.as_dict())

@beartype.beartype
def read_external_connection_fuzzy(con: db.Connection, connection_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             action_id: Optional[int] = None,
             description: Optional[str] = None) -> Generator[ExternalConnection, None, None]:
    """
    Read from the external_connection table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param connection_id 
    @param sampling_feature_id 
    @param equipment_id 
    @param action_id 
    @param description 
    @return generator of ExternalConnection objects
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    result = db.query_fuzzy(con, 'external_connection', data)
    for row in result:
        yield ExternalConnection(**row.as_dict())

@beartype.beartype
def read_external_connection_any(con: db.Connection, connection_id: Optional[List[int]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None,
             action_id: Optional[List[int]] = None,
             description: Optional[List[str]] = None) -> Generator[ExternalConnection, None, None]:
    """
    Read from the external_connection table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param connection_id 
    @param sampling_feature_id 
    @param equipment_id 
    @param action_id 
    @param description 
    @return generator of ExternalConnection objects
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    result = db.query_any(con, 'external_connection', data)
    for row in result:
        yield ExternalConnection(**row.as_dict())

@beartype.beartype
def read_external_connection_one_or_none(con: db.Connection, connection_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             action_id: Optional[int] = None,
             description: Optional[str] = None) -> Optional[ExternalConnection]:
    """
    Read from the external_connection table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    result = db.query_one_or_none(con, 'external_connection', data)
    if result is None:
        return None
    return ExternalConnection(**result)

@beartype.beartype
def read_external_connection_one(con: db.Connection, connection_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             action_id: Optional[int] = None,
             description: Optional[str] = None) -> ExternalConnection:
    """
    Read from the external_connection table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    result = db.query_one(con, 'external_connection', data)
    return ExternalConnection(**result)

@beartype.beartype
def read_external_connection_all(con: db.Connection, connection_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             action_id: Optional[int] = None,
             description: Optional[str] = None) -> List[ExternalConnection]:
    """
    Read from the external_connection table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'connection_id': connection_id,
        'sampling_feature_id': sampling_feature_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
        'description': description,
    }
    result = db.query(con, 'external_connection', data)
    return [ExternalConnection(**row.as_dict()) for row in result]

@beartype.beartype
def read_external_connection_by_id(con: db.Connection, connection_id: int) -> Optional[ExternalConnection]:
    result = db.query_one(con, 'external_connection', {'connection_id': connection_id})
    if result is None:
        return None
    return ExternalConnection(**result)

@beartype.beartype
def delete_external_connection_by_id(con: db.Connection, connection_id: int):
    db.delete(con, 'external_connection', {'connection_id': connection_id})
# Associate the functions with the class
ExternalConnection.create_from_json_dict = create_external_connection_from_json_dict
ExternalConnection.write = write_external_connection
ExternalConnection.update = update_external_connection
ExternalConnection.write_many = write_external_connection_many
ExternalConnection.read = read_external_connection
ExternalConnection.read_fuzzy = read_external_connection_fuzzy
ExternalConnection.read_any = read_external_connection_any
ExternalConnection.read_one = read_external_connection_one
ExternalConnection.read_one_or_none = read_external_connection_one_or_none
ExternalConnection.read_all = read_external_connection_all
ExternalConnection.delete = delete_external_connection_by_id
ExternalConnection.read_by_id = read_external_connection_by_id
ExternalConnection.delete_by_id = delete_external_connection_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ImageEquipmentBridge:
    """
    Bridge between equipment and bridge

    @param bridge_id 
    @param equipment_id 
    @param image_id 

    This is an automatically generated class
    """
    equipment_id: int # equipment_id integer (default: )
    image_id: int # image_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

    @beartype.beartype
    def get_image(self, con: db.Connection) -> Optional['Images']:
        return read_images_one_or_none(con, image_id=self.image_id)

@beartype.beartype
def create_image_equipment_bridge_from_json_dict(json_obj: dict):
        """
        Create a ImageEquipmentBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ImageEquipmentBridge(**json_obj)


@beartype.beartype
def write_image_equipment_bridge_obj(con: db.Connection, obj: ImageEquipmentBridge) -> int:
    """
    Write a ImageEquipmentBridge object to the database
    @param con: database connection
    @param obj: ImageEquipmentBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'image_equipment_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_image_equipment_bridge(
            con: db.Connection,
            equipment_id: int,
            image_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the image_equipment_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param image_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    return db.upsert(con, 'image_equipment_bridge', data)

@beartype.beartype
def write_image_equipment_bridge_many(con: db.Connection, objs: List[ImageEquipmentBridge], upsert: bool = False) -> int:
    """
    Write a list of ImageEquipmentBridge objects to the database
    @param con: database connection
    @param objs: list of ImageEquipmentBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'image_equipment_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_image_equipment_bridge(con: db.Connection, bridge_id: int,
            equipment_id: Optional[int] = None,
            image_id: Optional[int] = None) -> int:
    """
    Update a row in the image_equipment_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param image_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    return db.update(con, 'image_equipment_bridge', data)

@beartype.beartype
def read_image_equipment_bridge(
            con: db.Connection,
            equipment_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ImageEquipmentBridge, None, None]:
    """
    Read from the image_equipment_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param image_id 
    @return generator of ImageEquipmentBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    result = db.query(con, 'image_equipment_bridge', data)
    for row in result:
        yield ImageEquipmentBridge(**row.as_dict())

@beartype.beartype
def read_image_equipment_bridge_fuzzy(con: db.Connection, equipment_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ImageEquipmentBridge, None, None]:
    """
    Read from the image_equipment_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param image_id 
    @return generator of ImageEquipmentBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    result = db.query_fuzzy(con, 'image_equipment_bridge', data)
    for row in result:
        yield ImageEquipmentBridge(**row.as_dict())

@beartype.beartype
def read_image_equipment_bridge_any(con: db.Connection, equipment_id: Optional[List[int]] = None,
             image_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ImageEquipmentBridge, None, None]:
    """
    Read from the image_equipment_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param image_id 
    @return generator of ImageEquipmentBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    result = db.query_any(con, 'image_equipment_bridge', data)
    for row in result:
        yield ImageEquipmentBridge(**row.as_dict())

@beartype.beartype
def read_image_equipment_bridge_one_or_none(con: db.Connection, equipment_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ImageEquipmentBridge]:
    """
    Read from the image_equipment_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    result = db.query_one_or_none(con, 'image_equipment_bridge', data)
    if result is None:
        return None
    return ImageEquipmentBridge(**result)

@beartype.beartype
def read_image_equipment_bridge_one(con: db.Connection, equipment_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ImageEquipmentBridge:
    """
    Read from the image_equipment_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    result = db.query_one(con, 'image_equipment_bridge', data)
    return ImageEquipmentBridge(**result)

@beartype.beartype
def read_image_equipment_bridge_all(con: db.Connection, equipment_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ImageEquipmentBridge]:
    """
    Read from the image_equipment_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'image_id': image_id,
    }
    result = db.query(con, 'image_equipment_bridge', data)
    return [ImageEquipmentBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_image_equipment_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[ImageEquipmentBridge]:
    result = db.query_one(con, 'image_equipment_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ImageEquipmentBridge(**result)

@beartype.beartype
def delete_image_equipment_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'image_equipment_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
ImageEquipmentBridge.create_from_json_dict = create_image_equipment_bridge_from_json_dict
ImageEquipmentBridge.write = write_image_equipment_bridge
ImageEquipmentBridge.update = update_image_equipment_bridge
ImageEquipmentBridge.write_many = write_image_equipment_bridge_many
ImageEquipmentBridge.read = read_image_equipment_bridge
ImageEquipmentBridge.read_fuzzy = read_image_equipment_bridge_fuzzy
ImageEquipmentBridge.read_any = read_image_equipment_bridge_any
ImageEquipmentBridge.read_one = read_image_equipment_bridge_one
ImageEquipmentBridge.read_one_or_none = read_image_equipment_bridge_one_or_none
ImageEquipmentBridge.read_all = read_image_equipment_bridge_all
ImageEquipmentBridge.delete = delete_image_equipment_bridge_by_id
ImageEquipmentBridge.read_by_id = read_image_equipment_bridge_by_id
ImageEquipmentBridge.delete_by_id = delete_image_equipment_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ImagePersonsBridge:
    """
    Bridge table linking images to persons

    @param bridge_id 
    @param person_id 
    @param image_id 

    This is an automatically generated class
    """
    person_id: int # person_id integer (default: )
    image_id: int # image_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_image(self, con: db.Connection) -> Optional['Images']:
        return read_images_one_or_none(con, image_id=self.image_id)

    @beartype.beartype
    def get_person(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.person_id)

@beartype.beartype
def create_image_persons_bridge_from_json_dict(json_obj: dict):
        """
        Create a ImagePersonsBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ImagePersonsBridge(**json_obj)


@beartype.beartype
def write_image_persons_bridge_obj(con: db.Connection, obj: ImagePersonsBridge) -> int:
    """
    Write a ImagePersonsBridge object to the database
    @param con: database connection
    @param obj: ImagePersonsBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'image_persons_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_image_persons_bridge(
            con: db.Connection,
            person_id: int,
            image_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the image_persons_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param image_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    return db.upsert(con, 'image_persons_bridge', data)

@beartype.beartype
def write_image_persons_bridge_many(con: db.Connection, objs: List[ImagePersonsBridge], upsert: bool = False) -> int:
    """
    Write a list of ImagePersonsBridge objects to the database
    @param con: database connection
    @param objs: list of ImagePersonsBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'image_persons_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_image_persons_bridge(con: db.Connection, bridge_id: int,
            person_id: Optional[int] = None,
            image_id: Optional[int] = None) -> int:
    """
    Update a row in the image_persons_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param image_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    return db.update(con, 'image_persons_bridge', data)

@beartype.beartype
def read_image_persons_bridge(
            con: db.Connection,
            person_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ImagePersonsBridge, None, None]:
    """
    Read from the image_persons_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param image_id 
    @return generator of ImagePersonsBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    result = db.query(con, 'image_persons_bridge', data)
    for row in result:
        yield ImagePersonsBridge(**row.as_dict())

@beartype.beartype
def read_image_persons_bridge_fuzzy(con: db.Connection, person_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ImagePersonsBridge, None, None]:
    """
    Read from the image_persons_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param image_id 
    @return generator of ImagePersonsBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    result = db.query_fuzzy(con, 'image_persons_bridge', data)
    for row in result:
        yield ImagePersonsBridge(**row.as_dict())

@beartype.beartype
def read_image_persons_bridge_any(con: db.Connection, person_id: Optional[List[int]] = None,
             image_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ImagePersonsBridge, None, None]:
    """
    Read from the image_persons_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param image_id 
    @return generator of ImagePersonsBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    result = db.query_any(con, 'image_persons_bridge', data)
    for row in result:
        yield ImagePersonsBridge(**row.as_dict())

@beartype.beartype
def read_image_persons_bridge_one_or_none(con: db.Connection, person_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ImagePersonsBridge]:
    """
    Read from the image_persons_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    result = db.query_one_or_none(con, 'image_persons_bridge', data)
    if result is None:
        return None
    return ImagePersonsBridge(**result)

@beartype.beartype
def read_image_persons_bridge_one(con: db.Connection, person_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ImagePersonsBridge:
    """
    Read from the image_persons_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    result = db.query_one(con, 'image_persons_bridge', data)
    return ImagePersonsBridge(**result)

@beartype.beartype
def read_image_persons_bridge_all(con: db.Connection, person_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ImagePersonsBridge]:
    """
    Read from the image_persons_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'image_id': image_id,
    }
    result = db.query(con, 'image_persons_bridge', data)
    return [ImagePersonsBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_image_persons_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[ImagePersonsBridge]:
    result = db.query_one(con, 'image_persons_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ImagePersonsBridge(**result)

@beartype.beartype
def delete_image_persons_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'image_persons_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
ImagePersonsBridge.create_from_json_dict = create_image_persons_bridge_from_json_dict
ImagePersonsBridge.write = write_image_persons_bridge
ImagePersonsBridge.update = update_image_persons_bridge
ImagePersonsBridge.write_many = write_image_persons_bridge_many
ImagePersonsBridge.read = read_image_persons_bridge
ImagePersonsBridge.read_fuzzy = read_image_persons_bridge_fuzzy
ImagePersonsBridge.read_any = read_image_persons_bridge_any
ImagePersonsBridge.read_one = read_image_persons_bridge_one
ImagePersonsBridge.read_one_or_none = read_image_persons_bridge_one_or_none
ImagePersonsBridge.read_all = read_image_persons_bridge_all
ImagePersonsBridge.delete = delete_image_persons_bridge_by_id
ImagePersonsBridge.read_by_id = read_image_persons_bridge_by_id
ImagePersonsBridge.delete_by_id = delete_image_persons_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ImageSamplingFeatureBridge:
    """
    Bridge table between sampling features and Images

    @param bridge_id 
    @param sampling_feature_id 
    @param image_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    image_id: int # image_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_image(self, con: db.Connection) -> Optional['Images']:
        return read_images_one_or_none(con, image_id=self.image_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_image_sampling_feature_bridge_from_json_dict(json_obj: dict):
        """
        Create a ImageSamplingFeatureBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ImageSamplingFeatureBridge(**json_obj)


@beartype.beartype
def write_image_sampling_feature_bridge_obj(con: db.Connection, obj: ImageSamplingFeatureBridge) -> int:
    """
    Write a ImageSamplingFeatureBridge object to the database
    @param con: database connection
    @param obj: ImageSamplingFeatureBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'image_sampling_feature_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_image_sampling_feature_bridge(
            con: db.Connection,
            sampling_feature_id: int,
            image_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the image_sampling_feature_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param image_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    return db.upsert(con, 'image_sampling_feature_bridge', data)

@beartype.beartype
def write_image_sampling_feature_bridge_many(con: db.Connection, objs: List[ImageSamplingFeatureBridge], upsert: bool = False) -> int:
    """
    Write a list of ImageSamplingFeatureBridge objects to the database
    @param con: database connection
    @param objs: list of ImageSamplingFeatureBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'image_sampling_feature_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_image_sampling_feature_bridge(con: db.Connection, bridge_id: int,
            sampling_feature_id: Optional[int] = None,
            image_id: Optional[int] = None) -> int:
    """
    Update a row in the image_sampling_feature_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param image_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    return db.update(con, 'image_sampling_feature_bridge', data)

@beartype.beartype
def read_image_sampling_feature_bridge(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ImageSamplingFeatureBridge, None, None]:
    """
    Read from the image_sampling_feature_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param image_id 
    @return generator of ImageSamplingFeatureBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    result = db.query(con, 'image_sampling_feature_bridge', data)
    for row in result:
        yield ImageSamplingFeatureBridge(**row.as_dict())

@beartype.beartype
def read_image_sampling_feature_bridge_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ImageSamplingFeatureBridge, None, None]:
    """
    Read from the image_sampling_feature_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param image_id 
    @return generator of ImageSamplingFeatureBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    result = db.query_fuzzy(con, 'image_sampling_feature_bridge', data)
    for row in result:
        yield ImageSamplingFeatureBridge(**row.as_dict())

@beartype.beartype
def read_image_sampling_feature_bridge_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             image_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ImageSamplingFeatureBridge, None, None]:
    """
    Read from the image_sampling_feature_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param image_id 
    @return generator of ImageSamplingFeatureBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    result = db.query_any(con, 'image_sampling_feature_bridge', data)
    for row in result:
        yield ImageSamplingFeatureBridge(**row.as_dict())

@beartype.beartype
def read_image_sampling_feature_bridge_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ImageSamplingFeatureBridge]:
    """
    Read from the image_sampling_feature_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    result = db.query_one_or_none(con, 'image_sampling_feature_bridge', data)
    if result is None:
        return None
    return ImageSamplingFeatureBridge(**result)

@beartype.beartype
def read_image_sampling_feature_bridge_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ImageSamplingFeatureBridge:
    """
    Read from the image_sampling_feature_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    result = db.query_one(con, 'image_sampling_feature_bridge', data)
    return ImageSamplingFeatureBridge(**result)

@beartype.beartype
def read_image_sampling_feature_bridge_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             image_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ImageSamplingFeatureBridge]:
    """
    Read from the image_sampling_feature_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'image_id': image_id,
    }
    result = db.query(con, 'image_sampling_feature_bridge', data)
    return [ImageSamplingFeatureBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_image_sampling_feature_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[ImageSamplingFeatureBridge]:
    result = db.query_one(con, 'image_sampling_feature_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ImageSamplingFeatureBridge(**result)

@beartype.beartype
def delete_image_sampling_feature_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'image_sampling_feature_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
ImageSamplingFeatureBridge.create_from_json_dict = create_image_sampling_feature_bridge_from_json_dict
ImageSamplingFeatureBridge.write = write_image_sampling_feature_bridge
ImageSamplingFeatureBridge.update = update_image_sampling_feature_bridge
ImageSamplingFeatureBridge.write_many = write_image_sampling_feature_bridge_many
ImageSamplingFeatureBridge.read = read_image_sampling_feature_bridge
ImageSamplingFeatureBridge.read_fuzzy = read_image_sampling_feature_bridge_fuzzy
ImageSamplingFeatureBridge.read_any = read_image_sampling_feature_bridge_any
ImageSamplingFeatureBridge.read_one = read_image_sampling_feature_bridge_one
ImageSamplingFeatureBridge.read_one_or_none = read_image_sampling_feature_bridge_one_or_none
ImageSamplingFeatureBridge.read_all = read_image_sampling_feature_bridge_all
ImageSamplingFeatureBridge.delete = delete_image_sampling_feature_bridge_by_id
ImageSamplingFeatureBridge.read_by_id = read_image_sampling_feature_bridge_by_id
ImageSamplingFeatureBridge.delete_by_id = delete_image_sampling_feature_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CvVariableDomain:
    """
    Table containing terms used in the VariableDomain controlled vocabulary.

    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 

    This is an automatically generated class
    """
    term: str # term character varying (default: )
    name: str # name character varying (default: )
    definition: Optional[str] = None # definition character varying (default: )
    category: Optional[str] = None # category character varying (default: )
    provenance: Optional[str] = None # provenance character varying (default: )
    provenance_uri: Optional[str] = None # provenance_uri character varying (default: )
    note: Optional[str] = None # note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'term'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_cv_variable_domain_from_json_dict(json_obj: dict):
        """
        Create a CvVariableDomain from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CvVariableDomain(**json_obj)


@beartype.beartype
def write_cv_variable_domain_obj(con: db.Connection, obj: CvVariableDomain) -> str:
    """
    Write a CvVariableDomain object to the database
    @param con: database connection
    @param obj: CvVariableDomain object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'cv_variable_domain', dataclasses.asdict(obj))

@beartype.beartype
def write_cv_variable_domain(
            con: db.Connection,
            term: str,
            name: str,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> str:
    """
    Write to the cv_variable_domain table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return id of the inserted/updated row
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.upsert(con, 'cv_variable_domain', data)

@beartype.beartype
def write_cv_variable_domain_many(con: db.Connection, objs: List[CvVariableDomain], upsert: bool = False) -> int:
    """
    Write a list of CvVariableDomain objects to the database
    @param con: database connection
    @param objs: list of CvVariableDomain objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'cv_variable_domain', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_cv_variable_domain(con: db.Connection, term: str,
            name: Optional[str] = None,
            definition: Optional[str] = None,
            category: Optional[str] = None,
            provenance: Optional[str] = None,
            provenance_uri: Optional[str] = None,
            note: Optional[str] = None) -> int:
    """
    Update a row in the cv_variable_domain table in the database
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return The number of rows updated
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    return db.update(con, 'cv_variable_domain', data)

@beartype.beartype
def read_cv_variable_domain(
            con: db.Connection,
            term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvVariableDomain, None, None]:
    """
    Read from the cv_variable_domain table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvVariableDomain objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_variable_domain', data)
    for row in result:
        yield CvVariableDomain(**row.as_dict())

@beartype.beartype
def read_cv_variable_domain_fuzzy(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Generator[CvVariableDomain, None, None]:
    """
    Read from the cv_variable_domain table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvVariableDomain objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_fuzzy(con, 'cv_variable_domain', data)
    for row in result:
        yield CvVariableDomain(**row.as_dict())

@beartype.beartype
def read_cv_variable_domain_any(con: db.Connection, term: Optional[List[str]] = None,
             name: Optional[List[str]] = None,
             definition: Optional[List[str]] = None,
             category: Optional[List[str]] = None,
             provenance: Optional[List[str]] = None,
             provenance_uri: Optional[List[str]] = None,
             note: Optional[List[str]] = None) -> Generator[CvVariableDomain, None, None]:
    """
    Read from the cv_variable_domain table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param term 
    @param name 
    @param definition 
    @param category 
    @param provenance 
    @param provenance_uri 
    @param note 
    @return generator of CvVariableDomain objects
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_any(con, 'cv_variable_domain', data)
    for row in result:
        yield CvVariableDomain(**row.as_dict())

@beartype.beartype
def read_cv_variable_domain_one_or_none(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> Optional[CvVariableDomain]:
    """
    Read from the cv_variable_domain table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one_or_none(con, 'cv_variable_domain', data)
    if result is None:
        return None
    return CvVariableDomain(**result)

@beartype.beartype
def read_cv_variable_domain_one(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> CvVariableDomain:
    """
    Read from the cv_variable_domain table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query_one(con, 'cv_variable_domain', data)
    return CvVariableDomain(**result)

@beartype.beartype
def read_cv_variable_domain_all(con: db.Connection, term: Optional[str] = None,
             name: Optional[str] = None,
             definition: Optional[str] = None,
             category: Optional[str] = None,
             provenance: Optional[str] = None,
             provenance_uri: Optional[str] = None,
             note: Optional[str] = None) -> List[CvVariableDomain]:
    """
    Read from the cv_variable_domain table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'term': term,
        'name': name,
        'definition': definition,
        'category': category,
        'provenance': provenance,
        'provenance_uri': provenance_uri,
        'note': note,
    }
    result = db.query(con, 'cv_variable_domain', data)
    return [CvVariableDomain(**row.as_dict()) for row in result]

@beartype.beartype
def read_cv_variable_domain_by_id(con: db.Connection, term: str) -> Optional[CvVariableDomain]:
    result = db.query_one(con, 'cv_variable_domain', {'term': term})
    if result is None:
        return None
    return CvVariableDomain(**result)

@beartype.beartype
def delete_cv_variable_domain_by_id(con: db.Connection, term: str):
    db.delete(con, 'cv_variable_domain', {'term': term})
# Associate the functions with the class
CvVariableDomain.create_from_json_dict = create_cv_variable_domain_from_json_dict
CvVariableDomain.write = write_cv_variable_domain
CvVariableDomain.update = update_cv_variable_domain
CvVariableDomain.write_many = write_cv_variable_domain_many
CvVariableDomain.read = read_cv_variable_domain
CvVariableDomain.read_fuzzy = read_cv_variable_domain_fuzzy
CvVariableDomain.read_any = read_cv_variable_domain_any
CvVariableDomain.read_one = read_cv_variable_domain_one
CvVariableDomain.read_one_or_none = read_cv_variable_domain_one_or_none
CvVariableDomain.read_all = read_cv_variable_domain_all
CvVariableDomain.delete = delete_cv_variable_domain_by_id
CvVariableDomain.read_by_id = read_cv_variable_domain_by_id
CvVariableDomain.delete_by_id = delete_cv_variable_domain_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Results:
    """
    Describes the results of observation actions (e.g., groups of one or more numeric data values that result from an observation action)

    @param result_id 
    @param result_uuid 
    @param feature_action_id 
    @param result_type_cv 
    @param variable_id 
    @param units_id 
    @param processing_level_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param valid_date_time 
    @param valid_date_time_utc_offset 
    @param status_cv 
    @param value_count 
    @param no_data_value 

    This is an automatically generated class
    """
    result_uuid: str # result_uuid character varying (default: )
    feature_action_id: int # feature_action_id integer (default: )
    result_type_cv: str # result_type_cv character varying (default: )
    variable_id: int # variable_id integer (default: )
    units_id: int # units_id integer (default: )
    processing_level_id: int # processing_level_id integer (default: )
    value_count: int # value_count integer (default: )
    result_id: Optional[int] = None # result_id bigint (default: )
    result_date_time: Optional[datetime.datetime] = None # result_date_time timestamp without time zone (default: )
    result_date_time_utc_offset: Optional[int] = None # result_date_time_utc_offset bigint (default: )
    valid_date_time: Optional[datetime.datetime] = None # valid_date_time timestamp without time zone (default: )
    valid_date_time_utc_offset: Optional[int] = None # valid_date_time_utc_offset bigint (default: )
    status_cv: Optional[str] = None # status_cv character varying (default: )
    no_data_value: Optional[float] = None # no_data_value double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.result_date_time is not None:
            obj['result_date_time'] = self.result_date_time.isoformat()
        if self.valid_date_time is not None:
            obj['valid_date_time'] = self.valid_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_result_type_cv(self, con: db.Connection) -> Optional['CvResultType']:
        return read_cv_result_type_one_or_none(con, term=self.result_type_cv)

    @beartype.beartype
    def get_status_cv(self, con: db.Connection) -> Optional['CvStatus']:
        return read_cv_status_one_or_none(con, term=self.status_cv)

    @beartype.beartype
    def get_feature_action(self, con: db.Connection) -> Optional['FeatureActions']:
        return read_feature_actions_one_or_none(con, feature_action_id=self.feature_action_id)

    @beartype.beartype
    def get_processing_level(self, con: db.Connection) -> Optional['ProcessingLevels']:
        return read_processing_levels_one_or_none(con, processing_level_id=self.processing_level_id)

    @beartype.beartype
    def get_units(self, con: db.Connection) -> Optional['CvUnits']:
        return read_cv_units_one_or_none(con, units_id=self.units_id)

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_results_from_json_dict(json_obj: dict):
        """
        Create a Results from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'result_date_time' in json_obj and json_obj['result_date_time'] is not None:
            json_obj['result_date_time'] = datetime.datetime.fromisoformat(json_obj['result_date_time'])
        if 'valid_date_time' in json_obj and json_obj['valid_date_time'] is not None:
            json_obj['valid_date_time'] = datetime.datetime.fromisoformat(json_obj['valid_date_time'])
        return Results(**json_obj)


@beartype.beartype
def write_results_obj(con: db.Connection, obj: Results) -> int:
    """
    Write a Results object to the database
    @param con: database connection
    @param obj: Results object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'results', dataclasses.asdict(obj))

@beartype.beartype
def write_results(
            con: db.Connection,
            result_uuid: str,
            feature_action_id: int,
            result_type_cv: str,
            variable_id: int,
            units_id: int,
            processing_level_id: int,
            value_count: int,
            result_id: Optional[int] = None,
            result_date_time: Optional[datetime.datetime] = None,
            result_date_time_utc_offset: Optional[int] = None,
            valid_date_time: Optional[datetime.datetime] = None,
            valid_date_time_utc_offset: Optional[int] = None,
            status_cv: Optional[str] = None,
            no_data_value: Optional[float] = None) -> int:
    """
    Write to the results table in the database
    @param con: database connection
    @param result_id 
    @param result_uuid 
    @param feature_action_id 
    @param result_type_cv 
    @param variable_id 
    @param units_id 
    @param processing_level_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param valid_date_time 
    @param valid_date_time_utc_offset 
    @param status_cv 
    @param value_count 
    @param no_data_value 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    return db.upsert(con, 'results', data)

@beartype.beartype
def write_results_many(con: db.Connection, objs: List[Results], upsert: bool = False) -> int:
    """
    Write a list of Results objects to the database
    @param con: database connection
    @param objs: list of Results objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_results(con: db.Connection, result_id: int,
            result_uuid: Optional[str] = None,
            feature_action_id: Optional[int] = None,
            result_type_cv: Optional[str] = None,
            variable_id: Optional[int] = None,
            units_id: Optional[int] = None,
            processing_level_id: Optional[int] = None,
            value_count: Optional[int] = None,
            result_date_time: Optional[datetime.datetime] = None,
            result_date_time_utc_offset: Optional[int] = None,
            valid_date_time: Optional[datetime.datetime] = None,
            valid_date_time_utc_offset: Optional[int] = None,
            status_cv: Optional[str] = None,
            no_data_value: Optional[float] = None) -> int:
    """
    Update a row in the results table in the database
    @param con: database connection
    @param result_id 
    @param result_uuid 
    @param feature_action_id 
    @param result_type_cv 
    @param variable_id 
    @param units_id 
    @param processing_level_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param valid_date_time 
    @param valid_date_time_utc_offset 
    @param status_cv 
    @param value_count 
    @param no_data_value 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    return db.update(con, 'results', data)

@beartype.beartype
def read_results(
            con: db.Connection,
            result_uuid: Optional[str] = None,
             feature_action_id: Optional[int] = None,
             result_type_cv: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             processing_level_id: Optional[int] = None,
             value_count: Optional[int] = None,
             result_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             valid_date_time: Optional[datetime.datetime] = None,
             valid_date_time_utc_offset: Optional[int] = None,
             status_cv: Optional[str] = None,
             no_data_value: Optional[float] = None) -> Generator[Results, None, None]:
    """
    Read from the results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param result_uuid 
    @param feature_action_id 
    @param result_type_cv 
    @param variable_id 
    @param units_id 
    @param processing_level_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param valid_date_time 
    @param valid_date_time_utc_offset 
    @param status_cv 
    @param value_count 
    @param no_data_value 
    @return generator of Results objects
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    result = db.query(con, 'results', data)
    for row in result:
        yield Results(**row.as_dict())

@beartype.beartype
def read_results_fuzzy(con: db.Connection, result_uuid: Optional[str] = None,
             feature_action_id: Optional[int] = None,
             result_type_cv: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             processing_level_id: Optional[int] = None,
             value_count: Optional[int] = None,
             result_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             valid_date_time: Optional[datetime.datetime] = None,
             valid_date_time_utc_offset: Optional[int] = None,
             status_cv: Optional[str] = None,
             no_data_value: Optional[float] = None) -> Generator[Results, None, None]:
    """
    Read from the results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param result_uuid 
    @param feature_action_id 
    @param result_type_cv 
    @param variable_id 
    @param units_id 
    @param processing_level_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param valid_date_time 
    @param valid_date_time_utc_offset 
    @param status_cv 
    @param value_count 
    @param no_data_value 
    @return generator of Results objects
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    result = db.query_fuzzy(con, 'results', data)
    for row in result:
        yield Results(**row.as_dict())

@beartype.beartype
def read_results_any(con: db.Connection, result_uuid: Optional[List[str]] = None,
             feature_action_id: Optional[List[int]] = None,
             result_type_cv: Optional[List[str]] = None,
             variable_id: Optional[List[int]] = None,
             units_id: Optional[List[int]] = None,
             processing_level_id: Optional[List[int]] = None,
             value_count: Optional[List[int]] = None,
             result_id: Optional[List[int]] = None,
             result_date_time: Optional[List[datetime.datetime]] = None,
             result_date_time_utc_offset: Optional[List[int]] = None,
             valid_date_time: Optional[List[datetime.datetime]] = None,
             valid_date_time_utc_offset: Optional[List[int]] = None,
             status_cv: Optional[List[str]] = None,
             no_data_value: Optional[List[float]] = None) -> Generator[Results, None, None]:
    """
    Read from the results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param result_uuid 
    @param feature_action_id 
    @param result_type_cv 
    @param variable_id 
    @param units_id 
    @param processing_level_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param valid_date_time 
    @param valid_date_time_utc_offset 
    @param status_cv 
    @param value_count 
    @param no_data_value 
    @return generator of Results objects
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    result = db.query_any(con, 'results', data)
    for row in result:
        yield Results(**row.as_dict())

@beartype.beartype
def read_results_one_or_none(con: db.Connection, result_uuid: Optional[str] = None,
             feature_action_id: Optional[int] = None,
             result_type_cv: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             processing_level_id: Optional[int] = None,
             value_count: Optional[int] = None,
             result_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             valid_date_time: Optional[datetime.datetime] = None,
             valid_date_time_utc_offset: Optional[int] = None,
             status_cv: Optional[str] = None,
             no_data_value: Optional[float] = None) -> Optional[Results]:
    """
    Read from the results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    result = db.query_one_or_none(con, 'results', data)
    if result is None:
        return None
    return Results(**result)

@beartype.beartype
def read_results_one(con: db.Connection, result_uuid: Optional[str] = None,
             feature_action_id: Optional[int] = None,
             result_type_cv: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             processing_level_id: Optional[int] = None,
             value_count: Optional[int] = None,
             result_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             valid_date_time: Optional[datetime.datetime] = None,
             valid_date_time_utc_offset: Optional[int] = None,
             status_cv: Optional[str] = None,
             no_data_value: Optional[float] = None) -> Results:
    """
    Read from the results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    result = db.query_one(con, 'results', data)
    return Results(**result)

@beartype.beartype
def read_results_all(con: db.Connection, result_uuid: Optional[str] = None,
             feature_action_id: Optional[int] = None,
             result_type_cv: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             processing_level_id: Optional[int] = None,
             value_count: Optional[int] = None,
             result_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             valid_date_time: Optional[datetime.datetime] = None,
             valid_date_time_utc_offset: Optional[int] = None,
             status_cv: Optional[str] = None,
             no_data_value: Optional[float] = None) -> List[Results]:
    """
    Read from the results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'result_uuid': result_uuid,
        'feature_action_id': feature_action_id,
        'result_type_cv': result_type_cv,
        'variable_id': variable_id,
        'units_id': units_id,
        'processing_level_id': processing_level_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'valid_date_time': valid_date_time,
        'valid_date_time_utc_offset': valid_date_time_utc_offset,
        'status_cv': status_cv,
        'value_count': value_count,
        'no_data_value': no_data_value,
    }
    result = db.query(con, 'results', data)
    return [Results(**row.as_dict()) for row in result]

@beartype.beartype
def read_results_by_id(con: db.Connection, result_id: int) -> Optional[Results]:
    result = db.query_one(con, 'results', {'result_id': result_id})
    if result is None:
        return None
    return Results(**result)

@beartype.beartype
def delete_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'results', {'result_id': result_id})
# Associate the functions with the class
Results.create_from_json_dict = create_results_from_json_dict
Results.write = write_results
Results.update = update_results
Results.write_many = write_results_many
Results.read = read_results
Results.read_fuzzy = read_results_fuzzy
Results.read_any = read_results_any
Results.read_one = read_results_one
Results.read_one_or_none = read_results_one_or_none
Results.read_all = read_results_all
Results.delete = delete_results_by_id
Results.read_by_id = read_results_by_id
Results.delete_by_id = delete_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Images:
    """
    A table to store image data

    @param image_id 
    @param utc_date_time_taken 
    @param image_description 
    @param photo_storage_name 
    @param photo_storage_path 
    @param photo_storage_type 
    @param pitch 
    @param roll 
    @param yaw 
    @param altitude_taken 
    @param image_width 
    @param image_height 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param latitude 
    @param longitude 

    This is an automatically generated class
    """
    photo_storage_name: str # photo_storage_name character varying (default: )
    photo_storage_path: str # photo_storage_path character varying (default: )
    photo_storage_type: str # photo_storage_type character varying (default: )
    image_id: Optional[int] = None # image_id integer (default: )
    utc_date_time_taken: Optional[int] = None # utc_date_time_taken bigint (default: )
    image_description: Optional[str] = None # image_description character varying (default: )
    pitch: Optional[float] = None # pitch double precision (default: )
    roll: Optional[float] = None # roll double precision (default: )
    yaw: Optional[float] = None # yaw double precision (default: )
    altitude_taken: Optional[float] = None # altitude_taken double precision (default: )
    image_width: Optional[int] = None # image_width integer (default: )
    image_height: Optional[int] = None # image_height integer (default: )
    exposure_time: Optional[float] = None # exposure_time double precision (default: )
    aperture: Optional[float] = None # aperture double precision (default: )
    flash_used: Optional[bool] = None # flash_used boolean (default: )
    focal_length: Optional[float] = None # focal_length double precision (default: )
    iso_speed: Optional[int] = None # iso_speed integer (default: )
    metering_mode: Optional[str] = None # metering_mode character varying (default: )
    sensor: Optional[str] = None # sensor character varying (default: )
    exposure_mode: Optional[str] = None # exposure_mode character varying (default: )
    color_space: Optional[str] = None # color_space character varying (default: )
    white_balance: Optional[str] = None # white_balance character varying (default: )
    exposure_bias: Optional[float] = None # exposure_bias double precision (default: )
    max_aperture_value: Optional[float] = None # max_aperture_value double precision (default: )
    latitude: Optional[float] = None # latitude double precision (default: )
    longitude: Optional[float] = None # longitude double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'image_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_images_from_json_dict(json_obj: dict):
        """
        Create a Images from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Images(**json_obj)


@beartype.beartype
def write_images_obj(con: db.Connection, obj: Images) -> int:
    """
    Write a Images object to the database
    @param con: database connection
    @param obj: Images object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'images', dataclasses.asdict(obj))

@beartype.beartype
def write_images(
            con: db.Connection,
            photo_storage_name: str,
            photo_storage_path: str,
            photo_storage_type: str,
            image_id: Optional[int] = None,
            utc_date_time_taken: Optional[int] = None,
            image_description: Optional[str] = None,
            pitch: Optional[float] = None,
            roll: Optional[float] = None,
            yaw: Optional[float] = None,
            altitude_taken: Optional[float] = None,
            image_width: Optional[int] = None,
            image_height: Optional[int] = None,
            exposure_time: Optional[float] = None,
            aperture: Optional[float] = None,
            flash_used: Optional[bool] = None,
            focal_length: Optional[float] = None,
            iso_speed: Optional[int] = None,
            metering_mode: Optional[str] = None,
            sensor: Optional[str] = None,
            exposure_mode: Optional[str] = None,
            color_space: Optional[str] = None,
            white_balance: Optional[str] = None,
            exposure_bias: Optional[float] = None,
            max_aperture_value: Optional[float] = None,
            latitude: Optional[float] = None,
            longitude: Optional[float] = None) -> int:
    """
    Write to the images table in the database
    @param con: database connection
    @param image_id 
    @param utc_date_time_taken 
    @param image_description 
    @param photo_storage_name 
    @param photo_storage_path 
    @param photo_storage_type 
    @param pitch 
    @param roll 
    @param yaw 
    @param altitude_taken 
    @param image_width 
    @param image_height 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param latitude 
    @param longitude 
    @return id of the inserted/updated row
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    return db.upsert(con, 'images', data)

@beartype.beartype
def write_images_many(con: db.Connection, objs: List[Images], upsert: bool = False) -> int:
    """
    Write a list of Images objects to the database
    @param con: database connection
    @param objs: list of Images objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'images', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_images(con: db.Connection, image_id: int,
            photo_storage_name: Optional[str] = None,
            photo_storage_path: Optional[str] = None,
            photo_storage_type: Optional[str] = None,
            utc_date_time_taken: Optional[int] = None,
            image_description: Optional[str] = None,
            pitch: Optional[float] = None,
            roll: Optional[float] = None,
            yaw: Optional[float] = None,
            altitude_taken: Optional[float] = None,
            image_width: Optional[int] = None,
            image_height: Optional[int] = None,
            exposure_time: Optional[float] = None,
            aperture: Optional[float] = None,
            flash_used: Optional[bool] = None,
            focal_length: Optional[float] = None,
            iso_speed: Optional[int] = None,
            metering_mode: Optional[str] = None,
            sensor: Optional[str] = None,
            exposure_mode: Optional[str] = None,
            color_space: Optional[str] = None,
            white_balance: Optional[str] = None,
            exposure_bias: Optional[float] = None,
            max_aperture_value: Optional[float] = None,
            latitude: Optional[float] = None,
            longitude: Optional[float] = None) -> int:
    """
    Update a row in the images table in the database
    @param con: database connection
    @param image_id 
    @param utc_date_time_taken 
    @param image_description 
    @param photo_storage_name 
    @param photo_storage_path 
    @param photo_storage_type 
    @param pitch 
    @param roll 
    @param yaw 
    @param altitude_taken 
    @param image_width 
    @param image_height 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param latitude 
    @param longitude 
    @return The number of rows updated
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    return db.update(con, 'images', data)

@beartype.beartype
def read_images(
            con: db.Connection,
            photo_storage_name: Optional[str] = None,
             photo_storage_path: Optional[str] = None,
             photo_storage_type: Optional[str] = None,
             image_id: Optional[int] = None,
             utc_date_time_taken: Optional[int] = None,
             image_description: Optional[str] = None,
             pitch: Optional[float] = None,
             roll: Optional[float] = None,
             yaw: Optional[float] = None,
             altitude_taken: Optional[float] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None) -> Generator[Images, None, None]:
    """
    Read from the images table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param image_id 
    @param utc_date_time_taken 
    @param image_description 
    @param photo_storage_name 
    @param photo_storage_path 
    @param photo_storage_type 
    @param pitch 
    @param roll 
    @param yaw 
    @param altitude_taken 
    @param image_width 
    @param image_height 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param latitude 
    @param longitude 
    @return generator of Images objects
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    result = db.query(con, 'images', data)
    for row in result:
        yield Images(**row.as_dict())

@beartype.beartype
def read_images_fuzzy(con: db.Connection, photo_storage_name: Optional[str] = None,
             photo_storage_path: Optional[str] = None,
             photo_storage_type: Optional[str] = None,
             image_id: Optional[int] = None,
             utc_date_time_taken: Optional[int] = None,
             image_description: Optional[str] = None,
             pitch: Optional[float] = None,
             roll: Optional[float] = None,
             yaw: Optional[float] = None,
             altitude_taken: Optional[float] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None) -> Generator[Images, None, None]:
    """
    Read from the images table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param image_id 
    @param utc_date_time_taken 
    @param image_description 
    @param photo_storage_name 
    @param photo_storage_path 
    @param photo_storage_type 
    @param pitch 
    @param roll 
    @param yaw 
    @param altitude_taken 
    @param image_width 
    @param image_height 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param latitude 
    @param longitude 
    @return generator of Images objects
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    result = db.query_fuzzy(con, 'images', data)
    for row in result:
        yield Images(**row.as_dict())

@beartype.beartype
def read_images_any(con: db.Connection, photo_storage_name: Optional[List[str]] = None,
             photo_storage_path: Optional[List[str]] = None,
             photo_storage_type: Optional[List[str]] = None,
             image_id: Optional[List[int]] = None,
             utc_date_time_taken: Optional[List[int]] = None,
             image_description: Optional[List[str]] = None,
             pitch: Optional[List[float]] = None,
             roll: Optional[List[float]] = None,
             yaw: Optional[List[float]] = None,
             altitude_taken: Optional[List[float]] = None,
             image_width: Optional[List[int]] = None,
             image_height: Optional[List[int]] = None,
             exposure_time: Optional[List[float]] = None,
             aperture: Optional[List[float]] = None,
             flash_used: Optional[List[bool]] = None,
             focal_length: Optional[List[float]] = None,
             iso_speed: Optional[List[int]] = None,
             metering_mode: Optional[List[str]] = None,
             sensor: Optional[List[str]] = None,
             exposure_mode: Optional[List[str]] = None,
             color_space: Optional[List[str]] = None,
             white_balance: Optional[List[str]] = None,
             exposure_bias: Optional[List[float]] = None,
             max_aperture_value: Optional[List[float]] = None,
             latitude: Optional[List[float]] = None,
             longitude: Optional[List[float]] = None) -> Generator[Images, None, None]:
    """
    Read from the images table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param image_id 
    @param utc_date_time_taken 
    @param image_description 
    @param photo_storage_name 
    @param photo_storage_path 
    @param photo_storage_type 
    @param pitch 
    @param roll 
    @param yaw 
    @param altitude_taken 
    @param image_width 
    @param image_height 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param latitude 
    @param longitude 
    @return generator of Images objects
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    result = db.query_any(con, 'images', data)
    for row in result:
        yield Images(**row.as_dict())

@beartype.beartype
def read_images_one_or_none(con: db.Connection, photo_storage_name: Optional[str] = None,
             photo_storage_path: Optional[str] = None,
             photo_storage_type: Optional[str] = None,
             image_id: Optional[int] = None,
             utc_date_time_taken: Optional[int] = None,
             image_description: Optional[str] = None,
             pitch: Optional[float] = None,
             roll: Optional[float] = None,
             yaw: Optional[float] = None,
             altitude_taken: Optional[float] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None) -> Optional[Images]:
    """
    Read from the images table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    result = db.query_one_or_none(con, 'images', data)
    if result is None:
        return None
    return Images(**result)

@beartype.beartype
def read_images_one(con: db.Connection, photo_storage_name: Optional[str] = None,
             photo_storage_path: Optional[str] = None,
             photo_storage_type: Optional[str] = None,
             image_id: Optional[int] = None,
             utc_date_time_taken: Optional[int] = None,
             image_description: Optional[str] = None,
             pitch: Optional[float] = None,
             roll: Optional[float] = None,
             yaw: Optional[float] = None,
             altitude_taken: Optional[float] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None) -> Images:
    """
    Read from the images table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    result = db.query_one(con, 'images', data)
    return Images(**result)

@beartype.beartype
def read_images_all(con: db.Connection, photo_storage_name: Optional[str] = None,
             photo_storage_path: Optional[str] = None,
             photo_storage_type: Optional[str] = None,
             image_id: Optional[int] = None,
             utc_date_time_taken: Optional[int] = None,
             image_description: Optional[str] = None,
             pitch: Optional[float] = None,
             roll: Optional[float] = None,
             yaw: Optional[float] = None,
             altitude_taken: Optional[float] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None) -> List[Images]:
    """
    Read from the images table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'image_id': image_id,
        'utc_date_time_taken': utc_date_time_taken,
        'image_description': image_description,
        'photo_storage_name': photo_storage_name,
        'photo_storage_path': photo_storage_path,
        'photo_storage_type': photo_storage_type,
        'pitch': pitch,
        'roll': roll,
        'yaw': yaw,
        'altitude_taken': altitude_taken,
        'image_width': image_width,
        'image_height': image_height,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'latitude': latitude,
        'longitude': longitude,
    }
    result = db.query(con, 'images', data)
    return [Images(**row.as_dict()) for row in result]

@beartype.beartype
def read_images_by_id(con: db.Connection, image_id: int) -> Optional[Images]:
    result = db.query_one(con, 'images', {'image_id': image_id})
    if result is None:
        return None
    return Images(**result)

@beartype.beartype
def delete_images_by_id(con: db.Connection, image_id: int):
    db.delete(con, 'images', {'image_id': image_id})
# Associate the functions with the class
Images.create_from_json_dict = create_images_from_json_dict
Images.write = write_images
Images.update = update_images
Images.write_many = write_images_many
Images.read = read_images
Images.read_fuzzy = read_images_fuzzy
Images.read_any = read_images_any
Images.read_one = read_images_one
Images.read_one_or_none = read_images_one_or_none
Images.read_all = read_images_all
Images.delete = delete_images_by_id
Images.read_by_id = read_images_by_id
Images.delete_by_id = delete_images_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Methods:
    """
    Describes methods used to perform actions recorded in ODM (e.g., observation methods, sample analysis methods, sample preparation methods, etc.)

    @param method_id 
    @param method_type_cv 
    @param method_code 
    @param method_name 
    @param method_description 
    @param method_link 
    @param organization_id 

    This is an automatically generated class
    """
    method_type_cv: str # method_type_cv character varying (default: )
    method_code: str # method_code character varying (default: )
    method_name: str # method_name character varying (default: )
    method_id: Optional[int] = None # method_id integer (default: )
    method_description: Optional[str] = None # method_description character varying (default: )
    method_link: Optional[str] = None # method_link character varying (default: )
    organization_id: Optional[int] = None # organization_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'method_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_method_type_cv(self, con: db.Connection) -> Optional['CvMethodType']:
        return read_cv_method_type_one_or_none(con, term=self.method_type_cv)

    @beartype.beartype
    def get_organization(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.organization_id)

@beartype.beartype
def create_methods_from_json_dict(json_obj: dict):
        """
        Create a Methods from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Methods(**json_obj)


@beartype.beartype
def write_methods_obj(con: db.Connection, obj: Methods) -> int:
    """
    Write a Methods object to the database
    @param con: database connection
    @param obj: Methods object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'methods', dataclasses.asdict(obj))

@beartype.beartype
def write_methods(
            con: db.Connection,
            method_type_cv: str,
            method_code: str,
            method_name: str,
            method_id: Optional[int] = None,
            method_description: Optional[str] = None,
            method_link: Optional[str] = None,
            organization_id: Optional[int] = None) -> int:
    """
    Write to the methods table in the database
    @param con: database connection
    @param method_id 
    @param method_type_cv 
    @param method_code 
    @param method_name 
    @param method_description 
    @param method_link 
    @param organization_id 
    @return id of the inserted/updated row
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    return db.upsert(con, 'methods', data)

@beartype.beartype
def write_methods_many(con: db.Connection, objs: List[Methods], upsert: bool = False) -> int:
    """
    Write a list of Methods objects to the database
    @param con: database connection
    @param objs: list of Methods objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'methods', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_methods(con: db.Connection, method_id: int,
            method_type_cv: Optional[str] = None,
            method_code: Optional[str] = None,
            method_name: Optional[str] = None,
            method_description: Optional[str] = None,
            method_link: Optional[str] = None,
            organization_id: Optional[int] = None) -> int:
    """
    Update a row in the methods table in the database
    @param con: database connection
    @param method_id 
    @param method_type_cv 
    @param method_code 
    @param method_name 
    @param method_description 
    @param method_link 
    @param organization_id 
    @return The number of rows updated
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    return db.update(con, 'methods', data)

@beartype.beartype
def read_methods(
            con: db.Connection,
            method_type_cv: Optional[str] = None,
             method_code: Optional[str] = None,
             method_name: Optional[str] = None,
             method_id: Optional[int] = None,
             method_description: Optional[str] = None,
             method_link: Optional[str] = None,
             organization_id: Optional[int] = None) -> Generator[Methods, None, None]:
    """
    Read from the methods table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param method_id 
    @param method_type_cv 
    @param method_code 
    @param method_name 
    @param method_description 
    @param method_link 
    @param organization_id 
    @return generator of Methods objects
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    result = db.query(con, 'methods', data)
    for row in result:
        yield Methods(**row.as_dict())

@beartype.beartype
def read_methods_fuzzy(con: db.Connection, method_type_cv: Optional[str] = None,
             method_code: Optional[str] = None,
             method_name: Optional[str] = None,
             method_id: Optional[int] = None,
             method_description: Optional[str] = None,
             method_link: Optional[str] = None,
             organization_id: Optional[int] = None) -> Generator[Methods, None, None]:
    """
    Read from the methods table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param method_id 
    @param method_type_cv 
    @param method_code 
    @param method_name 
    @param method_description 
    @param method_link 
    @param organization_id 
    @return generator of Methods objects
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    result = db.query_fuzzy(con, 'methods', data)
    for row in result:
        yield Methods(**row.as_dict())

@beartype.beartype
def read_methods_any(con: db.Connection, method_type_cv: Optional[List[str]] = None,
             method_code: Optional[List[str]] = None,
             method_name: Optional[List[str]] = None,
             method_id: Optional[List[int]] = None,
             method_description: Optional[List[str]] = None,
             method_link: Optional[List[str]] = None,
             organization_id: Optional[List[int]] = None) -> Generator[Methods, None, None]:
    """
    Read from the methods table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param method_id 
    @param method_type_cv 
    @param method_code 
    @param method_name 
    @param method_description 
    @param method_link 
    @param organization_id 
    @return generator of Methods objects
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    result = db.query_any(con, 'methods', data)
    for row in result:
        yield Methods(**row.as_dict())

@beartype.beartype
def read_methods_one_or_none(con: db.Connection, method_type_cv: Optional[str] = None,
             method_code: Optional[str] = None,
             method_name: Optional[str] = None,
             method_id: Optional[int] = None,
             method_description: Optional[str] = None,
             method_link: Optional[str] = None,
             organization_id: Optional[int] = None) -> Optional[Methods]:
    """
    Read from the methods table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    result = db.query_one_or_none(con, 'methods', data)
    if result is None:
        return None
    return Methods(**result)

@beartype.beartype
def read_methods_one(con: db.Connection, method_type_cv: Optional[str] = None,
             method_code: Optional[str] = None,
             method_name: Optional[str] = None,
             method_id: Optional[int] = None,
             method_description: Optional[str] = None,
             method_link: Optional[str] = None,
             organization_id: Optional[int] = None) -> Methods:
    """
    Read from the methods table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    result = db.query_one(con, 'methods', data)
    return Methods(**result)

@beartype.beartype
def read_methods_all(con: db.Connection, method_type_cv: Optional[str] = None,
             method_code: Optional[str] = None,
             method_name: Optional[str] = None,
             method_id: Optional[int] = None,
             method_description: Optional[str] = None,
             method_link: Optional[str] = None,
             organization_id: Optional[int] = None) -> List[Methods]:
    """
    Read from the methods table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'method_id': method_id,
        'method_type_cv': method_type_cv,
        'method_code': method_code,
        'method_name': method_name,
        'method_description': method_description,
        'method_link': method_link,
        'organization_id': organization_id,
    }
    result = db.query(con, 'methods', data)
    return [Methods(**row.as_dict()) for row in result]

@beartype.beartype
def read_methods_by_id(con: db.Connection, method_id: int) -> Optional[Methods]:
    result = db.query_one(con, 'methods', {'method_id': method_id})
    if result is None:
        return None
    return Methods(**result)

@beartype.beartype
def delete_methods_by_id(con: db.Connection, method_id: int):
    db.delete(con, 'methods', {'method_id': method_id})
# Associate the functions with the class
Methods.create_from_json_dict = create_methods_from_json_dict
Methods.write = write_methods
Methods.update = update_methods
Methods.write_many = write_methods_many
Methods.read = read_methods
Methods.read_fuzzy = read_methods_fuzzy
Methods.read_any = read_methods_any
Methods.read_one = read_methods_one
Methods.read_one_or_none = read_methods_one_or_none
Methods.read_all = read_methods_all
Methods.delete = delete_methods_by_id
Methods.read_by_id = read_methods_by_id
Methods.delete_by_id = delete_methods_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SamplingFeaturesAliases:
    """
    @param sampling_features_aliases_id 
    @param alias 
    @param alias_category 
    @param sampling_feature_id 
    @param display_priority 

    This is an automatically generated class
    """
    alias: str # alias character varying (default: )
    sampling_feature_id: int # sampling_feature_id integer (default: )
    display_priority: int # display_priority integer (default: )
    sampling_features_aliases_id: Optional[int] = None # sampling_features_aliases_id integer (default: )
    alias_category: Optional[str] = None # alias_category character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'sampling_features_aliases_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_sampling_features_aliases_from_json_dict(json_obj: dict):
        """
        Create a SamplingFeaturesAliases from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SamplingFeaturesAliases(**json_obj)


@beartype.beartype
def write_sampling_features_aliases_obj(con: db.Connection, obj: SamplingFeaturesAliases) -> int:
    """
    Write a SamplingFeaturesAliases object to the database
    @param con: database connection
    @param obj: SamplingFeaturesAliases object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampling_features_aliases', dataclasses.asdict(obj))

@beartype.beartype
def write_sampling_features_aliases(
            con: db.Connection,
            alias: str,
            sampling_feature_id: int,
            display_priority: int,
            sampling_features_aliases_id: Optional[int] = None,
            alias_category: Optional[str] = None) -> int:
    """
    Write to the sampling_features_aliases table in the database
    @param con: database connection
    @param sampling_features_aliases_id 
    @param alias 
    @param alias_category 
    @param sampling_feature_id 
    @param display_priority 
    @return id of the inserted/updated row
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    return db.upsert(con, 'sampling_features_aliases', data)

@beartype.beartype
def write_sampling_features_aliases_many(con: db.Connection, objs: List[SamplingFeaturesAliases], upsert: bool = False) -> int:
    """
    Write a list of SamplingFeaturesAliases objects to the database
    @param con: database connection
    @param objs: list of SamplingFeaturesAliases objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampling_features_aliases', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampling_features_aliases(con: db.Connection, sampling_features_aliases_id: int,
            alias: Optional[str] = None,
            sampling_feature_id: Optional[int] = None,
            display_priority: Optional[int] = None,
            alias_category: Optional[str] = None) -> int:
    """
    Update a row in the sampling_features_aliases table in the database
    @param con: database connection
    @param sampling_features_aliases_id 
    @param alias 
    @param alias_category 
    @param sampling_feature_id 
    @param display_priority 
    @return The number of rows updated
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    return db.update(con, 'sampling_features_aliases', data)

@beartype.beartype
def read_sampling_features_aliases(
            con: db.Connection,
            alias: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             display_priority: Optional[int] = None,
             sampling_features_aliases_id: Optional[int] = None,
             alias_category: Optional[str] = None) -> Generator[SamplingFeaturesAliases, None, None]:
    """
    Read from the sampling_features_aliases table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_features_aliases_id 
    @param alias 
    @param alias_category 
    @param sampling_feature_id 
    @param display_priority 
    @return generator of SamplingFeaturesAliases objects
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    result = db.query(con, 'sampling_features_aliases', data)
    for row in result:
        yield SamplingFeaturesAliases(**row.as_dict())

@beartype.beartype
def read_sampling_features_aliases_fuzzy(con: db.Connection, alias: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             display_priority: Optional[int] = None,
             sampling_features_aliases_id: Optional[int] = None,
             alias_category: Optional[str] = None) -> Generator[SamplingFeaturesAliases, None, None]:
    """
    Read from the sampling_features_aliases table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_features_aliases_id 
    @param alias 
    @param alias_category 
    @param sampling_feature_id 
    @param display_priority 
    @return generator of SamplingFeaturesAliases objects
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    result = db.query_fuzzy(con, 'sampling_features_aliases', data)
    for row in result:
        yield SamplingFeaturesAliases(**row.as_dict())

@beartype.beartype
def read_sampling_features_aliases_any(con: db.Connection, alias: Optional[List[str]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             display_priority: Optional[List[int]] = None,
             sampling_features_aliases_id: Optional[List[int]] = None,
             alias_category: Optional[List[str]] = None) -> Generator[SamplingFeaturesAliases, None, None]:
    """
    Read from the sampling_features_aliases table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_features_aliases_id 
    @param alias 
    @param alias_category 
    @param sampling_feature_id 
    @param display_priority 
    @return generator of SamplingFeaturesAliases objects
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    result = db.query_any(con, 'sampling_features_aliases', data)
    for row in result:
        yield SamplingFeaturesAliases(**row.as_dict())

@beartype.beartype
def read_sampling_features_aliases_one_or_none(con: db.Connection, alias: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             display_priority: Optional[int] = None,
             sampling_features_aliases_id: Optional[int] = None,
             alias_category: Optional[str] = None) -> Optional[SamplingFeaturesAliases]:
    """
    Read from the sampling_features_aliases table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    result = db.query_one_or_none(con, 'sampling_features_aliases', data)
    if result is None:
        return None
    return SamplingFeaturesAliases(**result)

@beartype.beartype
def read_sampling_features_aliases_one(con: db.Connection, alias: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             display_priority: Optional[int] = None,
             sampling_features_aliases_id: Optional[int] = None,
             alias_category: Optional[str] = None) -> SamplingFeaturesAliases:
    """
    Read from the sampling_features_aliases table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    result = db.query_one(con, 'sampling_features_aliases', data)
    return SamplingFeaturesAliases(**result)

@beartype.beartype
def read_sampling_features_aliases_all(con: db.Connection, alias: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             display_priority: Optional[int] = None,
             sampling_features_aliases_id: Optional[int] = None,
             alias_category: Optional[str] = None) -> List[SamplingFeaturesAliases]:
    """
    Read from the sampling_features_aliases table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'sampling_features_aliases_id': sampling_features_aliases_id,
        'alias': alias,
        'alias_category': alias_category,
        'sampling_feature_id': sampling_feature_id,
        'display_priority': display_priority,
    }
    result = db.query(con, 'sampling_features_aliases', data)
    return [SamplingFeaturesAliases(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampling_features_aliases_by_id(con: db.Connection, sampling_features_aliases_id: int) -> Optional[SamplingFeaturesAliases]:
    result = db.query_one(con, 'sampling_features_aliases', {'sampling_features_aliases_id': sampling_features_aliases_id})
    if result is None:
        return None
    return SamplingFeaturesAliases(**result)

@beartype.beartype
def delete_sampling_features_aliases_by_id(con: db.Connection, sampling_features_aliases_id: int):
    db.delete(con, 'sampling_features_aliases', {'sampling_features_aliases_id': sampling_features_aliases_id})
# Associate the functions with the class
SamplingFeaturesAliases.create_from_json_dict = create_sampling_features_aliases_from_json_dict
SamplingFeaturesAliases.write = write_sampling_features_aliases
SamplingFeaturesAliases.update = update_sampling_features_aliases
SamplingFeaturesAliases.write_many = write_sampling_features_aliases_many
SamplingFeaturesAliases.read = read_sampling_features_aliases
SamplingFeaturesAliases.read_fuzzy = read_sampling_features_aliases_fuzzy
SamplingFeaturesAliases.read_any = read_sampling_features_aliases_any
SamplingFeaturesAliases.read_one = read_sampling_features_aliases_one
SamplingFeaturesAliases.read_one_or_none = read_sampling_features_aliases_one_or_none
SamplingFeaturesAliases.read_all = read_sampling_features_aliases_all
SamplingFeaturesAliases.delete = delete_sampling_features_aliases_by_id
SamplingFeaturesAliases.read_by_id = read_sampling_features_aliases_by_id
SamplingFeaturesAliases.delete_by_id = delete_sampling_features_aliases_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ProcessingLevels:
    """
    Describes the processing level of Results

    @param processing_level_id 
    @param processing_level_code 
    @param definition 
    @param explanation 

    This is an automatically generated class
    """
    processing_level_code: str # processing_level_code character varying (default: )
    processing_level_id: Optional[int] = None # processing_level_id integer (default: )
    definition: Optional[str] = None # definition character varying (default: )
    explanation: Optional[str] = None # explanation character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'processing_level_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_processing_levels_from_json_dict(json_obj: dict):
        """
        Create a ProcessingLevels from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ProcessingLevels(**json_obj)


@beartype.beartype
def write_processing_levels_obj(con: db.Connection, obj: ProcessingLevels) -> int:
    """
    Write a ProcessingLevels object to the database
    @param con: database connection
    @param obj: ProcessingLevels object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'processing_levels', dataclasses.asdict(obj))

@beartype.beartype
def write_processing_levels(
            con: db.Connection,
            processing_level_code: str,
            processing_level_id: Optional[int] = None,
            definition: Optional[str] = None,
            explanation: Optional[str] = None) -> int:
    """
    Write to the processing_levels table in the database
    @param con: database connection
    @param processing_level_id 
    @param processing_level_code 
    @param definition 
    @param explanation 
    @return id of the inserted/updated row
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    return db.upsert(con, 'processing_levels', data)

@beartype.beartype
def write_processing_levels_many(con: db.Connection, objs: List[ProcessingLevels], upsert: bool = False) -> int:
    """
    Write a list of ProcessingLevels objects to the database
    @param con: database connection
    @param objs: list of ProcessingLevels objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'processing_levels', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_processing_levels(con: db.Connection, processing_level_id: int,
            processing_level_code: Optional[str] = None,
            definition: Optional[str] = None,
            explanation: Optional[str] = None) -> int:
    """
    Update a row in the processing_levels table in the database
    @param con: database connection
    @param processing_level_id 
    @param processing_level_code 
    @param definition 
    @param explanation 
    @return The number of rows updated
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    return db.update(con, 'processing_levels', data)

@beartype.beartype
def read_processing_levels(
            con: db.Connection,
            processing_level_code: Optional[str] = None,
             processing_level_id: Optional[int] = None,
             definition: Optional[str] = None,
             explanation: Optional[str] = None) -> Generator[ProcessingLevels, None, None]:
    """
    Read from the processing_levels table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param processing_level_id 
    @param processing_level_code 
    @param definition 
    @param explanation 
    @return generator of ProcessingLevels objects
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    result = db.query(con, 'processing_levels', data)
    for row in result:
        yield ProcessingLevels(**row.as_dict())

@beartype.beartype
def read_processing_levels_fuzzy(con: db.Connection, processing_level_code: Optional[str] = None,
             processing_level_id: Optional[int] = None,
             definition: Optional[str] = None,
             explanation: Optional[str] = None) -> Generator[ProcessingLevels, None, None]:
    """
    Read from the processing_levels table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param processing_level_id 
    @param processing_level_code 
    @param definition 
    @param explanation 
    @return generator of ProcessingLevels objects
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    result = db.query_fuzzy(con, 'processing_levels', data)
    for row in result:
        yield ProcessingLevels(**row.as_dict())

@beartype.beartype
def read_processing_levels_any(con: db.Connection, processing_level_code: Optional[List[str]] = None,
             processing_level_id: Optional[List[int]] = None,
             definition: Optional[List[str]] = None,
             explanation: Optional[List[str]] = None) -> Generator[ProcessingLevels, None, None]:
    """
    Read from the processing_levels table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param processing_level_id 
    @param processing_level_code 
    @param definition 
    @param explanation 
    @return generator of ProcessingLevels objects
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    result = db.query_any(con, 'processing_levels', data)
    for row in result:
        yield ProcessingLevels(**row.as_dict())

@beartype.beartype
def read_processing_levels_one_or_none(con: db.Connection, processing_level_code: Optional[str] = None,
             processing_level_id: Optional[int] = None,
             definition: Optional[str] = None,
             explanation: Optional[str] = None) -> Optional[ProcessingLevels]:
    """
    Read from the processing_levels table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    result = db.query_one_or_none(con, 'processing_levels', data)
    if result is None:
        return None
    return ProcessingLevels(**result)

@beartype.beartype
def read_processing_levels_one(con: db.Connection, processing_level_code: Optional[str] = None,
             processing_level_id: Optional[int] = None,
             definition: Optional[str] = None,
             explanation: Optional[str] = None) -> ProcessingLevels:
    """
    Read from the processing_levels table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    result = db.query_one(con, 'processing_levels', data)
    return ProcessingLevels(**result)

@beartype.beartype
def read_processing_levels_all(con: db.Connection, processing_level_code: Optional[str] = None,
             processing_level_id: Optional[int] = None,
             definition: Optional[str] = None,
             explanation: Optional[str] = None) -> List[ProcessingLevels]:
    """
    Read from the processing_levels table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'processing_level_id': processing_level_id,
        'processing_level_code': processing_level_code,
        'definition': definition,
        'explanation': explanation,
    }
    result = db.query(con, 'processing_levels', data)
    return [ProcessingLevels(**row.as_dict()) for row in result]

@beartype.beartype
def read_processing_levels_by_id(con: db.Connection, processing_level_id: int) -> Optional[ProcessingLevels]:
    result = db.query_one(con, 'processing_levels', {'processing_level_id': processing_level_id})
    if result is None:
        return None
    return ProcessingLevels(**result)

@beartype.beartype
def delete_processing_levels_by_id(con: db.Connection, processing_level_id: int):
    db.delete(con, 'processing_levels', {'processing_level_id': processing_level_id})
# Associate the functions with the class
ProcessingLevels.create_from_json_dict = create_processing_levels_from_json_dict
ProcessingLevels.write = write_processing_levels
ProcessingLevels.update = update_processing_levels
ProcessingLevels.write_many = write_processing_levels_many
ProcessingLevels.read = read_processing_levels
ProcessingLevels.read_fuzzy = read_processing_levels_fuzzy
ProcessingLevels.read_any = read_processing_levels_any
ProcessingLevels.read_one = read_processing_levels_one
ProcessingLevels.read_one_or_none = read_processing_levels_one_or_none
ProcessingLevels.read_all = read_processing_levels_all
ProcessingLevels.delete = delete_processing_levels_by_id
ProcessingLevels.read_by_id = read_processing_levels_by_id
ProcessingLevels.delete_by_id = delete_processing_levels_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SamplingFeatures:
    """
    Describes the sampling features on which observations are made.

    @param sampling_feature_id 
    @param sampling_feature_uuid 
    @param sampling_feature_type_cv 
    @param sampling_feature_code 
    @param sampling_feature_name 
    @param sampling_feature_description 
    @param sampling_feature_geotype_cv 
    @param feature_geometry 
    @param feature_geometry_wkt 
    @param elevation_m 
    @param elevation_datum_cv 
    @param latitude 
    @param longitude 
    @param epsg 

    This is an automatically generated class
    """
    sampling_feature_uuid: str # sampling_feature_uuid character varying (default: )
    sampling_feature_type_cv: str # sampling_feature_type_cv character varying (default: )
    sampling_feature_code: str # sampling_feature_code character varying (default: )
    sampling_feature_id: Optional[int] = None # sampling_feature_id integer (default: )
    sampling_feature_name: Optional[str] = None # sampling_feature_name character varying (default: )
    sampling_feature_description: Optional[str] = None # sampling_feature_description character varying (default: )
    sampling_feature_geotype_cv: Optional[str] = None # sampling_feature_geotype_cv character varying (default: )
    feature_geometry: Optional[str] = None # feature_geometry USER-DEFINED (default: )
    feature_geometry_wkt: Optional[str] = None # feature_geometry_wkt character varying (default: )
    elevation_m: Optional[float] = None # elevation_m double precision (default: )
    elevation_datum_cv: Optional[str] = None # elevation_datum_cv character varying (default: )
    latitude: Optional[float] = None # latitude double precision (default: )
    longitude: Optional[float] = None # longitude double precision (default: )
    epsg: Optional[str] = None # epsg character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'sampling_feature_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_elevation_datum_cv(self, con: db.Connection) -> Optional['CvElevationDatum']:
        return read_cv_elevation_datum_one_or_none(con, term=self.elevation_datum_cv)

    @beartype.beartype
    def get_sampling_feature_geotype_cv(self, con: db.Connection) -> Optional['CvSamplingFeatureGeoType']:
        return read_cv_sampling_feature_geo_type_one_or_none(con, term=self.sampling_feature_geotype_cv)

    @beartype.beartype
    def get_sampling_feature_type_cv(self, con: db.Connection) -> Optional['CvSamplingFeatureType']:
        return read_cv_sampling_feature_type_one_or_none(con, term=self.sampling_feature_type_cv)

@beartype.beartype
def create_sampling_features_from_json_dict(json_obj: dict):
        """
        Create a SamplingFeatures from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SamplingFeatures(**json_obj)


@beartype.beartype
def write_sampling_features_obj(con: db.Connection, obj: SamplingFeatures) -> int:
    """
    Write a SamplingFeatures object to the database
    @param con: database connection
    @param obj: SamplingFeatures object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampling_features', dataclasses.asdict(obj))

@beartype.beartype
def write_sampling_features(
            con: db.Connection,
            sampling_feature_uuid: str,
            sampling_feature_type_cv: str,
            sampling_feature_code: str,
            sampling_feature_id: Optional[int] = None,
            sampling_feature_name: Optional[str] = None,
            sampling_feature_description: Optional[str] = None,
            sampling_feature_geotype_cv: Optional[str] = None,
            feature_geometry: Optional[str] = None,
            feature_geometry_wkt: Optional[str] = None,
            elevation_m: Optional[float] = None,
            elevation_datum_cv: Optional[str] = None,
            latitude: Optional[float] = None,
            longitude: Optional[float] = None,
            epsg: Optional[str] = None) -> int:
    """
    Write to the sampling_features table in the database
    @param con: database connection
    @param sampling_feature_id 
    @param sampling_feature_uuid 
    @param sampling_feature_type_cv 
    @param sampling_feature_code 
    @param sampling_feature_name 
    @param sampling_feature_description 
    @param sampling_feature_geotype_cv 
    @param feature_geometry 
    @param feature_geometry_wkt 
    @param elevation_m 
    @param elevation_datum_cv 
    @param latitude 
    @param longitude 
    @param epsg 
    @return id of the inserted/updated row
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    return db.upsert(con, 'sampling_features', data)

@beartype.beartype
def write_sampling_features_many(con: db.Connection, objs: List[SamplingFeatures], upsert: bool = False) -> int:
    """
    Write a list of SamplingFeatures objects to the database
    @param con: database connection
    @param objs: list of SamplingFeatures objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampling_features', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampling_features(con: db.Connection, sampling_feature_id: int,
            sampling_feature_uuid: Optional[str] = None,
            sampling_feature_type_cv: Optional[str] = None,
            sampling_feature_code: Optional[str] = None,
            sampling_feature_name: Optional[str] = None,
            sampling_feature_description: Optional[str] = None,
            sampling_feature_geotype_cv: Optional[str] = None,
            feature_geometry: Optional[str] = None,
            feature_geometry_wkt: Optional[str] = None,
            elevation_m: Optional[float] = None,
            elevation_datum_cv: Optional[str] = None,
            latitude: Optional[float] = None,
            longitude: Optional[float] = None,
            epsg: Optional[str] = None) -> int:
    """
    Update a row in the sampling_features table in the database
    @param con: database connection
    @param sampling_feature_id 
    @param sampling_feature_uuid 
    @param sampling_feature_type_cv 
    @param sampling_feature_code 
    @param sampling_feature_name 
    @param sampling_feature_description 
    @param sampling_feature_geotype_cv 
    @param feature_geometry 
    @param feature_geometry_wkt 
    @param elevation_m 
    @param elevation_datum_cv 
    @param latitude 
    @param longitude 
    @param epsg 
    @return The number of rows updated
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    return db.update(con, 'sampling_features', data)

@beartype.beartype
def read_sampling_features(
            con: db.Connection,
            sampling_feature_uuid: Optional[str] = None,
             sampling_feature_type_cv: Optional[str] = None,
             sampling_feature_code: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             sampling_feature_name: Optional[str] = None,
             sampling_feature_description: Optional[str] = None,
             sampling_feature_geotype_cv: Optional[str] = None,
             feature_geometry: Optional[str] = None,
             feature_geometry_wkt: Optional[str] = None,
             elevation_m: Optional[float] = None,
             elevation_datum_cv: Optional[str] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None,
             epsg: Optional[str] = None) -> Generator[SamplingFeatures, None, None]:
    """
    Read from the sampling_features table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_feature_id 
    @param sampling_feature_uuid 
    @param sampling_feature_type_cv 
    @param sampling_feature_code 
    @param sampling_feature_name 
    @param sampling_feature_description 
    @param sampling_feature_geotype_cv 
    @param feature_geometry 
    @param feature_geometry_wkt 
    @param elevation_m 
    @param elevation_datum_cv 
    @param latitude 
    @param longitude 
    @param epsg 
    @return generator of SamplingFeatures objects
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    result = db.query(con, 'sampling_features', data)
    for row in result:
        yield SamplingFeatures(**row.as_dict())

@beartype.beartype
def read_sampling_features_fuzzy(con: db.Connection, sampling_feature_uuid: Optional[str] = None,
             sampling_feature_type_cv: Optional[str] = None,
             sampling_feature_code: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             sampling_feature_name: Optional[str] = None,
             sampling_feature_description: Optional[str] = None,
             sampling_feature_geotype_cv: Optional[str] = None,
             feature_geometry: Optional[str] = None,
             feature_geometry_wkt: Optional[str] = None,
             elevation_m: Optional[float] = None,
             elevation_datum_cv: Optional[str] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None,
             epsg: Optional[str] = None) -> Generator[SamplingFeatures, None, None]:
    """
    Read from the sampling_features table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_feature_id 
    @param sampling_feature_uuid 
    @param sampling_feature_type_cv 
    @param sampling_feature_code 
    @param sampling_feature_name 
    @param sampling_feature_description 
    @param sampling_feature_geotype_cv 
    @param feature_geometry 
    @param feature_geometry_wkt 
    @param elevation_m 
    @param elevation_datum_cv 
    @param latitude 
    @param longitude 
    @param epsg 
    @return generator of SamplingFeatures objects
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    result = db.query_fuzzy(con, 'sampling_features', data)
    for row in result:
        yield SamplingFeatures(**row.as_dict())

@beartype.beartype
def read_sampling_features_any(con: db.Connection, sampling_feature_uuid: Optional[List[str]] = None,
             sampling_feature_type_cv: Optional[List[str]] = None,
             sampling_feature_code: Optional[List[str]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             sampling_feature_name: Optional[List[str]] = None,
             sampling_feature_description: Optional[List[str]] = None,
             sampling_feature_geotype_cv: Optional[List[str]] = None,
             feature_geometry: Optional[List[str]] = None,
             feature_geometry_wkt: Optional[List[str]] = None,
             elevation_m: Optional[List[float]] = None,
             elevation_datum_cv: Optional[List[str]] = None,
             latitude: Optional[List[float]] = None,
             longitude: Optional[List[float]] = None,
             epsg: Optional[List[str]] = None) -> Generator[SamplingFeatures, None, None]:
    """
    Read from the sampling_features table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_feature_id 
    @param sampling_feature_uuid 
    @param sampling_feature_type_cv 
    @param sampling_feature_code 
    @param sampling_feature_name 
    @param sampling_feature_description 
    @param sampling_feature_geotype_cv 
    @param feature_geometry 
    @param feature_geometry_wkt 
    @param elevation_m 
    @param elevation_datum_cv 
    @param latitude 
    @param longitude 
    @param epsg 
    @return generator of SamplingFeatures objects
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    result = db.query_any(con, 'sampling_features', data)
    for row in result:
        yield SamplingFeatures(**row.as_dict())

@beartype.beartype
def read_sampling_features_one_or_none(con: db.Connection, sampling_feature_uuid: Optional[str] = None,
             sampling_feature_type_cv: Optional[str] = None,
             sampling_feature_code: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             sampling_feature_name: Optional[str] = None,
             sampling_feature_description: Optional[str] = None,
             sampling_feature_geotype_cv: Optional[str] = None,
             feature_geometry: Optional[str] = None,
             feature_geometry_wkt: Optional[str] = None,
             elevation_m: Optional[float] = None,
             elevation_datum_cv: Optional[str] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None,
             epsg: Optional[str] = None) -> Optional[SamplingFeatures]:
    """
    Read from the sampling_features table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    result = db.query_one_or_none(con, 'sampling_features', data)
    if result is None:
        return None
    return SamplingFeatures(**result)

@beartype.beartype
def read_sampling_features_one(con: db.Connection, sampling_feature_uuid: Optional[str] = None,
             sampling_feature_type_cv: Optional[str] = None,
             sampling_feature_code: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             sampling_feature_name: Optional[str] = None,
             sampling_feature_description: Optional[str] = None,
             sampling_feature_geotype_cv: Optional[str] = None,
             feature_geometry: Optional[str] = None,
             feature_geometry_wkt: Optional[str] = None,
             elevation_m: Optional[float] = None,
             elevation_datum_cv: Optional[str] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None,
             epsg: Optional[str] = None) -> SamplingFeatures:
    """
    Read from the sampling_features table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    result = db.query_one(con, 'sampling_features', data)
    return SamplingFeatures(**result)

@beartype.beartype
def read_sampling_features_all(con: db.Connection, sampling_feature_uuid: Optional[str] = None,
             sampling_feature_type_cv: Optional[str] = None,
             sampling_feature_code: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             sampling_feature_name: Optional[str] = None,
             sampling_feature_description: Optional[str] = None,
             sampling_feature_geotype_cv: Optional[str] = None,
             feature_geometry: Optional[str] = None,
             feature_geometry_wkt: Optional[str] = None,
             elevation_m: Optional[float] = None,
             elevation_datum_cv: Optional[str] = None,
             latitude: Optional[float] = None,
             longitude: Optional[float] = None,
             epsg: Optional[str] = None) -> List[SamplingFeatures]:
    """
    Read from the sampling_features table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'sampling_feature_uuid': sampling_feature_uuid,
        'sampling_feature_type_cv': sampling_feature_type_cv,
        'sampling_feature_code': sampling_feature_code,
        'sampling_feature_name': sampling_feature_name,
        'sampling_feature_description': sampling_feature_description,
        'sampling_feature_geotype_cv': sampling_feature_geotype_cv,
        'feature_geometry': feature_geometry,
        'feature_geometry_wkt': feature_geometry_wkt,
        'elevation_m': elevation_m,
        'elevation_datum_cv': elevation_datum_cv,
        'latitude': latitude,
        'longitude': longitude,
        'epsg': epsg,
    }
    result = db.query(con, 'sampling_features', data)
    return [SamplingFeatures(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampling_features_by_id(con: db.Connection, sampling_feature_id: int) -> Optional[SamplingFeatures]:
    result = db.query_one(con, 'sampling_features', {'sampling_feature_id': sampling_feature_id})
    if result is None:
        return None
    return SamplingFeatures(**result)

@beartype.beartype
def delete_sampling_features_by_id(con: db.Connection, sampling_feature_id: int):
    db.delete(con, 'sampling_features', {'sampling_feature_id': sampling_feature_id})
# Associate the functions with the class
SamplingFeatures.create_from_json_dict = create_sampling_features_from_json_dict
SamplingFeatures.write = write_sampling_features
SamplingFeatures.update = update_sampling_features
SamplingFeatures.write_many = write_sampling_features_many
SamplingFeatures.read = read_sampling_features
SamplingFeatures.read_fuzzy = read_sampling_features_fuzzy
SamplingFeatures.read_any = read_sampling_features_any
SamplingFeatures.read_one = read_sampling_features_one
SamplingFeatures.read_one_or_none = read_sampling_features_one_or_none
SamplingFeatures.read_all = read_sampling_features_all
SamplingFeatures.delete = delete_sampling_features_by_id
SamplingFeatures.read_by_id = read_sampling_features_by_id
SamplingFeatures.delete_by_id = delete_sampling_features_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Organizations:
    """
    Describes organizations - as in research groups, companies, universities, etc.

    @param organization_id 
    @param organization_type_cv 
    @param organization_code 
    @param organization_name 
    @param organization_description 
    @param organization_link 
    @param parent_organization_id 

    This is an automatically generated class
    """
    organization_type_cv: str # organization_type_cv character varying (default: )
    organization_code: str # organization_code character varying (default: )
    organization_name: str # organization_name character varying (default: )
    organization_id: Optional[int] = None # organization_id integer (default: )
    organization_description: Optional[str] = None # organization_description character varying (default: )
    organization_link: Optional[str] = None # organization_link character varying (default: )
    parent_organization_id: Optional[int] = None # parent_organization_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'organization_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_organization_type_cv(self, con: db.Connection) -> Optional['CvOrganizationType']:
        return read_cv_organization_type_one_or_none(con, term=self.organization_type_cv)

    @beartype.beartype
    def get_parent_organization(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.parent_organization_id)

@beartype.beartype
def create_organizations_from_json_dict(json_obj: dict):
        """
        Create a Organizations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Organizations(**json_obj)


@beartype.beartype
def write_organizations_obj(con: db.Connection, obj: Organizations) -> int:
    """
    Write a Organizations object to the database
    @param con: database connection
    @param obj: Organizations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'organizations', dataclasses.asdict(obj))

@beartype.beartype
def write_organizations(
            con: db.Connection,
            organization_type_cv: str,
            organization_code: str,
            organization_name: str,
            organization_id: Optional[int] = None,
            organization_description: Optional[str] = None,
            organization_link: Optional[str] = None,
            parent_organization_id: Optional[int] = None) -> int:
    """
    Write to the organizations table in the database
    @param con: database connection
    @param organization_id 
    @param organization_type_cv 
    @param organization_code 
    @param organization_name 
    @param organization_description 
    @param organization_link 
    @param parent_organization_id 
    @return id of the inserted/updated row
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    return db.upsert(con, 'organizations', data)

@beartype.beartype
def write_organizations_many(con: db.Connection, objs: List[Organizations], upsert: bool = False) -> int:
    """
    Write a list of Organizations objects to the database
    @param con: database connection
    @param objs: list of Organizations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'organizations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_organizations(con: db.Connection, organization_id: int,
            organization_type_cv: Optional[str] = None,
            organization_code: Optional[str] = None,
            organization_name: Optional[str] = None,
            organization_description: Optional[str] = None,
            organization_link: Optional[str] = None,
            parent_organization_id: Optional[int] = None) -> int:
    """
    Update a row in the organizations table in the database
    @param con: database connection
    @param organization_id 
    @param organization_type_cv 
    @param organization_code 
    @param organization_name 
    @param organization_description 
    @param organization_link 
    @param parent_organization_id 
    @return The number of rows updated
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    return db.update(con, 'organizations', data)

@beartype.beartype
def read_organizations(
            con: db.Connection,
            organization_type_cv: Optional[str] = None,
             organization_code: Optional[str] = None,
             organization_name: Optional[str] = None,
             organization_id: Optional[int] = None,
             organization_description: Optional[str] = None,
             organization_link: Optional[str] = None,
             parent_organization_id: Optional[int] = None) -> Generator[Organizations, None, None]:
    """
    Read from the organizations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param organization_id 
    @param organization_type_cv 
    @param organization_code 
    @param organization_name 
    @param organization_description 
    @param organization_link 
    @param parent_organization_id 
    @return generator of Organizations objects
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    result = db.query(con, 'organizations', data)
    for row in result:
        yield Organizations(**row.as_dict())

@beartype.beartype
def read_organizations_fuzzy(con: db.Connection, organization_type_cv: Optional[str] = None,
             organization_code: Optional[str] = None,
             organization_name: Optional[str] = None,
             organization_id: Optional[int] = None,
             organization_description: Optional[str] = None,
             organization_link: Optional[str] = None,
             parent_organization_id: Optional[int] = None) -> Generator[Organizations, None, None]:
    """
    Read from the organizations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param organization_id 
    @param organization_type_cv 
    @param organization_code 
    @param organization_name 
    @param organization_description 
    @param organization_link 
    @param parent_organization_id 
    @return generator of Organizations objects
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    result = db.query_fuzzy(con, 'organizations', data)
    for row in result:
        yield Organizations(**row.as_dict())

@beartype.beartype
def read_organizations_any(con: db.Connection, organization_type_cv: Optional[List[str]] = None,
             organization_code: Optional[List[str]] = None,
             organization_name: Optional[List[str]] = None,
             organization_id: Optional[List[int]] = None,
             organization_description: Optional[List[str]] = None,
             organization_link: Optional[List[str]] = None,
             parent_organization_id: Optional[List[int]] = None) -> Generator[Organizations, None, None]:
    """
    Read from the organizations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param organization_id 
    @param organization_type_cv 
    @param organization_code 
    @param organization_name 
    @param organization_description 
    @param organization_link 
    @param parent_organization_id 
    @return generator of Organizations objects
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    result = db.query_any(con, 'organizations', data)
    for row in result:
        yield Organizations(**row.as_dict())

@beartype.beartype
def read_organizations_one_or_none(con: db.Connection, organization_type_cv: Optional[str] = None,
             organization_code: Optional[str] = None,
             organization_name: Optional[str] = None,
             organization_id: Optional[int] = None,
             organization_description: Optional[str] = None,
             organization_link: Optional[str] = None,
             parent_organization_id: Optional[int] = None) -> Optional[Organizations]:
    """
    Read from the organizations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    result = db.query_one_or_none(con, 'organizations', data)
    if result is None:
        return None
    return Organizations(**result)

@beartype.beartype
def read_organizations_one(con: db.Connection, organization_type_cv: Optional[str] = None,
             organization_code: Optional[str] = None,
             organization_name: Optional[str] = None,
             organization_id: Optional[int] = None,
             organization_description: Optional[str] = None,
             organization_link: Optional[str] = None,
             parent_organization_id: Optional[int] = None) -> Organizations:
    """
    Read from the organizations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    result = db.query_one(con, 'organizations', data)
    return Organizations(**result)

@beartype.beartype
def read_organizations_all(con: db.Connection, organization_type_cv: Optional[str] = None,
             organization_code: Optional[str] = None,
             organization_name: Optional[str] = None,
             organization_id: Optional[int] = None,
             organization_description: Optional[str] = None,
             organization_link: Optional[str] = None,
             parent_organization_id: Optional[int] = None) -> List[Organizations]:
    """
    Read from the organizations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'organization_id': organization_id,
        'organization_type_cv': organization_type_cv,
        'organization_code': organization_code,
        'organization_name': organization_name,
        'organization_description': organization_description,
        'organization_link': organization_link,
        'parent_organization_id': parent_organization_id,
    }
    result = db.query(con, 'organizations', data)
    return [Organizations(**row.as_dict()) for row in result]

@beartype.beartype
def read_organizations_by_id(con: db.Connection, organization_id: int) -> Optional[Organizations]:
    result = db.query_one(con, 'organizations', {'organization_id': organization_id})
    if result is None:
        return None
    return Organizations(**result)

@beartype.beartype
def delete_organizations_by_id(con: db.Connection, organization_id: int):
    db.delete(con, 'organizations', {'organization_id': organization_id})
# Associate the functions with the class
Organizations.create_from_json_dict = create_organizations_from_json_dict
Organizations.write = write_organizations
Organizations.update = update_organizations
Organizations.write_many = write_organizations_many
Organizations.read = read_organizations
Organizations.read_fuzzy = read_organizations_fuzzy
Organizations.read_any = read_organizations_any
Organizations.read_one = read_organizations_one
Organizations.read_one_or_none = read_organizations_one_or_none
Organizations.read_all = read_organizations_all
Organizations.delete = delete_organizations_by_id
Organizations.read_by_id = read_organizations_by_id
Organizations.delete_by_id = delete_organizations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Persons:
    """
    Describes people.

    @param person_id 
    @param person_first_name 
    @param person_middle_name 
    @param person_last_name 
    @param orc_id 

    This is an automatically generated class
    """
    person_first_name: str # person_first_name character varying (default: )
    person_last_name: str # person_last_name character varying (default: )
    person_id: Optional[int] = None # person_id integer (default: )
    person_middle_name: Optional[str] = None # person_middle_name character varying (default: )
    orc_id: Optional[str] = None # orc_id character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'person_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_persons_from_json_dict(json_obj: dict):
        """
        Create a Persons from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Persons(**json_obj)


@beartype.beartype
def write_persons_obj(con: db.Connection, obj: Persons) -> int:
    """
    Write a Persons object to the database
    @param con: database connection
    @param obj: Persons object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'persons', dataclasses.asdict(obj))

@beartype.beartype
def write_persons(
            con: db.Connection,
            person_first_name: str,
            person_last_name: str,
            person_id: Optional[int] = None,
            person_middle_name: Optional[str] = None,
            orc_id: Optional[str] = None) -> int:
    """
    Write to the persons table in the database
    @param con: database connection
    @param person_id 
    @param person_first_name 
    @param person_middle_name 
    @param person_last_name 
    @param orc_id 
    @return id of the inserted/updated row
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    return db.upsert(con, 'persons', data)

@beartype.beartype
def write_persons_many(con: db.Connection, objs: List[Persons], upsert: bool = False) -> int:
    """
    Write a list of Persons objects to the database
    @param con: database connection
    @param objs: list of Persons objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'persons', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_persons(con: db.Connection, person_id: int,
            person_first_name: Optional[str] = None,
            person_last_name: Optional[str] = None,
            person_middle_name: Optional[str] = None,
            orc_id: Optional[str] = None) -> int:
    """
    Update a row in the persons table in the database
    @param con: database connection
    @param person_id 
    @param person_first_name 
    @param person_middle_name 
    @param person_last_name 
    @param orc_id 
    @return The number of rows updated
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    return db.update(con, 'persons', data)

@beartype.beartype
def read_persons(
            con: db.Connection,
            person_first_name: Optional[str] = None,
             person_last_name: Optional[str] = None,
             person_id: Optional[int] = None,
             person_middle_name: Optional[str] = None,
             orc_id: Optional[str] = None) -> Generator[Persons, None, None]:
    """
    Read from the persons table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param person_id 
    @param person_first_name 
    @param person_middle_name 
    @param person_last_name 
    @param orc_id 
    @return generator of Persons objects
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    result = db.query(con, 'persons', data)
    for row in result:
        yield Persons(**row.as_dict())

@beartype.beartype
def read_persons_fuzzy(con: db.Connection, person_first_name: Optional[str] = None,
             person_last_name: Optional[str] = None,
             person_id: Optional[int] = None,
             person_middle_name: Optional[str] = None,
             orc_id: Optional[str] = None) -> Generator[Persons, None, None]:
    """
    Read from the persons table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param person_id 
    @param person_first_name 
    @param person_middle_name 
    @param person_last_name 
    @param orc_id 
    @return generator of Persons objects
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    result = db.query_fuzzy(con, 'persons', data)
    for row in result:
        yield Persons(**row.as_dict())

@beartype.beartype
def read_persons_any(con: db.Connection, person_first_name: Optional[List[str]] = None,
             person_last_name: Optional[List[str]] = None,
             person_id: Optional[List[int]] = None,
             person_middle_name: Optional[List[str]] = None,
             orc_id: Optional[List[str]] = None) -> Generator[Persons, None, None]:
    """
    Read from the persons table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param person_id 
    @param person_first_name 
    @param person_middle_name 
    @param person_last_name 
    @param orc_id 
    @return generator of Persons objects
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    result = db.query_any(con, 'persons', data)
    for row in result:
        yield Persons(**row.as_dict())

@beartype.beartype
def read_persons_one_or_none(con: db.Connection, person_first_name: Optional[str] = None,
             person_last_name: Optional[str] = None,
             person_id: Optional[int] = None,
             person_middle_name: Optional[str] = None,
             orc_id: Optional[str] = None) -> Optional[Persons]:
    """
    Read from the persons table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    result = db.query_one_or_none(con, 'persons', data)
    if result is None:
        return None
    return Persons(**result)

@beartype.beartype
def read_persons_one(con: db.Connection, person_first_name: Optional[str] = None,
             person_last_name: Optional[str] = None,
             person_id: Optional[int] = None,
             person_middle_name: Optional[str] = None,
             orc_id: Optional[str] = None) -> Persons:
    """
    Read from the persons table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    result = db.query_one(con, 'persons', data)
    return Persons(**result)

@beartype.beartype
def read_persons_all(con: db.Connection, person_first_name: Optional[str] = None,
             person_last_name: Optional[str] = None,
             person_id: Optional[int] = None,
             person_middle_name: Optional[str] = None,
             orc_id: Optional[str] = None) -> List[Persons]:
    """
    Read from the persons table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'person_id': person_id,
        'person_first_name': person_first_name,
        'person_middle_name': person_middle_name,
        'person_last_name': person_last_name,
        'orc_id': orc_id,
    }
    result = db.query(con, 'persons', data)
    return [Persons(**row.as_dict()) for row in result]

@beartype.beartype
def read_persons_by_id(con: db.Connection, person_id: int) -> Optional[Persons]:
    result = db.query_one(con, 'persons', {'person_id': person_id})
    if result is None:
        return None
    return Persons(**result)

@beartype.beartype
def delete_persons_by_id(con: db.Connection, person_id: int):
    db.delete(con, 'persons', {'person_id': person_id})
# Associate the functions with the class
Persons.create_from_json_dict = create_persons_from_json_dict
Persons.write = write_persons
Persons.update = update_persons
Persons.write_many = write_persons_many
Persons.read = read_persons
Persons.read_fuzzy = read_persons_fuzzy
Persons.read_any = read_persons_any
Persons.read_one = read_persons_one
Persons.read_one_or_none = read_persons_one_or_none
Persons.read_all = read_persons_all
Persons.delete = delete_persons_by_id
Persons.read_by_id = read_persons_by_id
Persons.delete_by_id = delete_persons_by_id



@beartype_wrap_init
@dataclasses.dataclass
class InstrumentActions:
    """
    @param instrument_action_id 
    @param equipment_id 
    @param action_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    instrument_action_id: Optional[int] = None # instrument_action_id integer (default: )
    equipment_id: Optional[int] = None # equipment_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'instrument_action_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

@beartype.beartype
def create_instrument_actions_from_json_dict(json_obj: dict):
        """
        Create a InstrumentActions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return InstrumentActions(**json_obj)


@beartype.beartype
def write_instrument_actions_obj(con: db.Connection, obj: InstrumentActions) -> int:
    """
    Write a InstrumentActions object to the database
    @param con: database connection
    @param obj: InstrumentActions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'instrument_actions', dataclasses.asdict(obj))

@beartype.beartype
def write_instrument_actions(
            con: db.Connection,
            action_id: int,
            instrument_action_id: Optional[int] = None,
            equipment_id: Optional[int] = None) -> int:
    """
    Write to the instrument_actions table in the database
    @param con: database connection
    @param instrument_action_id 
    @param equipment_id 
    @param action_id 
    @return id of the inserted/updated row
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    return db.upsert(con, 'instrument_actions', data)

@beartype.beartype
def write_instrument_actions_many(con: db.Connection, objs: List[InstrumentActions], upsert: bool = False) -> int:
    """
    Write a list of InstrumentActions objects to the database
    @param con: database connection
    @param objs: list of InstrumentActions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'instrument_actions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_instrument_actions(con: db.Connection, instrument_action_id: int,
            action_id: Optional[int] = None,
            equipment_id: Optional[int] = None) -> int:
    """
    Update a row in the instrument_actions table in the database
    @param con: database connection
    @param instrument_action_id 
    @param equipment_id 
    @param action_id 
    @return The number of rows updated
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    return db.update(con, 'instrument_actions', data)

@beartype.beartype
def read_instrument_actions(
            con: db.Connection,
            action_id: Optional[int] = None,
             instrument_action_id: Optional[int] = None,
             equipment_id: Optional[int] = None) -> Generator[InstrumentActions, None, None]:
    """
    Read from the instrument_actions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param instrument_action_id 
    @param equipment_id 
    @param action_id 
    @return generator of InstrumentActions objects
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    result = db.query(con, 'instrument_actions', data)
    for row in result:
        yield InstrumentActions(**row.as_dict())

@beartype.beartype
def read_instrument_actions_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             instrument_action_id: Optional[int] = None,
             equipment_id: Optional[int] = None) -> Generator[InstrumentActions, None, None]:
    """
    Read from the instrument_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param instrument_action_id 
    @param equipment_id 
    @param action_id 
    @return generator of InstrumentActions objects
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    result = db.query_fuzzy(con, 'instrument_actions', data)
    for row in result:
        yield InstrumentActions(**row.as_dict())

@beartype.beartype
def read_instrument_actions_any(con: db.Connection, action_id: Optional[List[int]] = None,
             instrument_action_id: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None) -> Generator[InstrumentActions, None, None]:
    """
    Read from the instrument_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param instrument_action_id 
    @param equipment_id 
    @param action_id 
    @return generator of InstrumentActions objects
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    result = db.query_any(con, 'instrument_actions', data)
    for row in result:
        yield InstrumentActions(**row.as_dict())

@beartype.beartype
def read_instrument_actions_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             instrument_action_id: Optional[int] = None,
             equipment_id: Optional[int] = None) -> Optional[InstrumentActions]:
    """
    Read from the instrument_actions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    result = db.query_one_or_none(con, 'instrument_actions', data)
    if result is None:
        return None
    return InstrumentActions(**result)

@beartype.beartype
def read_instrument_actions_one(con: db.Connection, action_id: Optional[int] = None,
             instrument_action_id: Optional[int] = None,
             equipment_id: Optional[int] = None) -> InstrumentActions:
    """
    Read from the instrument_actions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    result = db.query_one(con, 'instrument_actions', data)
    return InstrumentActions(**result)

@beartype.beartype
def read_instrument_actions_all(con: db.Connection, action_id: Optional[int] = None,
             instrument_action_id: Optional[int] = None,
             equipment_id: Optional[int] = None) -> List[InstrumentActions]:
    """
    Read from the instrument_actions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'instrument_action_id': instrument_action_id,
        'equipment_id': equipment_id,
        'action_id': action_id,
    }
    result = db.query(con, 'instrument_actions', data)
    return [InstrumentActions(**row.as_dict()) for row in result]

@beartype.beartype
def read_instrument_actions_by_id(con: db.Connection, instrument_action_id: int) -> Optional[InstrumentActions]:
    result = db.query_one(con, 'instrument_actions', {'instrument_action_id': instrument_action_id})
    if result is None:
        return None
    return InstrumentActions(**result)

@beartype.beartype
def delete_instrument_actions_by_id(con: db.Connection, instrument_action_id: int):
    db.delete(con, 'instrument_actions', {'instrument_action_id': instrument_action_id})
# Associate the functions with the class
InstrumentActions.create_from_json_dict = create_instrument_actions_from_json_dict
InstrumentActions.write = write_instrument_actions
InstrumentActions.update = update_instrument_actions
InstrumentActions.write_many = write_instrument_actions_many
InstrumentActions.read = read_instrument_actions
InstrumentActions.read_fuzzy = read_instrument_actions_fuzzy
InstrumentActions.read_any = read_instrument_actions_any
InstrumentActions.read_one = read_instrument_actions_one
InstrumentActions.read_one_or_none = read_instrument_actions_one_or_none
InstrumentActions.read_all = read_instrument_actions_all
InstrumentActions.delete = delete_instrument_actions_by_id
InstrumentActions.read_by_id = read_instrument_actions_by_id
InstrumentActions.delete_by_id = delete_instrument_actions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class OrganizationSamplingFeatureBridge:
    """
    Bridge table between organizations and sampling features

    @param bridge_id 
    @param organization_id 
    @param sampling_feature_id 

    This is an automatically generated class
    """
    organization_id: int # organization_id integer (default: )
    sampling_feature_id: int # sampling_feature_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_organization(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.organization_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_organization_sampling_feature_bridge_from_json_dict(json_obj: dict):
        """
        Create a OrganizationSamplingFeatureBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return OrganizationSamplingFeatureBridge(**json_obj)


@beartype.beartype
def write_organization_sampling_feature_bridge_obj(con: db.Connection, obj: OrganizationSamplingFeatureBridge) -> int:
    """
    Write a OrganizationSamplingFeatureBridge object to the database
    @param con: database connection
    @param obj: OrganizationSamplingFeatureBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'organization_sampling_feature_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_organization_sampling_feature_bridge(
            con: db.Connection,
            organization_id: int,
            sampling_feature_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the organization_sampling_feature_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param organization_id 
    @param sampling_feature_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    return db.upsert(con, 'organization_sampling_feature_bridge', data)

@beartype.beartype
def write_organization_sampling_feature_bridge_many(con: db.Connection, objs: List[OrganizationSamplingFeatureBridge], upsert: bool = False) -> int:
    """
    Write a list of OrganizationSamplingFeatureBridge objects to the database
    @param con: database connection
    @param objs: list of OrganizationSamplingFeatureBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'organization_sampling_feature_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_organization_sampling_feature_bridge(con: db.Connection, bridge_id: int,
            organization_id: Optional[int] = None,
            sampling_feature_id: Optional[int] = None) -> int:
    """
    Update a row in the organization_sampling_feature_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param organization_id 
    @param sampling_feature_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    return db.update(con, 'organization_sampling_feature_bridge', data)

@beartype.beartype
def read_organization_sampling_feature_bridge(
            con: db.Connection,
            organization_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[OrganizationSamplingFeatureBridge, None, None]:
    """
    Read from the organization_sampling_feature_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param organization_id 
    @param sampling_feature_id 
    @return generator of OrganizationSamplingFeatureBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query(con, 'organization_sampling_feature_bridge', data)
    for row in result:
        yield OrganizationSamplingFeatureBridge(**row.as_dict())

@beartype.beartype
def read_organization_sampling_feature_bridge_fuzzy(con: db.Connection, organization_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[OrganizationSamplingFeatureBridge, None, None]:
    """
    Read from the organization_sampling_feature_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param organization_id 
    @param sampling_feature_id 
    @return generator of OrganizationSamplingFeatureBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_fuzzy(con, 'organization_sampling_feature_bridge', data)
    for row in result:
        yield OrganizationSamplingFeatureBridge(**row.as_dict())

@beartype.beartype
def read_organization_sampling_feature_bridge_any(con: db.Connection, organization_id: Optional[List[int]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[OrganizationSamplingFeatureBridge, None, None]:
    """
    Read from the organization_sampling_feature_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param organization_id 
    @param sampling_feature_id 
    @return generator of OrganizationSamplingFeatureBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_any(con, 'organization_sampling_feature_bridge', data)
    for row in result:
        yield OrganizationSamplingFeatureBridge(**row.as_dict())

@beartype.beartype
def read_organization_sampling_feature_bridge_one_or_none(con: db.Connection, organization_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[OrganizationSamplingFeatureBridge]:
    """
    Read from the organization_sampling_feature_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_one_or_none(con, 'organization_sampling_feature_bridge', data)
    if result is None:
        return None
    return OrganizationSamplingFeatureBridge(**result)

@beartype.beartype
def read_organization_sampling_feature_bridge_one(con: db.Connection, organization_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> OrganizationSamplingFeatureBridge:
    """
    Read from the organization_sampling_feature_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_one(con, 'organization_sampling_feature_bridge', data)
    return OrganizationSamplingFeatureBridge(**result)

@beartype.beartype
def read_organization_sampling_feature_bridge_all(con: db.Connection, organization_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[OrganizationSamplingFeatureBridge]:
    """
    Read from the organization_sampling_feature_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'organization_id': organization_id,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query(con, 'organization_sampling_feature_bridge', data)
    return [OrganizationSamplingFeatureBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_organization_sampling_feature_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[OrganizationSamplingFeatureBridge]:
    result = db.query_one(con, 'organization_sampling_feature_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return OrganizationSamplingFeatureBridge(**result)

@beartype.beartype
def delete_organization_sampling_feature_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'organization_sampling_feature_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
OrganizationSamplingFeatureBridge.create_from_json_dict = create_organization_sampling_feature_bridge_from_json_dict
OrganizationSamplingFeatureBridge.write = write_organization_sampling_feature_bridge
OrganizationSamplingFeatureBridge.update = update_organization_sampling_feature_bridge
OrganizationSamplingFeatureBridge.write_many = write_organization_sampling_feature_bridge_many
OrganizationSamplingFeatureBridge.read = read_organization_sampling_feature_bridge
OrganizationSamplingFeatureBridge.read_fuzzy = read_organization_sampling_feature_bridge_fuzzy
OrganizationSamplingFeatureBridge.read_any = read_organization_sampling_feature_bridge_any
OrganizationSamplingFeatureBridge.read_one = read_organization_sampling_feature_bridge_one
OrganizationSamplingFeatureBridge.read_one_or_none = read_organization_sampling_feature_bridge_one_or_none
OrganizationSamplingFeatureBridge.read_all = read_organization_sampling_feature_bridge_all
OrganizationSamplingFeatureBridge.delete = delete_organization_sampling_feature_bridge_by_id
OrganizationSamplingFeatureBridge.read_by_id = read_organization_sampling_feature_bridge_by_id
OrganizationSamplingFeatureBridge.delete_by_id = delete_organization_sampling_feature_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedActions:
    """
    Describes Actions that are related to one another.

    @param relation_id 
    @param action_id 
    @param relationship_type_cv 
    @param related_action_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_action_id: int # related_action_id integer (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_related_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.related_action_id)

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

@beartype.beartype
def create_related_actions_from_json_dict(json_obj: dict):
        """
        Create a RelatedActions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedActions(**json_obj)


@beartype.beartype
def write_related_actions_obj(con: db.Connection, obj: RelatedActions) -> int:
    """
    Write a RelatedActions object to the database
    @param con: database connection
    @param obj: RelatedActions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_actions', dataclasses.asdict(obj))

@beartype.beartype
def write_related_actions(
            con: db.Connection,
            action_id: int,
            relationship_type_cv: str,
            related_action_id: int,
            relation_id: Optional[int] = None) -> int:
    """
    Write to the related_actions table in the database
    @param con: database connection
    @param relation_id 
    @param action_id 
    @param relationship_type_cv 
    @param related_action_id 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    return db.upsert(con, 'related_actions', data)

@beartype.beartype
def write_related_actions_many(con: db.Connection, objs: List[RelatedActions], upsert: bool = False) -> int:
    """
    Write a list of RelatedActions objects to the database
    @param con: database connection
    @param objs: list of RelatedActions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_actions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_actions(con: db.Connection, relation_id: int,
            action_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_action_id: Optional[int] = None) -> int:
    """
    Update a row in the related_actions table in the database
    @param con: database connection
    @param relation_id 
    @param action_id 
    @param relationship_type_cv 
    @param related_action_id 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    return db.update(con, 'related_actions', data)

@beartype.beartype
def read_related_actions(
            con: db.Connection,
            action_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_action_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Generator[RelatedActions, None, None]:
    """
    Read from the related_actions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param action_id 
    @param relationship_type_cv 
    @param related_action_id 
    @return generator of RelatedActions objects
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    result = db.query(con, 'related_actions', data)
    for row in result:
        yield RelatedActions(**row.as_dict())

@beartype.beartype
def read_related_actions_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_action_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Generator[RelatedActions, None, None]:
    """
    Read from the related_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param action_id 
    @param relationship_type_cv 
    @param related_action_id 
    @return generator of RelatedActions objects
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    result = db.query_fuzzy(con, 'related_actions', data)
    for row in result:
        yield RelatedActions(**row.as_dict())

@beartype.beartype
def read_related_actions_any(con: db.Connection, action_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_action_id: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None) -> Generator[RelatedActions, None, None]:
    """
    Read from the related_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param action_id 
    @param relationship_type_cv 
    @param related_action_id 
    @return generator of RelatedActions objects
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    result = db.query_any(con, 'related_actions', data)
    for row in result:
        yield RelatedActions(**row.as_dict())

@beartype.beartype
def read_related_actions_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_action_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Optional[RelatedActions]:
    """
    Read from the related_actions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    result = db.query_one_or_none(con, 'related_actions', data)
    if result is None:
        return None
    return RelatedActions(**result)

@beartype.beartype
def read_related_actions_one(con: db.Connection, action_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_action_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> RelatedActions:
    """
    Read from the related_actions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    result = db.query_one(con, 'related_actions', data)
    return RelatedActions(**result)

@beartype.beartype
def read_related_actions_all(con: db.Connection, action_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_action_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> List[RelatedActions]:
    """
    Read from the related_actions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'action_id': action_id,
        'relationship_type_cv': relationship_type_cv,
        'related_action_id': related_action_id,
    }
    result = db.query(con, 'related_actions', data)
    return [RelatedActions(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_actions_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedActions]:
    result = db.query_one(con, 'related_actions', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedActions(**result)

@beartype.beartype
def delete_related_actions_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_actions', {'relation_id': relation_id})
# Associate the functions with the class
RelatedActions.create_from_json_dict = create_related_actions_from_json_dict
RelatedActions.write = write_related_actions
RelatedActions.update = update_related_actions
RelatedActions.write_many = write_related_actions_many
RelatedActions.read = read_related_actions
RelatedActions.read_fuzzy = read_related_actions_fuzzy
RelatedActions.read_any = read_related_actions_any
RelatedActions.read_one = read_related_actions_one
RelatedActions.read_one_or_none = read_related_actions_one_or_none
RelatedActions.read_all = read_related_actions_all
RelatedActions.delete = delete_related_actions_by_id
RelatedActions.read_by_id = read_related_actions_by_id
RelatedActions.delete_by_id = delete_related_actions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class VariablesTaxonomicClassifiersBridge:
    """
    Bridge table between Variables and Taxonomic Classifiers

    @param variables_taxonomic_classifiers_bridge_id 
    @param taxonomic_classifier_id 
    @param variable_id 
    @param relation_classification 

    This is an automatically generated class
    """
    taxonomic_classifier_id: int # taxonomic_classifier_id integer (default: )
    variable_id: int # variable_id integer (default: )
    variables_taxonomic_classifiers_bridge_id: Optional[int] = None # variables_taxonomic_classifiers_bridge_id integer (default: )
    relation_classification: Optional[str] = None # relation_classification character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'variables_taxonomic_classifiers_bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_taxonomic_classifier(self, con: db.Connection) -> Optional['TaxonomicClassifiers']:
        return read_taxonomic_classifiers_one_or_none(con, taxonomic_classifier_id=self.taxonomic_classifier_id)

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_variables_taxonomic_classifiers_bridge_from_json_dict(json_obj: dict):
        """
        Create a VariablesTaxonomicClassifiersBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return VariablesTaxonomicClassifiersBridge(**json_obj)


@beartype.beartype
def write_variables_taxonomic_classifiers_bridge_obj(con: db.Connection, obj: VariablesTaxonomicClassifiersBridge) -> int:
    """
    Write a VariablesTaxonomicClassifiersBridge object to the database
    @param con: database connection
    @param obj: VariablesTaxonomicClassifiersBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'variables_taxonomic_classifiers_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_variables_taxonomic_classifiers_bridge(
            con: db.Connection,
            taxonomic_classifier_id: int,
            variable_id: int,
            variables_taxonomic_classifiers_bridge_id: Optional[int] = None,
            relation_classification: Optional[str] = None) -> int:
    """
    Write to the variables_taxonomic_classifiers_bridge table in the database
    @param con: database connection
    @param variables_taxonomic_classifiers_bridge_id 
    @param taxonomic_classifier_id 
    @param variable_id 
    @param relation_classification 
    @return id of the inserted/updated row
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    return db.upsert(con, 'variables_taxonomic_classifiers_bridge', data)

@beartype.beartype
def write_variables_taxonomic_classifiers_bridge_many(con: db.Connection, objs: List[VariablesTaxonomicClassifiersBridge], upsert: bool = False) -> int:
    """
    Write a list of VariablesTaxonomicClassifiersBridge objects to the database
    @param con: database connection
    @param objs: list of VariablesTaxonomicClassifiersBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'variables_taxonomic_classifiers_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_variables_taxonomic_classifiers_bridge(con: db.Connection, variables_taxonomic_classifiers_bridge_id: int,
            taxonomic_classifier_id: Optional[int] = None,
            variable_id: Optional[int] = None,
            relation_classification: Optional[str] = None) -> int:
    """
    Update a row in the variables_taxonomic_classifiers_bridge table in the database
    @param con: database connection
    @param variables_taxonomic_classifiers_bridge_id 
    @param taxonomic_classifier_id 
    @param variable_id 
    @param relation_classification 
    @return The number of rows updated
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    return db.update(con, 'variables_taxonomic_classifiers_bridge', data)

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge(
            con: db.Connection,
            taxonomic_classifier_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             variables_taxonomic_classifiers_bridge_id: Optional[int] = None,
             relation_classification: Optional[str] = None) -> Generator[VariablesTaxonomicClassifiersBridge, None, None]:
    """
    Read from the variables_taxonomic_classifiers_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variables_taxonomic_classifiers_bridge_id 
    @param taxonomic_classifier_id 
    @param variable_id 
    @param relation_classification 
    @return generator of VariablesTaxonomicClassifiersBridge objects
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    result = db.query(con, 'variables_taxonomic_classifiers_bridge', data)
    for row in result:
        yield VariablesTaxonomicClassifiersBridge(**row.as_dict())

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge_fuzzy(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             variables_taxonomic_classifiers_bridge_id: Optional[int] = None,
             relation_classification: Optional[str] = None) -> Generator[VariablesTaxonomicClassifiersBridge, None, None]:
    """
    Read from the variables_taxonomic_classifiers_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variables_taxonomic_classifiers_bridge_id 
    @param taxonomic_classifier_id 
    @param variable_id 
    @param relation_classification 
    @return generator of VariablesTaxonomicClassifiersBridge objects
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    result = db.query_fuzzy(con, 'variables_taxonomic_classifiers_bridge', data)
    for row in result:
        yield VariablesTaxonomicClassifiersBridge(**row.as_dict())

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge_any(con: db.Connection, taxonomic_classifier_id: Optional[List[int]] = None,
             variable_id: Optional[List[int]] = None,
             variables_taxonomic_classifiers_bridge_id: Optional[List[int]] = None,
             relation_classification: Optional[List[str]] = None) -> Generator[VariablesTaxonomicClassifiersBridge, None, None]:
    """
    Read from the variables_taxonomic_classifiers_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variables_taxonomic_classifiers_bridge_id 
    @param taxonomic_classifier_id 
    @param variable_id 
    @param relation_classification 
    @return generator of VariablesTaxonomicClassifiersBridge objects
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    result = db.query_any(con, 'variables_taxonomic_classifiers_bridge', data)
    for row in result:
        yield VariablesTaxonomicClassifiersBridge(**row.as_dict())

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge_one_or_none(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             variables_taxonomic_classifiers_bridge_id: Optional[int] = None,
             relation_classification: Optional[str] = None) -> Optional[VariablesTaxonomicClassifiersBridge]:
    """
    Read from the variables_taxonomic_classifiers_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    result = db.query_one_or_none(con, 'variables_taxonomic_classifiers_bridge', data)
    if result is None:
        return None
    return VariablesTaxonomicClassifiersBridge(**result)

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge_one(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             variables_taxonomic_classifiers_bridge_id: Optional[int] = None,
             relation_classification: Optional[str] = None) -> VariablesTaxonomicClassifiersBridge:
    """
    Read from the variables_taxonomic_classifiers_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    result = db.query_one(con, 'variables_taxonomic_classifiers_bridge', data)
    return VariablesTaxonomicClassifiersBridge(**result)

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge_all(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             variables_taxonomic_classifiers_bridge_id: Optional[int] = None,
             relation_classification: Optional[str] = None) -> List[VariablesTaxonomicClassifiersBridge]:
    """
    Read from the variables_taxonomic_classifiers_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'variable_id': variable_id,
        'relation_classification': relation_classification,
    }
    result = db.query(con, 'variables_taxonomic_classifiers_bridge', data)
    return [VariablesTaxonomicClassifiersBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_variables_taxonomic_classifiers_bridge_by_id(con: db.Connection, variables_taxonomic_classifiers_bridge_id: int) -> Optional[VariablesTaxonomicClassifiersBridge]:
    result = db.query_one(con, 'variables_taxonomic_classifiers_bridge', {'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id})
    if result is None:
        return None
    return VariablesTaxonomicClassifiersBridge(**result)

@beartype.beartype
def delete_variables_taxonomic_classifiers_bridge_by_id(con: db.Connection, variables_taxonomic_classifiers_bridge_id: int):
    db.delete(con, 'variables_taxonomic_classifiers_bridge', {'variables_taxonomic_classifiers_bridge_id': variables_taxonomic_classifiers_bridge_id})
# Associate the functions with the class
VariablesTaxonomicClassifiersBridge.create_from_json_dict = create_variables_taxonomic_classifiers_bridge_from_json_dict
VariablesTaxonomicClassifiersBridge.write = write_variables_taxonomic_classifiers_bridge
VariablesTaxonomicClassifiersBridge.update = update_variables_taxonomic_classifiers_bridge
VariablesTaxonomicClassifiersBridge.write_many = write_variables_taxonomic_classifiers_bridge_many
VariablesTaxonomicClassifiersBridge.read = read_variables_taxonomic_classifiers_bridge
VariablesTaxonomicClassifiersBridge.read_fuzzy = read_variables_taxonomic_classifiers_bridge_fuzzy
VariablesTaxonomicClassifiersBridge.read_any = read_variables_taxonomic_classifiers_bridge_any
VariablesTaxonomicClassifiersBridge.read_one = read_variables_taxonomic_classifiers_bridge_one
VariablesTaxonomicClassifiersBridge.read_one_or_none = read_variables_taxonomic_classifiers_bridge_one_or_none
VariablesTaxonomicClassifiersBridge.read_all = read_variables_taxonomic_classifiers_bridge_all
VariablesTaxonomicClassifiersBridge.delete = delete_variables_taxonomic_classifiers_bridge_by_id
VariablesTaxonomicClassifiersBridge.read_by_id = read_variables_taxonomic_classifiers_bridge_by_id
VariablesTaxonomicClassifiersBridge.delete_by_id = delete_variables_taxonomic_classifiers_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TaxonomicClassifiers:
    """
    @param taxonomic_classifier_id 
    @param taxonomic_classifier_term 
    @param taxonomic_classifier_name 
    @param taxonomic_classifier_alternate_name 
    @param taxonomic_classifier_definition 
    @param taxonomic_classifier_domain_cv 
    @param taxonomic_classifier_source_uri 

    This is an automatically generated class
    """
    taxonomic_classifier_term: str # taxonomic_classifier_term character varying (default: )
    taxonomic_classifier_name: str # taxonomic_classifier_name character varying (default: )
    taxonomic_classifier_id: Optional[int] = None # taxonomic_classifier_id integer (default: )
    taxonomic_classifier_alternate_name: Optional[str] = None # taxonomic_classifier_alternate_name character varying (default: )
    taxonomic_classifier_definition: Optional[str] = None # taxonomic_classifier_definition character varying (default: )
    taxonomic_classifier_domain_cv: Optional[str] = None # taxonomic_classifier_domain_cv character varying (default: )
    taxonomic_classifier_source_uri: Optional[str] = None # taxonomic_classifier_source_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'taxonomic_classifier_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_taxonomic_classifier_domain_cv(self, con: db.Connection) -> Optional['CvTaxonomicClassifierDomain']:
        return read_cv_taxonomic_classifier_domain_one_or_none(con, term=self.taxonomic_classifier_domain_cv)

@beartype.beartype
def create_taxonomic_classifiers_from_json_dict(json_obj: dict):
        """
        Create a TaxonomicClassifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TaxonomicClassifiers(**json_obj)


@beartype.beartype
def write_taxonomic_classifiers_obj(con: db.Connection, obj: TaxonomicClassifiers) -> int:
    """
    Write a TaxonomicClassifiers object to the database
    @param con: database connection
    @param obj: TaxonomicClassifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'taxonomic_classifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_taxonomic_classifiers(
            con: db.Connection,
            taxonomic_classifier_term: str,
            taxonomic_classifier_name: str,
            taxonomic_classifier_id: Optional[int] = None,
            taxonomic_classifier_alternate_name: Optional[str] = None,
            taxonomic_classifier_definition: Optional[str] = None,
            taxonomic_classifier_domain_cv: Optional[str] = None,
            taxonomic_classifier_source_uri: Optional[str] = None) -> int:
    """
    Write to the taxonomic_classifiers table in the database
    @param con: database connection
    @param taxonomic_classifier_id 
    @param taxonomic_classifier_term 
    @param taxonomic_classifier_name 
    @param taxonomic_classifier_alternate_name 
    @param taxonomic_classifier_definition 
    @param taxonomic_classifier_domain_cv 
    @param taxonomic_classifier_source_uri 
    @return id of the inserted/updated row
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    return db.upsert(con, 'taxonomic_classifiers', data)

@beartype.beartype
def write_taxonomic_classifiers_many(con: db.Connection, objs: List[TaxonomicClassifiers], upsert: bool = False) -> int:
    """
    Write a list of TaxonomicClassifiers objects to the database
    @param con: database connection
    @param objs: list of TaxonomicClassifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'taxonomic_classifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_taxonomic_classifiers(con: db.Connection, taxonomic_classifier_id: int,
            taxonomic_classifier_term: Optional[str] = None,
            taxonomic_classifier_name: Optional[str] = None,
            taxonomic_classifier_alternate_name: Optional[str] = None,
            taxonomic_classifier_definition: Optional[str] = None,
            taxonomic_classifier_domain_cv: Optional[str] = None,
            taxonomic_classifier_source_uri: Optional[str] = None) -> int:
    """
    Update a row in the taxonomic_classifiers table in the database
    @param con: database connection
    @param taxonomic_classifier_id 
    @param taxonomic_classifier_term 
    @param taxonomic_classifier_name 
    @param taxonomic_classifier_alternate_name 
    @param taxonomic_classifier_definition 
    @param taxonomic_classifier_domain_cv 
    @param taxonomic_classifier_source_uri 
    @return The number of rows updated
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    return db.update(con, 'taxonomic_classifiers', data)

@beartype.beartype
def read_taxonomic_classifiers(
            con: db.Connection,
            taxonomic_classifier_term: Optional[str] = None,
             taxonomic_classifier_name: Optional[str] = None,
             taxonomic_classifier_id: Optional[int] = None,
             taxonomic_classifier_alternate_name: Optional[str] = None,
             taxonomic_classifier_definition: Optional[str] = None,
             taxonomic_classifier_domain_cv: Optional[str] = None,
             taxonomic_classifier_source_uri: Optional[str] = None) -> Generator[TaxonomicClassifiers, None, None]:
    """
    Read from the taxonomic_classifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param taxonomic_classifier_id 
    @param taxonomic_classifier_term 
    @param taxonomic_classifier_name 
    @param taxonomic_classifier_alternate_name 
    @param taxonomic_classifier_definition 
    @param taxonomic_classifier_domain_cv 
    @param taxonomic_classifier_source_uri 
    @return generator of TaxonomicClassifiers objects
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    result = db.query(con, 'taxonomic_classifiers', data)
    for row in result:
        yield TaxonomicClassifiers(**row.as_dict())

@beartype.beartype
def read_taxonomic_classifiers_fuzzy(con: db.Connection, taxonomic_classifier_term: Optional[str] = None,
             taxonomic_classifier_name: Optional[str] = None,
             taxonomic_classifier_id: Optional[int] = None,
             taxonomic_classifier_alternate_name: Optional[str] = None,
             taxonomic_classifier_definition: Optional[str] = None,
             taxonomic_classifier_domain_cv: Optional[str] = None,
             taxonomic_classifier_source_uri: Optional[str] = None) -> Generator[TaxonomicClassifiers, None, None]:
    """
    Read from the taxonomic_classifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param taxonomic_classifier_id 
    @param taxonomic_classifier_term 
    @param taxonomic_classifier_name 
    @param taxonomic_classifier_alternate_name 
    @param taxonomic_classifier_definition 
    @param taxonomic_classifier_domain_cv 
    @param taxonomic_classifier_source_uri 
    @return generator of TaxonomicClassifiers objects
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    result = db.query_fuzzy(con, 'taxonomic_classifiers', data)
    for row in result:
        yield TaxonomicClassifiers(**row.as_dict())

@beartype.beartype
def read_taxonomic_classifiers_any(con: db.Connection, taxonomic_classifier_term: Optional[List[str]] = None,
             taxonomic_classifier_name: Optional[List[str]] = None,
             taxonomic_classifier_id: Optional[List[int]] = None,
             taxonomic_classifier_alternate_name: Optional[List[str]] = None,
             taxonomic_classifier_definition: Optional[List[str]] = None,
             taxonomic_classifier_domain_cv: Optional[List[str]] = None,
             taxonomic_classifier_source_uri: Optional[List[str]] = None) -> Generator[TaxonomicClassifiers, None, None]:
    """
    Read from the taxonomic_classifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param taxonomic_classifier_id 
    @param taxonomic_classifier_term 
    @param taxonomic_classifier_name 
    @param taxonomic_classifier_alternate_name 
    @param taxonomic_classifier_definition 
    @param taxonomic_classifier_domain_cv 
    @param taxonomic_classifier_source_uri 
    @return generator of TaxonomicClassifiers objects
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    result = db.query_any(con, 'taxonomic_classifiers', data)
    for row in result:
        yield TaxonomicClassifiers(**row.as_dict())

@beartype.beartype
def read_taxonomic_classifiers_one_or_none(con: db.Connection, taxonomic_classifier_term: Optional[str] = None,
             taxonomic_classifier_name: Optional[str] = None,
             taxonomic_classifier_id: Optional[int] = None,
             taxonomic_classifier_alternate_name: Optional[str] = None,
             taxonomic_classifier_definition: Optional[str] = None,
             taxonomic_classifier_domain_cv: Optional[str] = None,
             taxonomic_classifier_source_uri: Optional[str] = None) -> Optional[TaxonomicClassifiers]:
    """
    Read from the taxonomic_classifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    result = db.query_one_or_none(con, 'taxonomic_classifiers', data)
    if result is None:
        return None
    return TaxonomicClassifiers(**result)

@beartype.beartype
def read_taxonomic_classifiers_one(con: db.Connection, taxonomic_classifier_term: Optional[str] = None,
             taxonomic_classifier_name: Optional[str] = None,
             taxonomic_classifier_id: Optional[int] = None,
             taxonomic_classifier_alternate_name: Optional[str] = None,
             taxonomic_classifier_definition: Optional[str] = None,
             taxonomic_classifier_domain_cv: Optional[str] = None,
             taxonomic_classifier_source_uri: Optional[str] = None) -> TaxonomicClassifiers:
    """
    Read from the taxonomic_classifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    result = db.query_one(con, 'taxonomic_classifiers', data)
    return TaxonomicClassifiers(**result)

@beartype.beartype
def read_taxonomic_classifiers_all(con: db.Connection, taxonomic_classifier_term: Optional[str] = None,
             taxonomic_classifier_name: Optional[str] = None,
             taxonomic_classifier_id: Optional[int] = None,
             taxonomic_classifier_alternate_name: Optional[str] = None,
             taxonomic_classifier_definition: Optional[str] = None,
             taxonomic_classifier_domain_cv: Optional[str] = None,
             taxonomic_classifier_source_uri: Optional[str] = None) -> List[TaxonomicClassifiers]:
    """
    Read from the taxonomic_classifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'taxonomic_classifier_term': taxonomic_classifier_term,
        'taxonomic_classifier_name': taxonomic_classifier_name,
        'taxonomic_classifier_alternate_name': taxonomic_classifier_alternate_name,
        'taxonomic_classifier_definition': taxonomic_classifier_definition,
        'taxonomic_classifier_domain_cv': taxonomic_classifier_domain_cv,
        'taxonomic_classifier_source_uri': taxonomic_classifier_source_uri,
    }
    result = db.query(con, 'taxonomic_classifiers', data)
    return [TaxonomicClassifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_taxonomic_classifiers_by_id(con: db.Connection, taxonomic_classifier_id: int) -> Optional[TaxonomicClassifiers]:
    result = db.query_one(con, 'taxonomic_classifiers', {'taxonomic_classifier_id': taxonomic_classifier_id})
    if result is None:
        return None
    return TaxonomicClassifiers(**result)

@beartype.beartype
def delete_taxonomic_classifiers_by_id(con: db.Connection, taxonomic_classifier_id: int):
    db.delete(con, 'taxonomic_classifiers', {'taxonomic_classifier_id': taxonomic_classifier_id})
# Associate the functions with the class
TaxonomicClassifiers.create_from_json_dict = create_taxonomic_classifiers_from_json_dict
TaxonomicClassifiers.write = write_taxonomic_classifiers
TaxonomicClassifiers.update = update_taxonomic_classifiers
TaxonomicClassifiers.write_many = write_taxonomic_classifiers_many
TaxonomicClassifiers.read = read_taxonomic_classifiers
TaxonomicClassifiers.read_fuzzy = read_taxonomic_classifiers_fuzzy
TaxonomicClassifiers.read_any = read_taxonomic_classifiers_any
TaxonomicClassifiers.read_one = read_taxonomic_classifiers_one
TaxonomicClassifiers.read_one_or_none = read_taxonomic_classifiers_one_or_none
TaxonomicClassifiers.read_all = read_taxonomic_classifiers_all
TaxonomicClassifiers.delete = delete_taxonomic_classifiers_by_id
TaxonomicClassifiers.read_by_id = read_taxonomic_classifiers_by_id
TaxonomicClassifiers.delete_by_id = delete_taxonomic_classifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DataQuality:
    """
    @param data_quality_id 
    @param data_quality_type_cv 
    @param data_quality_code 
    @param data_quality_value 
    @param data_quality_value_units_id 
    @param data_quality_description 
    @param data_quality_link 

    This is an automatically generated class
    """
    data_quality_id: int # data_quality_id integer (default: )
    data_quality_type_cv: str # data_quality_type_cv character varying (default: )
    data_quality_code: str # data_quality_code character varying (default: )
    data_quality_value: Optional[float] = None # data_quality_value double precision (default: )
    data_quality_value_units_id: Optional[int] = None # data_quality_value_units_id integer (default: )
    data_quality_description: Optional[str] = None # data_quality_description character varying (default: )
    data_quality_link: Optional[str] = None # data_quality_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'data_quality_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_data_quality_type_cv(self, con: db.Connection) -> Optional['CvDataQualityType']:
        return read_cv_data_quality_type_one_or_none(con, term=self.data_quality_type_cv)

@beartype.beartype
def create_data_quality_from_json_dict(json_obj: dict):
        """
        Create a DataQuality from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DataQuality(**json_obj)


@beartype.beartype
def write_data_quality_obj(con: db.Connection, obj: DataQuality) -> int:
    """
    Write a DataQuality object to the database
    @param con: database connection
    @param obj: DataQuality object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'data_quality', dataclasses.asdict(obj))

@beartype.beartype
def write_data_quality(
            con: db.Connection,
            data_quality_id: int,
            data_quality_type_cv: str,
            data_quality_code: str,
            data_quality_value: Optional[float] = None,
            data_quality_value_units_id: Optional[int] = None,
            data_quality_description: Optional[str] = None,
            data_quality_link: Optional[str] = None) -> int:
    """
    Write to the data_quality table in the database
    @param con: database connection
    @param data_quality_id 
    @param data_quality_type_cv 
    @param data_quality_code 
    @param data_quality_value 
    @param data_quality_value_units_id 
    @param data_quality_description 
    @param data_quality_link 
    @return id of the inserted/updated row
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    return db.upsert(con, 'data_quality', data)

@beartype.beartype
def write_data_quality_many(con: db.Connection, objs: List[DataQuality], upsert: bool = False) -> int:
    """
    Write a list of DataQuality objects to the database
    @param con: database connection
    @param objs: list of DataQuality objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'data_quality', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_data_quality(con: db.Connection, data_quality_id: int,
            data_quality_type_cv: Optional[str] = None,
            data_quality_code: Optional[str] = None,
            data_quality_value: Optional[float] = None,
            data_quality_value_units_id: Optional[int] = None,
            data_quality_description: Optional[str] = None,
            data_quality_link: Optional[str] = None) -> int:
    """
    Update a row in the data_quality table in the database
    @param con: database connection
    @param data_quality_id 
    @param data_quality_type_cv 
    @param data_quality_code 
    @param data_quality_value 
    @param data_quality_value_units_id 
    @param data_quality_description 
    @param data_quality_link 
    @return The number of rows updated
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    return db.update(con, 'data_quality', data)

@beartype.beartype
def read_data_quality(
            con: db.Connection,
            data_quality_id: Optional[int] = None,
             data_quality_type_cv: Optional[str] = None,
             data_quality_code: Optional[str] = None,
             data_quality_value: Optional[float] = None,
             data_quality_value_units_id: Optional[int] = None,
             data_quality_description: Optional[str] = None,
             data_quality_link: Optional[str] = None) -> Generator[DataQuality, None, None]:
    """
    Read from the data_quality table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param data_quality_id 
    @param data_quality_type_cv 
    @param data_quality_code 
    @param data_quality_value 
    @param data_quality_value_units_id 
    @param data_quality_description 
    @param data_quality_link 
    @return generator of DataQuality objects
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    result = db.query(con, 'data_quality', data)
    for row in result:
        yield DataQuality(**row.as_dict())

@beartype.beartype
def read_data_quality_fuzzy(con: db.Connection, data_quality_id: Optional[int] = None,
             data_quality_type_cv: Optional[str] = None,
             data_quality_code: Optional[str] = None,
             data_quality_value: Optional[float] = None,
             data_quality_value_units_id: Optional[int] = None,
             data_quality_description: Optional[str] = None,
             data_quality_link: Optional[str] = None) -> Generator[DataQuality, None, None]:
    """
    Read from the data_quality table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param data_quality_id 
    @param data_quality_type_cv 
    @param data_quality_code 
    @param data_quality_value 
    @param data_quality_value_units_id 
    @param data_quality_description 
    @param data_quality_link 
    @return generator of DataQuality objects
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    result = db.query_fuzzy(con, 'data_quality', data)
    for row in result:
        yield DataQuality(**row.as_dict())

@beartype.beartype
def read_data_quality_any(con: db.Connection, data_quality_id: Optional[List[int]] = None,
             data_quality_type_cv: Optional[List[str]] = None,
             data_quality_code: Optional[List[str]] = None,
             data_quality_value: Optional[List[float]] = None,
             data_quality_value_units_id: Optional[List[int]] = None,
             data_quality_description: Optional[List[str]] = None,
             data_quality_link: Optional[List[str]] = None) -> Generator[DataQuality, None, None]:
    """
    Read from the data_quality table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param data_quality_id 
    @param data_quality_type_cv 
    @param data_quality_code 
    @param data_quality_value 
    @param data_quality_value_units_id 
    @param data_quality_description 
    @param data_quality_link 
    @return generator of DataQuality objects
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    result = db.query_any(con, 'data_quality', data)
    for row in result:
        yield DataQuality(**row.as_dict())

@beartype.beartype
def read_data_quality_one_or_none(con: db.Connection, data_quality_id: Optional[int] = None,
             data_quality_type_cv: Optional[str] = None,
             data_quality_code: Optional[str] = None,
             data_quality_value: Optional[float] = None,
             data_quality_value_units_id: Optional[int] = None,
             data_quality_description: Optional[str] = None,
             data_quality_link: Optional[str] = None) -> Optional[DataQuality]:
    """
    Read from the data_quality table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    result = db.query_one_or_none(con, 'data_quality', data)
    if result is None:
        return None
    return DataQuality(**result)

@beartype.beartype
def read_data_quality_one(con: db.Connection, data_quality_id: Optional[int] = None,
             data_quality_type_cv: Optional[str] = None,
             data_quality_code: Optional[str] = None,
             data_quality_value: Optional[float] = None,
             data_quality_value_units_id: Optional[int] = None,
             data_quality_description: Optional[str] = None,
             data_quality_link: Optional[str] = None) -> DataQuality:
    """
    Read from the data_quality table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    result = db.query_one(con, 'data_quality', data)
    return DataQuality(**result)

@beartype.beartype
def read_data_quality_all(con: db.Connection, data_quality_id: Optional[int] = None,
             data_quality_type_cv: Optional[str] = None,
             data_quality_code: Optional[str] = None,
             data_quality_value: Optional[float] = None,
             data_quality_value_units_id: Optional[int] = None,
             data_quality_description: Optional[str] = None,
             data_quality_link: Optional[str] = None) -> List[DataQuality]:
    """
    Read from the data_quality table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'data_quality_id': data_quality_id,
        'data_quality_type_cv': data_quality_type_cv,
        'data_quality_code': data_quality_code,
        'data_quality_value': data_quality_value,
        'data_quality_value_units_id': data_quality_value_units_id,
        'data_quality_description': data_quality_description,
        'data_quality_link': data_quality_link,
    }
    result = db.query(con, 'data_quality', data)
    return [DataQuality(**row.as_dict()) for row in result]

@beartype.beartype
def read_data_quality_by_id(con: db.Connection, data_quality_id: int) -> Optional[DataQuality]:
    result = db.query_one(con, 'data_quality', {'data_quality_id': data_quality_id})
    if result is None:
        return None
    return DataQuality(**result)

@beartype.beartype
def delete_data_quality_by_id(con: db.Connection, data_quality_id: int):
    db.delete(con, 'data_quality', {'data_quality_id': data_quality_id})
# Associate the functions with the class
DataQuality.create_from_json_dict = create_data_quality_from_json_dict
DataQuality.write = write_data_quality
DataQuality.update = update_data_quality
DataQuality.write_many = write_data_quality_many
DataQuality.read = read_data_quality
DataQuality.read_fuzzy = read_data_quality_fuzzy
DataQuality.read_any = read_data_quality_any
DataQuality.read_one = read_data_quality_one
DataQuality.read_one_or_none = read_data_quality_one_or_none
DataQuality.read_all = read_data_quality_all
DataQuality.delete = delete_data_quality_by_id
DataQuality.read_by_id = read_data_quality_by_id
DataQuality.delete_by_id = delete_data_quality_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ReferenceMaterialValues:
    """
    accepted property values for a Reference Material, which can be certified by an agency or vendor, established in the literature by the research community, or developed for "in house" use only by a laboratory.

    @param reference_material_value_id 
    @param reference_material_id 
    @param reference_material_value 
    @param reference_material_accuracy 
    @param variable_id 
    @param units_id 
    @param citation_id 

    This is an automatically generated class
    """
    reference_material_id: int # reference_material_id integer (default: )
    reference_material_value: float # reference_material_value double precision (default: )
    variable_id: int # variable_id integer (default: )
    units_id: int # units_id integer (default: )
    reference_material_value_id: Optional[int] = None # reference_material_value_id integer (default: )
    reference_material_accuracy: Optional[float] = None # reference_material_accuracy double precision (default: )
    citation_id: Optional[int] = None # citation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'reference_material_value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_reference_material(self, con: db.Connection) -> Optional['ReferenceMaterials']:
        return read_reference_materials_one_or_none(con, reference_material_id=self.reference_material_id)

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_reference_material_values_from_json_dict(json_obj: dict):
        """
        Create a ReferenceMaterialValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ReferenceMaterialValues(**json_obj)


@beartype.beartype
def write_reference_material_values_obj(con: db.Connection, obj: ReferenceMaterialValues) -> int:
    """
    Write a ReferenceMaterialValues object to the database
    @param con: database connection
    @param obj: ReferenceMaterialValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'reference_material_values', dataclasses.asdict(obj))

@beartype.beartype
def write_reference_material_values(
            con: db.Connection,
            reference_material_id: int,
            reference_material_value: float,
            variable_id: int,
            units_id: int,
            reference_material_value_id: Optional[int] = None,
            reference_material_accuracy: Optional[float] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Write to the reference_material_values table in the database
    @param con: database connection
    @param reference_material_value_id 
    @param reference_material_id 
    @param reference_material_value 
    @param reference_material_accuracy 
    @param variable_id 
    @param units_id 
    @param citation_id 
    @return id of the inserted/updated row
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    return db.upsert(con, 'reference_material_values', data)

@beartype.beartype
def write_reference_material_values_many(con: db.Connection, objs: List[ReferenceMaterialValues], upsert: bool = False) -> int:
    """
    Write a list of ReferenceMaterialValues objects to the database
    @param con: database connection
    @param objs: list of ReferenceMaterialValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'reference_material_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_reference_material_values(con: db.Connection, reference_material_value_id: int,
            reference_material_id: Optional[int] = None,
            reference_material_value: Optional[float] = None,
            variable_id: Optional[int] = None,
            units_id: Optional[int] = None,
            reference_material_accuracy: Optional[float] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Update a row in the reference_material_values table in the database
    @param con: database connection
    @param reference_material_value_id 
    @param reference_material_id 
    @param reference_material_value 
    @param reference_material_accuracy 
    @param variable_id 
    @param units_id 
    @param citation_id 
    @return The number of rows updated
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    return db.update(con, 'reference_material_values', data)

@beartype.beartype
def read_reference_material_values(
            con: db.Connection,
            reference_material_id: Optional[int] = None,
             reference_material_value: Optional[float] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             reference_material_value_id: Optional[int] = None,
             reference_material_accuracy: Optional[float] = None,
             citation_id: Optional[int] = None) -> Generator[ReferenceMaterialValues, None, None]:
    """
    Read from the reference_material_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param reference_material_value_id 
    @param reference_material_id 
    @param reference_material_value 
    @param reference_material_accuracy 
    @param variable_id 
    @param units_id 
    @param citation_id 
    @return generator of ReferenceMaterialValues objects
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    result = db.query(con, 'reference_material_values', data)
    for row in result:
        yield ReferenceMaterialValues(**row.as_dict())

@beartype.beartype
def read_reference_material_values_fuzzy(con: db.Connection, reference_material_id: Optional[int] = None,
             reference_material_value: Optional[float] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             reference_material_value_id: Optional[int] = None,
             reference_material_accuracy: Optional[float] = None,
             citation_id: Optional[int] = None) -> Generator[ReferenceMaterialValues, None, None]:
    """
    Read from the reference_material_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param reference_material_value_id 
    @param reference_material_id 
    @param reference_material_value 
    @param reference_material_accuracy 
    @param variable_id 
    @param units_id 
    @param citation_id 
    @return generator of ReferenceMaterialValues objects
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    result = db.query_fuzzy(con, 'reference_material_values', data)
    for row in result:
        yield ReferenceMaterialValues(**row.as_dict())

@beartype.beartype
def read_reference_material_values_any(con: db.Connection, reference_material_id: Optional[List[int]] = None,
             reference_material_value: Optional[List[float]] = None,
             variable_id: Optional[List[int]] = None,
             units_id: Optional[List[int]] = None,
             reference_material_value_id: Optional[List[int]] = None,
             reference_material_accuracy: Optional[List[float]] = None,
             citation_id: Optional[List[int]] = None) -> Generator[ReferenceMaterialValues, None, None]:
    """
    Read from the reference_material_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param reference_material_value_id 
    @param reference_material_id 
    @param reference_material_value 
    @param reference_material_accuracy 
    @param variable_id 
    @param units_id 
    @param citation_id 
    @return generator of ReferenceMaterialValues objects
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    result = db.query_any(con, 'reference_material_values', data)
    for row in result:
        yield ReferenceMaterialValues(**row.as_dict())

@beartype.beartype
def read_reference_material_values_one_or_none(con: db.Connection, reference_material_id: Optional[int] = None,
             reference_material_value: Optional[float] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             reference_material_value_id: Optional[int] = None,
             reference_material_accuracy: Optional[float] = None,
             citation_id: Optional[int] = None) -> Optional[ReferenceMaterialValues]:
    """
    Read from the reference_material_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    result = db.query_one_or_none(con, 'reference_material_values', data)
    if result is None:
        return None
    return ReferenceMaterialValues(**result)

@beartype.beartype
def read_reference_material_values_one(con: db.Connection, reference_material_id: Optional[int] = None,
             reference_material_value: Optional[float] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             reference_material_value_id: Optional[int] = None,
             reference_material_accuracy: Optional[float] = None,
             citation_id: Optional[int] = None) -> ReferenceMaterialValues:
    """
    Read from the reference_material_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    result = db.query_one(con, 'reference_material_values', data)
    return ReferenceMaterialValues(**result)

@beartype.beartype
def read_reference_material_values_all(con: db.Connection, reference_material_id: Optional[int] = None,
             reference_material_value: Optional[float] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             reference_material_value_id: Optional[int] = None,
             reference_material_accuracy: Optional[float] = None,
             citation_id: Optional[int] = None) -> List[ReferenceMaterialValues]:
    """
    Read from the reference_material_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'reference_material_value_id': reference_material_value_id,
        'reference_material_id': reference_material_id,
        'reference_material_value': reference_material_value,
        'reference_material_accuracy': reference_material_accuracy,
        'variable_id': variable_id,
        'units_id': units_id,
        'citation_id': citation_id,
    }
    result = db.query(con, 'reference_material_values', data)
    return [ReferenceMaterialValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_reference_material_values_by_id(con: db.Connection, reference_material_value_id: int) -> Optional[ReferenceMaterialValues]:
    result = db.query_one(con, 'reference_material_values', {'reference_material_value_id': reference_material_value_id})
    if result is None:
        return None
    return ReferenceMaterialValues(**result)

@beartype.beartype
def delete_reference_material_values_by_id(con: db.Connection, reference_material_value_id: int):
    db.delete(con, 'reference_material_values', {'reference_material_value_id': reference_material_value_id})
# Associate the functions with the class
ReferenceMaterialValues.create_from_json_dict = create_reference_material_values_from_json_dict
ReferenceMaterialValues.write = write_reference_material_values
ReferenceMaterialValues.update = update_reference_material_values
ReferenceMaterialValues.write_many = write_reference_material_values_many
ReferenceMaterialValues.read = read_reference_material_values
ReferenceMaterialValues.read_fuzzy = read_reference_material_values_fuzzy
ReferenceMaterialValues.read_any = read_reference_material_values_any
ReferenceMaterialValues.read_one = read_reference_material_values_one
ReferenceMaterialValues.read_one_or_none = read_reference_material_values_one_or_none
ReferenceMaterialValues.read_all = read_reference_material_values_all
ReferenceMaterialValues.delete = delete_reference_material_values_by_id
ReferenceMaterialValues.read_by_id = read_reference_material_values_by_id
ReferenceMaterialValues.delete_by_id = delete_reference_material_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ResultNormalizationValues:
    """
    Extends the Results table with a foreign key to NormalizationReferenceMaterialValues when the optional DataQuality schema is implemented.  In a database implementation, we would not implement this as a separate table from Results.

    @param result_normalization_values_id 
    @param normalized_by_reference_material_value_id 
    @param result_id 

    This is an automatically generated class
    """
    normalized_by_reference_material_value_id: int # normalized_by_reference_material_value_id integer (default: )
    result_id: int # result_id bigint (default: )
    result_normalization_values_id: Optional[int] = None # result_normalization_values_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_normalization_values_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_normalized_by_reference_material_value(self, con: db.Connection) -> Optional['ReferenceMaterialValues']:
        return read_reference_material_values_one_or_none(con, reference_material_value_id=self.normalized_by_reference_material_value_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_result_normalization_values_from_json_dict(json_obj: dict):
        """
        Create a ResultNormalizationValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ResultNormalizationValues(**json_obj)


@beartype.beartype
def write_result_normalization_values_obj(con: db.Connection, obj: ResultNormalizationValues) -> int:
    """
    Write a ResultNormalizationValues object to the database
    @param con: database connection
    @param obj: ResultNormalizationValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'result_normalization_values', dataclasses.asdict(obj))

@beartype.beartype
def write_result_normalization_values(
            con: db.Connection,
            normalized_by_reference_material_value_id: int,
            result_id: int,
            result_normalization_values_id: Optional[int] = None) -> int:
    """
    Write to the result_normalization_values table in the database
    @param con: database connection
    @param result_normalization_values_id 
    @param normalized_by_reference_material_value_id 
    @param result_id 
    @return id of the inserted/updated row
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    return db.upsert(con, 'result_normalization_values', data)

@beartype.beartype
def write_result_normalization_values_many(con: db.Connection, objs: List[ResultNormalizationValues], upsert: bool = False) -> int:
    """
    Write a list of ResultNormalizationValues objects to the database
    @param con: database connection
    @param objs: list of ResultNormalizationValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'result_normalization_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_result_normalization_values(con: db.Connection, result_normalization_values_id: int,
            normalized_by_reference_material_value_id: Optional[int] = None,
            result_id: Optional[int] = None) -> int:
    """
    Update a row in the result_normalization_values table in the database
    @param con: database connection
    @param result_normalization_values_id 
    @param normalized_by_reference_material_value_id 
    @param result_id 
    @return The number of rows updated
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    return db.update(con, 'result_normalization_values', data)

@beartype.beartype
def read_result_normalization_values(
            con: db.Connection,
            normalized_by_reference_material_value_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_normalization_values_id: Optional[int] = None) -> Generator[ResultNormalizationValues, None, None]:
    """
    Read from the result_normalization_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_normalization_values_id 
    @param normalized_by_reference_material_value_id 
    @param result_id 
    @return generator of ResultNormalizationValues objects
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    result = db.query(con, 'result_normalization_values', data)
    for row in result:
        yield ResultNormalizationValues(**row.as_dict())

@beartype.beartype
def read_result_normalization_values_fuzzy(con: db.Connection, normalized_by_reference_material_value_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_normalization_values_id: Optional[int] = None) -> Generator[ResultNormalizationValues, None, None]:
    """
    Read from the result_normalization_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_normalization_values_id 
    @param normalized_by_reference_material_value_id 
    @param result_id 
    @return generator of ResultNormalizationValues objects
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    result = db.query_fuzzy(con, 'result_normalization_values', data)
    for row in result:
        yield ResultNormalizationValues(**row.as_dict())

@beartype.beartype
def read_result_normalization_values_any(con: db.Connection, normalized_by_reference_material_value_id: Optional[List[int]] = None,
             result_id: Optional[List[int]] = None,
             result_normalization_values_id: Optional[List[int]] = None) -> Generator[ResultNormalizationValues, None, None]:
    """
    Read from the result_normalization_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_normalization_values_id 
    @param normalized_by_reference_material_value_id 
    @param result_id 
    @return generator of ResultNormalizationValues objects
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    result = db.query_any(con, 'result_normalization_values', data)
    for row in result:
        yield ResultNormalizationValues(**row.as_dict())

@beartype.beartype
def read_result_normalization_values_one_or_none(con: db.Connection, normalized_by_reference_material_value_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_normalization_values_id: Optional[int] = None) -> Optional[ResultNormalizationValues]:
    """
    Read from the result_normalization_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    result = db.query_one_or_none(con, 'result_normalization_values', data)
    if result is None:
        return None
    return ResultNormalizationValues(**result)

@beartype.beartype
def read_result_normalization_values_one(con: db.Connection, normalized_by_reference_material_value_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_normalization_values_id: Optional[int] = None) -> ResultNormalizationValues:
    """
    Read from the result_normalization_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    result = db.query_one(con, 'result_normalization_values', data)
    return ResultNormalizationValues(**result)

@beartype.beartype
def read_result_normalization_values_all(con: db.Connection, normalized_by_reference_material_value_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_normalization_values_id: Optional[int] = None) -> List[ResultNormalizationValues]:
    """
    Read from the result_normalization_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_normalization_values_id': result_normalization_values_id,
        'normalized_by_reference_material_value_id': normalized_by_reference_material_value_id,
        'result_id': result_id,
    }
    result = db.query(con, 'result_normalization_values', data)
    return [ResultNormalizationValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_result_normalization_values_by_id(con: db.Connection, result_normalization_values_id: int) -> Optional[ResultNormalizationValues]:
    result = db.query_one(con, 'result_normalization_values', {'result_normalization_values_id': result_normalization_values_id})
    if result is None:
        return None
    return ResultNormalizationValues(**result)

@beartype.beartype
def delete_result_normalization_values_by_id(con: db.Connection, result_normalization_values_id: int):
    db.delete(con, 'result_normalization_values', {'result_normalization_values_id': result_normalization_values_id})
# Associate the functions with the class
ResultNormalizationValues.create_from_json_dict = create_result_normalization_values_from_json_dict
ResultNormalizationValues.write = write_result_normalization_values
ResultNormalizationValues.update = update_result_normalization_values
ResultNormalizationValues.write_many = write_result_normalization_values_many
ResultNormalizationValues.read = read_result_normalization_values
ResultNormalizationValues.read_fuzzy = read_result_normalization_values_fuzzy
ResultNormalizationValues.read_any = read_result_normalization_values_any
ResultNormalizationValues.read_one = read_result_normalization_values_one
ResultNormalizationValues.read_one_or_none = read_result_normalization_values_one_or_none
ResultNormalizationValues.read_all = read_result_normalization_values_all
ResultNormalizationValues.delete = delete_result_normalization_values_by_id
ResultNormalizationValues.read_by_id = read_result_normalization_values_by_id
ResultNormalizationValues.delete_by_id = delete_result_normalization_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CalibrationReferenceEquipment:
    """
    Information about equipment used as referenece for a calibration

    @param bridge_id 
    @param action_id 
    @param equipment_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    equipment_id: int # equipment_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['CalibrationActions']:
        return read_calibration_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

@beartype.beartype
def create_calibration_reference_equipment_from_json_dict(json_obj: dict):
        """
        Create a CalibrationReferenceEquipment from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CalibrationReferenceEquipment(**json_obj)


@beartype.beartype
def write_calibration_reference_equipment_obj(con: db.Connection, obj: CalibrationReferenceEquipment) -> int:
    """
    Write a CalibrationReferenceEquipment object to the database
    @param con: database connection
    @param obj: CalibrationReferenceEquipment object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'calibration_reference_equipment', dataclasses.asdict(obj))

@beartype.beartype
def write_calibration_reference_equipment(
            con: db.Connection,
            action_id: int,
            equipment_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the calibration_reference_equipment table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    return db.upsert(con, 'calibration_reference_equipment', data)

@beartype.beartype
def write_calibration_reference_equipment_many(con: db.Connection, objs: List[CalibrationReferenceEquipment], upsert: bool = False) -> int:
    """
    Write a list of CalibrationReferenceEquipment objects to the database
    @param con: database connection
    @param objs: list of CalibrationReferenceEquipment objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'calibration_reference_equipment', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_calibration_reference_equipment(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            equipment_id: Optional[int] = None) -> int:
    """
    Update a row in the calibration_reference_equipment table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    return db.update(con, 'calibration_reference_equipment', data)

@beartype.beartype
def read_calibration_reference_equipment(
            con: db.Connection,
            action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[CalibrationReferenceEquipment, None, None]:
    """
    Read from the calibration_reference_equipment table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return generator of CalibrationReferenceEquipment objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query(con, 'calibration_reference_equipment', data)
    for row in result:
        yield CalibrationReferenceEquipment(**row.as_dict())

@beartype.beartype
def read_calibration_reference_equipment_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[CalibrationReferenceEquipment, None, None]:
    """
    Read from the calibration_reference_equipment table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return generator of CalibrationReferenceEquipment objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_fuzzy(con, 'calibration_reference_equipment', data)
    for row in result:
        yield CalibrationReferenceEquipment(**row.as_dict())

@beartype.beartype
def read_calibration_reference_equipment_any(con: db.Connection, action_id: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[CalibrationReferenceEquipment, None, None]:
    """
    Read from the calibration_reference_equipment table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return generator of CalibrationReferenceEquipment objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_any(con, 'calibration_reference_equipment', data)
    for row in result:
        yield CalibrationReferenceEquipment(**row.as_dict())

@beartype.beartype
def read_calibration_reference_equipment_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[CalibrationReferenceEquipment]:
    """
    Read from the calibration_reference_equipment table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_one_or_none(con, 'calibration_reference_equipment', data)
    if result is None:
        return None
    return CalibrationReferenceEquipment(**result)

@beartype.beartype
def read_calibration_reference_equipment_one(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> CalibrationReferenceEquipment:
    """
    Read from the calibration_reference_equipment table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_one(con, 'calibration_reference_equipment', data)
    return CalibrationReferenceEquipment(**result)

@beartype.beartype
def read_calibration_reference_equipment_all(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[CalibrationReferenceEquipment]:
    """
    Read from the calibration_reference_equipment table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query(con, 'calibration_reference_equipment', data)
    return [CalibrationReferenceEquipment(**row.as_dict()) for row in result]

@beartype.beartype
def read_calibration_reference_equipment_by_id(con: db.Connection, bridge_id: int) -> Optional[CalibrationReferenceEquipment]:
    result = db.query_one(con, 'calibration_reference_equipment', {'bridge_id': bridge_id})
    if result is None:
        return None
    return CalibrationReferenceEquipment(**result)

@beartype.beartype
def delete_calibration_reference_equipment_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'calibration_reference_equipment', {'bridge_id': bridge_id})
# Associate the functions with the class
CalibrationReferenceEquipment.create_from_json_dict = create_calibration_reference_equipment_from_json_dict
CalibrationReferenceEquipment.write = write_calibration_reference_equipment
CalibrationReferenceEquipment.update = update_calibration_reference_equipment
CalibrationReferenceEquipment.write_many = write_calibration_reference_equipment_many
CalibrationReferenceEquipment.read = read_calibration_reference_equipment
CalibrationReferenceEquipment.read_fuzzy = read_calibration_reference_equipment_fuzzy
CalibrationReferenceEquipment.read_any = read_calibration_reference_equipment_any
CalibrationReferenceEquipment.read_one = read_calibration_reference_equipment_one
CalibrationReferenceEquipment.read_one_or_none = read_calibration_reference_equipment_one_or_none
CalibrationReferenceEquipment.read_all = read_calibration_reference_equipment_all
CalibrationReferenceEquipment.delete = delete_calibration_reference_equipment_by_id
CalibrationReferenceEquipment.read_by_id = read_calibration_reference_equipment_by_id
CalibrationReferenceEquipment.delete_by_id = delete_calibration_reference_equipment_by_id



@beartype_wrap_init
@dataclasses.dataclass
class VariableMapping:
    """
    @param variable_mapping_id 
    @param variable_id 
    @param project_variable_name 

    This is an automatically generated class
    """
    variable_mapping_id: Optional[int] = None # variable_mapping_id integer (default: )
    variable_id: Optional[int] = None # variable_id integer (default: )
    project_variable_name: Optional[str] = None # project_variable_name character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'variable_mapping_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_variable_mapping_from_json_dict(json_obj: dict):
        """
        Create a VariableMapping from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return VariableMapping(**json_obj)


@beartype.beartype
def write_variable_mapping_obj(con: db.Connection, obj: VariableMapping) -> int:
    """
    Write a VariableMapping object to the database
    @param con: database connection
    @param obj: VariableMapping object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'variable_mapping', dataclasses.asdict(obj))

@beartype.beartype
def write_variable_mapping(
            con: db.Connection,
            variable_mapping_id: Optional[int] = None,
            variable_id: Optional[int] = None,
            project_variable_name: Optional[str] = None) -> int:
    """
    Write to the variable_mapping table in the database
    @param con: database connection
    @param variable_mapping_id 
    @param variable_id 
    @param project_variable_name 
    @return id of the inserted/updated row
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    return db.upsert(con, 'variable_mapping', data)

@beartype.beartype
def write_variable_mapping_many(con: db.Connection, objs: List[VariableMapping], upsert: bool = False) -> int:
    """
    Write a list of VariableMapping objects to the database
    @param con: database connection
    @param objs: list of VariableMapping objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'variable_mapping', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_variable_mapping(con: db.Connection, variable_mapping_id: int,
            variable_id: Optional[int] = None,
            project_variable_name: Optional[str] = None) -> int:
    """
    Update a row in the variable_mapping table in the database
    @param con: database connection
    @param variable_mapping_id 
    @param variable_id 
    @param project_variable_name 
    @return The number of rows updated
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    return db.update(con, 'variable_mapping', data)

@beartype.beartype
def read_variable_mapping(
            con: db.Connection,
            variable_mapping_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             project_variable_name: Optional[str] = None) -> Generator[VariableMapping, None, None]:
    """
    Read from the variable_mapping table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_mapping_id 
    @param variable_id 
    @param project_variable_name 
    @return generator of VariableMapping objects
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    result = db.query(con, 'variable_mapping', data)
    for row in result:
        yield VariableMapping(**row.as_dict())

@beartype.beartype
def read_variable_mapping_fuzzy(con: db.Connection, variable_mapping_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             project_variable_name: Optional[str] = None) -> Generator[VariableMapping, None, None]:
    """
    Read from the variable_mapping table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_mapping_id 
    @param variable_id 
    @param project_variable_name 
    @return generator of VariableMapping objects
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    result = db.query_fuzzy(con, 'variable_mapping', data)
    for row in result:
        yield VariableMapping(**row.as_dict())

@beartype.beartype
def read_variable_mapping_any(con: db.Connection, variable_mapping_id: Optional[List[int]] = None,
             variable_id: Optional[List[int]] = None,
             project_variable_name: Optional[List[str]] = None) -> Generator[VariableMapping, None, None]:
    """
    Read from the variable_mapping table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_mapping_id 
    @param variable_id 
    @param project_variable_name 
    @return generator of VariableMapping objects
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    result = db.query_any(con, 'variable_mapping', data)
    for row in result:
        yield VariableMapping(**row.as_dict())

@beartype.beartype
def read_variable_mapping_one_or_none(con: db.Connection, variable_mapping_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             project_variable_name: Optional[str] = None) -> Optional[VariableMapping]:
    """
    Read from the variable_mapping table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    result = db.query_one_or_none(con, 'variable_mapping', data)
    if result is None:
        return None
    return VariableMapping(**result)

@beartype.beartype
def read_variable_mapping_one(con: db.Connection, variable_mapping_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             project_variable_name: Optional[str] = None) -> VariableMapping:
    """
    Read from the variable_mapping table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    result = db.query_one(con, 'variable_mapping', data)
    return VariableMapping(**result)

@beartype.beartype
def read_variable_mapping_all(con: db.Connection, variable_mapping_id: Optional[int] = None,
             variable_id: Optional[int] = None,
             project_variable_name: Optional[str] = None) -> List[VariableMapping]:
    """
    Read from the variable_mapping table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'variable_mapping_id': variable_mapping_id,
        'variable_id': variable_id,
        'project_variable_name': project_variable_name,
    }
    result = db.query(con, 'variable_mapping', data)
    return [VariableMapping(**row.as_dict()) for row in result]

@beartype.beartype
def read_variable_mapping_by_id(con: db.Connection, variable_mapping_id: int) -> Optional[VariableMapping]:
    result = db.query_one(con, 'variable_mapping', {'variable_mapping_id': variable_mapping_id})
    if result is None:
        return None
    return VariableMapping(**result)

@beartype.beartype
def delete_variable_mapping_by_id(con: db.Connection, variable_mapping_id: int):
    db.delete(con, 'variable_mapping', {'variable_mapping_id': variable_mapping_id})
# Associate the functions with the class
VariableMapping.create_from_json_dict = create_variable_mapping_from_json_dict
VariableMapping.write = write_variable_mapping
VariableMapping.update = update_variable_mapping
VariableMapping.write_many = write_variable_mapping_many
VariableMapping.read = read_variable_mapping
VariableMapping.read_fuzzy = read_variable_mapping_fuzzy
VariableMapping.read_any = read_variable_mapping_any
VariableMapping.read_one = read_variable_mapping_one
VariableMapping.read_one_or_none = read_variable_mapping_one_or_none
VariableMapping.read_all = read_variable_mapping_all
VariableMapping.delete = delete_variable_mapping_by_id
VariableMapping.read_by_id = read_variable_mapping_by_id
VariableMapping.delete_by_id = delete_variable_mapping_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ReferenceMaterials:
    """
    Describes materials that are used for the calibration of an instrument, the assessment of a measurement method, or for assigning values to unknown specimens.

    @param reference_material_id 
    @param reference_material_medium_cv 
    @param reference_material_organization_id 
    @param reference_material_code 
    @param reference_material_lot_code 
    @param reference_material_purchase_date 
    @param reference_material_expiration_date 
    @param reference_material_certificate_link 
    @param sampling_feature_id 

    This is an automatically generated class
    """
    reference_material_medium_cv: str # reference_material_medium_cv character varying (default: )
    reference_material_organization_id: int # reference_material_organization_id integer (default: )
    reference_material_code: str # reference_material_code character varying (default: )
    reference_material_id: Optional[int] = None # reference_material_id integer (default: )
    reference_material_lot_code: Optional[str] = None # reference_material_lot_code character varying (default: )
    reference_material_purchase_date: Optional[datetime.datetime] = None # reference_material_purchase_date timestamp without time zone (default: )
    reference_material_expiration_date: Optional[datetime.datetime] = None # reference_material_expiration_date timestamp without time zone (default: )
    reference_material_certificate_link: Optional[str] = None # reference_material_certificate_link character varying (default: )
    sampling_feature_id: Optional[int] = None # sampling_feature_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'reference_material_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.reference_material_purchase_date is not None:
            obj['reference_material_purchase_date'] = self.reference_material_purchase_date.isoformat()
        if self.reference_material_expiration_date is not None:
            obj['reference_material_expiration_date'] = self.reference_material_expiration_date.isoformat()
        return obj

    @beartype.beartype
    def get_reference_material_medium_cv(self, con: db.Connection) -> Optional['CvMedium']:
        return read_cv_medium_one_or_none(con, term=self.reference_material_medium_cv)

    @beartype.beartype
    def get_reference_material_organization(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.reference_material_organization_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_reference_materials_from_json_dict(json_obj: dict):
        """
        Create a ReferenceMaterials from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'reference_material_purchase_date' in json_obj and json_obj['reference_material_purchase_date'] is not None:
            json_obj['reference_material_purchase_date'] = datetime.datetime.fromisoformat(json_obj['reference_material_purchase_date'])
        if 'reference_material_expiration_date' in json_obj and json_obj['reference_material_expiration_date'] is not None:
            json_obj['reference_material_expiration_date'] = datetime.datetime.fromisoformat(json_obj['reference_material_expiration_date'])
        return ReferenceMaterials(**json_obj)


@beartype.beartype
def write_reference_materials_obj(con: db.Connection, obj: ReferenceMaterials) -> int:
    """
    Write a ReferenceMaterials object to the database
    @param con: database connection
    @param obj: ReferenceMaterials object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'reference_materials', dataclasses.asdict(obj))

@beartype.beartype
def write_reference_materials(
            con: db.Connection,
            reference_material_medium_cv: str,
            reference_material_organization_id: int,
            reference_material_code: str,
            reference_material_id: Optional[int] = None,
            reference_material_lot_code: Optional[str] = None,
            reference_material_purchase_date: Optional[datetime.datetime] = None,
            reference_material_expiration_date: Optional[datetime.datetime] = None,
            reference_material_certificate_link: Optional[str] = None,
            sampling_feature_id: Optional[int] = None) -> int:
    """
    Write to the reference_materials table in the database
    @param con: database connection
    @param reference_material_id 
    @param reference_material_medium_cv 
    @param reference_material_organization_id 
    @param reference_material_code 
    @param reference_material_lot_code 
    @param reference_material_purchase_date 
    @param reference_material_expiration_date 
    @param reference_material_certificate_link 
    @param sampling_feature_id 
    @return id of the inserted/updated row
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    return db.upsert(con, 'reference_materials', data)

@beartype.beartype
def write_reference_materials_many(con: db.Connection, objs: List[ReferenceMaterials], upsert: bool = False) -> int:
    """
    Write a list of ReferenceMaterials objects to the database
    @param con: database connection
    @param objs: list of ReferenceMaterials objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'reference_materials', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_reference_materials(con: db.Connection, reference_material_id: int,
            reference_material_medium_cv: Optional[str] = None,
            reference_material_organization_id: Optional[int] = None,
            reference_material_code: Optional[str] = None,
            reference_material_lot_code: Optional[str] = None,
            reference_material_purchase_date: Optional[datetime.datetime] = None,
            reference_material_expiration_date: Optional[datetime.datetime] = None,
            reference_material_certificate_link: Optional[str] = None,
            sampling_feature_id: Optional[int] = None) -> int:
    """
    Update a row in the reference_materials table in the database
    @param con: database connection
    @param reference_material_id 
    @param reference_material_medium_cv 
    @param reference_material_organization_id 
    @param reference_material_code 
    @param reference_material_lot_code 
    @param reference_material_purchase_date 
    @param reference_material_expiration_date 
    @param reference_material_certificate_link 
    @param sampling_feature_id 
    @return The number of rows updated
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    return db.update(con, 'reference_materials', data)

@beartype.beartype
def read_reference_materials(
            con: db.Connection,
            reference_material_medium_cv: Optional[str] = None,
             reference_material_organization_id: Optional[int] = None,
             reference_material_code: Optional[str] = None,
             reference_material_id: Optional[int] = None,
             reference_material_lot_code: Optional[str] = None,
             reference_material_purchase_date: Optional[datetime.datetime] = None,
             reference_material_expiration_date: Optional[datetime.datetime] = None,
             reference_material_certificate_link: Optional[str] = None,
             sampling_feature_id: Optional[int] = None) -> Generator[ReferenceMaterials, None, None]:
    """
    Read from the reference_materials table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param reference_material_id 
    @param reference_material_medium_cv 
    @param reference_material_organization_id 
    @param reference_material_code 
    @param reference_material_lot_code 
    @param reference_material_purchase_date 
    @param reference_material_expiration_date 
    @param reference_material_certificate_link 
    @param sampling_feature_id 
    @return generator of ReferenceMaterials objects
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query(con, 'reference_materials', data)
    for row in result:
        yield ReferenceMaterials(**row.as_dict())

@beartype.beartype
def read_reference_materials_fuzzy(con: db.Connection, reference_material_medium_cv: Optional[str] = None,
             reference_material_organization_id: Optional[int] = None,
             reference_material_code: Optional[str] = None,
             reference_material_id: Optional[int] = None,
             reference_material_lot_code: Optional[str] = None,
             reference_material_purchase_date: Optional[datetime.datetime] = None,
             reference_material_expiration_date: Optional[datetime.datetime] = None,
             reference_material_certificate_link: Optional[str] = None,
             sampling_feature_id: Optional[int] = None) -> Generator[ReferenceMaterials, None, None]:
    """
    Read from the reference_materials table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param reference_material_id 
    @param reference_material_medium_cv 
    @param reference_material_organization_id 
    @param reference_material_code 
    @param reference_material_lot_code 
    @param reference_material_purchase_date 
    @param reference_material_expiration_date 
    @param reference_material_certificate_link 
    @param sampling_feature_id 
    @return generator of ReferenceMaterials objects
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_fuzzy(con, 'reference_materials', data)
    for row in result:
        yield ReferenceMaterials(**row.as_dict())

@beartype.beartype
def read_reference_materials_any(con: db.Connection, reference_material_medium_cv: Optional[List[str]] = None,
             reference_material_organization_id: Optional[List[int]] = None,
             reference_material_code: Optional[List[str]] = None,
             reference_material_id: Optional[List[int]] = None,
             reference_material_lot_code: Optional[List[str]] = None,
             reference_material_purchase_date: Optional[List[datetime.datetime]] = None,
             reference_material_expiration_date: Optional[List[datetime.datetime]] = None,
             reference_material_certificate_link: Optional[List[str]] = None,
             sampling_feature_id: Optional[List[int]] = None) -> Generator[ReferenceMaterials, None, None]:
    """
    Read from the reference_materials table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param reference_material_id 
    @param reference_material_medium_cv 
    @param reference_material_organization_id 
    @param reference_material_code 
    @param reference_material_lot_code 
    @param reference_material_purchase_date 
    @param reference_material_expiration_date 
    @param reference_material_certificate_link 
    @param sampling_feature_id 
    @return generator of ReferenceMaterials objects
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_any(con, 'reference_materials', data)
    for row in result:
        yield ReferenceMaterials(**row.as_dict())

@beartype.beartype
def read_reference_materials_one_or_none(con: db.Connection, reference_material_medium_cv: Optional[str] = None,
             reference_material_organization_id: Optional[int] = None,
             reference_material_code: Optional[str] = None,
             reference_material_id: Optional[int] = None,
             reference_material_lot_code: Optional[str] = None,
             reference_material_purchase_date: Optional[datetime.datetime] = None,
             reference_material_expiration_date: Optional[datetime.datetime] = None,
             reference_material_certificate_link: Optional[str] = None,
             sampling_feature_id: Optional[int] = None) -> Optional[ReferenceMaterials]:
    """
    Read from the reference_materials table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_one_or_none(con, 'reference_materials', data)
    if result is None:
        return None
    return ReferenceMaterials(**result)

@beartype.beartype
def read_reference_materials_one(con: db.Connection, reference_material_medium_cv: Optional[str] = None,
             reference_material_organization_id: Optional[int] = None,
             reference_material_code: Optional[str] = None,
             reference_material_id: Optional[int] = None,
             reference_material_lot_code: Optional[str] = None,
             reference_material_purchase_date: Optional[datetime.datetime] = None,
             reference_material_expiration_date: Optional[datetime.datetime] = None,
             reference_material_certificate_link: Optional[str] = None,
             sampling_feature_id: Optional[int] = None) -> ReferenceMaterials:
    """
    Read from the reference_materials table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query_one(con, 'reference_materials', data)
    return ReferenceMaterials(**result)

@beartype.beartype
def read_reference_materials_all(con: db.Connection, reference_material_medium_cv: Optional[str] = None,
             reference_material_organization_id: Optional[int] = None,
             reference_material_code: Optional[str] = None,
             reference_material_id: Optional[int] = None,
             reference_material_lot_code: Optional[str] = None,
             reference_material_purchase_date: Optional[datetime.datetime] = None,
             reference_material_expiration_date: Optional[datetime.datetime] = None,
             reference_material_certificate_link: Optional[str] = None,
             sampling_feature_id: Optional[int] = None) -> List[ReferenceMaterials]:
    """
    Read from the reference_materials table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'reference_material_id': reference_material_id,
        'reference_material_medium_cv': reference_material_medium_cv,
        'reference_material_organization_id': reference_material_organization_id,
        'reference_material_code': reference_material_code,
        'reference_material_lot_code': reference_material_lot_code,
        'reference_material_purchase_date': reference_material_purchase_date,
        'reference_material_expiration_date': reference_material_expiration_date,
        'reference_material_certificate_link': reference_material_certificate_link,
        'sampling_feature_id': sampling_feature_id,
    }
    result = db.query(con, 'reference_materials', data)
    return [ReferenceMaterials(**row.as_dict()) for row in result]

@beartype.beartype
def read_reference_materials_by_id(con: db.Connection, reference_material_id: int) -> Optional[ReferenceMaterials]:
    result = db.query_one(con, 'reference_materials', {'reference_material_id': reference_material_id})
    if result is None:
        return None
    return ReferenceMaterials(**result)

@beartype.beartype
def delete_reference_materials_by_id(con: db.Connection, reference_material_id: int):
    db.delete(con, 'reference_materials', {'reference_material_id': reference_material_id})
# Associate the functions with the class
ReferenceMaterials.create_from_json_dict = create_reference_materials_from_json_dict
ReferenceMaterials.write = write_reference_materials
ReferenceMaterials.update = update_reference_materials
ReferenceMaterials.write_many = write_reference_materials_many
ReferenceMaterials.read = read_reference_materials
ReferenceMaterials.read_fuzzy = read_reference_materials_fuzzy
ReferenceMaterials.read_any = read_reference_materials_any
ReferenceMaterials.read_one = read_reference_materials_one
ReferenceMaterials.read_one_or_none = read_reference_materials_one_or_none
ReferenceMaterials.read_all = read_reference_materials_all
ReferenceMaterials.delete = delete_reference_materials_by_id
ReferenceMaterials.read_by_id = read_reference_materials_by_id
ReferenceMaterials.delete_by_id = delete_reference_materials_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ResultsDataQuality:
    """
    @param bridge_id 
    @param result_id 
    @param data_quality_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_quality_id: int # data_quality_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_data_quality(self, con: db.Connection) -> Optional['DataQuality']:
        return read_data_quality_one_or_none(con, data_quality_id=self.data_quality_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_results_data_quality_from_json_dict(json_obj: dict):
        """
        Create a ResultsDataQuality from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ResultsDataQuality(**json_obj)


@beartype.beartype
def write_results_data_quality_obj(con: db.Connection, obj: ResultsDataQuality) -> int:
    """
    Write a ResultsDataQuality object to the database
    @param con: database connection
    @param obj: ResultsDataQuality object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'results_data_quality', dataclasses.asdict(obj))

@beartype.beartype
def write_results_data_quality(
            con: db.Connection,
            result_id: int,
            data_quality_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the results_data_quality table in the database
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param data_quality_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    return db.upsert(con, 'results_data_quality', data)

@beartype.beartype
def write_results_data_quality_many(con: db.Connection, objs: List[ResultsDataQuality], upsert: bool = False) -> int:
    """
    Write a list of ResultsDataQuality objects to the database
    @param con: database connection
    @param objs: list of ResultsDataQuality objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'results_data_quality', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_results_data_quality(con: db.Connection, bridge_id: int,
            result_id: Optional[int] = None,
            data_quality_id: Optional[int] = None) -> int:
    """
    Update a row in the results_data_quality table in the database
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param data_quality_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    return db.update(con, 'results_data_quality', data)

@beartype.beartype
def read_results_data_quality(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_quality_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ResultsDataQuality, None, None]:
    """
    Read from the results_data_quality table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param data_quality_id 
    @return generator of ResultsDataQuality objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    result = db.query(con, 'results_data_quality', data)
    for row in result:
        yield ResultsDataQuality(**row.as_dict())

@beartype.beartype
def read_results_data_quality_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_quality_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ResultsDataQuality, None, None]:
    """
    Read from the results_data_quality table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param data_quality_id 
    @return generator of ResultsDataQuality objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    result = db.query_fuzzy(con, 'results_data_quality', data)
    for row in result:
        yield ResultsDataQuality(**row.as_dict())

@beartype.beartype
def read_results_data_quality_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_quality_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ResultsDataQuality, None, None]:
    """
    Read from the results_data_quality table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param data_quality_id 
    @return generator of ResultsDataQuality objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    result = db.query_any(con, 'results_data_quality', data)
    for row in result:
        yield ResultsDataQuality(**row.as_dict())

@beartype.beartype
def read_results_data_quality_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_quality_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ResultsDataQuality]:
    """
    Read from the results_data_quality table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    result = db.query_one_or_none(con, 'results_data_quality', data)
    if result is None:
        return None
    return ResultsDataQuality(**result)

@beartype.beartype
def read_results_data_quality_one(con: db.Connection, result_id: Optional[int] = None,
             data_quality_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ResultsDataQuality:
    """
    Read from the results_data_quality table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    result = db.query_one(con, 'results_data_quality', data)
    return ResultsDataQuality(**result)

@beartype.beartype
def read_results_data_quality_all(con: db.Connection, result_id: Optional[int] = None,
             data_quality_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ResultsDataQuality]:
    """
    Read from the results_data_quality table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'data_quality_id': data_quality_id,
    }
    result = db.query(con, 'results_data_quality', data)
    return [ResultsDataQuality(**row.as_dict()) for row in result]

@beartype.beartype
def read_results_data_quality_by_id(con: db.Connection, bridge_id: int) -> Optional[ResultsDataQuality]:
    result = db.query_one(con, 'results_data_quality', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ResultsDataQuality(**result)

@beartype.beartype
def delete_results_data_quality_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'results_data_quality', {'bridge_id': bridge_id})
# Associate the functions with the class
ResultsDataQuality.create_from_json_dict = create_results_data_quality_from_json_dict
ResultsDataQuality.write = write_results_data_quality
ResultsDataQuality.update = update_results_data_quality
ResultsDataQuality.write_many = write_results_data_quality_many
ResultsDataQuality.read = read_results_data_quality
ResultsDataQuality.read_fuzzy = read_results_data_quality_fuzzy
ResultsDataQuality.read_any = read_results_data_quality_any
ResultsDataQuality.read_one = read_results_data_quality_one
ResultsDataQuality.read_one_or_none = read_results_data_quality_one_or_none
ResultsDataQuality.read_all = read_results_data_quality_all
ResultsDataQuality.delete = delete_results_data_quality_by_id
ResultsDataQuality.read_by_id = read_results_data_quality_by_id
ResultsDataQuality.delete_by_id = delete_results_data_quality_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CalibrationActions:
    """
    Information about calibration Actions

    @param action_id 
    @param calibration_check_value 
    @param instrument_output_variable_id 
    @param calibration_equation 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    instrument_output_variable_id: int # instrument_output_variable_id integer (default: )
    calibration_check_value: Optional[float] = None # calibration_check_value double precision (default: )
    calibration_equation: Optional[str] = None # calibration_equation character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'action_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_instrument_output_variable(self, con: db.Connection) -> Optional['InstrumentOutputQuantityKind']:
        return read_instrument_output_quantity_kind_one_or_none(con, instrument_output_quantity_kind_id=self.instrument_output_variable_id)

@beartype.beartype
def create_calibration_actions_from_json_dict(json_obj: dict):
        """
        Create a CalibrationActions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CalibrationActions(**json_obj)


@beartype.beartype
def write_calibration_actions_obj(con: db.Connection, obj: CalibrationActions) -> int:
    """
    Write a CalibrationActions object to the database
    @param con: database connection
    @param obj: CalibrationActions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'calibration_actions', dataclasses.asdict(obj))

@beartype.beartype
def write_calibration_actions(
            con: db.Connection,
            action_id: int,
            instrument_output_variable_id: int,
            calibration_check_value: Optional[float] = None,
            calibration_equation: Optional[str] = None) -> int:
    """
    Write to the calibration_actions table in the database
    @param con: database connection
    @param action_id 
    @param calibration_check_value 
    @param instrument_output_variable_id 
    @param calibration_equation 
    @return id of the inserted/updated row
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    return db.upsert(con, 'calibration_actions', data)

@beartype.beartype
def write_calibration_actions_many(con: db.Connection, objs: List[CalibrationActions], upsert: bool = False) -> int:
    """
    Write a list of CalibrationActions objects to the database
    @param con: database connection
    @param objs: list of CalibrationActions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'calibration_actions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_calibration_actions(con: db.Connection, action_id: int,
            instrument_output_variable_id: Optional[int] = None,
            calibration_check_value: Optional[float] = None,
            calibration_equation: Optional[str] = None) -> int:
    """
    Update a row in the calibration_actions table in the database
    @param con: database connection
    @param action_id 
    @param calibration_check_value 
    @param instrument_output_variable_id 
    @param calibration_equation 
    @return The number of rows updated
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    return db.update(con, 'calibration_actions', data)

@beartype.beartype
def read_calibration_actions(
            con: db.Connection,
            action_id: Optional[int] = None,
             instrument_output_variable_id: Optional[int] = None,
             calibration_check_value: Optional[float] = None,
             calibration_equation: Optional[str] = None) -> Generator[CalibrationActions, None, None]:
    """
    Read from the calibration_actions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param calibration_check_value 
    @param instrument_output_variable_id 
    @param calibration_equation 
    @return generator of CalibrationActions objects
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    result = db.query(con, 'calibration_actions', data)
    for row in result:
        yield CalibrationActions(**row.as_dict())

@beartype.beartype
def read_calibration_actions_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             instrument_output_variable_id: Optional[int] = None,
             calibration_check_value: Optional[float] = None,
             calibration_equation: Optional[str] = None) -> Generator[CalibrationActions, None, None]:
    """
    Read from the calibration_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param calibration_check_value 
    @param instrument_output_variable_id 
    @param calibration_equation 
    @return generator of CalibrationActions objects
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    result = db.query_fuzzy(con, 'calibration_actions', data)
    for row in result:
        yield CalibrationActions(**row.as_dict())

@beartype.beartype
def read_calibration_actions_any(con: db.Connection, action_id: Optional[List[int]] = None,
             instrument_output_variable_id: Optional[List[int]] = None,
             calibration_check_value: Optional[List[float]] = None,
             calibration_equation: Optional[List[str]] = None) -> Generator[CalibrationActions, None, None]:
    """
    Read from the calibration_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param calibration_check_value 
    @param instrument_output_variable_id 
    @param calibration_equation 
    @return generator of CalibrationActions objects
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    result = db.query_any(con, 'calibration_actions', data)
    for row in result:
        yield CalibrationActions(**row.as_dict())

@beartype.beartype
def read_calibration_actions_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             instrument_output_variable_id: Optional[int] = None,
             calibration_check_value: Optional[float] = None,
             calibration_equation: Optional[str] = None) -> Optional[CalibrationActions]:
    """
    Read from the calibration_actions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    result = db.query_one_or_none(con, 'calibration_actions', data)
    if result is None:
        return None
    return CalibrationActions(**result)

@beartype.beartype
def read_calibration_actions_one(con: db.Connection, action_id: Optional[int] = None,
             instrument_output_variable_id: Optional[int] = None,
             calibration_check_value: Optional[float] = None,
             calibration_equation: Optional[str] = None) -> CalibrationActions:
    """
    Read from the calibration_actions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    result = db.query_one(con, 'calibration_actions', data)
    return CalibrationActions(**result)

@beartype.beartype
def read_calibration_actions_all(con: db.Connection, action_id: Optional[int] = None,
             instrument_output_variable_id: Optional[int] = None,
             calibration_check_value: Optional[float] = None,
             calibration_equation: Optional[str] = None) -> List[CalibrationActions]:
    """
    Read from the calibration_actions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'calibration_check_value': calibration_check_value,
        'instrument_output_variable_id': instrument_output_variable_id,
        'calibration_equation': calibration_equation,
    }
    result = db.query(con, 'calibration_actions', data)
    return [CalibrationActions(**row.as_dict()) for row in result]

@beartype.beartype
def read_calibration_actions_by_id(con: db.Connection, action_id: int) -> Optional[CalibrationActions]:
    result = db.query_one(con, 'calibration_actions', {'action_id': action_id})
    if result is None:
        return None
    return CalibrationActions(**result)

@beartype.beartype
def delete_calibration_actions_by_id(con: db.Connection, action_id: int):
    db.delete(con, 'calibration_actions', {'action_id': action_id})
# Associate the functions with the class
CalibrationActions.create_from_json_dict = create_calibration_actions_from_json_dict
CalibrationActions.write = write_calibration_actions
CalibrationActions.update = update_calibration_actions
CalibrationActions.write_many = write_calibration_actions_many
CalibrationActions.read = read_calibration_actions
CalibrationActions.read_fuzzy = read_calibration_actions_fuzzy
CalibrationActions.read_any = read_calibration_actions_any
CalibrationActions.read_one = read_calibration_actions_one
CalibrationActions.read_one_or_none = read_calibration_actions_one_or_none
CalibrationActions.read_all = read_calibration_actions_all
CalibrationActions.delete = delete_calibration_actions_by_id
CalibrationActions.read_by_id = read_calibration_actions_by_id
CalibrationActions.delete_by_id = delete_calibration_actions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CalibrationStandards:
    """
    Bridge table linking field calibrations to the reference materials used

    @param bridge_id 
    @param action_id 
    @param reference_material_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    reference_material_id: int # reference_material_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['CalibrationActions']:
        return read_calibration_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_reference_material(self, con: db.Connection) -> Optional['ReferenceMaterials']:
        return read_reference_materials_one_or_none(con, reference_material_id=self.reference_material_id)

@beartype.beartype
def create_calibration_standards_from_json_dict(json_obj: dict):
        """
        Create a CalibrationStandards from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CalibrationStandards(**json_obj)


@beartype.beartype
def write_calibration_standards_obj(con: db.Connection, obj: CalibrationStandards) -> int:
    """
    Write a CalibrationStandards object to the database
    @param con: database connection
    @param obj: CalibrationStandards object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'calibration_standards', dataclasses.asdict(obj))

@beartype.beartype
def write_calibration_standards(
            con: db.Connection,
            action_id: int,
            reference_material_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the calibration_standards table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param reference_material_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    return db.upsert(con, 'calibration_standards', data)

@beartype.beartype
def write_calibration_standards_many(con: db.Connection, objs: List[CalibrationStandards], upsert: bool = False) -> int:
    """
    Write a list of CalibrationStandards objects to the database
    @param con: database connection
    @param objs: list of CalibrationStandards objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'calibration_standards', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_calibration_standards(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            reference_material_id: Optional[int] = None) -> int:
    """
    Update a row in the calibration_standards table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param reference_material_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    return db.update(con, 'calibration_standards', data)

@beartype.beartype
def read_calibration_standards(
            con: db.Connection,
            action_id: Optional[int] = None,
             reference_material_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[CalibrationStandards, None, None]:
    """
    Read from the calibration_standards table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param reference_material_id 
    @return generator of CalibrationStandards objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    result = db.query(con, 'calibration_standards', data)
    for row in result:
        yield CalibrationStandards(**row.as_dict())

@beartype.beartype
def read_calibration_standards_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             reference_material_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[CalibrationStandards, None, None]:
    """
    Read from the calibration_standards table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param reference_material_id 
    @return generator of CalibrationStandards objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    result = db.query_fuzzy(con, 'calibration_standards', data)
    for row in result:
        yield CalibrationStandards(**row.as_dict())

@beartype.beartype
def read_calibration_standards_any(con: db.Connection, action_id: Optional[List[int]] = None,
             reference_material_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[CalibrationStandards, None, None]:
    """
    Read from the calibration_standards table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param reference_material_id 
    @return generator of CalibrationStandards objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    result = db.query_any(con, 'calibration_standards', data)
    for row in result:
        yield CalibrationStandards(**row.as_dict())

@beartype.beartype
def read_calibration_standards_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             reference_material_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[CalibrationStandards]:
    """
    Read from the calibration_standards table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    result = db.query_one_or_none(con, 'calibration_standards', data)
    if result is None:
        return None
    return CalibrationStandards(**result)

@beartype.beartype
def read_calibration_standards_one(con: db.Connection, action_id: Optional[int] = None,
             reference_material_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> CalibrationStandards:
    """
    Read from the calibration_standards table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    result = db.query_one(con, 'calibration_standards', data)
    return CalibrationStandards(**result)

@beartype.beartype
def read_calibration_standards_all(con: db.Connection, action_id: Optional[int] = None,
             reference_material_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[CalibrationStandards]:
    """
    Read from the calibration_standards table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'reference_material_id': reference_material_id,
    }
    result = db.query(con, 'calibration_standards', data)
    return [CalibrationStandards(**row.as_dict()) for row in result]

@beartype.beartype
def read_calibration_standards_by_id(con: db.Connection, bridge_id: int) -> Optional[CalibrationStandards]:
    result = db.query_one(con, 'calibration_standards', {'bridge_id': bridge_id})
    if result is None:
        return None
    return CalibrationStandards(**result)

@beartype.beartype
def delete_calibration_standards_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'calibration_standards', {'bridge_id': bridge_id})
# Associate the functions with the class
CalibrationStandards.create_from_json_dict = create_calibration_standards_from_json_dict
CalibrationStandards.write = write_calibration_standards
CalibrationStandards.update = update_calibration_standards
CalibrationStandards.write_many = write_calibration_standards_many
CalibrationStandards.read = read_calibration_standards
CalibrationStandards.read_fuzzy = read_calibration_standards_fuzzy
CalibrationStandards.read_any = read_calibration_standards_any
CalibrationStandards.read_one = read_calibration_standards_one
CalibrationStandards.read_one_or_none = read_calibration_standards_one_or_none
CalibrationStandards.read_all = read_calibration_standards_all
CalibrationStandards.delete = delete_calibration_standards_by_id
CalibrationStandards.read_by_id = read_calibration_standards_by_id
CalibrationStandards.delete_by_id = delete_calibration_standards_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DataloggerFileColumns:
    """
    Information about columns in datalogger files

    @param datalogger_file_column_id 
    @param result_id 
    @param datalogger_file_id 
    @param instrument_output_quantity_kind_id 
    @param column_label 
    @param column_description 
    @param measurement_equation 
    @param scan_interval 
    @param scan_interval_units_id 
    @param recording_interval 
    @param recording_interval_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    datalogger_file_id: int # datalogger_file_id integer (default: )
    instrument_output_quantity_kind_id: int # instrument_output_quantity_kind_id integer (default: )
    column_label: str # column_label character varying (default: )
    datalogger_file_column_id: Optional[int] = None # datalogger_file_column_id integer (default: )
    result_id: Optional[int] = None # result_id bigint (default: )
    column_description: Optional[str] = None # column_description character varying (default: )
    measurement_equation: Optional[str] = None # measurement_equation character varying (default: )
    scan_interval: Optional[float] = None # scan_interval double precision (default: )
    scan_interval_units_id: Optional[int] = None # scan_interval_units_id integer (default: )
    recording_interval: Optional[float] = None # recording_interval double precision (default: )
    recording_interval_units_id: Optional[int] = None # recording_interval_units_id integer (default: )
    aggregation_statistic_cv: Optional[str] = None # aggregation_statistic_cv character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'datalogger_file_column_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_datalogger_file(self, con: db.Connection) -> Optional['DataloggerFiles']:
        return read_datalogger_files_one_or_none(con, datalogger_file_id=self.datalogger_file_id)

    @beartype.beartype
    def get_instrument_output_quantity_kind(self, con: db.Connection) -> Optional['InstrumentOutputQuantityKind']:
        return read_instrument_output_quantity_kind_one_or_none(con, instrument_output_quantity_kind_id=self.instrument_output_quantity_kind_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_datalogger_file_columns_from_json_dict(json_obj: dict):
        """
        Create a DataloggerFileColumns from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DataloggerFileColumns(**json_obj)


@beartype.beartype
def write_datalogger_file_columns_obj(con: db.Connection, obj: DataloggerFileColumns) -> int:
    """
    Write a DataloggerFileColumns object to the database
    @param con: database connection
    @param obj: DataloggerFileColumns object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datalogger_file_columns', dataclasses.asdict(obj))

@beartype.beartype
def write_datalogger_file_columns(
            con: db.Connection,
            datalogger_file_id: int,
            instrument_output_quantity_kind_id: int,
            column_label: str,
            datalogger_file_column_id: Optional[int] = None,
            result_id: Optional[int] = None,
            column_description: Optional[str] = None,
            measurement_equation: Optional[str] = None,
            scan_interval: Optional[float] = None,
            scan_interval_units_id: Optional[int] = None,
            recording_interval: Optional[float] = None,
            recording_interval_units_id: Optional[int] = None,
            aggregation_statistic_cv: Optional[str] = None) -> int:
    """
    Write to the datalogger_file_columns table in the database
    @param con: database connection
    @param datalogger_file_column_id 
    @param result_id 
    @param datalogger_file_id 
    @param instrument_output_quantity_kind_id 
    @param column_label 
    @param column_description 
    @param measurement_equation 
    @param scan_interval 
    @param scan_interval_units_id 
    @param recording_interval 
    @param recording_interval_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'datalogger_file_columns', data)

@beartype.beartype
def write_datalogger_file_columns_many(con: db.Connection, objs: List[DataloggerFileColumns], upsert: bool = False) -> int:
    """
    Write a list of DataloggerFileColumns objects to the database
    @param con: database connection
    @param objs: list of DataloggerFileColumns objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datalogger_file_columns', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datalogger_file_columns(con: db.Connection, datalogger_file_column_id: int,
            datalogger_file_id: Optional[int] = None,
            instrument_output_quantity_kind_id: Optional[int] = None,
            column_label: Optional[str] = None,
            result_id: Optional[int] = None,
            column_description: Optional[str] = None,
            measurement_equation: Optional[str] = None,
            scan_interval: Optional[float] = None,
            scan_interval_units_id: Optional[int] = None,
            recording_interval: Optional[float] = None,
            recording_interval_units_id: Optional[int] = None,
            aggregation_statistic_cv: Optional[str] = None) -> int:
    """
    Update a row in the datalogger_file_columns table in the database
    @param con: database connection
    @param datalogger_file_column_id 
    @param result_id 
    @param datalogger_file_id 
    @param instrument_output_quantity_kind_id 
    @param column_label 
    @param column_description 
    @param measurement_equation 
    @param scan_interval 
    @param scan_interval_units_id 
    @param recording_interval 
    @param recording_interval_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'datalogger_file_columns', data)

@beartype.beartype
def read_datalogger_file_columns(
            con: db.Connection,
            datalogger_file_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             column_label: Optional[str] = None,
             datalogger_file_column_id: Optional[int] = None,
             result_id: Optional[int] = None,
             column_description: Optional[str] = None,
             measurement_equation: Optional[str] = None,
             scan_interval: Optional[float] = None,
             scan_interval_units_id: Optional[int] = None,
             recording_interval: Optional[float] = None,
             recording_interval_units_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None) -> Generator[DataloggerFileColumns, None, None]:
    """
    Read from the datalogger_file_columns table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datalogger_file_column_id 
    @param result_id 
    @param datalogger_file_id 
    @param instrument_output_quantity_kind_id 
    @param column_label 
    @param column_description 
    @param measurement_equation 
    @param scan_interval 
    @param scan_interval_units_id 
    @param recording_interval 
    @param recording_interval_units_id 
    @param aggregation_statistic_cv 
    @return generator of DataloggerFileColumns objects
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'datalogger_file_columns', data)
    for row in result:
        yield DataloggerFileColumns(**row.as_dict())

@beartype.beartype
def read_datalogger_file_columns_fuzzy(con: db.Connection, datalogger_file_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             column_label: Optional[str] = None,
             datalogger_file_column_id: Optional[int] = None,
             result_id: Optional[int] = None,
             column_description: Optional[str] = None,
             measurement_equation: Optional[str] = None,
             scan_interval: Optional[float] = None,
             scan_interval_units_id: Optional[int] = None,
             recording_interval: Optional[float] = None,
             recording_interval_units_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None) -> Generator[DataloggerFileColumns, None, None]:
    """
    Read from the datalogger_file_columns table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datalogger_file_column_id 
    @param result_id 
    @param datalogger_file_id 
    @param instrument_output_quantity_kind_id 
    @param column_label 
    @param column_description 
    @param measurement_equation 
    @param scan_interval 
    @param scan_interval_units_id 
    @param recording_interval 
    @param recording_interval_units_id 
    @param aggregation_statistic_cv 
    @return generator of DataloggerFileColumns objects
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'datalogger_file_columns', data)
    for row in result:
        yield DataloggerFileColumns(**row.as_dict())

@beartype.beartype
def read_datalogger_file_columns_any(con: db.Connection, datalogger_file_id: Optional[List[int]] = None,
             instrument_output_quantity_kind_id: Optional[List[int]] = None,
             column_label: Optional[List[str]] = None,
             datalogger_file_column_id: Optional[List[int]] = None,
             result_id: Optional[List[int]] = None,
             column_description: Optional[List[str]] = None,
             measurement_equation: Optional[List[str]] = None,
             scan_interval: Optional[List[float]] = None,
             scan_interval_units_id: Optional[List[int]] = None,
             recording_interval: Optional[List[float]] = None,
             recording_interval_units_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None) -> Generator[DataloggerFileColumns, None, None]:
    """
    Read from the datalogger_file_columns table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datalogger_file_column_id 
    @param result_id 
    @param datalogger_file_id 
    @param instrument_output_quantity_kind_id 
    @param column_label 
    @param column_description 
    @param measurement_equation 
    @param scan_interval 
    @param scan_interval_units_id 
    @param recording_interval 
    @param recording_interval_units_id 
    @param aggregation_statistic_cv 
    @return generator of DataloggerFileColumns objects
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'datalogger_file_columns', data)
    for row in result:
        yield DataloggerFileColumns(**row.as_dict())

@beartype.beartype
def read_datalogger_file_columns_one_or_none(con: db.Connection, datalogger_file_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             column_label: Optional[str] = None,
             datalogger_file_column_id: Optional[int] = None,
             result_id: Optional[int] = None,
             column_description: Optional[str] = None,
             measurement_equation: Optional[str] = None,
             scan_interval: Optional[float] = None,
             scan_interval_units_id: Optional[int] = None,
             recording_interval: Optional[float] = None,
             recording_interval_units_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None) -> Optional[DataloggerFileColumns]:
    """
    Read from the datalogger_file_columns table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'datalogger_file_columns', data)
    if result is None:
        return None
    return DataloggerFileColumns(**result)

@beartype.beartype
def read_datalogger_file_columns_one(con: db.Connection, datalogger_file_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             column_label: Optional[str] = None,
             datalogger_file_column_id: Optional[int] = None,
             result_id: Optional[int] = None,
             column_description: Optional[str] = None,
             measurement_equation: Optional[str] = None,
             scan_interval: Optional[float] = None,
             scan_interval_units_id: Optional[int] = None,
             recording_interval: Optional[float] = None,
             recording_interval_units_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None) -> DataloggerFileColumns:
    """
    Read from the datalogger_file_columns table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'datalogger_file_columns', data)
    return DataloggerFileColumns(**result)

@beartype.beartype
def read_datalogger_file_columns_all(con: db.Connection, datalogger_file_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             column_label: Optional[str] = None,
             datalogger_file_column_id: Optional[int] = None,
             result_id: Optional[int] = None,
             column_description: Optional[str] = None,
             measurement_equation: Optional[str] = None,
             scan_interval: Optional[float] = None,
             scan_interval_units_id: Optional[int] = None,
             recording_interval: Optional[float] = None,
             recording_interval_units_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None) -> List[DataloggerFileColumns]:
    """
    Read from the datalogger_file_columns table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'datalogger_file_column_id': datalogger_file_column_id,
        'result_id': result_id,
        'datalogger_file_id': datalogger_file_id,
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'column_label': column_label,
        'column_description': column_description,
        'measurement_equation': measurement_equation,
        'scan_interval': scan_interval,
        'scan_interval_units_id': scan_interval_units_id,
        'recording_interval': recording_interval,
        'recording_interval_units_id': recording_interval_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'datalogger_file_columns', data)
    return [DataloggerFileColumns(**row.as_dict()) for row in result]

@beartype.beartype
def read_datalogger_file_columns_by_id(con: db.Connection, datalogger_file_column_id: int) -> Optional[DataloggerFileColumns]:
    result = db.query_one(con, 'datalogger_file_columns', {'datalogger_file_column_id': datalogger_file_column_id})
    if result is None:
        return None
    return DataloggerFileColumns(**result)

@beartype.beartype
def delete_datalogger_file_columns_by_id(con: db.Connection, datalogger_file_column_id: int):
    db.delete(con, 'datalogger_file_columns', {'datalogger_file_column_id': datalogger_file_column_id})
# Associate the functions with the class
DataloggerFileColumns.create_from_json_dict = create_datalogger_file_columns_from_json_dict
DataloggerFileColumns.write = write_datalogger_file_columns
DataloggerFileColumns.update = update_datalogger_file_columns
DataloggerFileColumns.write_many = write_datalogger_file_columns_many
DataloggerFileColumns.read = read_datalogger_file_columns
DataloggerFileColumns.read_fuzzy = read_datalogger_file_columns_fuzzy
DataloggerFileColumns.read_any = read_datalogger_file_columns_any
DataloggerFileColumns.read_one = read_datalogger_file_columns_one
DataloggerFileColumns.read_one_or_none = read_datalogger_file_columns_one_or_none
DataloggerFileColumns.read_all = read_datalogger_file_columns_all
DataloggerFileColumns.delete = delete_datalogger_file_columns_by_id
DataloggerFileColumns.read_by_id = read_datalogger_file_columns_by_id
DataloggerFileColumns.delete_by_id = delete_datalogger_file_columns_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DataloggerProgramFiles:
    """
    Information about datalogger program files

    @param program_id 
    @param affiliation_id 
    @param program_name 
    @param program_description 
    @param program_version 
    @param program_file_link 

    This is an automatically generated class
    """
    affiliation_id: int # affiliation_id integer (default: )
    program_name: str # program_name character varying (default: )
    program_id: Optional[int] = None # program_id integer (default: )
    program_description: Optional[str] = None # program_description character varying (default: )
    program_version: Optional[str] = None # program_version character varying (default: )
    program_file_link: Optional[str] = None # program_file_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'program_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_affiliation(self, con: db.Connection) -> Optional['Affiliations']:
        return read_affiliations_one_or_none(con, affiliation_id=self.affiliation_id)

@beartype.beartype
def create_datalogger_program_files_from_json_dict(json_obj: dict):
        """
        Create a DataloggerProgramFiles from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DataloggerProgramFiles(**json_obj)


@beartype.beartype
def write_datalogger_program_files_obj(con: db.Connection, obj: DataloggerProgramFiles) -> int:
    """
    Write a DataloggerProgramFiles object to the database
    @param con: database connection
    @param obj: DataloggerProgramFiles object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datalogger_program_files', dataclasses.asdict(obj))

@beartype.beartype
def write_datalogger_program_files(
            con: db.Connection,
            affiliation_id: int,
            program_name: str,
            program_id: Optional[int] = None,
            program_description: Optional[str] = None,
            program_version: Optional[str] = None,
            program_file_link: Optional[str] = None) -> int:
    """
    Write to the datalogger_program_files table in the database
    @param con: database connection
    @param program_id 
    @param affiliation_id 
    @param program_name 
    @param program_description 
    @param program_version 
    @param program_file_link 
    @return id of the inserted/updated row
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    return db.upsert(con, 'datalogger_program_files', data)

@beartype.beartype
def write_datalogger_program_files_many(con: db.Connection, objs: List[DataloggerProgramFiles], upsert: bool = False) -> int:
    """
    Write a list of DataloggerProgramFiles objects to the database
    @param con: database connection
    @param objs: list of DataloggerProgramFiles objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datalogger_program_files', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datalogger_program_files(con: db.Connection, program_id: int,
            affiliation_id: Optional[int] = None,
            program_name: Optional[str] = None,
            program_description: Optional[str] = None,
            program_version: Optional[str] = None,
            program_file_link: Optional[str] = None) -> int:
    """
    Update a row in the datalogger_program_files table in the database
    @param con: database connection
    @param program_id 
    @param affiliation_id 
    @param program_name 
    @param program_description 
    @param program_version 
    @param program_file_link 
    @return The number of rows updated
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    return db.update(con, 'datalogger_program_files', data)

@beartype.beartype
def read_datalogger_program_files(
            con: db.Connection,
            affiliation_id: Optional[int] = None,
             program_name: Optional[str] = None,
             program_id: Optional[int] = None,
             program_description: Optional[str] = None,
             program_version: Optional[str] = None,
             program_file_link: Optional[str] = None) -> Generator[DataloggerProgramFiles, None, None]:
    """
    Read from the datalogger_program_files table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param program_id 
    @param affiliation_id 
    @param program_name 
    @param program_description 
    @param program_version 
    @param program_file_link 
    @return generator of DataloggerProgramFiles objects
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    result = db.query(con, 'datalogger_program_files', data)
    for row in result:
        yield DataloggerProgramFiles(**row.as_dict())

@beartype.beartype
def read_datalogger_program_files_fuzzy(con: db.Connection, affiliation_id: Optional[int] = None,
             program_name: Optional[str] = None,
             program_id: Optional[int] = None,
             program_description: Optional[str] = None,
             program_version: Optional[str] = None,
             program_file_link: Optional[str] = None) -> Generator[DataloggerProgramFiles, None, None]:
    """
    Read from the datalogger_program_files table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param program_id 
    @param affiliation_id 
    @param program_name 
    @param program_description 
    @param program_version 
    @param program_file_link 
    @return generator of DataloggerProgramFiles objects
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    result = db.query_fuzzy(con, 'datalogger_program_files', data)
    for row in result:
        yield DataloggerProgramFiles(**row.as_dict())

@beartype.beartype
def read_datalogger_program_files_any(con: db.Connection, affiliation_id: Optional[List[int]] = None,
             program_name: Optional[List[str]] = None,
             program_id: Optional[List[int]] = None,
             program_description: Optional[List[str]] = None,
             program_version: Optional[List[str]] = None,
             program_file_link: Optional[List[str]] = None) -> Generator[DataloggerProgramFiles, None, None]:
    """
    Read from the datalogger_program_files table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param program_id 
    @param affiliation_id 
    @param program_name 
    @param program_description 
    @param program_version 
    @param program_file_link 
    @return generator of DataloggerProgramFiles objects
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    result = db.query_any(con, 'datalogger_program_files', data)
    for row in result:
        yield DataloggerProgramFiles(**row.as_dict())

@beartype.beartype
def read_datalogger_program_files_one_or_none(con: db.Connection, affiliation_id: Optional[int] = None,
             program_name: Optional[str] = None,
             program_id: Optional[int] = None,
             program_description: Optional[str] = None,
             program_version: Optional[str] = None,
             program_file_link: Optional[str] = None) -> Optional[DataloggerProgramFiles]:
    """
    Read from the datalogger_program_files table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    result = db.query_one_or_none(con, 'datalogger_program_files', data)
    if result is None:
        return None
    return DataloggerProgramFiles(**result)

@beartype.beartype
def read_datalogger_program_files_one(con: db.Connection, affiliation_id: Optional[int] = None,
             program_name: Optional[str] = None,
             program_id: Optional[int] = None,
             program_description: Optional[str] = None,
             program_version: Optional[str] = None,
             program_file_link: Optional[str] = None) -> DataloggerProgramFiles:
    """
    Read from the datalogger_program_files table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    result = db.query_one(con, 'datalogger_program_files', data)
    return DataloggerProgramFiles(**result)

@beartype.beartype
def read_datalogger_program_files_all(con: db.Connection, affiliation_id: Optional[int] = None,
             program_name: Optional[str] = None,
             program_id: Optional[int] = None,
             program_description: Optional[str] = None,
             program_version: Optional[str] = None,
             program_file_link: Optional[str] = None) -> List[DataloggerProgramFiles]:
    """
    Read from the datalogger_program_files table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'program_id': program_id,
        'affiliation_id': affiliation_id,
        'program_name': program_name,
        'program_description': program_description,
        'program_version': program_version,
        'program_file_link': program_file_link,
    }
    result = db.query(con, 'datalogger_program_files', data)
    return [DataloggerProgramFiles(**row.as_dict()) for row in result]

@beartype.beartype
def read_datalogger_program_files_by_id(con: db.Connection, program_id: int) -> Optional[DataloggerProgramFiles]:
    result = db.query_one(con, 'datalogger_program_files', {'program_id': program_id})
    if result is None:
        return None
    return DataloggerProgramFiles(**result)

@beartype.beartype
def delete_datalogger_program_files_by_id(con: db.Connection, program_id: int):
    db.delete(con, 'datalogger_program_files', {'program_id': program_id})
# Associate the functions with the class
DataloggerProgramFiles.create_from_json_dict = create_datalogger_program_files_from_json_dict
DataloggerProgramFiles.write = write_datalogger_program_files
DataloggerProgramFiles.update = update_datalogger_program_files
DataloggerProgramFiles.write_many = write_datalogger_program_files_many
DataloggerProgramFiles.read = read_datalogger_program_files
DataloggerProgramFiles.read_fuzzy = read_datalogger_program_files_fuzzy
DataloggerProgramFiles.read_any = read_datalogger_program_files_any
DataloggerProgramFiles.read_one = read_datalogger_program_files_one
DataloggerProgramFiles.read_one_or_none = read_datalogger_program_files_one_or_none
DataloggerProgramFiles.read_all = read_datalogger_program_files_all
DataloggerProgramFiles.delete = delete_datalogger_program_files_by_id
DataloggerProgramFiles.read_by_id = read_datalogger_program_files_by_id
DataloggerProgramFiles.delete_by_id = delete_datalogger_program_files_by_id



@beartype_wrap_init
@dataclasses.dataclass
class EquipmentModels:
    """
    Describes models of sensors, loggers, and related equipment used in making observations.

    @param equipment_model_id 
    @param equipment_model_manufacturer_id 
    @param equipment_model_part_number 
    @param equipment_model_name 
    @param equipment_type_cv 
    @param equipment_model_description 
    @param is_instrument 
    @param equipment_model_specifications_file_link 
    @param equipment_model_description_url 
    @param is_retired 

    This is an automatically generated class
    """
    equipment_model_manufacturer_id: int # equipment_model_manufacturer_id integer (default: )
    equipment_model_name: str # equipment_model_name character varying (default: )
    equipment_type_cv: str # equipment_type_cv character varying (default: )
    is_instrument: bool # is_instrument boolean (default: )
    equipment_model_id: Optional[int] = None # equipment_model_id integer (default: )
    equipment_model_part_number: Optional[str] = None # equipment_model_part_number character varying (default: )
    equipment_model_description: Optional[str] = None # equipment_model_description character varying (default: )
    equipment_model_specifications_file_link: Optional[str] = None # equipment_model_specifications_file_link character varying (default: )
    equipment_model_description_url: Optional[str] = None # equipment_model_description_url character varying (default: )
    is_retired: Optional[bool] = None # is_retired boolean (default: )
    PRIMARY_KEY: ClassVar[str] = 'equipment_model_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_equipment_type_cv(self, con: db.Connection) -> Optional['CvEquipmentType']:
        return read_cv_equipment_type_one_or_none(con, term=self.equipment_type_cv)

    @beartype.beartype
    def get_equipment_model_manufacturer(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.equipment_model_manufacturer_id)

@beartype.beartype
def create_equipment_models_from_json_dict(json_obj: dict):
        """
        Create a EquipmentModels from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return EquipmentModels(**json_obj)


@beartype.beartype
def write_equipment_models_obj(con: db.Connection, obj: EquipmentModels) -> int:
    """
    Write a EquipmentModels object to the database
    @param con: database connection
    @param obj: EquipmentModels object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'equipment_models', dataclasses.asdict(obj))

@beartype.beartype
def write_equipment_models(
            con: db.Connection,
            equipment_model_manufacturer_id: int,
            equipment_model_name: str,
            equipment_type_cv: str,
            is_instrument: bool,
            equipment_model_id: Optional[int] = None,
            equipment_model_part_number: Optional[str] = None,
            equipment_model_description: Optional[str] = None,
            equipment_model_specifications_file_link: Optional[str] = None,
            equipment_model_description_url: Optional[str] = None,
            is_retired: Optional[bool] = None) -> int:
    """
    Write to the equipment_models table in the database
    @param con: database connection
    @param equipment_model_id 
    @param equipment_model_manufacturer_id 
    @param equipment_model_part_number 
    @param equipment_model_name 
    @param equipment_type_cv 
    @param equipment_model_description 
    @param is_instrument 
    @param equipment_model_specifications_file_link 
    @param equipment_model_description_url 
    @param is_retired 
    @return id of the inserted/updated row
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    return db.upsert(con, 'equipment_models', data)

@beartype.beartype
def write_equipment_models_many(con: db.Connection, objs: List[EquipmentModels], upsert: bool = False) -> int:
    """
    Write a list of EquipmentModels objects to the database
    @param con: database connection
    @param objs: list of EquipmentModels objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'equipment_models', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_equipment_models(con: db.Connection, equipment_model_id: int,
            equipment_model_manufacturer_id: Optional[int] = None,
            equipment_model_name: Optional[str] = None,
            equipment_type_cv: Optional[str] = None,
            is_instrument: Optional[bool] = None,
            equipment_model_part_number: Optional[str] = None,
            equipment_model_description: Optional[str] = None,
            equipment_model_specifications_file_link: Optional[str] = None,
            equipment_model_description_url: Optional[str] = None,
            is_retired: Optional[bool] = None) -> int:
    """
    Update a row in the equipment_models table in the database
    @param con: database connection
    @param equipment_model_id 
    @param equipment_model_manufacturer_id 
    @param equipment_model_part_number 
    @param equipment_model_name 
    @param equipment_type_cv 
    @param equipment_model_description 
    @param is_instrument 
    @param equipment_model_specifications_file_link 
    @param equipment_model_description_url 
    @param is_retired 
    @return The number of rows updated
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    return db.update(con, 'equipment_models', data)

@beartype.beartype
def read_equipment_models(
            con: db.Connection,
            equipment_model_manufacturer_id: Optional[int] = None,
             equipment_model_name: Optional[str] = None,
             equipment_type_cv: Optional[str] = None,
             is_instrument: Optional[bool] = None,
             equipment_model_id: Optional[int] = None,
             equipment_model_part_number: Optional[str] = None,
             equipment_model_description: Optional[str] = None,
             equipment_model_specifications_file_link: Optional[str] = None,
             equipment_model_description_url: Optional[str] = None,
             is_retired: Optional[bool] = None) -> Generator[EquipmentModels, None, None]:
    """
    Read from the equipment_models table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_model_id 
    @param equipment_model_manufacturer_id 
    @param equipment_model_part_number 
    @param equipment_model_name 
    @param equipment_type_cv 
    @param equipment_model_description 
    @param is_instrument 
    @param equipment_model_specifications_file_link 
    @param equipment_model_description_url 
    @param is_retired 
    @return generator of EquipmentModels objects
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    result = db.query(con, 'equipment_models', data)
    for row in result:
        yield EquipmentModels(**row.as_dict())

@beartype.beartype
def read_equipment_models_fuzzy(con: db.Connection, equipment_model_manufacturer_id: Optional[int] = None,
             equipment_model_name: Optional[str] = None,
             equipment_type_cv: Optional[str] = None,
             is_instrument: Optional[bool] = None,
             equipment_model_id: Optional[int] = None,
             equipment_model_part_number: Optional[str] = None,
             equipment_model_description: Optional[str] = None,
             equipment_model_specifications_file_link: Optional[str] = None,
             equipment_model_description_url: Optional[str] = None,
             is_retired: Optional[bool] = None) -> Generator[EquipmentModels, None, None]:
    """
    Read from the equipment_models table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_model_id 
    @param equipment_model_manufacturer_id 
    @param equipment_model_part_number 
    @param equipment_model_name 
    @param equipment_type_cv 
    @param equipment_model_description 
    @param is_instrument 
    @param equipment_model_specifications_file_link 
    @param equipment_model_description_url 
    @param is_retired 
    @return generator of EquipmentModels objects
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    result = db.query_fuzzy(con, 'equipment_models', data)
    for row in result:
        yield EquipmentModels(**row.as_dict())

@beartype.beartype
def read_equipment_models_any(con: db.Connection, equipment_model_manufacturer_id: Optional[List[int]] = None,
             equipment_model_name: Optional[List[str]] = None,
             equipment_type_cv: Optional[List[str]] = None,
             is_instrument: Optional[List[bool]] = None,
             equipment_model_id: Optional[List[int]] = None,
             equipment_model_part_number: Optional[List[str]] = None,
             equipment_model_description: Optional[List[str]] = None,
             equipment_model_specifications_file_link: Optional[List[str]] = None,
             equipment_model_description_url: Optional[List[str]] = None,
             is_retired: Optional[List[bool]] = None) -> Generator[EquipmentModels, None, None]:
    """
    Read from the equipment_models table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_model_id 
    @param equipment_model_manufacturer_id 
    @param equipment_model_part_number 
    @param equipment_model_name 
    @param equipment_type_cv 
    @param equipment_model_description 
    @param is_instrument 
    @param equipment_model_specifications_file_link 
    @param equipment_model_description_url 
    @param is_retired 
    @return generator of EquipmentModels objects
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    result = db.query_any(con, 'equipment_models', data)
    for row in result:
        yield EquipmentModels(**row.as_dict())

@beartype.beartype
def read_equipment_models_one_or_none(con: db.Connection, equipment_model_manufacturer_id: Optional[int] = None,
             equipment_model_name: Optional[str] = None,
             equipment_type_cv: Optional[str] = None,
             is_instrument: Optional[bool] = None,
             equipment_model_id: Optional[int] = None,
             equipment_model_part_number: Optional[str] = None,
             equipment_model_description: Optional[str] = None,
             equipment_model_specifications_file_link: Optional[str] = None,
             equipment_model_description_url: Optional[str] = None,
             is_retired: Optional[bool] = None) -> Optional[EquipmentModels]:
    """
    Read from the equipment_models table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    result = db.query_one_or_none(con, 'equipment_models', data)
    if result is None:
        return None
    return EquipmentModels(**result)

@beartype.beartype
def read_equipment_models_one(con: db.Connection, equipment_model_manufacturer_id: Optional[int] = None,
             equipment_model_name: Optional[str] = None,
             equipment_type_cv: Optional[str] = None,
             is_instrument: Optional[bool] = None,
             equipment_model_id: Optional[int] = None,
             equipment_model_part_number: Optional[str] = None,
             equipment_model_description: Optional[str] = None,
             equipment_model_specifications_file_link: Optional[str] = None,
             equipment_model_description_url: Optional[str] = None,
             is_retired: Optional[bool] = None) -> EquipmentModels:
    """
    Read from the equipment_models table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    result = db.query_one(con, 'equipment_models', data)
    return EquipmentModels(**result)

@beartype.beartype
def read_equipment_models_all(con: db.Connection, equipment_model_manufacturer_id: Optional[int] = None,
             equipment_model_name: Optional[str] = None,
             equipment_type_cv: Optional[str] = None,
             is_instrument: Optional[bool] = None,
             equipment_model_id: Optional[int] = None,
             equipment_model_part_number: Optional[str] = None,
             equipment_model_description: Optional[str] = None,
             equipment_model_specifications_file_link: Optional[str] = None,
             equipment_model_description_url: Optional[str] = None,
             is_retired: Optional[bool] = None) -> List[EquipmentModels]:
    """
    Read from the equipment_models table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'equipment_model_id': equipment_model_id,
        'equipment_model_manufacturer_id': equipment_model_manufacturer_id,
        'equipment_model_part_number': equipment_model_part_number,
        'equipment_model_name': equipment_model_name,
        'equipment_type_cv': equipment_type_cv,
        'equipment_model_description': equipment_model_description,
        'is_instrument': is_instrument,
        'equipment_model_specifications_file_link': equipment_model_specifications_file_link,
        'equipment_model_description_url': equipment_model_description_url,
        'is_retired': is_retired,
    }
    result = db.query(con, 'equipment_models', data)
    return [EquipmentModels(**row.as_dict()) for row in result]

@beartype.beartype
def read_equipment_models_by_id(con: db.Connection, equipment_model_id: int) -> Optional[EquipmentModels]:
    result = db.query_one(con, 'equipment_models', {'equipment_model_id': equipment_model_id})
    if result is None:
        return None
    return EquipmentModels(**result)

@beartype.beartype
def delete_equipment_models_by_id(con: db.Connection, equipment_model_id: int):
    db.delete(con, 'equipment_models', {'equipment_model_id': equipment_model_id})
# Associate the functions with the class
EquipmentModels.create_from_json_dict = create_equipment_models_from_json_dict
EquipmentModels.write = write_equipment_models
EquipmentModels.update = update_equipment_models
EquipmentModels.write_many = write_equipment_models_many
EquipmentModels.read = read_equipment_models
EquipmentModels.read_fuzzy = read_equipment_models_fuzzy
EquipmentModels.read_any = read_equipment_models_any
EquipmentModels.read_one = read_equipment_models_one
EquipmentModels.read_one_or_none = read_equipment_models_one_or_none
EquipmentModels.read_all = read_equipment_models_all
EquipmentModels.delete = delete_equipment_models_by_id
EquipmentModels.read_by_id = read_equipment_models_by_id
EquipmentModels.delete_by_id = delete_equipment_models_by_id



@beartype_wrap_init
@dataclasses.dataclass
class InstrumentOutputQuantityKind:
    """
    Information about the QuantityKind that an instrument is capable of measuring

    @param instrument_output_quantity_kind_id 
    @param equipment_model_id 
    @param quantity_kind 
    @param instrument_resolution 
    @param instrument_accuracy 
    @param instrument_raw_output_units_id 
    @param instrument_standard_output_variable 
    @param instrument_method_id 

    This is an automatically generated class
    """
    equipment_model_id: int # equipment_model_id integer (default: )
    quantity_kind: str # quantity_kind character varying (default: )
    instrument_raw_output_units_id: int # instrument_raw_output_units_id integer (default: )
    instrument_output_quantity_kind_id: Optional[int] = None # instrument_output_quantity_kind_id integer (default: )
    instrument_resolution: Optional[str] = None # instrument_resolution character varying (default: )
    instrument_accuracy: Optional[str] = None # instrument_accuracy character varying (default: )
    instrument_standard_output_variable: Optional[int] = None # instrument_standard_output_variable integer (default: )
    instrument_method_id: Optional[int] = None # instrument_method_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'instrument_output_quantity_kind_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_instrument_method(self, con: db.Connection) -> Optional['Methods']:
        return read_methods_one_or_none(con, method_id=self.instrument_method_id)

    @beartype.beartype
    def get_instrument_standard_output_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.instrument_standard_output_variable)

    @beartype.beartype
    def get_quantity_kind(self, con: db.Connection) -> Optional['CvQuantityKind']:
        return read_cv_quantity_kind_one_or_none(con, term=self.quantity_kind)

    @beartype.beartype
    def get_instrument_raw_output_units(self, con: db.Connection) -> Optional['CvUnits']:
        return read_cv_units_one_or_none(con, units_id=self.instrument_raw_output_units_id)

    @beartype.beartype
    def get_equipment_model(self, con: db.Connection) -> Optional['EquipmentModels']:
        return read_equipment_models_one_or_none(con, equipment_model_id=self.equipment_model_id)

@beartype.beartype
def create_instrument_output_quantity_kind_from_json_dict(json_obj: dict):
        """
        Create a InstrumentOutputQuantityKind from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return InstrumentOutputQuantityKind(**json_obj)


@beartype.beartype
def write_instrument_output_quantity_kind_obj(con: db.Connection, obj: InstrumentOutputQuantityKind) -> int:
    """
    Write a InstrumentOutputQuantityKind object to the database
    @param con: database connection
    @param obj: InstrumentOutputQuantityKind object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'instrument_output_quantity_kind', dataclasses.asdict(obj))

@beartype.beartype
def write_instrument_output_quantity_kind(
            con: db.Connection,
            equipment_model_id: int,
            quantity_kind: str,
            instrument_raw_output_units_id: int,
            instrument_output_quantity_kind_id: Optional[int] = None,
            instrument_resolution: Optional[str] = None,
            instrument_accuracy: Optional[str] = None,
            instrument_standard_output_variable: Optional[int] = None,
            instrument_method_id: Optional[int] = None) -> int:
    """
    Write to the instrument_output_quantity_kind table in the database
    @param con: database connection
    @param instrument_output_quantity_kind_id 
    @param equipment_model_id 
    @param quantity_kind 
    @param instrument_resolution 
    @param instrument_accuracy 
    @param instrument_raw_output_units_id 
    @param instrument_standard_output_variable 
    @param instrument_method_id 
    @return id of the inserted/updated row
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    return db.upsert(con, 'instrument_output_quantity_kind', data)

@beartype.beartype
def write_instrument_output_quantity_kind_many(con: db.Connection, objs: List[InstrumentOutputQuantityKind], upsert: bool = False) -> int:
    """
    Write a list of InstrumentOutputQuantityKind objects to the database
    @param con: database connection
    @param objs: list of InstrumentOutputQuantityKind objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'instrument_output_quantity_kind', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_instrument_output_quantity_kind(con: db.Connection, instrument_output_quantity_kind_id: int,
            equipment_model_id: Optional[int] = None,
            quantity_kind: Optional[str] = None,
            instrument_raw_output_units_id: Optional[int] = None,
            instrument_resolution: Optional[str] = None,
            instrument_accuracy: Optional[str] = None,
            instrument_standard_output_variable: Optional[int] = None,
            instrument_method_id: Optional[int] = None) -> int:
    """
    Update a row in the instrument_output_quantity_kind table in the database
    @param con: database connection
    @param instrument_output_quantity_kind_id 
    @param equipment_model_id 
    @param quantity_kind 
    @param instrument_resolution 
    @param instrument_accuracy 
    @param instrument_raw_output_units_id 
    @param instrument_standard_output_variable 
    @param instrument_method_id 
    @return The number of rows updated
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    return db.update(con, 'instrument_output_quantity_kind', data)

@beartype.beartype
def read_instrument_output_quantity_kind(
            con: db.Connection,
            equipment_model_id: Optional[int] = None,
             quantity_kind: Optional[str] = None,
             instrument_raw_output_units_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             instrument_resolution: Optional[str] = None,
             instrument_accuracy: Optional[str] = None,
             instrument_standard_output_variable: Optional[int] = None,
             instrument_method_id: Optional[int] = None) -> Generator[InstrumentOutputQuantityKind, None, None]:
    """
    Read from the instrument_output_quantity_kind table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param instrument_output_quantity_kind_id 
    @param equipment_model_id 
    @param quantity_kind 
    @param instrument_resolution 
    @param instrument_accuracy 
    @param instrument_raw_output_units_id 
    @param instrument_standard_output_variable 
    @param instrument_method_id 
    @return generator of InstrumentOutputQuantityKind objects
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    result = db.query(con, 'instrument_output_quantity_kind', data)
    for row in result:
        yield InstrumentOutputQuantityKind(**row.as_dict())

@beartype.beartype
def read_instrument_output_quantity_kind_fuzzy(con: db.Connection, equipment_model_id: Optional[int] = None,
             quantity_kind: Optional[str] = None,
             instrument_raw_output_units_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             instrument_resolution: Optional[str] = None,
             instrument_accuracy: Optional[str] = None,
             instrument_standard_output_variable: Optional[int] = None,
             instrument_method_id: Optional[int] = None) -> Generator[InstrumentOutputQuantityKind, None, None]:
    """
    Read from the instrument_output_quantity_kind table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param instrument_output_quantity_kind_id 
    @param equipment_model_id 
    @param quantity_kind 
    @param instrument_resolution 
    @param instrument_accuracy 
    @param instrument_raw_output_units_id 
    @param instrument_standard_output_variable 
    @param instrument_method_id 
    @return generator of InstrumentOutputQuantityKind objects
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    result = db.query_fuzzy(con, 'instrument_output_quantity_kind', data)
    for row in result:
        yield InstrumentOutputQuantityKind(**row.as_dict())

@beartype.beartype
def read_instrument_output_quantity_kind_any(con: db.Connection, equipment_model_id: Optional[List[int]] = None,
             quantity_kind: Optional[List[str]] = None,
             instrument_raw_output_units_id: Optional[List[int]] = None,
             instrument_output_quantity_kind_id: Optional[List[int]] = None,
             instrument_resolution: Optional[List[str]] = None,
             instrument_accuracy: Optional[List[str]] = None,
             instrument_standard_output_variable: Optional[List[int]] = None,
             instrument_method_id: Optional[List[int]] = None) -> Generator[InstrumentOutputQuantityKind, None, None]:
    """
    Read from the instrument_output_quantity_kind table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param instrument_output_quantity_kind_id 
    @param equipment_model_id 
    @param quantity_kind 
    @param instrument_resolution 
    @param instrument_accuracy 
    @param instrument_raw_output_units_id 
    @param instrument_standard_output_variable 
    @param instrument_method_id 
    @return generator of InstrumentOutputQuantityKind objects
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    result = db.query_any(con, 'instrument_output_quantity_kind', data)
    for row in result:
        yield InstrumentOutputQuantityKind(**row.as_dict())

@beartype.beartype
def read_instrument_output_quantity_kind_one_or_none(con: db.Connection, equipment_model_id: Optional[int] = None,
             quantity_kind: Optional[str] = None,
             instrument_raw_output_units_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             instrument_resolution: Optional[str] = None,
             instrument_accuracy: Optional[str] = None,
             instrument_standard_output_variable: Optional[int] = None,
             instrument_method_id: Optional[int] = None) -> Optional[InstrumentOutputQuantityKind]:
    """
    Read from the instrument_output_quantity_kind table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    result = db.query_one_or_none(con, 'instrument_output_quantity_kind', data)
    if result is None:
        return None
    return InstrumentOutputQuantityKind(**result)

@beartype.beartype
def read_instrument_output_quantity_kind_one(con: db.Connection, equipment_model_id: Optional[int] = None,
             quantity_kind: Optional[str] = None,
             instrument_raw_output_units_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             instrument_resolution: Optional[str] = None,
             instrument_accuracy: Optional[str] = None,
             instrument_standard_output_variable: Optional[int] = None,
             instrument_method_id: Optional[int] = None) -> InstrumentOutputQuantityKind:
    """
    Read from the instrument_output_quantity_kind table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    result = db.query_one(con, 'instrument_output_quantity_kind', data)
    return InstrumentOutputQuantityKind(**result)

@beartype.beartype
def read_instrument_output_quantity_kind_all(con: db.Connection, equipment_model_id: Optional[int] = None,
             quantity_kind: Optional[str] = None,
             instrument_raw_output_units_id: Optional[int] = None,
             instrument_output_quantity_kind_id: Optional[int] = None,
             instrument_resolution: Optional[str] = None,
             instrument_accuracy: Optional[str] = None,
             instrument_standard_output_variable: Optional[int] = None,
             instrument_method_id: Optional[int] = None) -> List[InstrumentOutputQuantityKind]:
    """
    Read from the instrument_output_quantity_kind table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id,
        'equipment_model_id': equipment_model_id,
        'quantity_kind': quantity_kind,
        'instrument_resolution': instrument_resolution,
        'instrument_accuracy': instrument_accuracy,
        'instrument_raw_output_units_id': instrument_raw_output_units_id,
        'instrument_standard_output_variable': instrument_standard_output_variable,
        'instrument_method_id': instrument_method_id,
    }
    result = db.query(con, 'instrument_output_quantity_kind', data)
    return [InstrumentOutputQuantityKind(**row.as_dict()) for row in result]

@beartype.beartype
def read_instrument_output_quantity_kind_by_id(con: db.Connection, instrument_output_quantity_kind_id: int) -> Optional[InstrumentOutputQuantityKind]:
    result = db.query_one(con, 'instrument_output_quantity_kind', {'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id})
    if result is None:
        return None
    return InstrumentOutputQuantityKind(**result)

@beartype.beartype
def delete_instrument_output_quantity_kind_by_id(con: db.Connection, instrument_output_quantity_kind_id: int):
    db.delete(con, 'instrument_output_quantity_kind', {'instrument_output_quantity_kind_id': instrument_output_quantity_kind_id})
# Associate the functions with the class
InstrumentOutputQuantityKind.create_from_json_dict = create_instrument_output_quantity_kind_from_json_dict
InstrumentOutputQuantityKind.write = write_instrument_output_quantity_kind
InstrumentOutputQuantityKind.update = update_instrument_output_quantity_kind
InstrumentOutputQuantityKind.write_many = write_instrument_output_quantity_kind_many
InstrumentOutputQuantityKind.read = read_instrument_output_quantity_kind
InstrumentOutputQuantityKind.read_fuzzy = read_instrument_output_quantity_kind_fuzzy
InstrumentOutputQuantityKind.read_any = read_instrument_output_quantity_kind_any
InstrumentOutputQuantityKind.read_one = read_instrument_output_quantity_kind_one
InstrumentOutputQuantityKind.read_one_or_none = read_instrument_output_quantity_kind_one_or_none
InstrumentOutputQuantityKind.read_all = read_instrument_output_quantity_kind_all
InstrumentOutputQuantityKind.delete = delete_instrument_output_quantity_kind_by_id
InstrumentOutputQuantityKind.read_by_id = read_instrument_output_quantity_kind_by_id
InstrumentOutputQuantityKind.delete_by_id = delete_instrument_output_quantity_kind_by_id



@beartype_wrap_init
@dataclasses.dataclass
class EquipmentPersonsBridge:
    """
    Bridge between Equipment and Person

    @param bridge_id 
    @param equipment_id 
    @param person_id 
    @param person_role_cv 

    This is an automatically generated class
    """
    equipment_id: int # equipment_id integer (default: )
    person_id: int # person_id integer (default: )
    person_role_cv: str # person_role_cv character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

    @beartype.beartype
    def get_person(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.person_id)

    @beartype.beartype
    def get_person_role_cv(self, con: db.Connection) -> Optional['CvPersonsRole']:
        return read_cv_persons_role_one_or_none(con, term=self.person_role_cv)

@beartype.beartype
def create_equipment_persons_bridge_from_json_dict(json_obj: dict):
        """
        Create a EquipmentPersonsBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return EquipmentPersonsBridge(**json_obj)


@beartype.beartype
def write_equipment_persons_bridge_obj(con: db.Connection, obj: EquipmentPersonsBridge) -> int:
    """
    Write a EquipmentPersonsBridge object to the database
    @param con: database connection
    @param obj: EquipmentPersonsBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'equipment_persons_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_equipment_persons_bridge(
            con: db.Connection,
            equipment_id: int,
            person_id: int,
            person_role_cv: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the equipment_persons_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param person_id 
    @param person_role_cv 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    return db.upsert(con, 'equipment_persons_bridge', data)

@beartype.beartype
def write_equipment_persons_bridge_many(con: db.Connection, objs: List[EquipmentPersonsBridge], upsert: bool = False) -> int:
    """
    Write a list of EquipmentPersonsBridge objects to the database
    @param con: database connection
    @param objs: list of EquipmentPersonsBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'equipment_persons_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_equipment_persons_bridge(con: db.Connection, bridge_id: int,
            equipment_id: Optional[int] = None,
            person_id: Optional[int] = None,
            person_role_cv: Optional[str] = None) -> int:
    """
    Update a row in the equipment_persons_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param person_id 
    @param person_role_cv 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    return db.update(con, 'equipment_persons_bridge', data)

@beartype.beartype
def read_equipment_persons_bridge(
            con: db.Connection,
            equipment_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role_cv: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[EquipmentPersonsBridge, None, None]:
    """
    Read from the equipment_persons_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param person_id 
    @param person_role_cv 
    @return generator of EquipmentPersonsBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    result = db.query(con, 'equipment_persons_bridge', data)
    for row in result:
        yield EquipmentPersonsBridge(**row.as_dict())

@beartype.beartype
def read_equipment_persons_bridge_fuzzy(con: db.Connection, equipment_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role_cv: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[EquipmentPersonsBridge, None, None]:
    """
    Read from the equipment_persons_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param person_id 
    @param person_role_cv 
    @return generator of EquipmentPersonsBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    result = db.query_fuzzy(con, 'equipment_persons_bridge', data)
    for row in result:
        yield EquipmentPersonsBridge(**row.as_dict())

@beartype.beartype
def read_equipment_persons_bridge_any(con: db.Connection, equipment_id: Optional[List[int]] = None,
             person_id: Optional[List[int]] = None,
             person_role_cv: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[EquipmentPersonsBridge, None, None]:
    """
    Read from the equipment_persons_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param equipment_id 
    @param person_id 
    @param person_role_cv 
    @return generator of EquipmentPersonsBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    result = db.query_any(con, 'equipment_persons_bridge', data)
    for row in result:
        yield EquipmentPersonsBridge(**row.as_dict())

@beartype.beartype
def read_equipment_persons_bridge_one_or_none(con: db.Connection, equipment_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role_cv: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[EquipmentPersonsBridge]:
    """
    Read from the equipment_persons_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    result = db.query_one_or_none(con, 'equipment_persons_bridge', data)
    if result is None:
        return None
    return EquipmentPersonsBridge(**result)

@beartype.beartype
def read_equipment_persons_bridge_one(con: db.Connection, equipment_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role_cv: Optional[str] = None,
             bridge_id: Optional[int] = None) -> EquipmentPersonsBridge:
    """
    Read from the equipment_persons_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    result = db.query_one(con, 'equipment_persons_bridge', data)
    return EquipmentPersonsBridge(**result)

@beartype.beartype
def read_equipment_persons_bridge_all(con: db.Connection, equipment_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role_cv: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[EquipmentPersonsBridge]:
    """
    Read from the equipment_persons_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'equipment_id': equipment_id,
        'person_id': person_id,
        'person_role_cv': person_role_cv,
    }
    result = db.query(con, 'equipment_persons_bridge', data)
    return [EquipmentPersonsBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_equipment_persons_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[EquipmentPersonsBridge]:
    result = db.query_one(con, 'equipment_persons_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return EquipmentPersonsBridge(**result)

@beartype.beartype
def delete_equipment_persons_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'equipment_persons_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
EquipmentPersonsBridge.create_from_json_dict = create_equipment_persons_bridge_from_json_dict
EquipmentPersonsBridge.write = write_equipment_persons_bridge
EquipmentPersonsBridge.update = update_equipment_persons_bridge
EquipmentPersonsBridge.write_many = write_equipment_persons_bridge_many
EquipmentPersonsBridge.read = read_equipment_persons_bridge
EquipmentPersonsBridge.read_fuzzy = read_equipment_persons_bridge_fuzzy
EquipmentPersonsBridge.read_any = read_equipment_persons_bridge_any
EquipmentPersonsBridge.read_one = read_equipment_persons_bridge_one
EquipmentPersonsBridge.read_one_or_none = read_equipment_persons_bridge_one_or_none
EquipmentPersonsBridge.read_all = read_equipment_persons_bridge_all
EquipmentPersonsBridge.delete = delete_equipment_persons_bridge_by_id
EquipmentPersonsBridge.read_by_id = read_equipment_persons_bridge_by_id
EquipmentPersonsBridge.delete_by_id = delete_equipment_persons_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class EquipmentPosition:
    """
    A table which gives the position of equipment relative to its parent equipment or sampling feature

    @param equipment_position_id 
    @param equipment_id 
    @param position_start_date_utc 
    @param position_end_date_utc 
    @param equipment_z_offset_m 
    @param equipment_ns_offset_m 
    @param equipment_ew_offset_m 
    @param equipment_height_note 

    This is an automatically generated class
    """
    equipment_id: int # equipment_id integer (default: )
    position_start_date_utc: int # position_start_date_utc bigint (default: )
    equipment_position_id: Optional[int] = None # equipment_position_id integer (default: )
    position_end_date_utc: Optional[int] = None # position_end_date_utc bigint (default: )
    equipment_z_offset_m: Optional[float] = None # equipment_z_offset_m double precision (default: )
    equipment_ns_offset_m: Optional[float] = None # equipment_ns_offset_m double precision (default: )
    equipment_ew_offset_m: Optional[float] = None # equipment_ew_offset_m double precision (default: )
    equipment_height_note: Optional[str] = None # equipment_height_note character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'equipment_position_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

@beartype.beartype
def create_equipment_position_from_json_dict(json_obj: dict):
        """
        Create a EquipmentPosition from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return EquipmentPosition(**json_obj)


@beartype.beartype
def write_equipment_position_obj(con: db.Connection, obj: EquipmentPosition) -> int:
    """
    Write a EquipmentPosition object to the database
    @param con: database connection
    @param obj: EquipmentPosition object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'equipment_position', dataclasses.asdict(obj))

@beartype.beartype
def write_equipment_position(
            con: db.Connection,
            equipment_id: int,
            position_start_date_utc: int,
            equipment_position_id: Optional[int] = None,
            position_end_date_utc: Optional[int] = None,
            equipment_z_offset_m: Optional[float] = None,
            equipment_ns_offset_m: Optional[float] = None,
            equipment_ew_offset_m: Optional[float] = None,
            equipment_height_note: Optional[str] = None) -> int:
    """
    Write to the equipment_position table in the database
    @param con: database connection
    @param equipment_position_id 
    @param equipment_id 
    @param position_start_date_utc 
    @param position_end_date_utc 
    @param equipment_z_offset_m 
    @param equipment_ns_offset_m 
    @param equipment_ew_offset_m 
    @param equipment_height_note 
    @return id of the inserted/updated row
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    return db.upsert(con, 'equipment_position', data)

@beartype.beartype
def write_equipment_position_many(con: db.Connection, objs: List[EquipmentPosition], upsert: bool = False) -> int:
    """
    Write a list of EquipmentPosition objects to the database
    @param con: database connection
    @param objs: list of EquipmentPosition objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'equipment_position', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_equipment_position(con: db.Connection, equipment_position_id: int,
            equipment_id: Optional[int] = None,
            position_start_date_utc: Optional[int] = None,
            position_end_date_utc: Optional[int] = None,
            equipment_z_offset_m: Optional[float] = None,
            equipment_ns_offset_m: Optional[float] = None,
            equipment_ew_offset_m: Optional[float] = None,
            equipment_height_note: Optional[str] = None) -> int:
    """
    Update a row in the equipment_position table in the database
    @param con: database connection
    @param equipment_position_id 
    @param equipment_id 
    @param position_start_date_utc 
    @param position_end_date_utc 
    @param equipment_z_offset_m 
    @param equipment_ns_offset_m 
    @param equipment_ew_offset_m 
    @param equipment_height_note 
    @return The number of rows updated
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    return db.update(con, 'equipment_position', data)

@beartype.beartype
def read_equipment_position(
            con: db.Connection,
            equipment_id: Optional[int] = None,
             position_start_date_utc: Optional[int] = None,
             equipment_position_id: Optional[int] = None,
             position_end_date_utc: Optional[int] = None,
             equipment_z_offset_m: Optional[float] = None,
             equipment_ns_offset_m: Optional[float] = None,
             equipment_ew_offset_m: Optional[float] = None,
             equipment_height_note: Optional[str] = None) -> Generator[EquipmentPosition, None, None]:
    """
    Read from the equipment_position table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_position_id 
    @param equipment_id 
    @param position_start_date_utc 
    @param position_end_date_utc 
    @param equipment_z_offset_m 
    @param equipment_ns_offset_m 
    @param equipment_ew_offset_m 
    @param equipment_height_note 
    @return generator of EquipmentPosition objects
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    result = db.query(con, 'equipment_position', data)
    for row in result:
        yield EquipmentPosition(**row.as_dict())

@beartype.beartype
def read_equipment_position_fuzzy(con: db.Connection, equipment_id: Optional[int] = None,
             position_start_date_utc: Optional[int] = None,
             equipment_position_id: Optional[int] = None,
             position_end_date_utc: Optional[int] = None,
             equipment_z_offset_m: Optional[float] = None,
             equipment_ns_offset_m: Optional[float] = None,
             equipment_ew_offset_m: Optional[float] = None,
             equipment_height_note: Optional[str] = None) -> Generator[EquipmentPosition, None, None]:
    """
    Read from the equipment_position table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_position_id 
    @param equipment_id 
    @param position_start_date_utc 
    @param position_end_date_utc 
    @param equipment_z_offset_m 
    @param equipment_ns_offset_m 
    @param equipment_ew_offset_m 
    @param equipment_height_note 
    @return generator of EquipmentPosition objects
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    result = db.query_fuzzy(con, 'equipment_position', data)
    for row in result:
        yield EquipmentPosition(**row.as_dict())

@beartype.beartype
def read_equipment_position_any(con: db.Connection, equipment_id: Optional[List[int]] = None,
             position_start_date_utc: Optional[List[int]] = None,
             equipment_position_id: Optional[List[int]] = None,
             position_end_date_utc: Optional[List[int]] = None,
             equipment_z_offset_m: Optional[List[float]] = None,
             equipment_ns_offset_m: Optional[List[float]] = None,
             equipment_ew_offset_m: Optional[List[float]] = None,
             equipment_height_note: Optional[List[str]] = None) -> Generator[EquipmentPosition, None, None]:
    """
    Read from the equipment_position table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_position_id 
    @param equipment_id 
    @param position_start_date_utc 
    @param position_end_date_utc 
    @param equipment_z_offset_m 
    @param equipment_ns_offset_m 
    @param equipment_ew_offset_m 
    @param equipment_height_note 
    @return generator of EquipmentPosition objects
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    result = db.query_any(con, 'equipment_position', data)
    for row in result:
        yield EquipmentPosition(**row.as_dict())

@beartype.beartype
def read_equipment_position_one_or_none(con: db.Connection, equipment_id: Optional[int] = None,
             position_start_date_utc: Optional[int] = None,
             equipment_position_id: Optional[int] = None,
             position_end_date_utc: Optional[int] = None,
             equipment_z_offset_m: Optional[float] = None,
             equipment_ns_offset_m: Optional[float] = None,
             equipment_ew_offset_m: Optional[float] = None,
             equipment_height_note: Optional[str] = None) -> Optional[EquipmentPosition]:
    """
    Read from the equipment_position table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    result = db.query_one_or_none(con, 'equipment_position', data)
    if result is None:
        return None
    return EquipmentPosition(**result)

@beartype.beartype
def read_equipment_position_one(con: db.Connection, equipment_id: Optional[int] = None,
             position_start_date_utc: Optional[int] = None,
             equipment_position_id: Optional[int] = None,
             position_end_date_utc: Optional[int] = None,
             equipment_z_offset_m: Optional[float] = None,
             equipment_ns_offset_m: Optional[float] = None,
             equipment_ew_offset_m: Optional[float] = None,
             equipment_height_note: Optional[str] = None) -> EquipmentPosition:
    """
    Read from the equipment_position table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    result = db.query_one(con, 'equipment_position', data)
    return EquipmentPosition(**result)

@beartype.beartype
def read_equipment_position_all(con: db.Connection, equipment_id: Optional[int] = None,
             position_start_date_utc: Optional[int] = None,
             equipment_position_id: Optional[int] = None,
             position_end_date_utc: Optional[int] = None,
             equipment_z_offset_m: Optional[float] = None,
             equipment_ns_offset_m: Optional[float] = None,
             equipment_ew_offset_m: Optional[float] = None,
             equipment_height_note: Optional[str] = None) -> List[EquipmentPosition]:
    """
    Read from the equipment_position table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'equipment_position_id': equipment_position_id,
        'equipment_id': equipment_id,
        'position_start_date_utc': position_start_date_utc,
        'position_end_date_utc': position_end_date_utc,
        'equipment_z_offset_m': equipment_z_offset_m,
        'equipment_ns_offset_m': equipment_ns_offset_m,
        'equipment_ew_offset_m': equipment_ew_offset_m,
        'equipment_height_note': equipment_height_note,
    }
    result = db.query(con, 'equipment_position', data)
    return [EquipmentPosition(**row.as_dict()) for row in result]

@beartype.beartype
def read_equipment_position_by_id(con: db.Connection, equipment_position_id: int) -> Optional[EquipmentPosition]:
    result = db.query_one(con, 'equipment_position', {'equipment_position_id': equipment_position_id})
    if result is None:
        return None
    return EquipmentPosition(**result)

@beartype.beartype
def delete_equipment_position_by_id(con: db.Connection, equipment_position_id: int):
    db.delete(con, 'equipment_position', {'equipment_position_id': equipment_position_id})
# Associate the functions with the class
EquipmentPosition.create_from_json_dict = create_equipment_position_from_json_dict
EquipmentPosition.write = write_equipment_position
EquipmentPosition.update = update_equipment_position
EquipmentPosition.write_many = write_equipment_position_many
EquipmentPosition.read = read_equipment_position
EquipmentPosition.read_fuzzy = read_equipment_position_fuzzy
EquipmentPosition.read_any = read_equipment_position_any
EquipmentPosition.read_one = read_equipment_position_one
EquipmentPosition.read_one_or_none = read_equipment_position_one_or_none
EquipmentPosition.read_all = read_equipment_position_all
EquipmentPosition.delete = delete_equipment_position_by_id
EquipmentPosition.read_by_id = read_equipment_position_by_id
EquipmentPosition.delete_by_id = delete_equipment_position_by_id



@beartype_wrap_init
@dataclasses.dataclass
class EquipmentUsed:
    """
    @param bridge_id 
    @param action_id 
    @param equipment_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    equipment_id: int # equipment_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

@beartype.beartype
def create_equipment_used_from_json_dict(json_obj: dict):
        """
        Create a EquipmentUsed from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return EquipmentUsed(**json_obj)


@beartype.beartype
def write_equipment_used_obj(con: db.Connection, obj: EquipmentUsed) -> int:
    """
    Write a EquipmentUsed object to the database
    @param con: database connection
    @param obj: EquipmentUsed object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'equipment_used', dataclasses.asdict(obj))

@beartype.beartype
def write_equipment_used(
            con: db.Connection,
            action_id: int,
            equipment_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the equipment_used table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    return db.upsert(con, 'equipment_used', data)

@beartype.beartype
def write_equipment_used_many(con: db.Connection, objs: List[EquipmentUsed], upsert: bool = False) -> int:
    """
    Write a list of EquipmentUsed objects to the database
    @param con: database connection
    @param objs: list of EquipmentUsed objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'equipment_used', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_equipment_used(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            equipment_id: Optional[int] = None) -> int:
    """
    Update a row in the equipment_used table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    return db.update(con, 'equipment_used', data)

@beartype.beartype
def read_equipment_used(
            con: db.Connection,
            action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[EquipmentUsed, None, None]:
    """
    Read from the equipment_used table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return generator of EquipmentUsed objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query(con, 'equipment_used', data)
    for row in result:
        yield EquipmentUsed(**row.as_dict())

@beartype.beartype
def read_equipment_used_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[EquipmentUsed, None, None]:
    """
    Read from the equipment_used table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return generator of EquipmentUsed objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_fuzzy(con, 'equipment_used', data)
    for row in result:
        yield EquipmentUsed(**row.as_dict())

@beartype.beartype
def read_equipment_used_any(con: db.Connection, action_id: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[EquipmentUsed, None, None]:
    """
    Read from the equipment_used table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param equipment_id 
    @return generator of EquipmentUsed objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_any(con, 'equipment_used', data)
    for row in result:
        yield EquipmentUsed(**row.as_dict())

@beartype.beartype
def read_equipment_used_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[EquipmentUsed]:
    """
    Read from the equipment_used table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_one_or_none(con, 'equipment_used', data)
    if result is None:
        return None
    return EquipmentUsed(**result)

@beartype.beartype
def read_equipment_used_one(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> EquipmentUsed:
    """
    Read from the equipment_used table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query_one(con, 'equipment_used', data)
    return EquipmentUsed(**result)

@beartype.beartype
def read_equipment_used_all(con: db.Connection, action_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[EquipmentUsed]:
    """
    Read from the equipment_used table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'equipment_id': equipment_id,
    }
    result = db.query(con, 'equipment_used', data)
    return [EquipmentUsed(**row.as_dict()) for row in result]

@beartype.beartype
def read_equipment_used_by_id(con: db.Connection, bridge_id: int) -> Optional[EquipmentUsed]:
    result = db.query_one(con, 'equipment_used', {'bridge_id': bridge_id})
    if result is None:
        return None
    return EquipmentUsed(**result)

@beartype.beartype
def delete_equipment_used_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'equipment_used', {'bridge_id': bridge_id})
# Associate the functions with the class
EquipmentUsed.create_from_json_dict = create_equipment_used_from_json_dict
EquipmentUsed.write = write_equipment_used
EquipmentUsed.update = update_equipment_used
EquipmentUsed.write_many = write_equipment_used_many
EquipmentUsed.read = read_equipment_used
EquipmentUsed.read_fuzzy = read_equipment_used_fuzzy
EquipmentUsed.read_any = read_equipment_used_any
EquipmentUsed.read_one = read_equipment_used_one
EquipmentUsed.read_one_or_none = read_equipment_used_one_or_none
EquipmentUsed.read_all = read_equipment_used_all
EquipmentUsed.delete = delete_equipment_used_by_id
EquipmentUsed.read_by_id = read_equipment_used_by_id
EquipmentUsed.delete_by_id = delete_equipment_used_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MaintenanceActions:
    """
    Information about maintenance Actions performed on Equipment

    @param action_id 
    @param is_factory_service 
    @param maintenance_code 
    @param maintenance_reason 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    is_factory_service: bool # is_factory_service boolean (default: )
    maintenance_code: Optional[str] = None # maintenance_code character varying (default: )
    maintenance_reason: Optional[str] = None # maintenance_reason character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'action_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

@beartype.beartype
def create_maintenance_actions_from_json_dict(json_obj: dict):
        """
        Create a MaintenanceActions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MaintenanceActions(**json_obj)


@beartype.beartype
def write_maintenance_actions_obj(con: db.Connection, obj: MaintenanceActions) -> int:
    """
    Write a MaintenanceActions object to the database
    @param con: database connection
    @param obj: MaintenanceActions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'maintenance_actions', dataclasses.asdict(obj))

@beartype.beartype
def write_maintenance_actions(
            con: db.Connection,
            action_id: int,
            is_factory_service: bool,
            maintenance_code: Optional[str] = None,
            maintenance_reason: Optional[str] = None) -> int:
    """
    Write to the maintenance_actions table in the database
    @param con: database connection
    @param action_id 
    @param is_factory_service 
    @param maintenance_code 
    @param maintenance_reason 
    @return id of the inserted/updated row
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    return db.upsert(con, 'maintenance_actions', data)

@beartype.beartype
def write_maintenance_actions_many(con: db.Connection, objs: List[MaintenanceActions], upsert: bool = False) -> int:
    """
    Write a list of MaintenanceActions objects to the database
    @param con: database connection
    @param objs: list of MaintenanceActions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'maintenance_actions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_maintenance_actions(con: db.Connection, action_id: int,
            is_factory_service: Optional[bool] = None,
            maintenance_code: Optional[str] = None,
            maintenance_reason: Optional[str] = None) -> int:
    """
    Update a row in the maintenance_actions table in the database
    @param con: database connection
    @param action_id 
    @param is_factory_service 
    @param maintenance_code 
    @param maintenance_reason 
    @return The number of rows updated
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    return db.update(con, 'maintenance_actions', data)

@beartype.beartype
def read_maintenance_actions(
            con: db.Connection,
            action_id: Optional[int] = None,
             is_factory_service: Optional[bool] = None,
             maintenance_code: Optional[str] = None,
             maintenance_reason: Optional[str] = None) -> Generator[MaintenanceActions, None, None]:
    """
    Read from the maintenance_actions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param is_factory_service 
    @param maintenance_code 
    @param maintenance_reason 
    @return generator of MaintenanceActions objects
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    result = db.query(con, 'maintenance_actions', data)
    for row in result:
        yield MaintenanceActions(**row.as_dict())

@beartype.beartype
def read_maintenance_actions_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             is_factory_service: Optional[bool] = None,
             maintenance_code: Optional[str] = None,
             maintenance_reason: Optional[str] = None) -> Generator[MaintenanceActions, None, None]:
    """
    Read from the maintenance_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param is_factory_service 
    @param maintenance_code 
    @param maintenance_reason 
    @return generator of MaintenanceActions objects
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    result = db.query_fuzzy(con, 'maintenance_actions', data)
    for row in result:
        yield MaintenanceActions(**row.as_dict())

@beartype.beartype
def read_maintenance_actions_any(con: db.Connection, action_id: Optional[List[int]] = None,
             is_factory_service: Optional[List[bool]] = None,
             maintenance_code: Optional[List[str]] = None,
             maintenance_reason: Optional[List[str]] = None) -> Generator[MaintenanceActions, None, None]:
    """
    Read from the maintenance_actions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param action_id 
    @param is_factory_service 
    @param maintenance_code 
    @param maintenance_reason 
    @return generator of MaintenanceActions objects
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    result = db.query_any(con, 'maintenance_actions', data)
    for row in result:
        yield MaintenanceActions(**row.as_dict())

@beartype.beartype
def read_maintenance_actions_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             is_factory_service: Optional[bool] = None,
             maintenance_code: Optional[str] = None,
             maintenance_reason: Optional[str] = None) -> Optional[MaintenanceActions]:
    """
    Read from the maintenance_actions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    result = db.query_one_or_none(con, 'maintenance_actions', data)
    if result is None:
        return None
    return MaintenanceActions(**result)

@beartype.beartype
def read_maintenance_actions_one(con: db.Connection, action_id: Optional[int] = None,
             is_factory_service: Optional[bool] = None,
             maintenance_code: Optional[str] = None,
             maintenance_reason: Optional[str] = None) -> MaintenanceActions:
    """
    Read from the maintenance_actions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    result = db.query_one(con, 'maintenance_actions', data)
    return MaintenanceActions(**result)

@beartype.beartype
def read_maintenance_actions_all(con: db.Connection, action_id: Optional[int] = None,
             is_factory_service: Optional[bool] = None,
             maintenance_code: Optional[str] = None,
             maintenance_reason: Optional[str] = None) -> List[MaintenanceActions]:
    """
    Read from the maintenance_actions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'action_id': action_id,
        'is_factory_service': is_factory_service,
        'maintenance_code': maintenance_code,
        'maintenance_reason': maintenance_reason,
    }
    result = db.query(con, 'maintenance_actions', data)
    return [MaintenanceActions(**row.as_dict()) for row in result]

@beartype.beartype
def read_maintenance_actions_by_id(con: db.Connection, action_id: int) -> Optional[MaintenanceActions]:
    result = db.query_one(con, 'maintenance_actions', {'action_id': action_id})
    if result is None:
        return None
    return MaintenanceActions(**result)

@beartype.beartype
def delete_maintenance_actions_by_id(con: db.Connection, action_id: int):
    db.delete(con, 'maintenance_actions', {'action_id': action_id})
# Associate the functions with the class
MaintenanceActions.create_from_json_dict = create_maintenance_actions_from_json_dict
MaintenanceActions.write = write_maintenance_actions
MaintenanceActions.update = update_maintenance_actions
MaintenanceActions.write_many = write_maintenance_actions_many
MaintenanceActions.read = read_maintenance_actions
MaintenanceActions.read_fuzzy = read_maintenance_actions_fuzzy
MaintenanceActions.read_any = read_maintenance_actions_any
MaintenanceActions.read_one = read_maintenance_actions_one
MaintenanceActions.read_one_or_none = read_maintenance_actions_one_or_none
MaintenanceActions.read_all = read_maintenance_actions_all
MaintenanceActions.delete = delete_maintenance_actions_by_id
MaintenanceActions.read_by_id = read_maintenance_actions_by_id
MaintenanceActions.delete_by_id = delete_maintenance_actions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DataloggerFiles:
    """
    Destibes datalogger files created by a deployment action

    @param datalogger_file_id 
    @param program_id 
    @param datalogger_file_name 
    @param datalogger_file_description 
    @param datalogger_file_link 

    This is an automatically generated class
    """
    program_id: int # program_id integer (default: )
    datalogger_file_name: str # datalogger_file_name character varying (default: )
    datalogger_file_id: Optional[int] = None # datalogger_file_id integer (default: )
    datalogger_file_description: Optional[str] = None # datalogger_file_description character varying (default: )
    datalogger_file_link: Optional[str] = None # datalogger_file_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'datalogger_file_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_program(self, con: db.Connection) -> Optional['DataloggerProgramFiles']:
        return read_datalogger_program_files_one_or_none(con, program_id=self.program_id)

@beartype.beartype
def create_datalogger_files_from_json_dict(json_obj: dict):
        """
        Create a DataloggerFiles from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DataloggerFiles(**json_obj)


@beartype.beartype
def write_datalogger_files_obj(con: db.Connection, obj: DataloggerFiles) -> int:
    """
    Write a DataloggerFiles object to the database
    @param con: database connection
    @param obj: DataloggerFiles object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datalogger_files', dataclasses.asdict(obj))

@beartype.beartype
def write_datalogger_files(
            con: db.Connection,
            program_id: int,
            datalogger_file_name: str,
            datalogger_file_id: Optional[int] = None,
            datalogger_file_description: Optional[str] = None,
            datalogger_file_link: Optional[str] = None) -> int:
    """
    Write to the datalogger_files table in the database
    @param con: database connection
    @param datalogger_file_id 
    @param program_id 
    @param datalogger_file_name 
    @param datalogger_file_description 
    @param datalogger_file_link 
    @return id of the inserted/updated row
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    return db.upsert(con, 'datalogger_files', data)

@beartype.beartype
def write_datalogger_files_many(con: db.Connection, objs: List[DataloggerFiles], upsert: bool = False) -> int:
    """
    Write a list of DataloggerFiles objects to the database
    @param con: database connection
    @param objs: list of DataloggerFiles objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datalogger_files', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datalogger_files(con: db.Connection, datalogger_file_id: int,
            program_id: Optional[int] = None,
            datalogger_file_name: Optional[str] = None,
            datalogger_file_description: Optional[str] = None,
            datalogger_file_link: Optional[str] = None) -> int:
    """
    Update a row in the datalogger_files table in the database
    @param con: database connection
    @param datalogger_file_id 
    @param program_id 
    @param datalogger_file_name 
    @param datalogger_file_description 
    @param datalogger_file_link 
    @return The number of rows updated
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    return db.update(con, 'datalogger_files', data)

@beartype.beartype
def read_datalogger_files(
            con: db.Connection,
            program_id: Optional[int] = None,
             datalogger_file_name: Optional[str] = None,
             datalogger_file_id: Optional[int] = None,
             datalogger_file_description: Optional[str] = None,
             datalogger_file_link: Optional[str] = None) -> Generator[DataloggerFiles, None, None]:
    """
    Read from the datalogger_files table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datalogger_file_id 
    @param program_id 
    @param datalogger_file_name 
    @param datalogger_file_description 
    @param datalogger_file_link 
    @return generator of DataloggerFiles objects
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    result = db.query(con, 'datalogger_files', data)
    for row in result:
        yield DataloggerFiles(**row.as_dict())

@beartype.beartype
def read_datalogger_files_fuzzy(con: db.Connection, program_id: Optional[int] = None,
             datalogger_file_name: Optional[str] = None,
             datalogger_file_id: Optional[int] = None,
             datalogger_file_description: Optional[str] = None,
             datalogger_file_link: Optional[str] = None) -> Generator[DataloggerFiles, None, None]:
    """
    Read from the datalogger_files table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datalogger_file_id 
    @param program_id 
    @param datalogger_file_name 
    @param datalogger_file_description 
    @param datalogger_file_link 
    @return generator of DataloggerFiles objects
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    result = db.query_fuzzy(con, 'datalogger_files', data)
    for row in result:
        yield DataloggerFiles(**row.as_dict())

@beartype.beartype
def read_datalogger_files_any(con: db.Connection, program_id: Optional[List[int]] = None,
             datalogger_file_name: Optional[List[str]] = None,
             datalogger_file_id: Optional[List[int]] = None,
             datalogger_file_description: Optional[List[str]] = None,
             datalogger_file_link: Optional[List[str]] = None) -> Generator[DataloggerFiles, None, None]:
    """
    Read from the datalogger_files table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datalogger_file_id 
    @param program_id 
    @param datalogger_file_name 
    @param datalogger_file_description 
    @param datalogger_file_link 
    @return generator of DataloggerFiles objects
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    result = db.query_any(con, 'datalogger_files', data)
    for row in result:
        yield DataloggerFiles(**row.as_dict())

@beartype.beartype
def read_datalogger_files_one_or_none(con: db.Connection, program_id: Optional[int] = None,
             datalogger_file_name: Optional[str] = None,
             datalogger_file_id: Optional[int] = None,
             datalogger_file_description: Optional[str] = None,
             datalogger_file_link: Optional[str] = None) -> Optional[DataloggerFiles]:
    """
    Read from the datalogger_files table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    result = db.query_one_or_none(con, 'datalogger_files', data)
    if result is None:
        return None
    return DataloggerFiles(**result)

@beartype.beartype
def read_datalogger_files_one(con: db.Connection, program_id: Optional[int] = None,
             datalogger_file_name: Optional[str] = None,
             datalogger_file_id: Optional[int] = None,
             datalogger_file_description: Optional[str] = None,
             datalogger_file_link: Optional[str] = None) -> DataloggerFiles:
    """
    Read from the datalogger_files table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    result = db.query_one(con, 'datalogger_files', data)
    return DataloggerFiles(**result)

@beartype.beartype
def read_datalogger_files_all(con: db.Connection, program_id: Optional[int] = None,
             datalogger_file_name: Optional[str] = None,
             datalogger_file_id: Optional[int] = None,
             datalogger_file_description: Optional[str] = None,
             datalogger_file_link: Optional[str] = None) -> List[DataloggerFiles]:
    """
    Read from the datalogger_files table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'datalogger_file_id': datalogger_file_id,
        'program_id': program_id,
        'datalogger_file_name': datalogger_file_name,
        'datalogger_file_description': datalogger_file_description,
        'datalogger_file_link': datalogger_file_link,
    }
    result = db.query(con, 'datalogger_files', data)
    return [DataloggerFiles(**row.as_dict()) for row in result]

@beartype.beartype
def read_datalogger_files_by_id(con: db.Connection, datalogger_file_id: int) -> Optional[DataloggerFiles]:
    result = db.query_one(con, 'datalogger_files', {'datalogger_file_id': datalogger_file_id})
    if result is None:
        return None
    return DataloggerFiles(**result)

@beartype.beartype
def delete_datalogger_files_by_id(con: db.Connection, datalogger_file_id: int):
    db.delete(con, 'datalogger_files', {'datalogger_file_id': datalogger_file_id})
# Associate the functions with the class
DataloggerFiles.create_from_json_dict = create_datalogger_files_from_json_dict
DataloggerFiles.write = write_datalogger_files
DataloggerFiles.update = update_datalogger_files
DataloggerFiles.write_many = write_datalogger_files_many
DataloggerFiles.read = read_datalogger_files
DataloggerFiles.read_fuzzy = read_datalogger_files_fuzzy
DataloggerFiles.read_any = read_datalogger_files_any
DataloggerFiles.read_one = read_datalogger_files_one
DataloggerFiles.read_one_or_none = read_datalogger_files_one_or_none
DataloggerFiles.read_all = read_datalogger_files_all
DataloggerFiles.delete = delete_datalogger_files_by_id
DataloggerFiles.read_by_id = read_datalogger_files_by_id
DataloggerFiles.delete_by_id = delete_datalogger_files_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedEquipment:
    """
    Information about relationships among Equipment

    @param relation_id 
    @param equipment_id 
    @param relationship_type_cv 
    @param related_equipment_id 
    @param relationship_start_date_time_utc 
    @param relationship_end_date_time_utc 

    This is an automatically generated class
    """
    equipment_id: int # equipment_id integer (default: )
    related_equipment_id: int # related_equipment_id integer (default: )
    relationship_start_date_time_utc: int # relationship_start_date_time_utc bigint (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    relationship_type_cv: Optional[str] = None # relationship_type_cv character varying (default: )
    relationship_end_date_time_utc: Optional[int] = None # relationship_end_date_time_utc bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

    @beartype.beartype
    def get_related_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.related_equipment_id)

@beartype.beartype
def create_related_equipment_from_json_dict(json_obj: dict):
        """
        Create a RelatedEquipment from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedEquipment(**json_obj)


@beartype.beartype
def write_related_equipment_obj(con: db.Connection, obj: RelatedEquipment) -> int:
    """
    Write a RelatedEquipment object to the database
    @param con: database connection
    @param obj: RelatedEquipment object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_equipment', dataclasses.asdict(obj))

@beartype.beartype
def write_related_equipment(
            con: db.Connection,
            equipment_id: int,
            related_equipment_id: int,
            relationship_start_date_time_utc: int,
            relation_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            relationship_end_date_time_utc: Optional[int] = None) -> int:
    """
    Write to the related_equipment table in the database
    @param con: database connection
    @param relation_id 
    @param equipment_id 
    @param relationship_type_cv 
    @param related_equipment_id 
    @param relationship_start_date_time_utc 
    @param relationship_end_date_time_utc 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    return db.upsert(con, 'related_equipment', data)

@beartype.beartype
def write_related_equipment_many(con: db.Connection, objs: List[RelatedEquipment], upsert: bool = False) -> int:
    """
    Write a list of RelatedEquipment objects to the database
    @param con: database connection
    @param objs: list of RelatedEquipment objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_equipment', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_equipment(con: db.Connection, relation_id: int,
            equipment_id: Optional[int] = None,
            related_equipment_id: Optional[int] = None,
            relationship_start_date_time_utc: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            relationship_end_date_time_utc: Optional[int] = None) -> int:
    """
    Update a row in the related_equipment table in the database
    @param con: database connection
    @param relation_id 
    @param equipment_id 
    @param relationship_type_cv 
    @param related_equipment_id 
    @param relationship_start_date_time_utc 
    @param relationship_end_date_time_utc 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    return db.update(con, 'related_equipment', data)

@beartype.beartype
def read_related_equipment(
            con: db.Connection,
            equipment_id: Optional[int] = None,
             related_equipment_id: Optional[int] = None,
             relationship_start_date_time_utc: Optional[int] = None,
             relation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             relationship_end_date_time_utc: Optional[int] = None) -> Generator[RelatedEquipment, None, None]:
    """
    Read from the related_equipment table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param equipment_id 
    @param relationship_type_cv 
    @param related_equipment_id 
    @param relationship_start_date_time_utc 
    @param relationship_end_date_time_utc 
    @return generator of RelatedEquipment objects
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    result = db.query(con, 'related_equipment', data)
    for row in result:
        yield RelatedEquipment(**row.as_dict())

@beartype.beartype
def read_related_equipment_fuzzy(con: db.Connection, equipment_id: Optional[int] = None,
             related_equipment_id: Optional[int] = None,
             relationship_start_date_time_utc: Optional[int] = None,
             relation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             relationship_end_date_time_utc: Optional[int] = None) -> Generator[RelatedEquipment, None, None]:
    """
    Read from the related_equipment table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param equipment_id 
    @param relationship_type_cv 
    @param related_equipment_id 
    @param relationship_start_date_time_utc 
    @param relationship_end_date_time_utc 
    @return generator of RelatedEquipment objects
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    result = db.query_fuzzy(con, 'related_equipment', data)
    for row in result:
        yield RelatedEquipment(**row.as_dict())

@beartype.beartype
def read_related_equipment_any(con: db.Connection, equipment_id: Optional[List[int]] = None,
             related_equipment_id: Optional[List[int]] = None,
             relationship_start_date_time_utc: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             relationship_end_date_time_utc: Optional[List[int]] = None) -> Generator[RelatedEquipment, None, None]:
    """
    Read from the related_equipment table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param equipment_id 
    @param relationship_type_cv 
    @param related_equipment_id 
    @param relationship_start_date_time_utc 
    @param relationship_end_date_time_utc 
    @return generator of RelatedEquipment objects
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    result = db.query_any(con, 'related_equipment', data)
    for row in result:
        yield RelatedEquipment(**row.as_dict())

@beartype.beartype
def read_related_equipment_one_or_none(con: db.Connection, equipment_id: Optional[int] = None,
             related_equipment_id: Optional[int] = None,
             relationship_start_date_time_utc: Optional[int] = None,
             relation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             relationship_end_date_time_utc: Optional[int] = None) -> Optional[RelatedEquipment]:
    """
    Read from the related_equipment table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    result = db.query_one_or_none(con, 'related_equipment', data)
    if result is None:
        return None
    return RelatedEquipment(**result)

@beartype.beartype
def read_related_equipment_one(con: db.Connection, equipment_id: Optional[int] = None,
             related_equipment_id: Optional[int] = None,
             relationship_start_date_time_utc: Optional[int] = None,
             relation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             relationship_end_date_time_utc: Optional[int] = None) -> RelatedEquipment:
    """
    Read from the related_equipment table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    result = db.query_one(con, 'related_equipment', data)
    return RelatedEquipment(**result)

@beartype.beartype
def read_related_equipment_all(con: db.Connection, equipment_id: Optional[int] = None,
             related_equipment_id: Optional[int] = None,
             relationship_start_date_time_utc: Optional[int] = None,
             relation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             relationship_end_date_time_utc: Optional[int] = None) -> List[RelatedEquipment]:
    """
    Read from the related_equipment table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'equipment_id': equipment_id,
        'relationship_type_cv': relationship_type_cv,
        'related_equipment_id': related_equipment_id,
        'relationship_start_date_time_utc': relationship_start_date_time_utc,
        'relationship_end_date_time_utc': relationship_end_date_time_utc,
    }
    result = db.query(con, 'related_equipment', data)
    return [RelatedEquipment(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_equipment_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedEquipment]:
    result = db.query_one(con, 'related_equipment', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedEquipment(**result)

@beartype.beartype
def delete_related_equipment_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_equipment', {'relation_id': relation_id})
# Associate the functions with the class
RelatedEquipment.create_from_json_dict = create_related_equipment_from_json_dict
RelatedEquipment.write = write_related_equipment
RelatedEquipment.update = update_related_equipment
RelatedEquipment.write_many = write_related_equipment_many
RelatedEquipment.read = read_related_equipment
RelatedEquipment.read_fuzzy = read_related_equipment_fuzzy
RelatedEquipment.read_any = read_related_equipment_any
RelatedEquipment.read_one = read_related_equipment_one
RelatedEquipment.read_one_or_none = read_related_equipment_one_or_none
RelatedEquipment.read_all = read_related_equipment_all
RelatedEquipment.delete = delete_related_equipment_by_id
RelatedEquipment.read_by_id = read_related_equipment_by_id
RelatedEquipment.delete_by_id = delete_related_equipment_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Equipment:
    """
    Descriptions of specific pieces of equipment.

    @param equipment_id 
    @param equipment_uuid 
    @param equipment_code 
    @param equipment_name 
    @param equipment_model_id 
    @param equipment_serial_number 
    @param equipment_vendor_id 
    @param equipment_purchase_date 
    @param equipment_purchase_order_number 
    @param equipment_description 
    @param equipment_documentation_link 

    This is an automatically generated class
    """
    equipment_uuid: str # equipment_uuid character varying (default: )
    equipment_code: str # equipment_code character varying (default: )
    equipment_name: str # equipment_name character varying (default: )
    equipment_model_id: int # equipment_model_id integer (default: )
    equipment_id: Optional[int] = None # equipment_id integer (default: )
    equipment_serial_number: Optional[str] = None # equipment_serial_number character varying (default: )
    equipment_vendor_id: Optional[int] = None # equipment_vendor_id integer (default: )
    equipment_purchase_date: Optional[datetime.datetime] = None # equipment_purchase_date timestamp without time zone (default: )
    equipment_purchase_order_number: Optional[str] = None # equipment_purchase_order_number character varying (default: )
    equipment_description: Optional[str] = None # equipment_description character varying (default: )
    equipment_documentation_link: Optional[str] = None # equipment_documentation_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'equipment_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.equipment_purchase_date is not None:
            obj['equipment_purchase_date'] = self.equipment_purchase_date.isoformat()
        return obj

    @beartype.beartype
    def get_equipment_model(self, con: db.Connection) -> Optional['EquipmentModels']:
        return read_equipment_models_one_or_none(con, equipment_model_id=self.equipment_model_id)

    @beartype.beartype
    def get_equipment_vendor(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.equipment_vendor_id)

@beartype.beartype
def create_equipment_from_json_dict(json_obj: dict):
        """
        Create a Equipment from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'equipment_purchase_date' in json_obj and json_obj['equipment_purchase_date'] is not None:
            json_obj['equipment_purchase_date'] = datetime.datetime.fromisoformat(json_obj['equipment_purchase_date'])
        return Equipment(**json_obj)


@beartype.beartype
def write_equipment_obj(con: db.Connection, obj: Equipment) -> int:
    """
    Write a Equipment object to the database
    @param con: database connection
    @param obj: Equipment object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'equipment', dataclasses.asdict(obj))

@beartype.beartype
def write_equipment(
            con: db.Connection,
            equipment_uuid: str,
            equipment_code: str,
            equipment_name: str,
            equipment_model_id: int,
            equipment_id: Optional[int] = None,
            equipment_serial_number: Optional[str] = None,
            equipment_vendor_id: Optional[int] = None,
            equipment_purchase_date: Optional[datetime.datetime] = None,
            equipment_purchase_order_number: Optional[str] = None,
            equipment_description: Optional[str] = None,
            equipment_documentation_link: Optional[str] = None) -> int:
    """
    Write to the equipment table in the database
    @param con: database connection
    @param equipment_id 
    @param equipment_uuid 
    @param equipment_code 
    @param equipment_name 
    @param equipment_model_id 
    @param equipment_serial_number 
    @param equipment_vendor_id 
    @param equipment_purchase_date 
    @param equipment_purchase_order_number 
    @param equipment_description 
    @param equipment_documentation_link 
    @return id of the inserted/updated row
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    return db.upsert(con, 'equipment', data)

@beartype.beartype
def write_equipment_many(con: db.Connection, objs: List[Equipment], upsert: bool = False) -> int:
    """
    Write a list of Equipment objects to the database
    @param con: database connection
    @param objs: list of Equipment objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'equipment', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_equipment(con: db.Connection, equipment_id: int,
            equipment_uuid: Optional[str] = None,
            equipment_code: Optional[str] = None,
            equipment_name: Optional[str] = None,
            equipment_model_id: Optional[int] = None,
            equipment_serial_number: Optional[str] = None,
            equipment_vendor_id: Optional[int] = None,
            equipment_purchase_date: Optional[datetime.datetime] = None,
            equipment_purchase_order_number: Optional[str] = None,
            equipment_description: Optional[str] = None,
            equipment_documentation_link: Optional[str] = None) -> int:
    """
    Update a row in the equipment table in the database
    @param con: database connection
    @param equipment_id 
    @param equipment_uuid 
    @param equipment_code 
    @param equipment_name 
    @param equipment_model_id 
    @param equipment_serial_number 
    @param equipment_vendor_id 
    @param equipment_purchase_date 
    @param equipment_purchase_order_number 
    @param equipment_description 
    @param equipment_documentation_link 
    @return The number of rows updated
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    return db.update(con, 'equipment', data)

@beartype.beartype
def read_equipment(
            con: db.Connection,
            equipment_uuid: Optional[str] = None,
             equipment_code: Optional[str] = None,
             equipment_name: Optional[str] = None,
             equipment_model_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             equipment_serial_number: Optional[str] = None,
             equipment_vendor_id: Optional[int] = None,
             equipment_purchase_date: Optional[datetime.datetime] = None,
             equipment_purchase_order_number: Optional[str] = None,
             equipment_description: Optional[str] = None,
             equipment_documentation_link: Optional[str] = None) -> Generator[Equipment, None, None]:
    """
    Read from the equipment table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_id 
    @param equipment_uuid 
    @param equipment_code 
    @param equipment_name 
    @param equipment_model_id 
    @param equipment_serial_number 
    @param equipment_vendor_id 
    @param equipment_purchase_date 
    @param equipment_purchase_order_number 
    @param equipment_description 
    @param equipment_documentation_link 
    @return generator of Equipment objects
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    result = db.query(con, 'equipment', data)
    for row in result:
        yield Equipment(**row.as_dict())

@beartype.beartype
def read_equipment_fuzzy(con: db.Connection, equipment_uuid: Optional[str] = None,
             equipment_code: Optional[str] = None,
             equipment_name: Optional[str] = None,
             equipment_model_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             equipment_serial_number: Optional[str] = None,
             equipment_vendor_id: Optional[int] = None,
             equipment_purchase_date: Optional[datetime.datetime] = None,
             equipment_purchase_order_number: Optional[str] = None,
             equipment_description: Optional[str] = None,
             equipment_documentation_link: Optional[str] = None) -> Generator[Equipment, None, None]:
    """
    Read from the equipment table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_id 
    @param equipment_uuid 
    @param equipment_code 
    @param equipment_name 
    @param equipment_model_id 
    @param equipment_serial_number 
    @param equipment_vendor_id 
    @param equipment_purchase_date 
    @param equipment_purchase_order_number 
    @param equipment_description 
    @param equipment_documentation_link 
    @return generator of Equipment objects
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    result = db.query_fuzzy(con, 'equipment', data)
    for row in result:
        yield Equipment(**row.as_dict())

@beartype.beartype
def read_equipment_any(con: db.Connection, equipment_uuid: Optional[List[str]] = None,
             equipment_code: Optional[List[str]] = None,
             equipment_name: Optional[List[str]] = None,
             equipment_model_id: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None,
             equipment_serial_number: Optional[List[str]] = None,
             equipment_vendor_id: Optional[List[int]] = None,
             equipment_purchase_date: Optional[List[datetime.datetime]] = None,
             equipment_purchase_order_number: Optional[List[str]] = None,
             equipment_description: Optional[List[str]] = None,
             equipment_documentation_link: Optional[List[str]] = None) -> Generator[Equipment, None, None]:
    """
    Read from the equipment table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param equipment_id 
    @param equipment_uuid 
    @param equipment_code 
    @param equipment_name 
    @param equipment_model_id 
    @param equipment_serial_number 
    @param equipment_vendor_id 
    @param equipment_purchase_date 
    @param equipment_purchase_order_number 
    @param equipment_description 
    @param equipment_documentation_link 
    @return generator of Equipment objects
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    result = db.query_any(con, 'equipment', data)
    for row in result:
        yield Equipment(**row.as_dict())

@beartype.beartype
def read_equipment_one_or_none(con: db.Connection, equipment_uuid: Optional[str] = None,
             equipment_code: Optional[str] = None,
             equipment_name: Optional[str] = None,
             equipment_model_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             equipment_serial_number: Optional[str] = None,
             equipment_vendor_id: Optional[int] = None,
             equipment_purchase_date: Optional[datetime.datetime] = None,
             equipment_purchase_order_number: Optional[str] = None,
             equipment_description: Optional[str] = None,
             equipment_documentation_link: Optional[str] = None) -> Optional[Equipment]:
    """
    Read from the equipment table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    result = db.query_one_or_none(con, 'equipment', data)
    if result is None:
        return None
    return Equipment(**result)

@beartype.beartype
def read_equipment_one(con: db.Connection, equipment_uuid: Optional[str] = None,
             equipment_code: Optional[str] = None,
             equipment_name: Optional[str] = None,
             equipment_model_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             equipment_serial_number: Optional[str] = None,
             equipment_vendor_id: Optional[int] = None,
             equipment_purchase_date: Optional[datetime.datetime] = None,
             equipment_purchase_order_number: Optional[str] = None,
             equipment_description: Optional[str] = None,
             equipment_documentation_link: Optional[str] = None) -> Equipment:
    """
    Read from the equipment table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    result = db.query_one(con, 'equipment', data)
    return Equipment(**result)

@beartype.beartype
def read_equipment_all(con: db.Connection, equipment_uuid: Optional[str] = None,
             equipment_code: Optional[str] = None,
             equipment_name: Optional[str] = None,
             equipment_model_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             equipment_serial_number: Optional[str] = None,
             equipment_vendor_id: Optional[int] = None,
             equipment_purchase_date: Optional[datetime.datetime] = None,
             equipment_purchase_order_number: Optional[str] = None,
             equipment_description: Optional[str] = None,
             equipment_documentation_link: Optional[str] = None) -> List[Equipment]:
    """
    Read from the equipment table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'equipment_id': equipment_id,
        'equipment_uuid': equipment_uuid,
        'equipment_code': equipment_code,
        'equipment_name': equipment_name,
        'equipment_model_id': equipment_model_id,
        'equipment_serial_number': equipment_serial_number,
        'equipment_vendor_id': equipment_vendor_id,
        'equipment_purchase_date': equipment_purchase_date,
        'equipment_purchase_order_number': equipment_purchase_order_number,
        'equipment_description': equipment_description,
        'equipment_documentation_link': equipment_documentation_link,
    }
    result = db.query(con, 'equipment', data)
    return [Equipment(**row.as_dict()) for row in result]

@beartype.beartype
def read_equipment_by_id(con: db.Connection, equipment_id: int) -> Optional[Equipment]:
    result = db.query_one(con, 'equipment', {'equipment_id': equipment_id})
    if result is None:
        return None
    return Equipment(**result)

@beartype.beartype
def delete_equipment_by_id(con: db.Connection, equipment_id: int):
    db.delete(con, 'equipment', {'equipment_id': equipment_id})
# Associate the functions with the class
Equipment.create_from_json_dict = create_equipment_from_json_dict
Equipment.write = write_equipment
Equipment.update = update_equipment
Equipment.write_many = write_equipment_many
Equipment.read = read_equipment
Equipment.read_fuzzy = read_equipment_fuzzy
Equipment.read_any = read_equipment_any
Equipment.read_one = read_equipment_one
Equipment.read_one_or_none = read_equipment_one_or_none
Equipment.read_all = read_equipment_all
Equipment.delete = delete_equipment_by_id
Equipment.read_by_id = read_equipment_by_id
Equipment.delete_by_id = delete_equipment_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Heartbeat:
    """
    This table provides update on the system connectivity status

    @param heartbeat_id 
    @param heartbeat_interval_seconds 
    @param last_heartbeat_utc 
    @param equipment_id 
    @param late_threshold_seconds_grace_period 
    @param equipment_status_cv 

    This is an automatically generated class
    """
    heartbeat_interval_seconds: int # heartbeat_interval_seconds integer (default: )
    last_heartbeat_utc: int # last_heartbeat_utc bigint (default: )
    equipment_id: int # equipment_id integer (default: )
    late_threshold_seconds_grace_period: int # late_threshold_seconds_grace_period integer (default: )
    equipment_status_cv: str # equipment_status_cv character varying (default: )
    heartbeat_id: Optional[int] = None # heartbeat_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'heartbeat_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_equipment_status_cv(self, con: db.Connection) -> Optional['CvEquipmentStatus']:
        return read_cv_equipment_status_one_or_none(con, term=self.equipment_status_cv)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

@beartype.beartype
def create_heartbeat_from_json_dict(json_obj: dict):
        """
        Create a Heartbeat from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Heartbeat(**json_obj)


@beartype.beartype
def write_heartbeat_obj(con: db.Connection, obj: Heartbeat) -> int:
    """
    Write a Heartbeat object to the database
    @param con: database connection
    @param obj: Heartbeat object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'heartbeat', dataclasses.asdict(obj))

@beartype.beartype
def write_heartbeat(
            con: db.Connection,
            heartbeat_interval_seconds: int,
            last_heartbeat_utc: int,
            equipment_id: int,
            late_threshold_seconds_grace_period: int,
            equipment_status_cv: str,
            heartbeat_id: Optional[int] = None) -> int:
    """
    Write to the heartbeat table in the database
    @param con: database connection
    @param heartbeat_id 
    @param heartbeat_interval_seconds 
    @param last_heartbeat_utc 
    @param equipment_id 
    @param late_threshold_seconds_grace_period 
    @param equipment_status_cv 
    @return id of the inserted/updated row
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    return db.upsert(con, 'heartbeat', data)

@beartype.beartype
def write_heartbeat_many(con: db.Connection, objs: List[Heartbeat], upsert: bool = False) -> int:
    """
    Write a list of Heartbeat objects to the database
    @param con: database connection
    @param objs: list of Heartbeat objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'heartbeat', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_heartbeat(con: db.Connection, heartbeat_id: int,
            heartbeat_interval_seconds: Optional[int] = None,
            last_heartbeat_utc: Optional[int] = None,
            equipment_id: Optional[int] = None,
            late_threshold_seconds_grace_period: Optional[int] = None,
            equipment_status_cv: Optional[str] = None) -> int:
    """
    Update a row in the heartbeat table in the database
    @param con: database connection
    @param heartbeat_id 
    @param heartbeat_interval_seconds 
    @param last_heartbeat_utc 
    @param equipment_id 
    @param late_threshold_seconds_grace_period 
    @param equipment_status_cv 
    @return The number of rows updated
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    return db.update(con, 'heartbeat', data)

@beartype.beartype
def read_heartbeat(
            con: db.Connection,
            heartbeat_interval_seconds: Optional[int] = None,
             last_heartbeat_utc: Optional[int] = None,
             equipment_id: Optional[int] = None,
             late_threshold_seconds_grace_period: Optional[int] = None,
             equipment_status_cv: Optional[str] = None,
             heartbeat_id: Optional[int] = None) -> Generator[Heartbeat, None, None]:
    """
    Read from the heartbeat table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param heartbeat_id 
    @param heartbeat_interval_seconds 
    @param last_heartbeat_utc 
    @param equipment_id 
    @param late_threshold_seconds_grace_period 
    @param equipment_status_cv 
    @return generator of Heartbeat objects
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    result = db.query(con, 'heartbeat', data)
    for row in result:
        yield Heartbeat(**row.as_dict())

@beartype.beartype
def read_heartbeat_fuzzy(con: db.Connection, heartbeat_interval_seconds: Optional[int] = None,
             last_heartbeat_utc: Optional[int] = None,
             equipment_id: Optional[int] = None,
             late_threshold_seconds_grace_period: Optional[int] = None,
             equipment_status_cv: Optional[str] = None,
             heartbeat_id: Optional[int] = None) -> Generator[Heartbeat, None, None]:
    """
    Read from the heartbeat table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param heartbeat_id 
    @param heartbeat_interval_seconds 
    @param last_heartbeat_utc 
    @param equipment_id 
    @param late_threshold_seconds_grace_period 
    @param equipment_status_cv 
    @return generator of Heartbeat objects
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    result = db.query_fuzzy(con, 'heartbeat', data)
    for row in result:
        yield Heartbeat(**row.as_dict())

@beartype.beartype
def read_heartbeat_any(con: db.Connection, heartbeat_interval_seconds: Optional[List[int]] = None,
             last_heartbeat_utc: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None,
             late_threshold_seconds_grace_period: Optional[List[int]] = None,
             equipment_status_cv: Optional[List[str]] = None,
             heartbeat_id: Optional[List[int]] = None) -> Generator[Heartbeat, None, None]:
    """
    Read from the heartbeat table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param heartbeat_id 
    @param heartbeat_interval_seconds 
    @param last_heartbeat_utc 
    @param equipment_id 
    @param late_threshold_seconds_grace_period 
    @param equipment_status_cv 
    @return generator of Heartbeat objects
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    result = db.query_any(con, 'heartbeat', data)
    for row in result:
        yield Heartbeat(**row.as_dict())

@beartype.beartype
def read_heartbeat_one_or_none(con: db.Connection, heartbeat_interval_seconds: Optional[int] = None,
             last_heartbeat_utc: Optional[int] = None,
             equipment_id: Optional[int] = None,
             late_threshold_seconds_grace_period: Optional[int] = None,
             equipment_status_cv: Optional[str] = None,
             heartbeat_id: Optional[int] = None) -> Optional[Heartbeat]:
    """
    Read from the heartbeat table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    result = db.query_one_or_none(con, 'heartbeat', data)
    if result is None:
        return None
    return Heartbeat(**result)

@beartype.beartype
def read_heartbeat_one(con: db.Connection, heartbeat_interval_seconds: Optional[int] = None,
             last_heartbeat_utc: Optional[int] = None,
             equipment_id: Optional[int] = None,
             late_threshold_seconds_grace_period: Optional[int] = None,
             equipment_status_cv: Optional[str] = None,
             heartbeat_id: Optional[int] = None) -> Heartbeat:
    """
    Read from the heartbeat table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    result = db.query_one(con, 'heartbeat', data)
    return Heartbeat(**result)

@beartype.beartype
def read_heartbeat_all(con: db.Connection, heartbeat_interval_seconds: Optional[int] = None,
             last_heartbeat_utc: Optional[int] = None,
             equipment_id: Optional[int] = None,
             late_threshold_seconds_grace_period: Optional[int] = None,
             equipment_status_cv: Optional[str] = None,
             heartbeat_id: Optional[int] = None) -> List[Heartbeat]:
    """
    Read from the heartbeat table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'heartbeat_id': heartbeat_id,
        'heartbeat_interval_seconds': heartbeat_interval_seconds,
        'last_heartbeat_utc': last_heartbeat_utc,
        'equipment_id': equipment_id,
        'late_threshold_seconds_grace_period': late_threshold_seconds_grace_period,
        'equipment_status_cv': equipment_status_cv,
    }
    result = db.query(con, 'heartbeat', data)
    return [Heartbeat(**row.as_dict()) for row in result]

@beartype.beartype
def read_heartbeat_by_id(con: db.Connection, heartbeat_id: int) -> Optional[Heartbeat]:
    result = db.query_one(con, 'heartbeat', {'heartbeat_id': heartbeat_id})
    if result is None:
        return None
    return Heartbeat(**result)

@beartype.beartype
def delete_heartbeat_by_id(con: db.Connection, heartbeat_id: int):
    db.delete(con, 'heartbeat', {'heartbeat_id': heartbeat_id})
# Associate the functions with the class
Heartbeat.create_from_json_dict = create_heartbeat_from_json_dict
Heartbeat.write = write_heartbeat
Heartbeat.update = update_heartbeat
Heartbeat.write_many = write_heartbeat_many
Heartbeat.read = read_heartbeat
Heartbeat.read_fuzzy = read_heartbeat_fuzzy
Heartbeat.read_any = read_heartbeat_any
Heartbeat.read_one = read_heartbeat_one
Heartbeat.read_one_or_none = read_heartbeat_one_or_none
Heartbeat.read_all = read_heartbeat_all
Heartbeat.delete = delete_heartbeat_by_id
Heartbeat.read_by_id = read_heartbeat_by_id
Heartbeat.delete_by_id = delete_heartbeat_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MethodExtensionPropertyValues:
    """
    Links extnsion properties to a Method

    @param bridge_id 
    @param method_id 
    @param property_id 
    @param property_value 

    This is an automatically generated class
    """
    method_id: int # method_id integer (default: )
    property_id: int # property_id integer (default: )
    property_value: str # property_value character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_property(self, con: db.Connection) -> Optional['ExtensionProperties']:
        return read_extension_properties_one_or_none(con, property_id=self.property_id)

    @beartype.beartype
    def get_method(self, con: db.Connection) -> Optional['Methods']:
        return read_methods_one_or_none(con, method_id=self.method_id)

@beartype.beartype
def create_method_extension_property_values_from_json_dict(json_obj: dict):
        """
        Create a MethodExtensionPropertyValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MethodExtensionPropertyValues(**json_obj)


@beartype.beartype
def write_method_extension_property_values_obj(con: db.Connection, obj: MethodExtensionPropertyValues) -> int:
    """
    Write a MethodExtensionPropertyValues object to the database
    @param con: database connection
    @param obj: MethodExtensionPropertyValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'method_extension_property_values', dataclasses.asdict(obj))

@beartype.beartype
def write_method_extension_property_values(
            con: db.Connection,
            method_id: int,
            property_id: int,
            property_value: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the method_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param property_id 
    @param property_value 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.upsert(con, 'method_extension_property_values', data)

@beartype.beartype
def write_method_extension_property_values_many(con: db.Connection, objs: List[MethodExtensionPropertyValues], upsert: bool = False) -> int:
    """
    Write a list of MethodExtensionPropertyValues objects to the database
    @param con: database connection
    @param objs: list of MethodExtensionPropertyValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'method_extension_property_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_method_extension_property_values(con: db.Connection, bridge_id: int,
            method_id: Optional[int] = None,
            property_id: Optional[int] = None,
            property_value: Optional[str] = None) -> int:
    """
    Update a row in the method_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param property_id 
    @param property_value 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.update(con, 'method_extension_property_values', data)

@beartype.beartype
def read_method_extension_property_values(
            con: db.Connection,
            method_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[MethodExtensionPropertyValues, None, None]:
    """
    Read from the method_extension_property_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param property_id 
    @param property_value 
    @return generator of MethodExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'method_extension_property_values', data)
    for row in result:
        yield MethodExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_method_extension_property_values_fuzzy(con: db.Connection, method_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[MethodExtensionPropertyValues, None, None]:
    """
    Read from the method_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param property_id 
    @param property_value 
    @return generator of MethodExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_fuzzy(con, 'method_extension_property_values', data)
    for row in result:
        yield MethodExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_method_extension_property_values_any(con: db.Connection, method_id: Optional[List[int]] = None,
             property_id: Optional[List[int]] = None,
             property_value: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[MethodExtensionPropertyValues, None, None]:
    """
    Read from the method_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param property_id 
    @param property_value 
    @return generator of MethodExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_any(con, 'method_extension_property_values', data)
    for row in result:
        yield MethodExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_method_extension_property_values_one_or_none(con: db.Connection, method_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[MethodExtensionPropertyValues]:
    """
    Read from the method_extension_property_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one_or_none(con, 'method_extension_property_values', data)
    if result is None:
        return None
    return MethodExtensionPropertyValues(**result)

@beartype.beartype
def read_method_extension_property_values_one(con: db.Connection, method_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> MethodExtensionPropertyValues:
    """
    Read from the method_extension_property_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one(con, 'method_extension_property_values', data)
    return MethodExtensionPropertyValues(**result)

@beartype.beartype
def read_method_extension_property_values_all(con: db.Connection, method_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[MethodExtensionPropertyValues]:
    """
    Read from the method_extension_property_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'method_extension_property_values', data)
    return [MethodExtensionPropertyValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_method_extension_property_values_by_id(con: db.Connection, bridge_id: int) -> Optional[MethodExtensionPropertyValues]:
    result = db.query_one(con, 'method_extension_property_values', {'bridge_id': bridge_id})
    if result is None:
        return None
    return MethodExtensionPropertyValues(**result)

@beartype.beartype
def delete_method_extension_property_values_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'method_extension_property_values', {'bridge_id': bridge_id})
# Associate the functions with the class
MethodExtensionPropertyValues.create_from_json_dict = create_method_extension_property_values_from_json_dict
MethodExtensionPropertyValues.write = write_method_extension_property_values
MethodExtensionPropertyValues.update = update_method_extension_property_values
MethodExtensionPropertyValues.write_many = write_method_extension_property_values_many
MethodExtensionPropertyValues.read = read_method_extension_property_values
MethodExtensionPropertyValues.read_fuzzy = read_method_extension_property_values_fuzzy
MethodExtensionPropertyValues.read_any = read_method_extension_property_values_any
MethodExtensionPropertyValues.read_one = read_method_extension_property_values_one
MethodExtensionPropertyValues.read_one_or_none = read_method_extension_property_values_one_or_none
MethodExtensionPropertyValues.read_all = read_method_extension_property_values_all
MethodExtensionPropertyValues.delete = delete_method_extension_property_values_by_id
MethodExtensionPropertyValues.read_by_id = read_method_extension_property_values_by_id
MethodExtensionPropertyValues.delete_by_id = delete_method_extension_property_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CitationExtensionPropertyValues:
    """
    Values for Citation Extension Properties

    @param bridge_id 
    @param citation_id 
    @param property_id 
    @param property_value 

    This is an automatically generated class
    """
    citation_id: int # citation_id integer (default: )
    property_id: int # property_id integer (default: )
    property_value: str # property_value character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_property(self, con: db.Connection) -> Optional['ExtensionProperties']:
        return read_extension_properties_one_or_none(con, property_id=self.property_id)

@beartype.beartype
def create_citation_extension_property_values_from_json_dict(json_obj: dict):
        """
        Create a CitationExtensionPropertyValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CitationExtensionPropertyValues(**json_obj)


@beartype.beartype
def write_citation_extension_property_values_obj(con: db.Connection, obj: CitationExtensionPropertyValues) -> int:
    """
    Write a CitationExtensionPropertyValues object to the database
    @param con: database connection
    @param obj: CitationExtensionPropertyValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'citation_extension_property_values', dataclasses.asdict(obj))

@beartype.beartype
def write_citation_extension_property_values(
            con: db.Connection,
            citation_id: int,
            property_id: int,
            property_value: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the citation_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param property_id 
    @param property_value 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.upsert(con, 'citation_extension_property_values', data)

@beartype.beartype
def write_citation_extension_property_values_many(con: db.Connection, objs: List[CitationExtensionPropertyValues], upsert: bool = False) -> int:
    """
    Write a list of CitationExtensionPropertyValues objects to the database
    @param con: database connection
    @param objs: list of CitationExtensionPropertyValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'citation_extension_property_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_citation_extension_property_values(con: db.Connection, bridge_id: int,
            citation_id: Optional[int] = None,
            property_id: Optional[int] = None,
            property_value: Optional[str] = None) -> int:
    """
    Update a row in the citation_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param property_id 
    @param property_value 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.update(con, 'citation_extension_property_values', data)

@beartype.beartype
def read_citation_extension_property_values(
            con: db.Connection,
            citation_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[CitationExtensionPropertyValues, None, None]:
    """
    Read from the citation_extension_property_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param property_id 
    @param property_value 
    @return generator of CitationExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'citation_extension_property_values', data)
    for row in result:
        yield CitationExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_citation_extension_property_values_fuzzy(con: db.Connection, citation_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[CitationExtensionPropertyValues, None, None]:
    """
    Read from the citation_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param property_id 
    @param property_value 
    @return generator of CitationExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_fuzzy(con, 'citation_extension_property_values', data)
    for row in result:
        yield CitationExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_citation_extension_property_values_any(con: db.Connection, citation_id: Optional[List[int]] = None,
             property_id: Optional[List[int]] = None,
             property_value: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[CitationExtensionPropertyValues, None, None]:
    """
    Read from the citation_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param property_id 
    @param property_value 
    @return generator of CitationExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_any(con, 'citation_extension_property_values', data)
    for row in result:
        yield CitationExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_citation_extension_property_values_one_or_none(con: db.Connection, citation_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[CitationExtensionPropertyValues]:
    """
    Read from the citation_extension_property_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one_or_none(con, 'citation_extension_property_values', data)
    if result is None:
        return None
    return CitationExtensionPropertyValues(**result)

@beartype.beartype
def read_citation_extension_property_values_one(con: db.Connection, citation_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> CitationExtensionPropertyValues:
    """
    Read from the citation_extension_property_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one(con, 'citation_extension_property_values', data)
    return CitationExtensionPropertyValues(**result)

@beartype.beartype
def read_citation_extension_property_values_all(con: db.Connection, citation_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[CitationExtensionPropertyValues]:
    """
    Read from the citation_extension_property_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'citation_extension_property_values', data)
    return [CitationExtensionPropertyValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_citation_extension_property_values_by_id(con: db.Connection, bridge_id: int) -> Optional[CitationExtensionPropertyValues]:
    result = db.query_one(con, 'citation_extension_property_values', {'bridge_id': bridge_id})
    if result is None:
        return None
    return CitationExtensionPropertyValues(**result)

@beartype.beartype
def delete_citation_extension_property_values_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'citation_extension_property_values', {'bridge_id': bridge_id})
# Associate the functions with the class
CitationExtensionPropertyValues.create_from_json_dict = create_citation_extension_property_values_from_json_dict
CitationExtensionPropertyValues.write = write_citation_extension_property_values
CitationExtensionPropertyValues.update = update_citation_extension_property_values
CitationExtensionPropertyValues.write_many = write_citation_extension_property_values_many
CitationExtensionPropertyValues.read = read_citation_extension_property_values
CitationExtensionPropertyValues.read_fuzzy = read_citation_extension_property_values_fuzzy
CitationExtensionPropertyValues.read_any = read_citation_extension_property_values_any
CitationExtensionPropertyValues.read_one = read_citation_extension_property_values_one
CitationExtensionPropertyValues.read_one_or_none = read_citation_extension_property_values_one_or_none
CitationExtensionPropertyValues.read_all = read_citation_extension_property_values_all
CitationExtensionPropertyValues.delete = delete_citation_extension_property_values_by_id
CitationExtensionPropertyValues.read_by_id = read_citation_extension_property_values_by_id
CitationExtensionPropertyValues.delete_by_id = delete_citation_extension_property_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ResultExtensionPropertyValues:
    """
    Links extension properties to a Result

    @param bridge_id 
    @param result_id 
    @param property_id 
    @param property_value 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    property_id: int # property_id integer (default: )
    property_value: str # property_value character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_property(self, con: db.Connection) -> Optional['ExtensionProperties']:
        return read_extension_properties_one_or_none(con, property_id=self.property_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_result_extension_property_values_from_json_dict(json_obj: dict):
        """
        Create a ResultExtensionPropertyValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ResultExtensionPropertyValues(**json_obj)


@beartype.beartype
def write_result_extension_property_values_obj(con: db.Connection, obj: ResultExtensionPropertyValues) -> int:
    """
    Write a ResultExtensionPropertyValues object to the database
    @param con: database connection
    @param obj: ResultExtensionPropertyValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'result_extension_property_values', dataclasses.asdict(obj))

@beartype.beartype
def write_result_extension_property_values(
            con: db.Connection,
            result_id: int,
            property_id: int,
            property_value: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the result_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param property_id 
    @param property_value 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.upsert(con, 'result_extension_property_values', data)

@beartype.beartype
def write_result_extension_property_values_many(con: db.Connection, objs: List[ResultExtensionPropertyValues], upsert: bool = False) -> int:
    """
    Write a list of ResultExtensionPropertyValues objects to the database
    @param con: database connection
    @param objs: list of ResultExtensionPropertyValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'result_extension_property_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_result_extension_property_values(con: db.Connection, bridge_id: int,
            result_id: Optional[int] = None,
            property_id: Optional[int] = None,
            property_value: Optional[str] = None) -> int:
    """
    Update a row in the result_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param property_id 
    @param property_value 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.update(con, 'result_extension_property_values', data)

@beartype.beartype
def read_result_extension_property_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[ResultExtensionPropertyValues, None, None]:
    """
    Read from the result_extension_property_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param property_id 
    @param property_value 
    @return generator of ResultExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'result_extension_property_values', data)
    for row in result:
        yield ResultExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_result_extension_property_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[ResultExtensionPropertyValues, None, None]:
    """
    Read from the result_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param property_id 
    @param property_value 
    @return generator of ResultExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_fuzzy(con, 'result_extension_property_values', data)
    for row in result:
        yield ResultExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_result_extension_property_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             property_id: Optional[List[int]] = None,
             property_value: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ResultExtensionPropertyValues, None, None]:
    """
    Read from the result_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param result_id 
    @param property_id 
    @param property_value 
    @return generator of ResultExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_any(con, 'result_extension_property_values', data)
    for row in result:
        yield ResultExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_result_extension_property_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[ResultExtensionPropertyValues]:
    """
    Read from the result_extension_property_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one_or_none(con, 'result_extension_property_values', data)
    if result is None:
        return None
    return ResultExtensionPropertyValues(**result)

@beartype.beartype
def read_result_extension_property_values_one(con: db.Connection, result_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> ResultExtensionPropertyValues:
    """
    Read from the result_extension_property_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one(con, 'result_extension_property_values', data)
    return ResultExtensionPropertyValues(**result)

@beartype.beartype
def read_result_extension_property_values_all(con: db.Connection, result_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[ResultExtensionPropertyValues]:
    """
    Read from the result_extension_property_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'result_id': result_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'result_extension_property_values', data)
    return [ResultExtensionPropertyValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_result_extension_property_values_by_id(con: db.Connection, bridge_id: int) -> Optional[ResultExtensionPropertyValues]:
    result = db.query_one(con, 'result_extension_property_values', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ResultExtensionPropertyValues(**result)

@beartype.beartype
def delete_result_extension_property_values_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'result_extension_property_values', {'bridge_id': bridge_id})
# Associate the functions with the class
ResultExtensionPropertyValues.create_from_json_dict = create_result_extension_property_values_from_json_dict
ResultExtensionPropertyValues.write = write_result_extension_property_values
ResultExtensionPropertyValues.update = update_result_extension_property_values
ResultExtensionPropertyValues.write_many = write_result_extension_property_values_many
ResultExtensionPropertyValues.read = read_result_extension_property_values
ResultExtensionPropertyValues.read_fuzzy = read_result_extension_property_values_fuzzy
ResultExtensionPropertyValues.read_any = read_result_extension_property_values_any
ResultExtensionPropertyValues.read_one = read_result_extension_property_values_one
ResultExtensionPropertyValues.read_one_or_none = read_result_extension_property_values_one_or_none
ResultExtensionPropertyValues.read_all = read_result_extension_property_values_all
ResultExtensionPropertyValues.delete = delete_result_extension_property_values_by_id
ResultExtensionPropertyValues.read_by_id = read_result_extension_property_values_by_id
ResultExtensionPropertyValues.delete_by_id = delete_result_extension_property_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SamplingFeatureExtensionPropertyValues:
    """
    @param bridge_id 
    @param sampling_feature_id 
    @param property_id 
    @param property_value 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    property_id: int # property_id integer (default: )
    property_value: str # property_value character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_property(self, con: db.Connection) -> Optional['ExtensionProperties']:
        return read_extension_properties_one_or_none(con, property_id=self.property_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_sampling_feature_extension_property_values_from_json_dict(json_obj: dict):
        """
        Create a SamplingFeatureExtensionPropertyValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SamplingFeatureExtensionPropertyValues(**json_obj)


@beartype.beartype
def write_sampling_feature_extension_property_values_obj(con: db.Connection, obj: SamplingFeatureExtensionPropertyValues) -> int:
    """
    Write a SamplingFeatureExtensionPropertyValues object to the database
    @param con: database connection
    @param obj: SamplingFeatureExtensionPropertyValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampling_feature_extension_property_values', dataclasses.asdict(obj))

@beartype.beartype
def write_sampling_feature_extension_property_values(
            con: db.Connection,
            sampling_feature_id: int,
            property_id: int,
            property_value: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the sampling_feature_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param property_id 
    @param property_value 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.upsert(con, 'sampling_feature_extension_property_values', data)

@beartype.beartype
def write_sampling_feature_extension_property_values_many(con: db.Connection, objs: List[SamplingFeatureExtensionPropertyValues], upsert: bool = False) -> int:
    """
    Write a list of SamplingFeatureExtensionPropertyValues objects to the database
    @param con: database connection
    @param objs: list of SamplingFeatureExtensionPropertyValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampling_feature_extension_property_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampling_feature_extension_property_values(con: db.Connection, bridge_id: int,
            sampling_feature_id: Optional[int] = None,
            property_id: Optional[int] = None,
            property_value: Optional[str] = None) -> int:
    """
    Update a row in the sampling_feature_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param property_id 
    @param property_value 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.update(con, 'sampling_feature_extension_property_values', data)

@beartype.beartype
def read_sampling_feature_extension_property_values(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[SamplingFeatureExtensionPropertyValues, None, None]:
    """
    Read from the sampling_feature_extension_property_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param property_id 
    @param property_value 
    @return generator of SamplingFeatureExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'sampling_feature_extension_property_values', data)
    for row in result:
        yield SamplingFeatureExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_sampling_feature_extension_property_values_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[SamplingFeatureExtensionPropertyValues, None, None]:
    """
    Read from the sampling_feature_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param property_id 
    @param property_value 
    @return generator of SamplingFeatureExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_fuzzy(con, 'sampling_feature_extension_property_values', data)
    for row in result:
        yield SamplingFeatureExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_sampling_feature_extension_property_values_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             property_id: Optional[List[int]] = None,
             property_value: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[SamplingFeatureExtensionPropertyValues, None, None]:
    """
    Read from the sampling_feature_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param property_id 
    @param property_value 
    @return generator of SamplingFeatureExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_any(con, 'sampling_feature_extension_property_values', data)
    for row in result:
        yield SamplingFeatureExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_sampling_feature_extension_property_values_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[SamplingFeatureExtensionPropertyValues]:
    """
    Read from the sampling_feature_extension_property_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one_or_none(con, 'sampling_feature_extension_property_values', data)
    if result is None:
        return None
    return SamplingFeatureExtensionPropertyValues(**result)

@beartype.beartype
def read_sampling_feature_extension_property_values_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> SamplingFeatureExtensionPropertyValues:
    """
    Read from the sampling_feature_extension_property_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one(con, 'sampling_feature_extension_property_values', data)
    return SamplingFeatureExtensionPropertyValues(**result)

@beartype.beartype
def read_sampling_feature_extension_property_values_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[SamplingFeatureExtensionPropertyValues]:
    """
    Read from the sampling_feature_extension_property_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'sampling_feature_extension_property_values', data)
    return [SamplingFeatureExtensionPropertyValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampling_feature_extension_property_values_by_id(con: db.Connection, bridge_id: int) -> Optional[SamplingFeatureExtensionPropertyValues]:
    result = db.query_one(con, 'sampling_feature_extension_property_values', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SamplingFeatureExtensionPropertyValues(**result)

@beartype.beartype
def delete_sampling_feature_extension_property_values_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'sampling_feature_extension_property_values', {'bridge_id': bridge_id})
# Associate the functions with the class
SamplingFeatureExtensionPropertyValues.create_from_json_dict = create_sampling_feature_extension_property_values_from_json_dict
SamplingFeatureExtensionPropertyValues.write = write_sampling_feature_extension_property_values
SamplingFeatureExtensionPropertyValues.update = update_sampling_feature_extension_property_values
SamplingFeatureExtensionPropertyValues.write_many = write_sampling_feature_extension_property_values_many
SamplingFeatureExtensionPropertyValues.read = read_sampling_feature_extension_property_values
SamplingFeatureExtensionPropertyValues.read_fuzzy = read_sampling_feature_extension_property_values_fuzzy
SamplingFeatureExtensionPropertyValues.read_any = read_sampling_feature_extension_property_values_any
SamplingFeatureExtensionPropertyValues.read_one = read_sampling_feature_extension_property_values_one
SamplingFeatureExtensionPropertyValues.read_one_or_none = read_sampling_feature_extension_property_values_one_or_none
SamplingFeatureExtensionPropertyValues.read_all = read_sampling_feature_extension_property_values_all
SamplingFeatureExtensionPropertyValues.delete = delete_sampling_feature_extension_property_values_by_id
SamplingFeatureExtensionPropertyValues.read_by_id = read_sampling_feature_extension_property_values_by_id
SamplingFeatureExtensionPropertyValues.delete_by_id = delete_sampling_feature_extension_property_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class VariableExtensionPropertyValues:
    """
    @param bridge_id 
    @param variable_id 
    @param property_id 
    @param property_value 

    This is an automatically generated class
    """
    variable_id: int # variable_id integer (default: )
    property_id: int # property_id integer (default: )
    property_value: str # property_value character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_property(self, con: db.Connection) -> Optional['ExtensionProperties']:
        return read_extension_properties_one_or_none(con, property_id=self.property_id)

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_variable_extension_property_values_from_json_dict(json_obj: dict):
        """
        Create a VariableExtensionPropertyValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return VariableExtensionPropertyValues(**json_obj)


@beartype.beartype
def write_variable_extension_property_values_obj(con: db.Connection, obj: VariableExtensionPropertyValues) -> int:
    """
    Write a VariableExtensionPropertyValues object to the database
    @param con: database connection
    @param obj: VariableExtensionPropertyValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'variable_extension_property_values', dataclasses.asdict(obj))

@beartype.beartype
def write_variable_extension_property_values(
            con: db.Connection,
            variable_id: int,
            property_id: int,
            property_value: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the variable_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param property_id 
    @param property_value 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.upsert(con, 'variable_extension_property_values', data)

@beartype.beartype
def write_variable_extension_property_values_many(con: db.Connection, objs: List[VariableExtensionPropertyValues], upsert: bool = False) -> int:
    """
    Write a list of VariableExtensionPropertyValues objects to the database
    @param con: database connection
    @param objs: list of VariableExtensionPropertyValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'variable_extension_property_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_variable_extension_property_values(con: db.Connection, bridge_id: int,
            variable_id: Optional[int] = None,
            property_id: Optional[int] = None,
            property_value: Optional[str] = None) -> int:
    """
    Update a row in the variable_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param property_id 
    @param property_value 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.update(con, 'variable_extension_property_values', data)

@beartype.beartype
def read_variable_extension_property_values(
            con: db.Connection,
            variable_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[VariableExtensionPropertyValues, None, None]:
    """
    Read from the variable_extension_property_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param property_id 
    @param property_value 
    @return generator of VariableExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'variable_extension_property_values', data)
    for row in result:
        yield VariableExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_variable_extension_property_values_fuzzy(con: db.Connection, variable_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[VariableExtensionPropertyValues, None, None]:
    """
    Read from the variable_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param property_id 
    @param property_value 
    @return generator of VariableExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_fuzzy(con, 'variable_extension_property_values', data)
    for row in result:
        yield VariableExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_variable_extension_property_values_any(con: db.Connection, variable_id: Optional[List[int]] = None,
             property_id: Optional[List[int]] = None,
             property_value: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[VariableExtensionPropertyValues, None, None]:
    """
    Read from the variable_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param property_id 
    @param property_value 
    @return generator of VariableExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_any(con, 'variable_extension_property_values', data)
    for row in result:
        yield VariableExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_variable_extension_property_values_one_or_none(con: db.Connection, variable_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[VariableExtensionPropertyValues]:
    """
    Read from the variable_extension_property_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one_or_none(con, 'variable_extension_property_values', data)
    if result is None:
        return None
    return VariableExtensionPropertyValues(**result)

@beartype.beartype
def read_variable_extension_property_values_one(con: db.Connection, variable_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> VariableExtensionPropertyValues:
    """
    Read from the variable_extension_property_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one(con, 'variable_extension_property_values', data)
    return VariableExtensionPropertyValues(**result)

@beartype.beartype
def read_variable_extension_property_values_all(con: db.Connection, variable_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[VariableExtensionPropertyValues]:
    """
    Read from the variable_extension_property_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'variable_extension_property_values', data)
    return [VariableExtensionPropertyValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_variable_extension_property_values_by_id(con: db.Connection, bridge_id: int) -> Optional[VariableExtensionPropertyValues]:
    result = db.query_one(con, 'variable_extension_property_values', {'bridge_id': bridge_id})
    if result is None:
        return None
    return VariableExtensionPropertyValues(**result)

@beartype.beartype
def delete_variable_extension_property_values_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'variable_extension_property_values', {'bridge_id': bridge_id})
# Associate the functions with the class
VariableExtensionPropertyValues.create_from_json_dict = create_variable_extension_property_values_from_json_dict
VariableExtensionPropertyValues.write = write_variable_extension_property_values
VariableExtensionPropertyValues.update = update_variable_extension_property_values
VariableExtensionPropertyValues.write_many = write_variable_extension_property_values_many
VariableExtensionPropertyValues.read = read_variable_extension_property_values
VariableExtensionPropertyValues.read_fuzzy = read_variable_extension_property_values_fuzzy
VariableExtensionPropertyValues.read_any = read_variable_extension_property_values_any
VariableExtensionPropertyValues.read_one = read_variable_extension_property_values_one
VariableExtensionPropertyValues.read_one_or_none = read_variable_extension_property_values_one_or_none
VariableExtensionPropertyValues.read_all = read_variable_extension_property_values_all
VariableExtensionPropertyValues.delete = delete_variable_extension_property_values_by_id
VariableExtensionPropertyValues.read_by_id = read_variable_extension_property_values_by_id
VariableExtensionPropertyValues.delete_by_id = delete_variable_extension_property_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CitationExternalIdentifiers:
    """
    @param bridge_id 
    @param citation_id 
    @param external_identifier_system_id 
    @param citation_external_identifier 
    @param citation_external_identifier_uri 

    This is an automatically generated class
    """
    citation_id: int # citation_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    citation_external_identifier: str # citation_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    citation_external_identifier_uri: Optional[str] = None # citation_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

@beartype.beartype
def create_citation_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a CitationExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CitationExternalIdentifiers(**json_obj)


@beartype.beartype
def write_citation_external_identifiers_obj(con: db.Connection, obj: CitationExternalIdentifiers) -> int:
    """
    Write a CitationExternalIdentifiers object to the database
    @param con: database connection
    @param obj: CitationExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'citation_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_citation_external_identifiers(
            con: db.Connection,
            citation_id: int,
            external_identifier_system_id: int,
            citation_external_identifier: str,
            bridge_id: Optional[int] = None,
            citation_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the citation_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param external_identifier_system_id 
    @param citation_external_identifier 
    @param citation_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    return db.upsert(con, 'citation_external_identifiers', data)

@beartype.beartype
def write_citation_external_identifiers_many(con: db.Connection, objs: List[CitationExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of CitationExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of CitationExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'citation_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_citation_external_identifiers(con: db.Connection, bridge_id: int,
            citation_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            citation_external_identifier: Optional[str] = None,
            citation_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the citation_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param external_identifier_system_id 
    @param citation_external_identifier 
    @param citation_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    return db.update(con, 'citation_external_identifiers', data)

@beartype.beartype
def read_citation_external_identifiers(
            con: db.Connection,
            citation_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             citation_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             citation_external_identifier_uri: Optional[str] = None) -> Generator[CitationExternalIdentifiers, None, None]:
    """
    Read from the citation_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param external_identifier_system_id 
    @param citation_external_identifier 
    @param citation_external_identifier_uri 
    @return generator of CitationExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    result = db.query(con, 'citation_external_identifiers', data)
    for row in result:
        yield CitationExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_citation_external_identifiers_fuzzy(con: db.Connection, citation_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             citation_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             citation_external_identifier_uri: Optional[str] = None) -> Generator[CitationExternalIdentifiers, None, None]:
    """
    Read from the citation_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param external_identifier_system_id 
    @param citation_external_identifier 
    @param citation_external_identifier_uri 
    @return generator of CitationExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'citation_external_identifiers', data)
    for row in result:
        yield CitationExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_citation_external_identifiers_any(con: db.Connection, citation_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             citation_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             citation_external_identifier_uri: Optional[List[str]] = None) -> Generator[CitationExternalIdentifiers, None, None]:
    """
    Read from the citation_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param external_identifier_system_id 
    @param citation_external_identifier 
    @param citation_external_identifier_uri 
    @return generator of CitationExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    result = db.query_any(con, 'citation_external_identifiers', data)
    for row in result:
        yield CitationExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_citation_external_identifiers_one_or_none(con: db.Connection, citation_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             citation_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             citation_external_identifier_uri: Optional[str] = None) -> Optional[CitationExternalIdentifiers]:
    """
    Read from the citation_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'citation_external_identifiers', data)
    if result is None:
        return None
    return CitationExternalIdentifiers(**result)

@beartype.beartype
def read_citation_external_identifiers_one(con: db.Connection, citation_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             citation_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             citation_external_identifier_uri: Optional[str] = None) -> CitationExternalIdentifiers:
    """
    Read from the citation_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    result = db.query_one(con, 'citation_external_identifiers', data)
    return CitationExternalIdentifiers(**result)

@beartype.beartype
def read_citation_external_identifiers_all(con: db.Connection, citation_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             citation_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             citation_external_identifier_uri: Optional[str] = None) -> List[CitationExternalIdentifiers]:
    """
    Read from the citation_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'external_identifier_system_id': external_identifier_system_id,
        'citation_external_identifier': citation_external_identifier,
        'citation_external_identifier_uri': citation_external_identifier_uri,
    }
    result = db.query(con, 'citation_external_identifiers', data)
    return [CitationExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_citation_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[CitationExternalIdentifiers]:
    result = db.query_one(con, 'citation_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return CitationExternalIdentifiers(**result)

@beartype.beartype
def delete_citation_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'citation_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
CitationExternalIdentifiers.create_from_json_dict = create_citation_external_identifiers_from_json_dict
CitationExternalIdentifiers.write = write_citation_external_identifiers
CitationExternalIdentifiers.update = update_citation_external_identifiers
CitationExternalIdentifiers.write_many = write_citation_external_identifiers_many
CitationExternalIdentifiers.read = read_citation_external_identifiers
CitationExternalIdentifiers.read_fuzzy = read_citation_external_identifiers_fuzzy
CitationExternalIdentifiers.read_any = read_citation_external_identifiers_any
CitationExternalIdentifiers.read_one = read_citation_external_identifiers_one
CitationExternalIdentifiers.read_one_or_none = read_citation_external_identifiers_one_or_none
CitationExternalIdentifiers.read_all = read_citation_external_identifiers_all
CitationExternalIdentifiers.delete = delete_citation_external_identifiers_by_id
CitationExternalIdentifiers.read_by_id = read_citation_external_identifiers_by_id
CitationExternalIdentifiers.delete_by_id = delete_citation_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ExternalIdentifierSystems:
    """
    A single table for connecting various primary keys with points to outside systems.

    @param external_identifier_system_id 
    @param external_identifier_system_name 
    @param identifier_system_organization_id 
    @param external_identifier_system_description 
    @param external_identifier_system_url 

    This is an automatically generated class
    """
    external_identifier_system_name: str # external_identifier_system_name character varying (default: )
    identifier_system_organization_id: int # identifier_system_organization_id integer (default: )
    external_identifier_system_id: Optional[int] = None # external_identifier_system_id integer (default: )
    external_identifier_system_description: Optional[str] = None # external_identifier_system_description character varying (default: )
    external_identifier_system_url: Optional[str] = None # external_identifier_system_url character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'external_identifier_system_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_identifier_system_organization(self, con: db.Connection) -> Optional['Organizations']:
        return read_organizations_one_or_none(con, organization_id=self.identifier_system_organization_id)

@beartype.beartype
def create_external_identifier_systems_from_json_dict(json_obj: dict):
        """
        Create a ExternalIdentifierSystems from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ExternalIdentifierSystems(**json_obj)


@beartype.beartype
def write_external_identifier_systems_obj(con: db.Connection, obj: ExternalIdentifierSystems) -> int:
    """
    Write a ExternalIdentifierSystems object to the database
    @param con: database connection
    @param obj: ExternalIdentifierSystems object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'external_identifier_systems', dataclasses.asdict(obj))

@beartype.beartype
def write_external_identifier_systems(
            con: db.Connection,
            external_identifier_system_name: str,
            identifier_system_organization_id: int,
            external_identifier_system_id: Optional[int] = None,
            external_identifier_system_description: Optional[str] = None,
            external_identifier_system_url: Optional[str] = None) -> int:
    """
    Write to the external_identifier_systems table in the database
    @param con: database connection
    @param external_identifier_system_id 
    @param external_identifier_system_name 
    @param identifier_system_organization_id 
    @param external_identifier_system_description 
    @param external_identifier_system_url 
    @return id of the inserted/updated row
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    return db.upsert(con, 'external_identifier_systems', data)

@beartype.beartype
def write_external_identifier_systems_many(con: db.Connection, objs: List[ExternalIdentifierSystems], upsert: bool = False) -> int:
    """
    Write a list of ExternalIdentifierSystems objects to the database
    @param con: database connection
    @param objs: list of ExternalIdentifierSystems objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'external_identifier_systems', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_external_identifier_systems(con: db.Connection, external_identifier_system_id: int,
            external_identifier_system_name: Optional[str] = None,
            identifier_system_organization_id: Optional[int] = None,
            external_identifier_system_description: Optional[str] = None,
            external_identifier_system_url: Optional[str] = None) -> int:
    """
    Update a row in the external_identifier_systems table in the database
    @param con: database connection
    @param external_identifier_system_id 
    @param external_identifier_system_name 
    @param identifier_system_organization_id 
    @param external_identifier_system_description 
    @param external_identifier_system_url 
    @return The number of rows updated
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    return db.update(con, 'external_identifier_systems', data)

@beartype.beartype
def read_external_identifier_systems(
            con: db.Connection,
            external_identifier_system_name: Optional[str] = None,
             identifier_system_organization_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             external_identifier_system_description: Optional[str] = None,
             external_identifier_system_url: Optional[str] = None) -> Generator[ExternalIdentifierSystems, None, None]:
    """
    Read from the external_identifier_systems table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param external_identifier_system_id 
    @param external_identifier_system_name 
    @param identifier_system_organization_id 
    @param external_identifier_system_description 
    @param external_identifier_system_url 
    @return generator of ExternalIdentifierSystems objects
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    result = db.query(con, 'external_identifier_systems', data)
    for row in result:
        yield ExternalIdentifierSystems(**row.as_dict())

@beartype.beartype
def read_external_identifier_systems_fuzzy(con: db.Connection, external_identifier_system_name: Optional[str] = None,
             identifier_system_organization_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             external_identifier_system_description: Optional[str] = None,
             external_identifier_system_url: Optional[str] = None) -> Generator[ExternalIdentifierSystems, None, None]:
    """
    Read from the external_identifier_systems table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param external_identifier_system_id 
    @param external_identifier_system_name 
    @param identifier_system_organization_id 
    @param external_identifier_system_description 
    @param external_identifier_system_url 
    @return generator of ExternalIdentifierSystems objects
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    result = db.query_fuzzy(con, 'external_identifier_systems', data)
    for row in result:
        yield ExternalIdentifierSystems(**row.as_dict())

@beartype.beartype
def read_external_identifier_systems_any(con: db.Connection, external_identifier_system_name: Optional[List[str]] = None,
             identifier_system_organization_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             external_identifier_system_description: Optional[List[str]] = None,
             external_identifier_system_url: Optional[List[str]] = None) -> Generator[ExternalIdentifierSystems, None, None]:
    """
    Read from the external_identifier_systems table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param external_identifier_system_id 
    @param external_identifier_system_name 
    @param identifier_system_organization_id 
    @param external_identifier_system_description 
    @param external_identifier_system_url 
    @return generator of ExternalIdentifierSystems objects
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    result = db.query_any(con, 'external_identifier_systems', data)
    for row in result:
        yield ExternalIdentifierSystems(**row.as_dict())

@beartype.beartype
def read_external_identifier_systems_one_or_none(con: db.Connection, external_identifier_system_name: Optional[str] = None,
             identifier_system_organization_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             external_identifier_system_description: Optional[str] = None,
             external_identifier_system_url: Optional[str] = None) -> Optional[ExternalIdentifierSystems]:
    """
    Read from the external_identifier_systems table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    result = db.query_one_or_none(con, 'external_identifier_systems', data)
    if result is None:
        return None
    return ExternalIdentifierSystems(**result)

@beartype.beartype
def read_external_identifier_systems_one(con: db.Connection, external_identifier_system_name: Optional[str] = None,
             identifier_system_organization_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             external_identifier_system_description: Optional[str] = None,
             external_identifier_system_url: Optional[str] = None) -> ExternalIdentifierSystems:
    """
    Read from the external_identifier_systems table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    result = db.query_one(con, 'external_identifier_systems', data)
    return ExternalIdentifierSystems(**result)

@beartype.beartype
def read_external_identifier_systems_all(con: db.Connection, external_identifier_system_name: Optional[str] = None,
             identifier_system_organization_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             external_identifier_system_description: Optional[str] = None,
             external_identifier_system_url: Optional[str] = None) -> List[ExternalIdentifierSystems]:
    """
    Read from the external_identifier_systems table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'external_identifier_system_id': external_identifier_system_id,
        'external_identifier_system_name': external_identifier_system_name,
        'identifier_system_organization_id': identifier_system_organization_id,
        'external_identifier_system_description': external_identifier_system_description,
        'external_identifier_system_url': external_identifier_system_url,
    }
    result = db.query(con, 'external_identifier_systems', data)
    return [ExternalIdentifierSystems(**row.as_dict()) for row in result]

@beartype.beartype
def read_external_identifier_systems_by_id(con: db.Connection, external_identifier_system_id: int) -> Optional[ExternalIdentifierSystems]:
    result = db.query_one(con, 'external_identifier_systems', {'external_identifier_system_id': external_identifier_system_id})
    if result is None:
        return None
    return ExternalIdentifierSystems(**result)

@beartype.beartype
def delete_external_identifier_systems_by_id(con: db.Connection, external_identifier_system_id: int):
    db.delete(con, 'external_identifier_systems', {'external_identifier_system_id': external_identifier_system_id})
# Associate the functions with the class
ExternalIdentifierSystems.create_from_json_dict = create_external_identifier_systems_from_json_dict
ExternalIdentifierSystems.write = write_external_identifier_systems
ExternalIdentifierSystems.update = update_external_identifier_systems
ExternalIdentifierSystems.write_many = write_external_identifier_systems_many
ExternalIdentifierSystems.read = read_external_identifier_systems
ExternalIdentifierSystems.read_fuzzy = read_external_identifier_systems_fuzzy
ExternalIdentifierSystems.read_any = read_external_identifier_systems_any
ExternalIdentifierSystems.read_one = read_external_identifier_systems_one
ExternalIdentifierSystems.read_one_or_none = read_external_identifier_systems_one_or_none
ExternalIdentifierSystems.read_all = read_external_identifier_systems_all
ExternalIdentifierSystems.delete = delete_external_identifier_systems_by_id
ExternalIdentifierSystems.read_by_id = read_external_identifier_systems_by_id
ExternalIdentifierSystems.delete_by_id = delete_external_identifier_systems_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MethodExternalIdentifiers:
    """
    @param bridge_id 
    @param method_id 
    @param external_identifier_system_id 
    @param method_external_identifier 
    @param method_external_identifier_uri 

    This is an automatically generated class
    """
    method_id: int # method_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    method_external_identifier: str # method_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    method_external_identifier_uri: Optional[str] = None # method_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_method(self, con: db.Connection) -> Optional['Methods']:
        return read_methods_one_or_none(con, method_id=self.method_id)

@beartype.beartype
def create_method_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a MethodExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MethodExternalIdentifiers(**json_obj)


@beartype.beartype
def write_method_external_identifiers_obj(con: db.Connection, obj: MethodExternalIdentifiers) -> int:
    """
    Write a MethodExternalIdentifiers object to the database
    @param con: database connection
    @param obj: MethodExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'method_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_method_external_identifiers(
            con: db.Connection,
            method_id: int,
            external_identifier_system_id: int,
            method_external_identifier: str,
            bridge_id: Optional[int] = None,
            method_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the method_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param external_identifier_system_id 
    @param method_external_identifier 
    @param method_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    return db.upsert(con, 'method_external_identifiers', data)

@beartype.beartype
def write_method_external_identifiers_many(con: db.Connection, objs: List[MethodExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of MethodExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of MethodExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'method_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_method_external_identifiers(con: db.Connection, bridge_id: int,
            method_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            method_external_identifier: Optional[str] = None,
            method_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the method_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param external_identifier_system_id 
    @param method_external_identifier 
    @param method_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    return db.update(con, 'method_external_identifiers', data)

@beartype.beartype
def read_method_external_identifiers(
            con: db.Connection,
            method_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             method_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             method_external_identifier_uri: Optional[str] = None) -> Generator[MethodExternalIdentifiers, None, None]:
    """
    Read from the method_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param external_identifier_system_id 
    @param method_external_identifier 
    @param method_external_identifier_uri 
    @return generator of MethodExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    result = db.query(con, 'method_external_identifiers', data)
    for row in result:
        yield MethodExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_method_external_identifiers_fuzzy(con: db.Connection, method_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             method_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             method_external_identifier_uri: Optional[str] = None) -> Generator[MethodExternalIdentifiers, None, None]:
    """
    Read from the method_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param external_identifier_system_id 
    @param method_external_identifier 
    @param method_external_identifier_uri 
    @return generator of MethodExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'method_external_identifiers', data)
    for row in result:
        yield MethodExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_method_external_identifiers_any(con: db.Connection, method_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             method_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             method_external_identifier_uri: Optional[List[str]] = None) -> Generator[MethodExternalIdentifiers, None, None]:
    """
    Read from the method_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param external_identifier_system_id 
    @param method_external_identifier 
    @param method_external_identifier_uri 
    @return generator of MethodExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    result = db.query_any(con, 'method_external_identifiers', data)
    for row in result:
        yield MethodExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_method_external_identifiers_one_or_none(con: db.Connection, method_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             method_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             method_external_identifier_uri: Optional[str] = None) -> Optional[MethodExternalIdentifiers]:
    """
    Read from the method_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'method_external_identifiers', data)
    if result is None:
        return None
    return MethodExternalIdentifiers(**result)

@beartype.beartype
def read_method_external_identifiers_one(con: db.Connection, method_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             method_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             method_external_identifier_uri: Optional[str] = None) -> MethodExternalIdentifiers:
    """
    Read from the method_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    result = db.query_one(con, 'method_external_identifiers', data)
    return MethodExternalIdentifiers(**result)

@beartype.beartype
def read_method_external_identifiers_all(con: db.Connection, method_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             method_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             method_external_identifier_uri: Optional[str] = None) -> List[MethodExternalIdentifiers]:
    """
    Read from the method_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'external_identifier_system_id': external_identifier_system_id,
        'method_external_identifier': method_external_identifier,
        'method_external_identifier_uri': method_external_identifier_uri,
    }
    result = db.query(con, 'method_external_identifiers', data)
    return [MethodExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_method_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[MethodExternalIdentifiers]:
    result = db.query_one(con, 'method_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return MethodExternalIdentifiers(**result)

@beartype.beartype
def delete_method_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'method_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
MethodExternalIdentifiers.create_from_json_dict = create_method_external_identifiers_from_json_dict
MethodExternalIdentifiers.write = write_method_external_identifiers
MethodExternalIdentifiers.update = update_method_external_identifiers
MethodExternalIdentifiers.write_many = write_method_external_identifiers_many
MethodExternalIdentifiers.read = read_method_external_identifiers
MethodExternalIdentifiers.read_fuzzy = read_method_external_identifiers_fuzzy
MethodExternalIdentifiers.read_any = read_method_external_identifiers_any
MethodExternalIdentifiers.read_one = read_method_external_identifiers_one
MethodExternalIdentifiers.read_one_or_none = read_method_external_identifiers_one_or_none
MethodExternalIdentifiers.read_all = read_method_external_identifiers_all
MethodExternalIdentifiers.delete = delete_method_external_identifiers_by_id
MethodExternalIdentifiers.read_by_id = read_method_external_identifiers_by_id
MethodExternalIdentifiers.delete_by_id = delete_method_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PersonExternalIdentifiers:
    """
    Cross reference linking table to allow many to many 

    @param bridge_id 
    @param person_id 
    @param external_identifier_system_id 
    @param person_external_identifier 
    @param person_external_identifier_uri 

    This is an automatically generated class
    """
    person_id: int # person_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    person_external_identifier: str # person_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    person_external_identifier_uri: Optional[str] = None # person_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_person(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.person_id)

@beartype.beartype
def create_person_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a PersonExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return PersonExternalIdentifiers(**json_obj)


@beartype.beartype
def write_person_external_identifiers_obj(con: db.Connection, obj: PersonExternalIdentifiers) -> int:
    """
    Write a PersonExternalIdentifiers object to the database
    @param con: database connection
    @param obj: PersonExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'person_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_person_external_identifiers(
            con: db.Connection,
            person_id: int,
            external_identifier_system_id: int,
            person_external_identifier: str,
            bridge_id: Optional[int] = None,
            person_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the person_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param external_identifier_system_id 
    @param person_external_identifier 
    @param person_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    return db.upsert(con, 'person_external_identifiers', data)

@beartype.beartype
def write_person_external_identifiers_many(con: db.Connection, objs: List[PersonExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of PersonExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of PersonExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'person_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_person_external_identifiers(con: db.Connection, bridge_id: int,
            person_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            person_external_identifier: Optional[str] = None,
            person_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the person_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param external_identifier_system_id 
    @param person_external_identifier 
    @param person_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    return db.update(con, 'person_external_identifiers', data)

@beartype.beartype
def read_person_external_identifiers(
            con: db.Connection,
            person_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             person_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             person_external_identifier_uri: Optional[str] = None) -> Generator[PersonExternalIdentifiers, None, None]:
    """
    Read from the person_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param external_identifier_system_id 
    @param person_external_identifier 
    @param person_external_identifier_uri 
    @return generator of PersonExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    result = db.query(con, 'person_external_identifiers', data)
    for row in result:
        yield PersonExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_person_external_identifiers_fuzzy(con: db.Connection, person_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             person_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             person_external_identifier_uri: Optional[str] = None) -> Generator[PersonExternalIdentifiers, None, None]:
    """
    Read from the person_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param external_identifier_system_id 
    @param person_external_identifier 
    @param person_external_identifier_uri 
    @return generator of PersonExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'person_external_identifiers', data)
    for row in result:
        yield PersonExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_person_external_identifiers_any(con: db.Connection, person_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             person_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             person_external_identifier_uri: Optional[List[str]] = None) -> Generator[PersonExternalIdentifiers, None, None]:
    """
    Read from the person_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param person_id 
    @param external_identifier_system_id 
    @param person_external_identifier 
    @param person_external_identifier_uri 
    @return generator of PersonExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    result = db.query_any(con, 'person_external_identifiers', data)
    for row in result:
        yield PersonExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_person_external_identifiers_one_or_none(con: db.Connection, person_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             person_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             person_external_identifier_uri: Optional[str] = None) -> Optional[PersonExternalIdentifiers]:
    """
    Read from the person_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'person_external_identifiers', data)
    if result is None:
        return None
    return PersonExternalIdentifiers(**result)

@beartype.beartype
def read_person_external_identifiers_one(con: db.Connection, person_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             person_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             person_external_identifier_uri: Optional[str] = None) -> PersonExternalIdentifiers:
    """
    Read from the person_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    result = db.query_one(con, 'person_external_identifiers', data)
    return PersonExternalIdentifiers(**result)

@beartype.beartype
def read_person_external_identifiers_all(con: db.Connection, person_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             person_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             person_external_identifier_uri: Optional[str] = None) -> List[PersonExternalIdentifiers]:
    """
    Read from the person_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'person_id': person_id,
        'external_identifier_system_id': external_identifier_system_id,
        'person_external_identifier': person_external_identifier,
        'person_external_identifier_uri': person_external_identifier_uri,
    }
    result = db.query(con, 'person_external_identifiers', data)
    return [PersonExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_person_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[PersonExternalIdentifiers]:
    result = db.query_one(con, 'person_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return PersonExternalIdentifiers(**result)

@beartype.beartype
def delete_person_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'person_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
PersonExternalIdentifiers.create_from_json_dict = create_person_external_identifiers_from_json_dict
PersonExternalIdentifiers.write = write_person_external_identifiers
PersonExternalIdentifiers.update = update_person_external_identifiers
PersonExternalIdentifiers.write_many = write_person_external_identifiers_many
PersonExternalIdentifiers.read = read_person_external_identifiers
PersonExternalIdentifiers.read_fuzzy = read_person_external_identifiers_fuzzy
PersonExternalIdentifiers.read_any = read_person_external_identifiers_any
PersonExternalIdentifiers.read_one = read_person_external_identifiers_one
PersonExternalIdentifiers.read_one_or_none = read_person_external_identifiers_one_or_none
PersonExternalIdentifiers.read_all = read_person_external_identifiers_all
PersonExternalIdentifiers.delete = delete_person_external_identifiers_by_id
PersonExternalIdentifiers.read_by_id = read_person_external_identifiers_by_id
PersonExternalIdentifiers.delete_by_id = delete_person_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ActionExtensionPropertyValues:
    """
    @param bridge_id 
    @param action_id 
    @param property_id 
    @param property_value 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    property_id: int # property_id integer (default: )
    property_value: str # property_value character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_property(self, con: db.Connection) -> Optional['ExtensionProperties']:
        return read_extension_properties_one_or_none(con, property_id=self.property_id)

@beartype.beartype
def create_action_extension_property_values_from_json_dict(json_obj: dict):
        """
        Create a ActionExtensionPropertyValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ActionExtensionPropertyValues(**json_obj)


@beartype.beartype
def write_action_extension_property_values_obj(con: db.Connection, obj: ActionExtensionPropertyValues) -> int:
    """
    Write a ActionExtensionPropertyValues object to the database
    @param con: database connection
    @param obj: ActionExtensionPropertyValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'action_extension_property_values', dataclasses.asdict(obj))

@beartype.beartype
def write_action_extension_property_values(
            con: db.Connection,
            action_id: int,
            property_id: int,
            property_value: str,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the action_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param property_id 
    @param property_value 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.upsert(con, 'action_extension_property_values', data)

@beartype.beartype
def write_action_extension_property_values_many(con: db.Connection, objs: List[ActionExtensionPropertyValues], upsert: bool = False) -> int:
    """
    Write a list of ActionExtensionPropertyValues objects to the database
    @param con: database connection
    @param objs: list of ActionExtensionPropertyValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'action_extension_property_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_action_extension_property_values(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            property_id: Optional[int] = None,
            property_value: Optional[str] = None) -> int:
    """
    Update a row in the action_extension_property_values table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param property_id 
    @param property_value 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    return db.update(con, 'action_extension_property_values', data)

@beartype.beartype
def read_action_extension_property_values(
            con: db.Connection,
            action_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[ActionExtensionPropertyValues, None, None]:
    """
    Read from the action_extension_property_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param property_id 
    @param property_value 
    @return generator of ActionExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'action_extension_property_values', data)
    for row in result:
        yield ActionExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_action_extension_property_values_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Generator[ActionExtensionPropertyValues, None, None]:
    """
    Read from the action_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param property_id 
    @param property_value 
    @return generator of ActionExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_fuzzy(con, 'action_extension_property_values', data)
    for row in result:
        yield ActionExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_action_extension_property_values_any(con: db.Connection, action_id: Optional[List[int]] = None,
             property_id: Optional[List[int]] = None,
             property_value: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ActionExtensionPropertyValues, None, None]:
    """
    Read from the action_extension_property_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param property_id 
    @param property_value 
    @return generator of ActionExtensionPropertyValues objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_any(con, 'action_extension_property_values', data)
    for row in result:
        yield ActionExtensionPropertyValues(**row.as_dict())

@beartype.beartype
def read_action_extension_property_values_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> Optional[ActionExtensionPropertyValues]:
    """
    Read from the action_extension_property_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one_or_none(con, 'action_extension_property_values', data)
    if result is None:
        return None
    return ActionExtensionPropertyValues(**result)

@beartype.beartype
def read_action_extension_property_values_one(con: db.Connection, action_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> ActionExtensionPropertyValues:
    """
    Read from the action_extension_property_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query_one(con, 'action_extension_property_values', data)
    return ActionExtensionPropertyValues(**result)

@beartype.beartype
def read_action_extension_property_values_all(con: db.Connection, action_id: Optional[int] = None,
             property_id: Optional[int] = None,
             property_value: Optional[str] = None,
             bridge_id: Optional[int] = None) -> List[ActionExtensionPropertyValues]:
    """
    Read from the action_extension_property_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'property_id': property_id,
        'property_value': property_value,
    }
    result = db.query(con, 'action_extension_property_values', data)
    return [ActionExtensionPropertyValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_action_extension_property_values_by_id(con: db.Connection, bridge_id: int) -> Optional[ActionExtensionPropertyValues]:
    result = db.query_one(con, 'action_extension_property_values', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ActionExtensionPropertyValues(**result)

@beartype.beartype
def delete_action_extension_property_values_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'action_extension_property_values', {'bridge_id': bridge_id})
# Associate the functions with the class
ActionExtensionPropertyValues.create_from_json_dict = create_action_extension_property_values_from_json_dict
ActionExtensionPropertyValues.write = write_action_extension_property_values
ActionExtensionPropertyValues.update = update_action_extension_property_values
ActionExtensionPropertyValues.write_many = write_action_extension_property_values_many
ActionExtensionPropertyValues.read = read_action_extension_property_values
ActionExtensionPropertyValues.read_fuzzy = read_action_extension_property_values_fuzzy
ActionExtensionPropertyValues.read_any = read_action_extension_property_values_any
ActionExtensionPropertyValues.read_one = read_action_extension_property_values_one
ActionExtensionPropertyValues.read_one_or_none = read_action_extension_property_values_one_or_none
ActionExtensionPropertyValues.read_all = read_action_extension_property_values_all
ActionExtensionPropertyValues.delete = delete_action_extension_property_values_by_id
ActionExtensionPropertyValues.read_by_id = read_action_extension_property_values_by_id
ActionExtensionPropertyValues.delete_by_id = delete_action_extension_property_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ExtensionProperties:
    """
    Describes extension properties added to objects in an ODM database

    @param property_id 
    @param property_name 
    @param property_description 
    @param property_data_type_cv 
    @param property_units_id 

    This is an automatically generated class
    """
    property_name: str # property_name character varying (default: )
    property_data_type_cv: str # property_data_type_cv character varying (default: )
    property_id: Optional[int] = None # property_id integer (default: )
    property_description: Optional[str] = None # property_description character varying (default: )
    property_units_id: Optional[int] = None # property_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'property_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_property_data_type_cv(self, con: db.Connection) -> Optional['CvPropertyDataType']:
        return read_cv_property_data_type_one_or_none(con, term=self.property_data_type_cv)

@beartype.beartype
def create_extension_properties_from_json_dict(json_obj: dict):
        """
        Create a ExtensionProperties from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ExtensionProperties(**json_obj)


@beartype.beartype
def write_extension_properties_obj(con: db.Connection, obj: ExtensionProperties) -> int:
    """
    Write a ExtensionProperties object to the database
    @param con: database connection
    @param obj: ExtensionProperties object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'extension_properties', dataclasses.asdict(obj))

@beartype.beartype
def write_extension_properties(
            con: db.Connection,
            property_name: str,
            property_data_type_cv: str,
            property_id: Optional[int] = None,
            property_description: Optional[str] = None,
            property_units_id: Optional[int] = None) -> int:
    """
    Write to the extension_properties table in the database
    @param con: database connection
    @param property_id 
    @param property_name 
    @param property_description 
    @param property_data_type_cv 
    @param property_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    return db.upsert(con, 'extension_properties', data)

@beartype.beartype
def write_extension_properties_many(con: db.Connection, objs: List[ExtensionProperties], upsert: bool = False) -> int:
    """
    Write a list of ExtensionProperties objects to the database
    @param con: database connection
    @param objs: list of ExtensionProperties objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'extension_properties', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_extension_properties(con: db.Connection, property_id: int,
            property_name: Optional[str] = None,
            property_data_type_cv: Optional[str] = None,
            property_description: Optional[str] = None,
            property_units_id: Optional[int] = None) -> int:
    """
    Update a row in the extension_properties table in the database
    @param con: database connection
    @param property_id 
    @param property_name 
    @param property_description 
    @param property_data_type_cv 
    @param property_units_id 
    @return The number of rows updated
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    return db.update(con, 'extension_properties', data)

@beartype.beartype
def read_extension_properties(
            con: db.Connection,
            property_name: Optional[str] = None,
             property_data_type_cv: Optional[str] = None,
             property_id: Optional[int] = None,
             property_description: Optional[str] = None,
             property_units_id: Optional[int] = None) -> Generator[ExtensionProperties, None, None]:
    """
    Read from the extension_properties table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param property_id 
    @param property_name 
    @param property_description 
    @param property_data_type_cv 
    @param property_units_id 
    @return generator of ExtensionProperties objects
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    result = db.query(con, 'extension_properties', data)
    for row in result:
        yield ExtensionProperties(**row.as_dict())

@beartype.beartype
def read_extension_properties_fuzzy(con: db.Connection, property_name: Optional[str] = None,
             property_data_type_cv: Optional[str] = None,
             property_id: Optional[int] = None,
             property_description: Optional[str] = None,
             property_units_id: Optional[int] = None) -> Generator[ExtensionProperties, None, None]:
    """
    Read from the extension_properties table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param property_id 
    @param property_name 
    @param property_description 
    @param property_data_type_cv 
    @param property_units_id 
    @return generator of ExtensionProperties objects
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    result = db.query_fuzzy(con, 'extension_properties', data)
    for row in result:
        yield ExtensionProperties(**row.as_dict())

@beartype.beartype
def read_extension_properties_any(con: db.Connection, property_name: Optional[List[str]] = None,
             property_data_type_cv: Optional[List[str]] = None,
             property_id: Optional[List[int]] = None,
             property_description: Optional[List[str]] = None,
             property_units_id: Optional[List[int]] = None) -> Generator[ExtensionProperties, None, None]:
    """
    Read from the extension_properties table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param property_id 
    @param property_name 
    @param property_description 
    @param property_data_type_cv 
    @param property_units_id 
    @return generator of ExtensionProperties objects
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    result = db.query_any(con, 'extension_properties', data)
    for row in result:
        yield ExtensionProperties(**row.as_dict())

@beartype.beartype
def read_extension_properties_one_or_none(con: db.Connection, property_name: Optional[str] = None,
             property_data_type_cv: Optional[str] = None,
             property_id: Optional[int] = None,
             property_description: Optional[str] = None,
             property_units_id: Optional[int] = None) -> Optional[ExtensionProperties]:
    """
    Read from the extension_properties table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    result = db.query_one_or_none(con, 'extension_properties', data)
    if result is None:
        return None
    return ExtensionProperties(**result)

@beartype.beartype
def read_extension_properties_one(con: db.Connection, property_name: Optional[str] = None,
             property_data_type_cv: Optional[str] = None,
             property_id: Optional[int] = None,
             property_description: Optional[str] = None,
             property_units_id: Optional[int] = None) -> ExtensionProperties:
    """
    Read from the extension_properties table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    result = db.query_one(con, 'extension_properties', data)
    return ExtensionProperties(**result)

@beartype.beartype
def read_extension_properties_all(con: db.Connection, property_name: Optional[str] = None,
             property_data_type_cv: Optional[str] = None,
             property_id: Optional[int] = None,
             property_description: Optional[str] = None,
             property_units_id: Optional[int] = None) -> List[ExtensionProperties]:
    """
    Read from the extension_properties table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'property_id': property_id,
        'property_name': property_name,
        'property_description': property_description,
        'property_data_type_cv': property_data_type_cv,
        'property_units_id': property_units_id,
    }
    result = db.query(con, 'extension_properties', data)
    return [ExtensionProperties(**row.as_dict()) for row in result]

@beartype.beartype
def read_extension_properties_by_id(con: db.Connection, property_id: int) -> Optional[ExtensionProperties]:
    result = db.query_one(con, 'extension_properties', {'property_id': property_id})
    if result is None:
        return None
    return ExtensionProperties(**result)

@beartype.beartype
def delete_extension_properties_by_id(con: db.Connection, property_id: int):
    db.delete(con, 'extension_properties', {'property_id': property_id})
# Associate the functions with the class
ExtensionProperties.create_from_json_dict = create_extension_properties_from_json_dict
ExtensionProperties.write = write_extension_properties
ExtensionProperties.update = update_extension_properties
ExtensionProperties.write_many = write_extension_properties_many
ExtensionProperties.read = read_extension_properties
ExtensionProperties.read_fuzzy = read_extension_properties_fuzzy
ExtensionProperties.read_any = read_extension_properties_any
ExtensionProperties.read_one = read_extension_properties_one
ExtensionProperties.read_one_or_none = read_extension_properties_one_or_none
ExtensionProperties.read_all = read_extension_properties_all
ExtensionProperties.delete = delete_extension_properties_by_id
ExtensionProperties.read_by_id = read_extension_properties_by_id
ExtensionProperties.delete_by_id = delete_extension_properties_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpatialReferenceExternalIdentifiers:
    """
    @param bridge_id 
    @param spatial_reference_id 
    @param external_identifier_system_id 
    @param spatial_reference_external_identifier 
    @param spatial_reference_external_identifier_uri 

    This is an automatically generated class
    """
    spatial_reference_id: int # spatial_reference_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    spatial_reference_external_identifier: str # spatial_reference_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    spatial_reference_external_identifier_uri: Optional[str] = None # spatial_reference_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_spatial_reference_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a SpatialReferenceExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpatialReferenceExternalIdentifiers(**json_obj)


@beartype.beartype
def write_spatial_reference_external_identifiers_obj(con: db.Connection, obj: SpatialReferenceExternalIdentifiers) -> int:
    """
    Write a SpatialReferenceExternalIdentifiers object to the database
    @param con: database connection
    @param obj: SpatialReferenceExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'spatial_reference_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_spatial_reference_external_identifiers(
            con: db.Connection,
            spatial_reference_id: int,
            external_identifier_system_id: int,
            spatial_reference_external_identifier: str,
            bridge_id: Optional[int] = None,
            spatial_reference_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the spatial_reference_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param spatial_reference_id 
    @param external_identifier_system_id 
    @param spatial_reference_external_identifier 
    @param spatial_reference_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    return db.upsert(con, 'spatial_reference_external_identifiers', data)

@beartype.beartype
def write_spatial_reference_external_identifiers_many(con: db.Connection, objs: List[SpatialReferenceExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of SpatialReferenceExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of SpatialReferenceExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'spatial_reference_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_spatial_reference_external_identifiers(con: db.Connection, bridge_id: int,
            spatial_reference_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            spatial_reference_external_identifier: Optional[str] = None,
            spatial_reference_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the spatial_reference_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param spatial_reference_id 
    @param external_identifier_system_id 
    @param spatial_reference_external_identifier 
    @param spatial_reference_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    return db.update(con, 'spatial_reference_external_identifiers', data)

@beartype.beartype
def read_spatial_reference_external_identifiers(
            con: db.Connection,
            spatial_reference_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             spatial_reference_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             spatial_reference_external_identifier_uri: Optional[str] = None) -> Generator[SpatialReferenceExternalIdentifiers, None, None]:
    """
    Read from the spatial_reference_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param spatial_reference_id 
    @param external_identifier_system_id 
    @param spatial_reference_external_identifier 
    @param spatial_reference_external_identifier_uri 
    @return generator of SpatialReferenceExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    result = db.query(con, 'spatial_reference_external_identifiers', data)
    for row in result:
        yield SpatialReferenceExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_spatial_reference_external_identifiers_fuzzy(con: db.Connection, spatial_reference_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             spatial_reference_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             spatial_reference_external_identifier_uri: Optional[str] = None) -> Generator[SpatialReferenceExternalIdentifiers, None, None]:
    """
    Read from the spatial_reference_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param spatial_reference_id 
    @param external_identifier_system_id 
    @param spatial_reference_external_identifier 
    @param spatial_reference_external_identifier_uri 
    @return generator of SpatialReferenceExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'spatial_reference_external_identifiers', data)
    for row in result:
        yield SpatialReferenceExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_spatial_reference_external_identifiers_any(con: db.Connection, spatial_reference_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             spatial_reference_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             spatial_reference_external_identifier_uri: Optional[List[str]] = None) -> Generator[SpatialReferenceExternalIdentifiers, None, None]:
    """
    Read from the spatial_reference_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param spatial_reference_id 
    @param external_identifier_system_id 
    @param spatial_reference_external_identifier 
    @param spatial_reference_external_identifier_uri 
    @return generator of SpatialReferenceExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    result = db.query_any(con, 'spatial_reference_external_identifiers', data)
    for row in result:
        yield SpatialReferenceExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_spatial_reference_external_identifiers_one_or_none(con: db.Connection, spatial_reference_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             spatial_reference_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             spatial_reference_external_identifier_uri: Optional[str] = None) -> Optional[SpatialReferenceExternalIdentifiers]:
    """
    Read from the spatial_reference_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'spatial_reference_external_identifiers', data)
    if result is None:
        return None
    return SpatialReferenceExternalIdentifiers(**result)

@beartype.beartype
def read_spatial_reference_external_identifiers_one(con: db.Connection, spatial_reference_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             spatial_reference_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             spatial_reference_external_identifier_uri: Optional[str] = None) -> SpatialReferenceExternalIdentifiers:
    """
    Read from the spatial_reference_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    result = db.query_one(con, 'spatial_reference_external_identifiers', data)
    return SpatialReferenceExternalIdentifiers(**result)

@beartype.beartype
def read_spatial_reference_external_identifiers_all(con: db.Connection, spatial_reference_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             spatial_reference_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             spatial_reference_external_identifier_uri: Optional[str] = None) -> List[SpatialReferenceExternalIdentifiers]:
    """
    Read from the spatial_reference_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'spatial_reference_id': spatial_reference_id,
        'external_identifier_system_id': external_identifier_system_id,
        'spatial_reference_external_identifier': spatial_reference_external_identifier,
        'spatial_reference_external_identifier_uri': spatial_reference_external_identifier_uri,
    }
    result = db.query(con, 'spatial_reference_external_identifiers', data)
    return [SpatialReferenceExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_spatial_reference_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[SpatialReferenceExternalIdentifiers]:
    result = db.query_one(con, 'spatial_reference_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SpatialReferenceExternalIdentifiers(**result)

@beartype.beartype
def delete_spatial_reference_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'spatial_reference_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
SpatialReferenceExternalIdentifiers.create_from_json_dict = create_spatial_reference_external_identifiers_from_json_dict
SpatialReferenceExternalIdentifiers.write = write_spatial_reference_external_identifiers
SpatialReferenceExternalIdentifiers.update = update_spatial_reference_external_identifiers
SpatialReferenceExternalIdentifiers.write_many = write_spatial_reference_external_identifiers_many
SpatialReferenceExternalIdentifiers.read = read_spatial_reference_external_identifiers
SpatialReferenceExternalIdentifiers.read_fuzzy = read_spatial_reference_external_identifiers_fuzzy
SpatialReferenceExternalIdentifiers.read_any = read_spatial_reference_external_identifiers_any
SpatialReferenceExternalIdentifiers.read_one = read_spatial_reference_external_identifiers_one
SpatialReferenceExternalIdentifiers.read_one_or_none = read_spatial_reference_external_identifiers_one_or_none
SpatialReferenceExternalIdentifiers.read_all = read_spatial_reference_external_identifiers_all
SpatialReferenceExternalIdentifiers.delete = delete_spatial_reference_external_identifiers_by_id
SpatialReferenceExternalIdentifiers.read_by_id = read_spatial_reference_external_identifiers_by_id
SpatialReferenceExternalIdentifiers.delete_by_id = delete_spatial_reference_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TaxonomicClassifierExternalIdentifiers:
    """
    @param bridge_id 
    @param taxonomic_classifier_id 
    @param external_identifier_system_id 
    @param taxonomic_classifier_external_identifier 
    @param taxonomic_classifier_external_identifier_uri 

    This is an automatically generated class
    """
    taxonomic_classifier_id: int # taxonomic_classifier_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    taxonomic_classifier_external_identifier: str # taxonomic_classifier_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    taxonomic_classifier_external_identifier_uri: Optional[str] = None # taxonomic_classifier_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_taxonomic_classifier(self, con: db.Connection) -> Optional['TaxonomicClassifiers']:
        return read_taxonomic_classifiers_one_or_none(con, taxonomic_classifier_id=self.taxonomic_classifier_id)

@beartype.beartype
def create_taxonomic_classifier_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a TaxonomicClassifierExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TaxonomicClassifierExternalIdentifiers(**json_obj)


@beartype.beartype
def write_taxonomic_classifier_external_identifiers_obj(con: db.Connection, obj: TaxonomicClassifierExternalIdentifiers) -> int:
    """
    Write a TaxonomicClassifierExternalIdentifiers object to the database
    @param con: database connection
    @param obj: TaxonomicClassifierExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'taxonomic_classifier_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_taxonomic_classifier_external_identifiers(
            con: db.Connection,
            taxonomic_classifier_id: int,
            external_identifier_system_id: int,
            taxonomic_classifier_external_identifier: str,
            bridge_id: Optional[int] = None,
            taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the taxonomic_classifier_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param taxonomic_classifier_id 
    @param external_identifier_system_id 
    @param taxonomic_classifier_external_identifier 
    @param taxonomic_classifier_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    return db.upsert(con, 'taxonomic_classifier_external_identifiers', data)

@beartype.beartype
def write_taxonomic_classifier_external_identifiers_many(con: db.Connection, objs: List[TaxonomicClassifierExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of TaxonomicClassifierExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of TaxonomicClassifierExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'taxonomic_classifier_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_taxonomic_classifier_external_identifiers(con: db.Connection, bridge_id: int,
            taxonomic_classifier_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            taxonomic_classifier_external_identifier: Optional[str] = None,
            taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the taxonomic_classifier_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param taxonomic_classifier_id 
    @param external_identifier_system_id 
    @param taxonomic_classifier_external_identifier 
    @param taxonomic_classifier_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    return db.update(con, 'taxonomic_classifier_external_identifiers', data)

@beartype.beartype
def read_taxonomic_classifier_external_identifiers(
            con: db.Connection,
            taxonomic_classifier_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             taxonomic_classifier_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> Generator[TaxonomicClassifierExternalIdentifiers, None, None]:
    """
    Read from the taxonomic_classifier_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param taxonomic_classifier_id 
    @param external_identifier_system_id 
    @param taxonomic_classifier_external_identifier 
    @param taxonomic_classifier_external_identifier_uri 
    @return generator of TaxonomicClassifierExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    result = db.query(con, 'taxonomic_classifier_external_identifiers', data)
    for row in result:
        yield TaxonomicClassifierExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_taxonomic_classifier_external_identifiers_fuzzy(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             taxonomic_classifier_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> Generator[TaxonomicClassifierExternalIdentifiers, None, None]:
    """
    Read from the taxonomic_classifier_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param taxonomic_classifier_id 
    @param external_identifier_system_id 
    @param taxonomic_classifier_external_identifier 
    @param taxonomic_classifier_external_identifier_uri 
    @return generator of TaxonomicClassifierExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'taxonomic_classifier_external_identifiers', data)
    for row in result:
        yield TaxonomicClassifierExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_taxonomic_classifier_external_identifiers_any(con: db.Connection, taxonomic_classifier_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             taxonomic_classifier_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             taxonomic_classifier_external_identifier_uri: Optional[List[str]] = None) -> Generator[TaxonomicClassifierExternalIdentifiers, None, None]:
    """
    Read from the taxonomic_classifier_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param taxonomic_classifier_id 
    @param external_identifier_system_id 
    @param taxonomic_classifier_external_identifier 
    @param taxonomic_classifier_external_identifier_uri 
    @return generator of TaxonomicClassifierExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    result = db.query_any(con, 'taxonomic_classifier_external_identifiers', data)
    for row in result:
        yield TaxonomicClassifierExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_taxonomic_classifier_external_identifiers_one_or_none(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             taxonomic_classifier_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> Optional[TaxonomicClassifierExternalIdentifiers]:
    """
    Read from the taxonomic_classifier_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'taxonomic_classifier_external_identifiers', data)
    if result is None:
        return None
    return TaxonomicClassifierExternalIdentifiers(**result)

@beartype.beartype
def read_taxonomic_classifier_external_identifiers_one(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             taxonomic_classifier_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> TaxonomicClassifierExternalIdentifiers:
    """
    Read from the taxonomic_classifier_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    result = db.query_one(con, 'taxonomic_classifier_external_identifiers', data)
    return TaxonomicClassifierExternalIdentifiers(**result)

@beartype.beartype
def read_taxonomic_classifier_external_identifiers_all(con: db.Connection, taxonomic_classifier_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             taxonomic_classifier_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             taxonomic_classifier_external_identifier_uri: Optional[str] = None) -> List[TaxonomicClassifierExternalIdentifiers]:
    """
    Read from the taxonomic_classifier_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'external_identifier_system_id': external_identifier_system_id,
        'taxonomic_classifier_external_identifier': taxonomic_classifier_external_identifier,
        'taxonomic_classifier_external_identifier_uri': taxonomic_classifier_external_identifier_uri,
    }
    result = db.query(con, 'taxonomic_classifier_external_identifiers', data)
    return [TaxonomicClassifierExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_taxonomic_classifier_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[TaxonomicClassifierExternalIdentifiers]:
    result = db.query_one(con, 'taxonomic_classifier_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return TaxonomicClassifierExternalIdentifiers(**result)

@beartype.beartype
def delete_taxonomic_classifier_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'taxonomic_classifier_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
TaxonomicClassifierExternalIdentifiers.create_from_json_dict = create_taxonomic_classifier_external_identifiers_from_json_dict
TaxonomicClassifierExternalIdentifiers.write = write_taxonomic_classifier_external_identifiers
TaxonomicClassifierExternalIdentifiers.update = update_taxonomic_classifier_external_identifiers
TaxonomicClassifierExternalIdentifiers.write_many = write_taxonomic_classifier_external_identifiers_many
TaxonomicClassifierExternalIdentifiers.read = read_taxonomic_classifier_external_identifiers
TaxonomicClassifierExternalIdentifiers.read_fuzzy = read_taxonomic_classifier_external_identifiers_fuzzy
TaxonomicClassifierExternalIdentifiers.read_any = read_taxonomic_classifier_external_identifiers_any
TaxonomicClassifierExternalIdentifiers.read_one = read_taxonomic_classifier_external_identifiers_one
TaxonomicClassifierExternalIdentifiers.read_one_or_none = read_taxonomic_classifier_external_identifiers_one_or_none
TaxonomicClassifierExternalIdentifiers.read_all = read_taxonomic_classifier_external_identifiers_all
TaxonomicClassifierExternalIdentifiers.delete = delete_taxonomic_classifier_external_identifiers_by_id
TaxonomicClassifierExternalIdentifiers.read_by_id = read_taxonomic_classifier_external_identifiers_by_id
TaxonomicClassifierExternalIdentifiers.delete_by_id = delete_taxonomic_classifier_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class VariableExternalIdentifiers:
    """
    @param bridge_id 
    @param variable_id 
    @param external_identifier_system_id 
    @param variable_external_identifier 
    @param variable_external_identifier_uri 

    This is an automatically generated class
    """
    variable_id: int # variable_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    variable_external_identifier: str # variable_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    variable_external_identifier_uri: Optional[str] = None # variable_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_variable_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a VariableExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return VariableExternalIdentifiers(**json_obj)


@beartype.beartype
def write_variable_external_identifiers_obj(con: db.Connection, obj: VariableExternalIdentifiers) -> int:
    """
    Write a VariableExternalIdentifiers object to the database
    @param con: database connection
    @param obj: VariableExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'variable_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_variable_external_identifiers(
            con: db.Connection,
            variable_id: int,
            external_identifier_system_id: int,
            variable_external_identifier: str,
            bridge_id: Optional[int] = None,
            variable_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the variable_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param external_identifier_system_id 
    @param variable_external_identifier 
    @param variable_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    return db.upsert(con, 'variable_external_identifiers', data)

@beartype.beartype
def write_variable_external_identifiers_many(con: db.Connection, objs: List[VariableExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of VariableExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of VariableExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'variable_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_variable_external_identifiers(con: db.Connection, bridge_id: int,
            variable_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            variable_external_identifier: Optional[str] = None,
            variable_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the variable_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param external_identifier_system_id 
    @param variable_external_identifier 
    @param variable_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    return db.update(con, 'variable_external_identifiers', data)

@beartype.beartype
def read_variable_external_identifiers(
            con: db.Connection,
            variable_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             variable_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             variable_external_identifier_uri: Optional[str] = None) -> Generator[VariableExternalIdentifiers, None, None]:
    """
    Read from the variable_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param external_identifier_system_id 
    @param variable_external_identifier 
    @param variable_external_identifier_uri 
    @return generator of VariableExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    result = db.query(con, 'variable_external_identifiers', data)
    for row in result:
        yield VariableExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_variable_external_identifiers_fuzzy(con: db.Connection, variable_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             variable_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             variable_external_identifier_uri: Optional[str] = None) -> Generator[VariableExternalIdentifiers, None, None]:
    """
    Read from the variable_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param external_identifier_system_id 
    @param variable_external_identifier 
    @param variable_external_identifier_uri 
    @return generator of VariableExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'variable_external_identifiers', data)
    for row in result:
        yield VariableExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_variable_external_identifiers_any(con: db.Connection, variable_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             variable_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             variable_external_identifier_uri: Optional[List[str]] = None) -> Generator[VariableExternalIdentifiers, None, None]:
    """
    Read from the variable_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param variable_id 
    @param external_identifier_system_id 
    @param variable_external_identifier 
    @param variable_external_identifier_uri 
    @return generator of VariableExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    result = db.query_any(con, 'variable_external_identifiers', data)
    for row in result:
        yield VariableExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_variable_external_identifiers_one_or_none(con: db.Connection, variable_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             variable_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             variable_external_identifier_uri: Optional[str] = None) -> Optional[VariableExternalIdentifiers]:
    """
    Read from the variable_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'variable_external_identifiers', data)
    if result is None:
        return None
    return VariableExternalIdentifiers(**result)

@beartype.beartype
def read_variable_external_identifiers_one(con: db.Connection, variable_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             variable_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             variable_external_identifier_uri: Optional[str] = None) -> VariableExternalIdentifiers:
    """
    Read from the variable_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    result = db.query_one(con, 'variable_external_identifiers', data)
    return VariableExternalIdentifiers(**result)

@beartype.beartype
def read_variable_external_identifiers_all(con: db.Connection, variable_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             variable_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             variable_external_identifier_uri: Optional[str] = None) -> List[VariableExternalIdentifiers]:
    """
    Read from the variable_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'variable_id': variable_id,
        'external_identifier_system_id': external_identifier_system_id,
        'variable_external_identifier': variable_external_identifier,
        'variable_external_identifier_uri': variable_external_identifier_uri,
    }
    result = db.query(con, 'variable_external_identifiers', data)
    return [VariableExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_variable_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[VariableExternalIdentifiers]:
    result = db.query_one(con, 'variable_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return VariableExternalIdentifiers(**result)

@beartype.beartype
def delete_variable_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'variable_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
VariableExternalIdentifiers.create_from_json_dict = create_variable_external_identifiers_from_json_dict
VariableExternalIdentifiers.write = write_variable_external_identifiers
VariableExternalIdentifiers.update = update_variable_external_identifiers
VariableExternalIdentifiers.write_many = write_variable_external_identifiers_many
VariableExternalIdentifiers.read = read_variable_external_identifiers
VariableExternalIdentifiers.read_fuzzy = read_variable_external_identifiers_fuzzy
VariableExternalIdentifiers.read_any = read_variable_external_identifiers_any
VariableExternalIdentifiers.read_one = read_variable_external_identifiers_one
VariableExternalIdentifiers.read_one_or_none = read_variable_external_identifiers_one_or_none
VariableExternalIdentifiers.read_all = read_variable_external_identifiers_all
VariableExternalIdentifiers.delete = delete_variable_external_identifiers_by_id
VariableExternalIdentifiers.read_by_id = read_variable_external_identifiers_by_id
VariableExternalIdentifiers.delete_by_id = delete_variable_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ActionDirectives:
    """
    @param bridge_id 
    @param action_id 
    @param directive_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    directive_id: int # directive_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_directive(self, con: db.Connection) -> Optional['Directives']:
        return read_directives_one_or_none(con, directive_id=self.directive_id)

@beartype.beartype
def create_action_directives_from_json_dict(json_obj: dict):
        """
        Create a ActionDirectives from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ActionDirectives(**json_obj)


@beartype.beartype
def write_action_directives_obj(con: db.Connection, obj: ActionDirectives) -> int:
    """
    Write a ActionDirectives object to the database
    @param con: database connection
    @param obj: ActionDirectives object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'action_directives', dataclasses.asdict(obj))

@beartype.beartype
def write_action_directives(
            con: db.Connection,
            action_id: int,
            directive_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the action_directives table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param directive_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    return db.upsert(con, 'action_directives', data)

@beartype.beartype
def write_action_directives_many(con: db.Connection, objs: List[ActionDirectives], upsert: bool = False) -> int:
    """
    Write a list of ActionDirectives objects to the database
    @param con: database connection
    @param objs: list of ActionDirectives objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'action_directives', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_action_directives(con: db.Connection, bridge_id: int,
            action_id: Optional[int] = None,
            directive_id: Optional[int] = None) -> int:
    """
    Update a row in the action_directives table in the database
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param directive_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    return db.update(con, 'action_directives', data)

@beartype.beartype
def read_action_directives(
            con: db.Connection,
            action_id: Optional[int] = None,
             directive_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ActionDirectives, None, None]:
    """
    Read from the action_directives table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param directive_id 
    @return generator of ActionDirectives objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    result = db.query(con, 'action_directives', data)
    for row in result:
        yield ActionDirectives(**row.as_dict())

@beartype.beartype
def read_action_directives_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             directive_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[ActionDirectives, None, None]:
    """
    Read from the action_directives table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param directive_id 
    @return generator of ActionDirectives objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    result = db.query_fuzzy(con, 'action_directives', data)
    for row in result:
        yield ActionDirectives(**row.as_dict())

@beartype.beartype
def read_action_directives_any(con: db.Connection, action_id: Optional[List[int]] = None,
             directive_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[ActionDirectives, None, None]:
    """
    Read from the action_directives table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param action_id 
    @param directive_id 
    @return generator of ActionDirectives objects
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    result = db.query_any(con, 'action_directives', data)
    for row in result:
        yield ActionDirectives(**row.as_dict())

@beartype.beartype
def read_action_directives_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             directive_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[ActionDirectives]:
    """
    Read from the action_directives table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    result = db.query_one_or_none(con, 'action_directives', data)
    if result is None:
        return None
    return ActionDirectives(**result)

@beartype.beartype
def read_action_directives_one(con: db.Connection, action_id: Optional[int] = None,
             directive_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> ActionDirectives:
    """
    Read from the action_directives table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    result = db.query_one(con, 'action_directives', data)
    return ActionDirectives(**result)

@beartype.beartype
def read_action_directives_all(con: db.Connection, action_id: Optional[int] = None,
             directive_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[ActionDirectives]:
    """
    Read from the action_directives table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'action_id': action_id,
        'directive_id': directive_id,
    }
    result = db.query(con, 'action_directives', data)
    return [ActionDirectives(**row.as_dict()) for row in result]

@beartype.beartype
def read_action_directives_by_id(con: db.Connection, bridge_id: int) -> Optional[ActionDirectives]:
    result = db.query_one(con, 'action_directives', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ActionDirectives(**result)

@beartype.beartype
def delete_action_directives_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'action_directives', {'bridge_id': bridge_id})
# Associate the functions with the class
ActionDirectives.create_from_json_dict = create_action_directives_from_json_dict
ActionDirectives.write = write_action_directives
ActionDirectives.update = update_action_directives
ActionDirectives.write_many = write_action_directives_many
ActionDirectives.read = read_action_directives
ActionDirectives.read_fuzzy = read_action_directives_fuzzy
ActionDirectives.read_any = read_action_directives_any
ActionDirectives.read_one = read_action_directives_one
ActionDirectives.read_one_or_none = read_action_directives_one_or_none
ActionDirectives.read_all = read_action_directives_all
ActionDirectives.delete = delete_action_directives_by_id
ActionDirectives.read_by_id = read_action_directives_by_id
ActionDirectives.delete_by_id = delete_action_directives_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpecimenBatchPositions:
    """
    Extends the FeatureActions table with a foreign key when the optional LabAnalyses schema is implemented.  In a database implementation, we would not implement this as a separate table from FeatureActions, but rather just add the additional field(s).

    @param feature_action_id 
    @param batch_position_number 
    @param batch_position_label 

    This is an automatically generated class
    """
    feature_action_id: int # feature_action_id integer (default: )
    batch_position_number: int # batch_position_number integer (default: )
    batch_position_label: Optional[str] = None # batch_position_label character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'feature_action_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_feature_action(self, con: db.Connection) -> Optional['FeatureActions']:
        return read_feature_actions_one_or_none(con, feature_action_id=self.feature_action_id)

@beartype.beartype
def create_specimen_batch_positions_from_json_dict(json_obj: dict):
        """
        Create a SpecimenBatchPositions from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpecimenBatchPositions(**json_obj)


@beartype.beartype
def write_specimen_batch_positions_obj(con: db.Connection, obj: SpecimenBatchPositions) -> int:
    """
    Write a SpecimenBatchPositions object to the database
    @param con: database connection
    @param obj: SpecimenBatchPositions object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'specimen_batch_positions', dataclasses.asdict(obj))

@beartype.beartype
def write_specimen_batch_positions(
            con: db.Connection,
            feature_action_id: int,
            batch_position_number: int,
            batch_position_label: Optional[str] = None) -> int:
    """
    Write to the specimen_batch_positions table in the database
    @param con: database connection
    @param feature_action_id 
    @param batch_position_number 
    @param batch_position_label 
    @return id of the inserted/updated row
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    return db.upsert(con, 'specimen_batch_positions', data)

@beartype.beartype
def write_specimen_batch_positions_many(con: db.Connection, objs: List[SpecimenBatchPositions], upsert: bool = False) -> int:
    """
    Write a list of SpecimenBatchPositions objects to the database
    @param con: database connection
    @param objs: list of SpecimenBatchPositions objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'specimen_batch_positions', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_specimen_batch_positions(con: db.Connection, feature_action_id: int,
            batch_position_number: Optional[int] = None,
            batch_position_label: Optional[str] = None) -> int:
    """
    Update a row in the specimen_batch_positions table in the database
    @param con: database connection
    @param feature_action_id 
    @param batch_position_number 
    @param batch_position_label 
    @return The number of rows updated
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    return db.update(con, 'specimen_batch_positions', data)

@beartype.beartype
def read_specimen_batch_positions(
            con: db.Connection,
            feature_action_id: Optional[int] = None,
             batch_position_number: Optional[int] = None,
             batch_position_label: Optional[str] = None) -> Generator[SpecimenBatchPositions, None, None]:
    """
    Read from the specimen_batch_positions table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param feature_action_id 
    @param batch_position_number 
    @param batch_position_label 
    @return generator of SpecimenBatchPositions objects
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    result = db.query(con, 'specimen_batch_positions', data)
    for row in result:
        yield SpecimenBatchPositions(**row.as_dict())

@beartype.beartype
def read_specimen_batch_positions_fuzzy(con: db.Connection, feature_action_id: Optional[int] = None,
             batch_position_number: Optional[int] = None,
             batch_position_label: Optional[str] = None) -> Generator[SpecimenBatchPositions, None, None]:
    """
    Read from the specimen_batch_positions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param feature_action_id 
    @param batch_position_number 
    @param batch_position_label 
    @return generator of SpecimenBatchPositions objects
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    result = db.query_fuzzy(con, 'specimen_batch_positions', data)
    for row in result:
        yield SpecimenBatchPositions(**row.as_dict())

@beartype.beartype
def read_specimen_batch_positions_any(con: db.Connection, feature_action_id: Optional[List[int]] = None,
             batch_position_number: Optional[List[int]] = None,
             batch_position_label: Optional[List[str]] = None) -> Generator[SpecimenBatchPositions, None, None]:
    """
    Read from the specimen_batch_positions table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param feature_action_id 
    @param batch_position_number 
    @param batch_position_label 
    @return generator of SpecimenBatchPositions objects
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    result = db.query_any(con, 'specimen_batch_positions', data)
    for row in result:
        yield SpecimenBatchPositions(**row.as_dict())

@beartype.beartype
def read_specimen_batch_positions_one_or_none(con: db.Connection, feature_action_id: Optional[int] = None,
             batch_position_number: Optional[int] = None,
             batch_position_label: Optional[str] = None) -> Optional[SpecimenBatchPositions]:
    """
    Read from the specimen_batch_positions table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    result = db.query_one_or_none(con, 'specimen_batch_positions', data)
    if result is None:
        return None
    return SpecimenBatchPositions(**result)

@beartype.beartype
def read_specimen_batch_positions_one(con: db.Connection, feature_action_id: Optional[int] = None,
             batch_position_number: Optional[int] = None,
             batch_position_label: Optional[str] = None) -> SpecimenBatchPositions:
    """
    Read from the specimen_batch_positions table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    result = db.query_one(con, 'specimen_batch_positions', data)
    return SpecimenBatchPositions(**result)

@beartype.beartype
def read_specimen_batch_positions_all(con: db.Connection, feature_action_id: Optional[int] = None,
             batch_position_number: Optional[int] = None,
             batch_position_label: Optional[str] = None) -> List[SpecimenBatchPositions]:
    """
    Read from the specimen_batch_positions table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'feature_action_id': feature_action_id,
        'batch_position_number': batch_position_number,
        'batch_position_label': batch_position_label,
    }
    result = db.query(con, 'specimen_batch_positions', data)
    return [SpecimenBatchPositions(**row.as_dict()) for row in result]

@beartype.beartype
def read_specimen_batch_positions_by_id(con: db.Connection, feature_action_id: int) -> Optional[SpecimenBatchPositions]:
    result = db.query_one(con, 'specimen_batch_positions', {'feature_action_id': feature_action_id})
    if result is None:
        return None
    return SpecimenBatchPositions(**result)

@beartype.beartype
def delete_specimen_batch_positions_by_id(con: db.Connection, feature_action_id: int):
    db.delete(con, 'specimen_batch_positions', {'feature_action_id': feature_action_id})
# Associate the functions with the class
SpecimenBatchPositions.create_from_json_dict = create_specimen_batch_positions_from_json_dict
SpecimenBatchPositions.write = write_specimen_batch_positions
SpecimenBatchPositions.update = update_specimen_batch_positions
SpecimenBatchPositions.write_many = write_specimen_batch_positions_many
SpecimenBatchPositions.read = read_specimen_batch_positions
SpecimenBatchPositions.read_fuzzy = read_specimen_batch_positions_fuzzy
SpecimenBatchPositions.read_any = read_specimen_batch_positions_any
SpecimenBatchPositions.read_one = read_specimen_batch_positions_one
SpecimenBatchPositions.read_one_or_none = read_specimen_batch_positions_one_or_none
SpecimenBatchPositions.read_all = read_specimen_batch_positions_all
SpecimenBatchPositions.delete = delete_specimen_batch_positions_by_id
SpecimenBatchPositions.read_by_id = read_specimen_batch_positions_by_id
SpecimenBatchPositions.delete_by_id = delete_specimen_batch_positions_by_id



@beartype_wrap_init
@dataclasses.dataclass
class AssemblyEvent:
    """
    @param assembly_event_id 
    @param method 
    @param assembly_event_date 
    @param assembly_event_date_utc_offset 
    @param version 
    @param assembly_event_type 
    @param qcd_reads_id 

    This is an automatically generated class
    """
    assembly_event_id: int # assembly_event_id integer (default: )
    method: Optional[str] = None # method character varying (default: )
    assembly_event_date: Optional[datetime.datetime] = None # assembly_event_date timestamp without time zone (default: )
    assembly_event_date_utc_offset: Optional[int] = None # assembly_event_date_utc_offset integer (default: )
    version: Optional[str] = None # version character varying (default: )
    assembly_event_type: Optional[str] = None # assembly_event_type character varying (default: )
    qcd_reads_id: Optional[int] = None # qcd_reads_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'assembly_event_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.assembly_event_date is not None:
            obj['assembly_event_date'] = self.assembly_event_date.isoformat()
        return obj

@beartype.beartype
def create_assembly_event_from_json_dict(json_obj: dict):
        """
        Create a AssemblyEvent from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'assembly_event_date' in json_obj and json_obj['assembly_event_date'] is not None:
            json_obj['assembly_event_date'] = datetime.datetime.fromisoformat(json_obj['assembly_event_date'])
        return AssemblyEvent(**json_obj)


@beartype.beartype
def write_assembly_event_obj(con: db.Connection, obj: AssemblyEvent) -> int:
    """
    Write a AssemblyEvent object to the database
    @param con: database connection
    @param obj: AssemblyEvent object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'assembly_event', dataclasses.asdict(obj))

@beartype.beartype
def write_assembly_event(
            con: db.Connection,
            assembly_event_id: int,
            method: Optional[str] = None,
            assembly_event_date: Optional[datetime.datetime] = None,
            assembly_event_date_utc_offset: Optional[int] = None,
            version: Optional[str] = None,
            assembly_event_type: Optional[str] = None,
            qcd_reads_id: Optional[int] = None) -> int:
    """
    Write to the assembly_event table in the database
    @param con: database connection
    @param assembly_event_id 
    @param method 
    @param assembly_event_date 
    @param assembly_event_date_utc_offset 
    @param version 
    @param assembly_event_type 
    @param qcd_reads_id 
    @return id of the inserted/updated row
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    return db.upsert(con, 'assembly_event', data)

@beartype.beartype
def write_assembly_event_many(con: db.Connection, objs: List[AssemblyEvent], upsert: bool = False) -> int:
    """
    Write a list of AssemblyEvent objects to the database
    @param con: database connection
    @param objs: list of AssemblyEvent objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'assembly_event', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_assembly_event(con: db.Connection, assembly_event_id: int,
            method: Optional[str] = None,
            assembly_event_date: Optional[datetime.datetime] = None,
            assembly_event_date_utc_offset: Optional[int] = None,
            version: Optional[str] = None,
            assembly_event_type: Optional[str] = None,
            qcd_reads_id: Optional[int] = None) -> int:
    """
    Update a row in the assembly_event table in the database
    @param con: database connection
    @param assembly_event_id 
    @param method 
    @param assembly_event_date 
    @param assembly_event_date_utc_offset 
    @param version 
    @param assembly_event_type 
    @param qcd_reads_id 
    @return The number of rows updated
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    return db.update(con, 'assembly_event', data)

@beartype.beartype
def read_assembly_event(
            con: db.Connection,
            assembly_event_id: Optional[int] = None,
             method: Optional[str] = None,
             assembly_event_date: Optional[datetime.datetime] = None,
             assembly_event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             assembly_event_type: Optional[str] = None,
             qcd_reads_id: Optional[int] = None) -> Generator[AssemblyEvent, None, None]:
    """
    Read from the assembly_event table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param assembly_event_id 
    @param method 
    @param assembly_event_date 
    @param assembly_event_date_utc_offset 
    @param version 
    @param assembly_event_type 
    @param qcd_reads_id 
    @return generator of AssemblyEvent objects
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    result = db.query(con, 'assembly_event', data)
    for row in result:
        yield AssemblyEvent(**row.as_dict())

@beartype.beartype
def read_assembly_event_fuzzy(con: db.Connection, assembly_event_id: Optional[int] = None,
             method: Optional[str] = None,
             assembly_event_date: Optional[datetime.datetime] = None,
             assembly_event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             assembly_event_type: Optional[str] = None,
             qcd_reads_id: Optional[int] = None) -> Generator[AssemblyEvent, None, None]:
    """
    Read from the assembly_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param assembly_event_id 
    @param method 
    @param assembly_event_date 
    @param assembly_event_date_utc_offset 
    @param version 
    @param assembly_event_type 
    @param qcd_reads_id 
    @return generator of AssemblyEvent objects
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    result = db.query_fuzzy(con, 'assembly_event', data)
    for row in result:
        yield AssemblyEvent(**row.as_dict())

@beartype.beartype
def read_assembly_event_any(con: db.Connection, assembly_event_id: Optional[List[int]] = None,
             method: Optional[List[str]] = None,
             assembly_event_date: Optional[List[datetime.datetime]] = None,
             assembly_event_date_utc_offset: Optional[List[int]] = None,
             version: Optional[List[str]] = None,
             assembly_event_type: Optional[List[str]] = None,
             qcd_reads_id: Optional[List[int]] = None) -> Generator[AssemblyEvent, None, None]:
    """
    Read from the assembly_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param assembly_event_id 
    @param method 
    @param assembly_event_date 
    @param assembly_event_date_utc_offset 
    @param version 
    @param assembly_event_type 
    @param qcd_reads_id 
    @return generator of AssemblyEvent objects
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    result = db.query_any(con, 'assembly_event', data)
    for row in result:
        yield AssemblyEvent(**row.as_dict())

@beartype.beartype
def read_assembly_event_one_or_none(con: db.Connection, assembly_event_id: Optional[int] = None,
             method: Optional[str] = None,
             assembly_event_date: Optional[datetime.datetime] = None,
             assembly_event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             assembly_event_type: Optional[str] = None,
             qcd_reads_id: Optional[int] = None) -> Optional[AssemblyEvent]:
    """
    Read from the assembly_event table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    result = db.query_one_or_none(con, 'assembly_event', data)
    if result is None:
        return None
    return AssemblyEvent(**result)

@beartype.beartype
def read_assembly_event_one(con: db.Connection, assembly_event_id: Optional[int] = None,
             method: Optional[str] = None,
             assembly_event_date: Optional[datetime.datetime] = None,
             assembly_event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             assembly_event_type: Optional[str] = None,
             qcd_reads_id: Optional[int] = None) -> AssemblyEvent:
    """
    Read from the assembly_event table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    result = db.query_one(con, 'assembly_event', data)
    return AssemblyEvent(**result)

@beartype.beartype
def read_assembly_event_all(con: db.Connection, assembly_event_id: Optional[int] = None,
             method: Optional[str] = None,
             assembly_event_date: Optional[datetime.datetime] = None,
             assembly_event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             assembly_event_type: Optional[str] = None,
             qcd_reads_id: Optional[int] = None) -> List[AssemblyEvent]:
    """
    Read from the assembly_event table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'assembly_event_id': assembly_event_id,
        'method': method,
        'assembly_event_date': assembly_event_date,
        'assembly_event_date_utc_offset': assembly_event_date_utc_offset,
        'version': version,
        'assembly_event_type': assembly_event_type,
        'qcd_reads_id': qcd_reads_id,
    }
    result = db.query(con, 'assembly_event', data)
    return [AssemblyEvent(**row.as_dict()) for row in result]

@beartype.beartype
def read_assembly_event_by_id(con: db.Connection, assembly_event_id: int) -> Optional[AssemblyEvent]:
    result = db.query_one(con, 'assembly_event', {'assembly_event_id': assembly_event_id})
    if result is None:
        return None
    return AssemblyEvent(**result)

@beartype.beartype
def delete_assembly_event_by_id(con: db.Connection, assembly_event_id: int):
    db.delete(con, 'assembly_event', {'assembly_event_id': assembly_event_id})
# Associate the functions with the class
AssemblyEvent.create_from_json_dict = create_assembly_event_from_json_dict
AssemblyEvent.write = write_assembly_event
AssemblyEvent.update = update_assembly_event
AssemblyEvent.write_many = write_assembly_event_many
AssemblyEvent.read = read_assembly_event
AssemblyEvent.read_fuzzy = read_assembly_event_fuzzy
AssemblyEvent.read_any = read_assembly_event_any
AssemblyEvent.read_one = read_assembly_event_one
AssemblyEvent.read_one_or_none = read_assembly_event_one_or_none
AssemblyEvent.read_all = read_assembly_event_all
AssemblyEvent.delete = delete_assembly_event_by_id
AssemblyEvent.read_by_id = read_assembly_event_by_id
AssemblyEvent.delete_by_id = delete_assembly_event_by_id



@beartype_wrap_init
@dataclasses.dataclass
class BinningEvent:
    """
    @param mag_binning_event_id 
    @param mag_processing_method 
    @param percentage_reads_mapped 
    @param number_of_mags 
    @param percentage_of_contigs_in_mags 
    @param assembled_contigs_id 
    @param percentage_binned 

    This is an automatically generated class
    """
    mag_binning_event_id: int # mag_binning_event_id integer (default: )
    mag_processing_method: Optional[str] = None # mag_processing_method character varying (default: )
    percentage_reads_mapped: Optional[float] = None # percentage_reads_mapped double precision (default: )
    number_of_mags: Optional[int] = None # number_of_mags integer (default: )
    percentage_of_contigs_in_mags: Optional[float] = None # percentage_of_contigs_in_mags double precision (default: )
    assembled_contigs_id: Optional[int] = None # assembled_contigs_id integer (default: )
    percentage_binned: Optional[float] = None # percentage_binned double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'mag_binning_event_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_assembled_contigs(self, con: db.Connection) -> Optional['Assembly']:
        return read_assembly_one_or_none(con, assembled_contigs_id=self.assembled_contigs_id)

@beartype.beartype
def create_binning_event_from_json_dict(json_obj: dict):
        """
        Create a BinningEvent from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return BinningEvent(**json_obj)


@beartype.beartype
def write_binning_event_obj(con: db.Connection, obj: BinningEvent) -> int:
    """
    Write a BinningEvent object to the database
    @param con: database connection
    @param obj: BinningEvent object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'binning_event', dataclasses.asdict(obj))

@beartype.beartype
def write_binning_event(
            con: db.Connection,
            mag_binning_event_id: int,
            mag_processing_method: Optional[str] = None,
            percentage_reads_mapped: Optional[float] = None,
            number_of_mags: Optional[int] = None,
            percentage_of_contigs_in_mags: Optional[float] = None,
            assembled_contigs_id: Optional[int] = None,
            percentage_binned: Optional[float] = None) -> int:
    """
    Write to the binning_event table in the database
    @param con: database connection
    @param mag_binning_event_id 
    @param mag_processing_method 
    @param percentage_reads_mapped 
    @param number_of_mags 
    @param percentage_of_contigs_in_mags 
    @param assembled_contigs_id 
    @param percentage_binned 
    @return id of the inserted/updated row
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    return db.upsert(con, 'binning_event', data)

@beartype.beartype
def write_binning_event_many(con: db.Connection, objs: List[BinningEvent], upsert: bool = False) -> int:
    """
    Write a list of BinningEvent objects to the database
    @param con: database connection
    @param objs: list of BinningEvent objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'binning_event', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_binning_event(con: db.Connection, mag_binning_event_id: int,
            mag_processing_method: Optional[str] = None,
            percentage_reads_mapped: Optional[float] = None,
            number_of_mags: Optional[int] = None,
            percentage_of_contigs_in_mags: Optional[float] = None,
            assembled_contigs_id: Optional[int] = None,
            percentage_binned: Optional[float] = None) -> int:
    """
    Update a row in the binning_event table in the database
    @param con: database connection
    @param mag_binning_event_id 
    @param mag_processing_method 
    @param percentage_reads_mapped 
    @param number_of_mags 
    @param percentage_of_contigs_in_mags 
    @param assembled_contigs_id 
    @param percentage_binned 
    @return The number of rows updated
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    return db.update(con, 'binning_event', data)

@beartype.beartype
def read_binning_event(
            con: db.Connection,
            mag_binning_event_id: Optional[int] = None,
             mag_processing_method: Optional[str] = None,
             percentage_reads_mapped: Optional[float] = None,
             number_of_mags: Optional[int] = None,
             percentage_of_contigs_in_mags: Optional[float] = None,
             assembled_contigs_id: Optional[int] = None,
             percentage_binned: Optional[float] = None) -> Generator[BinningEvent, None, None]:
    """
    Read from the binning_event table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_binning_event_id 
    @param mag_processing_method 
    @param percentage_reads_mapped 
    @param number_of_mags 
    @param percentage_of_contigs_in_mags 
    @param assembled_contigs_id 
    @param percentage_binned 
    @return generator of BinningEvent objects
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    result = db.query(con, 'binning_event', data)
    for row in result:
        yield BinningEvent(**row.as_dict())

@beartype.beartype
def read_binning_event_fuzzy(con: db.Connection, mag_binning_event_id: Optional[int] = None,
             mag_processing_method: Optional[str] = None,
             percentage_reads_mapped: Optional[float] = None,
             number_of_mags: Optional[int] = None,
             percentage_of_contigs_in_mags: Optional[float] = None,
             assembled_contigs_id: Optional[int] = None,
             percentage_binned: Optional[float] = None) -> Generator[BinningEvent, None, None]:
    """
    Read from the binning_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_binning_event_id 
    @param mag_processing_method 
    @param percentage_reads_mapped 
    @param number_of_mags 
    @param percentage_of_contigs_in_mags 
    @param assembled_contigs_id 
    @param percentage_binned 
    @return generator of BinningEvent objects
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    result = db.query_fuzzy(con, 'binning_event', data)
    for row in result:
        yield BinningEvent(**row.as_dict())

@beartype.beartype
def read_binning_event_any(con: db.Connection, mag_binning_event_id: Optional[List[int]] = None,
             mag_processing_method: Optional[List[str]] = None,
             percentage_reads_mapped: Optional[List[float]] = None,
             number_of_mags: Optional[List[int]] = None,
             percentage_of_contigs_in_mags: Optional[List[float]] = None,
             assembled_contigs_id: Optional[List[int]] = None,
             percentage_binned: Optional[List[float]] = None) -> Generator[BinningEvent, None, None]:
    """
    Read from the binning_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_binning_event_id 
    @param mag_processing_method 
    @param percentage_reads_mapped 
    @param number_of_mags 
    @param percentage_of_contigs_in_mags 
    @param assembled_contigs_id 
    @param percentage_binned 
    @return generator of BinningEvent objects
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    result = db.query_any(con, 'binning_event', data)
    for row in result:
        yield BinningEvent(**row.as_dict())

@beartype.beartype
def read_binning_event_one_or_none(con: db.Connection, mag_binning_event_id: Optional[int] = None,
             mag_processing_method: Optional[str] = None,
             percentage_reads_mapped: Optional[float] = None,
             number_of_mags: Optional[int] = None,
             percentage_of_contigs_in_mags: Optional[float] = None,
             assembled_contigs_id: Optional[int] = None,
             percentage_binned: Optional[float] = None) -> Optional[BinningEvent]:
    """
    Read from the binning_event table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    result = db.query_one_or_none(con, 'binning_event', data)
    if result is None:
        return None
    return BinningEvent(**result)

@beartype.beartype
def read_binning_event_one(con: db.Connection, mag_binning_event_id: Optional[int] = None,
             mag_processing_method: Optional[str] = None,
             percentage_reads_mapped: Optional[float] = None,
             number_of_mags: Optional[int] = None,
             percentage_of_contigs_in_mags: Optional[float] = None,
             assembled_contigs_id: Optional[int] = None,
             percentage_binned: Optional[float] = None) -> BinningEvent:
    """
    Read from the binning_event table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    result = db.query_one(con, 'binning_event', data)
    return BinningEvent(**result)

@beartype.beartype
def read_binning_event_all(con: db.Connection, mag_binning_event_id: Optional[int] = None,
             mag_processing_method: Optional[str] = None,
             percentage_reads_mapped: Optional[float] = None,
             number_of_mags: Optional[int] = None,
             percentage_of_contigs_in_mags: Optional[float] = None,
             assembled_contigs_id: Optional[int] = None,
             percentage_binned: Optional[float] = None) -> List[BinningEvent]:
    """
    Read from the binning_event table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'mag_binning_event_id': mag_binning_event_id,
        'mag_processing_method': mag_processing_method,
        'percentage_reads_mapped': percentage_reads_mapped,
        'number_of_mags': number_of_mags,
        'percentage_of_contigs_in_mags': percentage_of_contigs_in_mags,
        'assembled_contigs_id': assembled_contigs_id,
        'percentage_binned': percentage_binned,
    }
    result = db.query(con, 'binning_event', data)
    return [BinningEvent(**row.as_dict()) for row in result]

@beartype.beartype
def read_binning_event_by_id(con: db.Connection, mag_binning_event_id: int) -> Optional[BinningEvent]:
    result = db.query_one(con, 'binning_event', {'mag_binning_event_id': mag_binning_event_id})
    if result is None:
        return None
    return BinningEvent(**result)

@beartype.beartype
def delete_binning_event_by_id(con: db.Connection, mag_binning_event_id: int):
    db.delete(con, 'binning_event', {'mag_binning_event_id': mag_binning_event_id})
# Associate the functions with the class
BinningEvent.create_from_json_dict = create_binning_event_from_json_dict
BinningEvent.write = write_binning_event
BinningEvent.update = update_binning_event
BinningEvent.write_many = write_binning_event_many
BinningEvent.read = read_binning_event
BinningEvent.read_fuzzy = read_binning_event_fuzzy
BinningEvent.read_any = read_binning_event_any
BinningEvent.read_one = read_binning_event_one
BinningEvent.read_one_or_none = read_binning_event_one_or_none
BinningEvent.read_all = read_binning_event_all
BinningEvent.delete = delete_binning_event_by_id
BinningEvent.read_by_id = read_binning_event_by_id
BinningEvent.delete_by_id = delete_binning_event_by_id



@beartype_wrap_init
@dataclasses.dataclass
class BridgeContigsMags:
    """
    @param bridge_contigs_mags_id 
    @param contigs_id 
    @param mags_id 

    This is an automatically generated class
    """
    bridge_contigs_mags_id: int # bridge_contigs_mags_id integer (default: )
    contigs_id: Optional[int] = None # contigs_id integer (default: )
    mags_id: Optional[int] = None # mags_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_contigs_mags_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_contigs(self, con: db.Connection) -> Optional['Contigs']:
        return read_contigs_one_or_none(con, contigs_id=self.contigs_id)

    @beartype.beartype
    def get_mags(self, con: db.Connection) -> Optional['Mags']:
        return read_mags_one_or_none(con, mags_id=self.mags_id)

@beartype.beartype
def create_bridge_contigs_mags_from_json_dict(json_obj: dict):
        """
        Create a BridgeContigsMags from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return BridgeContigsMags(**json_obj)


@beartype.beartype
def write_bridge_contigs_mags_obj(con: db.Connection, obj: BridgeContigsMags) -> int:
    """
    Write a BridgeContigsMags object to the database
    @param con: database connection
    @param obj: BridgeContigsMags object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'bridge_contigs_mags', dataclasses.asdict(obj))

@beartype.beartype
def write_bridge_contigs_mags(
            con: db.Connection,
            bridge_contigs_mags_id: int,
            contigs_id: Optional[int] = None,
            mags_id: Optional[int] = None) -> int:
    """
    Write to the bridge_contigs_mags table in the database
    @param con: database connection
    @param bridge_contigs_mags_id 
    @param contigs_id 
    @param mags_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    return db.upsert(con, 'bridge_contigs_mags', data)

@beartype.beartype
def write_bridge_contigs_mags_many(con: db.Connection, objs: List[BridgeContigsMags], upsert: bool = False) -> int:
    """
    Write a list of BridgeContigsMags objects to the database
    @param con: database connection
    @param objs: list of BridgeContigsMags objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'bridge_contigs_mags', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_bridge_contigs_mags(con: db.Connection, bridge_contigs_mags_id: int,
            contigs_id: Optional[int] = None,
            mags_id: Optional[int] = None) -> int:
    """
    Update a row in the bridge_contigs_mags table in the database
    @param con: database connection
    @param bridge_contigs_mags_id 
    @param contigs_id 
    @param mags_id 
    @return The number of rows updated
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    return db.update(con, 'bridge_contigs_mags', data)

@beartype.beartype
def read_bridge_contigs_mags(
            con: db.Connection,
            bridge_contigs_mags_id: Optional[int] = None,
             contigs_id: Optional[int] = None,
             mags_id: Optional[int] = None) -> Generator[BridgeContigsMags, None, None]:
    """
    Read from the bridge_contigs_mags table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_contigs_mags_id 
    @param contigs_id 
    @param mags_id 
    @return generator of BridgeContigsMags objects
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    result = db.query(con, 'bridge_contigs_mags', data)
    for row in result:
        yield BridgeContigsMags(**row.as_dict())

@beartype.beartype
def read_bridge_contigs_mags_fuzzy(con: db.Connection, bridge_contigs_mags_id: Optional[int] = None,
             contigs_id: Optional[int] = None,
             mags_id: Optional[int] = None) -> Generator[BridgeContigsMags, None, None]:
    """
    Read from the bridge_contigs_mags table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_contigs_mags_id 
    @param contigs_id 
    @param mags_id 
    @return generator of BridgeContigsMags objects
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    result = db.query_fuzzy(con, 'bridge_contigs_mags', data)
    for row in result:
        yield BridgeContigsMags(**row.as_dict())

@beartype.beartype
def read_bridge_contigs_mags_any(con: db.Connection, bridge_contigs_mags_id: Optional[List[int]] = None,
             contigs_id: Optional[List[int]] = None,
             mags_id: Optional[List[int]] = None) -> Generator[BridgeContigsMags, None, None]:
    """
    Read from the bridge_contigs_mags table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_contigs_mags_id 
    @param contigs_id 
    @param mags_id 
    @return generator of BridgeContigsMags objects
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    result = db.query_any(con, 'bridge_contigs_mags', data)
    for row in result:
        yield BridgeContigsMags(**row.as_dict())

@beartype.beartype
def read_bridge_contigs_mags_one_or_none(con: db.Connection, bridge_contigs_mags_id: Optional[int] = None,
             contigs_id: Optional[int] = None,
             mags_id: Optional[int] = None) -> Optional[BridgeContigsMags]:
    """
    Read from the bridge_contigs_mags table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    result = db.query_one_or_none(con, 'bridge_contigs_mags', data)
    if result is None:
        return None
    return BridgeContigsMags(**result)

@beartype.beartype
def read_bridge_contigs_mags_one(con: db.Connection, bridge_contigs_mags_id: Optional[int] = None,
             contigs_id: Optional[int] = None,
             mags_id: Optional[int] = None) -> BridgeContigsMags:
    """
    Read from the bridge_contigs_mags table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    result = db.query_one(con, 'bridge_contigs_mags', data)
    return BridgeContigsMags(**result)

@beartype.beartype
def read_bridge_contigs_mags_all(con: db.Connection, bridge_contigs_mags_id: Optional[int] = None,
             contigs_id: Optional[int] = None,
             mags_id: Optional[int] = None) -> List[BridgeContigsMags]:
    """
    Read from the bridge_contigs_mags table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_contigs_mags_id': bridge_contigs_mags_id,
        'contigs_id': contigs_id,
        'mags_id': mags_id,
    }
    result = db.query(con, 'bridge_contigs_mags', data)
    return [BridgeContigsMags(**row.as_dict()) for row in result]

@beartype.beartype
def read_bridge_contigs_mags_by_id(con: db.Connection, bridge_contigs_mags_id: int) -> Optional[BridgeContigsMags]:
    result = db.query_one(con, 'bridge_contigs_mags', {'bridge_contigs_mags_id': bridge_contigs_mags_id})
    if result is None:
        return None
    return BridgeContigsMags(**result)

@beartype.beartype
def delete_bridge_contigs_mags_by_id(con: db.Connection, bridge_contigs_mags_id: int):
    db.delete(con, 'bridge_contigs_mags', {'bridge_contigs_mags_id': bridge_contigs_mags_id})
# Associate the functions with the class
BridgeContigsMags.create_from_json_dict = create_bridge_contigs_mags_from_json_dict
BridgeContigsMags.write = write_bridge_contigs_mags
BridgeContigsMags.update = update_bridge_contigs_mags
BridgeContigsMags.write_many = write_bridge_contigs_mags_many
BridgeContigsMags.read = read_bridge_contigs_mags
BridgeContigsMags.read_fuzzy = read_bridge_contigs_mags_fuzzy
BridgeContigsMags.read_any = read_bridge_contigs_mags_any
BridgeContigsMags.read_one = read_bridge_contigs_mags_one
BridgeContigsMags.read_one_or_none = read_bridge_contigs_mags_one_or_none
BridgeContigsMags.read_all = read_bridge_contigs_mags_all
BridgeContigsMags.delete = delete_bridge_contigs_mags_by_id
BridgeContigsMags.read_by_id = read_bridge_contigs_mags_by_id
BridgeContigsMags.delete_by_id = delete_bridge_contigs_mags_by_id



@beartype_wrap_init
@dataclasses.dataclass
class BridgeGenesGeneAnnotations:
    """
    @param bridge_id 
    @param gene_annotation_id 
    @param gene_id 

    This is an automatically generated class
    """
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    gene_annotation_id: Optional[int] = None # gene_annotation_id integer (default: )
    gene_id: Optional[int] = None # gene_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_gene_annotation(self, con: db.Connection) -> Optional['GeneAnnotations']:
        return read_gene_annotations_one_or_none(con, gene_annotation_id=self.gene_annotation_id)

    @beartype.beartype
    def get_gene(self, con: db.Connection) -> Optional['Genes']:
        return read_genes_one_or_none(con, gene_id=self.gene_id)

@beartype.beartype
def create_bridge_genes_gene_annotations_from_json_dict(json_obj: dict):
        """
        Create a BridgeGenesGeneAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return BridgeGenesGeneAnnotations(**json_obj)


@beartype.beartype
def write_bridge_genes_gene_annotations_obj(con: db.Connection, obj: BridgeGenesGeneAnnotations) -> int:
    """
    Write a BridgeGenesGeneAnnotations object to the database
    @param con: database connection
    @param obj: BridgeGenesGeneAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'bridge_genes_gene_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_bridge_genes_gene_annotations(
            con: db.Connection,
            bridge_id: Optional[int] = None,
            gene_annotation_id: Optional[int] = None,
            gene_id: Optional[int] = None) -> int:
    """
    Write to the bridge_genes_gene_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param gene_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    return db.upsert(con, 'bridge_genes_gene_annotations', data)

@beartype.beartype
def write_bridge_genes_gene_annotations_many(con: db.Connection, objs: List[BridgeGenesGeneAnnotations], upsert: bool = False) -> int:
    """
    Write a list of BridgeGenesGeneAnnotations objects to the database
    @param con: database connection
    @param objs: list of BridgeGenesGeneAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'bridge_genes_gene_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_bridge_genes_gene_annotations(con: db.Connection, bridge_id: int,
            gene_annotation_id: Optional[int] = None,
            gene_id: Optional[int] = None) -> int:
    """
    Update a row in the bridge_genes_gene_annotations table in the database
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param gene_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    return db.update(con, 'bridge_genes_gene_annotations', data)

@beartype.beartype
def read_bridge_genes_gene_annotations(
            con: db.Connection,
            bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             gene_id: Optional[int] = None) -> Generator[BridgeGenesGeneAnnotations, None, None]:
    """
    Read from the bridge_genes_gene_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param gene_id 
    @return generator of BridgeGenesGeneAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    result = db.query(con, 'bridge_genes_gene_annotations', data)
    for row in result:
        yield BridgeGenesGeneAnnotations(**row.as_dict())

@beartype.beartype
def read_bridge_genes_gene_annotations_fuzzy(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             gene_id: Optional[int] = None) -> Generator[BridgeGenesGeneAnnotations, None, None]:
    """
    Read from the bridge_genes_gene_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param gene_id 
    @return generator of BridgeGenesGeneAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    result = db.query_fuzzy(con, 'bridge_genes_gene_annotations', data)
    for row in result:
        yield BridgeGenesGeneAnnotations(**row.as_dict())

@beartype.beartype
def read_bridge_genes_gene_annotations_any(con: db.Connection, bridge_id: Optional[List[int]] = None,
             gene_annotation_id: Optional[List[int]] = None,
             gene_id: Optional[List[int]] = None) -> Generator[BridgeGenesGeneAnnotations, None, None]:
    """
    Read from the bridge_genes_gene_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param gene_id 
    @return generator of BridgeGenesGeneAnnotations objects
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    result = db.query_any(con, 'bridge_genes_gene_annotations', data)
    for row in result:
        yield BridgeGenesGeneAnnotations(**row.as_dict())

@beartype.beartype
def read_bridge_genes_gene_annotations_one_or_none(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             gene_id: Optional[int] = None) -> Optional[BridgeGenesGeneAnnotations]:
    """
    Read from the bridge_genes_gene_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    result = db.query_one_or_none(con, 'bridge_genes_gene_annotations', data)
    if result is None:
        return None
    return BridgeGenesGeneAnnotations(**result)

@beartype.beartype
def read_bridge_genes_gene_annotations_one(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             gene_id: Optional[int] = None) -> BridgeGenesGeneAnnotations:
    """
    Read from the bridge_genes_gene_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    result = db.query_one(con, 'bridge_genes_gene_annotations', data)
    return BridgeGenesGeneAnnotations(**result)

@beartype.beartype
def read_bridge_genes_gene_annotations_all(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             gene_id: Optional[int] = None) -> List[BridgeGenesGeneAnnotations]:
    """
    Read from the bridge_genes_gene_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'gene_id': gene_id,
    }
    result = db.query(con, 'bridge_genes_gene_annotations', data)
    return [BridgeGenesGeneAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_bridge_genes_gene_annotations_by_id(con: db.Connection, bridge_id: int) -> Optional[BridgeGenesGeneAnnotations]:
    result = db.query_one(con, 'bridge_genes_gene_annotations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return BridgeGenesGeneAnnotations(**result)

@beartype.beartype
def delete_bridge_genes_gene_annotations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'bridge_genes_gene_annotations', {'bridge_id': bridge_id})
# Associate the functions with the class
BridgeGenesGeneAnnotations.create_from_json_dict = create_bridge_genes_gene_annotations_from_json_dict
BridgeGenesGeneAnnotations.write = write_bridge_genes_gene_annotations
BridgeGenesGeneAnnotations.update = update_bridge_genes_gene_annotations
BridgeGenesGeneAnnotations.write_many = write_bridge_genes_gene_annotations_many
BridgeGenesGeneAnnotations.read = read_bridge_genes_gene_annotations
BridgeGenesGeneAnnotations.read_fuzzy = read_bridge_genes_gene_annotations_fuzzy
BridgeGenesGeneAnnotations.read_any = read_bridge_genes_gene_annotations_any
BridgeGenesGeneAnnotations.read_one = read_bridge_genes_gene_annotations_one
BridgeGenesGeneAnnotations.read_one_or_none = read_bridge_genes_gene_annotations_one_or_none
BridgeGenesGeneAnnotations.read_all = read_bridge_genes_gene_annotations_all
BridgeGenesGeneAnnotations.delete = delete_bridge_genes_gene_annotations_by_id
BridgeGenesGeneAnnotations.read_by_id = read_bridge_genes_gene_annotations_by_id
BridgeGenesGeneAnnotations.delete_by_id = delete_bridge_genes_gene_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SamplingFeatureExternalIdentifiers:
    """
    @param bridge_id 
    @param sampling_feature_id 
    @param external_identifier_system_id 
    @param sampling_feature_external_identifier 
    @param sampling_feature_external_identifier_uri 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    sampling_feature_external_identifier: str # sampling_feature_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    sampling_feature_external_identifier_uri: Optional[str] = None # sampling_feature_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_sampling_feature_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a SamplingFeatureExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SamplingFeatureExternalIdentifiers(**json_obj)


@beartype.beartype
def write_sampling_feature_external_identifiers_obj(con: db.Connection, obj: SamplingFeatureExternalIdentifiers) -> int:
    """
    Write a SamplingFeatureExternalIdentifiers object to the database
    @param con: database connection
    @param obj: SamplingFeatureExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampling_feature_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_sampling_feature_external_identifiers(
            con: db.Connection,
            sampling_feature_id: int,
            external_identifier_system_id: int,
            sampling_feature_external_identifier: str,
            bridge_id: Optional[int] = None,
            sampling_feature_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the sampling_feature_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param external_identifier_system_id 
    @param sampling_feature_external_identifier 
    @param sampling_feature_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    return db.upsert(con, 'sampling_feature_external_identifiers', data)

@beartype.beartype
def write_sampling_feature_external_identifiers_many(con: db.Connection, objs: List[SamplingFeatureExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of SamplingFeatureExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of SamplingFeatureExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampling_feature_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampling_feature_external_identifiers(con: db.Connection, bridge_id: int,
            sampling_feature_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            sampling_feature_external_identifier: Optional[str] = None,
            sampling_feature_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the sampling_feature_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param external_identifier_system_id 
    @param sampling_feature_external_identifier 
    @param sampling_feature_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    return db.update(con, 'sampling_feature_external_identifiers', data)

@beartype.beartype
def read_sampling_feature_external_identifiers(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             sampling_feature_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             sampling_feature_external_identifier_uri: Optional[str] = None) -> Generator[SamplingFeatureExternalIdentifiers, None, None]:
    """
    Read from the sampling_feature_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param external_identifier_system_id 
    @param sampling_feature_external_identifier 
    @param sampling_feature_external_identifier_uri 
    @return generator of SamplingFeatureExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    result = db.query(con, 'sampling_feature_external_identifiers', data)
    for row in result:
        yield SamplingFeatureExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_sampling_feature_external_identifiers_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             sampling_feature_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             sampling_feature_external_identifier_uri: Optional[str] = None) -> Generator[SamplingFeatureExternalIdentifiers, None, None]:
    """
    Read from the sampling_feature_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param external_identifier_system_id 
    @param sampling_feature_external_identifier 
    @param sampling_feature_external_identifier_uri 
    @return generator of SamplingFeatureExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'sampling_feature_external_identifiers', data)
    for row in result:
        yield SamplingFeatureExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_sampling_feature_external_identifiers_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             sampling_feature_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             sampling_feature_external_identifier_uri: Optional[List[str]] = None) -> Generator[SamplingFeatureExternalIdentifiers, None, None]:
    """
    Read from the sampling_feature_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param external_identifier_system_id 
    @param sampling_feature_external_identifier 
    @param sampling_feature_external_identifier_uri 
    @return generator of SamplingFeatureExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    result = db.query_any(con, 'sampling_feature_external_identifiers', data)
    for row in result:
        yield SamplingFeatureExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_sampling_feature_external_identifiers_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             sampling_feature_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             sampling_feature_external_identifier_uri: Optional[str] = None) -> Optional[SamplingFeatureExternalIdentifiers]:
    """
    Read from the sampling_feature_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'sampling_feature_external_identifiers', data)
    if result is None:
        return None
    return SamplingFeatureExternalIdentifiers(**result)

@beartype.beartype
def read_sampling_feature_external_identifiers_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             sampling_feature_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             sampling_feature_external_identifier_uri: Optional[str] = None) -> SamplingFeatureExternalIdentifiers:
    """
    Read from the sampling_feature_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    result = db.query_one(con, 'sampling_feature_external_identifiers', data)
    return SamplingFeatureExternalIdentifiers(**result)

@beartype.beartype
def read_sampling_feature_external_identifiers_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             sampling_feature_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             sampling_feature_external_identifier_uri: Optional[str] = None) -> List[SamplingFeatureExternalIdentifiers]:
    """
    Read from the sampling_feature_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'external_identifier_system_id': external_identifier_system_id,
        'sampling_feature_external_identifier': sampling_feature_external_identifier,
        'sampling_feature_external_identifier_uri': sampling_feature_external_identifier_uri,
    }
    result = db.query(con, 'sampling_feature_external_identifiers', data)
    return [SamplingFeatureExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampling_feature_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[SamplingFeatureExternalIdentifiers]:
    result = db.query_one(con, 'sampling_feature_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SamplingFeatureExternalIdentifiers(**result)

@beartype.beartype
def delete_sampling_feature_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'sampling_feature_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
SamplingFeatureExternalIdentifiers.create_from_json_dict = create_sampling_feature_external_identifiers_from_json_dict
SamplingFeatureExternalIdentifiers.write = write_sampling_feature_external_identifiers
SamplingFeatureExternalIdentifiers.update = update_sampling_feature_external_identifiers
SamplingFeatureExternalIdentifiers.write_many = write_sampling_feature_external_identifiers_many
SamplingFeatureExternalIdentifiers.read = read_sampling_feature_external_identifiers
SamplingFeatureExternalIdentifiers.read_fuzzy = read_sampling_feature_external_identifiers_fuzzy
SamplingFeatureExternalIdentifiers.read_any = read_sampling_feature_external_identifiers_any
SamplingFeatureExternalIdentifiers.read_one = read_sampling_feature_external_identifiers_one
SamplingFeatureExternalIdentifiers.read_one_or_none = read_sampling_feature_external_identifiers_one_or_none
SamplingFeatureExternalIdentifiers.read_all = read_sampling_feature_external_identifiers_all
SamplingFeatureExternalIdentifiers.delete = delete_sampling_feature_external_identifiers_by_id
SamplingFeatureExternalIdentifiers.read_by_id = read_sampling_feature_external_identifiers_by_id
SamplingFeatureExternalIdentifiers.delete_by_id = delete_sampling_feature_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Directives:
    """
    Describes the directive or purpose under which actions are made.  Directives can be projects, intended analyses for a specimen, etc.

    @param directive_id 
    @param directive_type_cv 
    @param directive_description 

    This is an automatically generated class
    """
    directive_type_cv: str # directive_type_cv character varying (default: )
    directive_description: str # directive_description character varying (default: )
    directive_id: Optional[int] = None # directive_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'directive_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_directive_type_cv(self, con: db.Connection) -> Optional['CvDirectiveType']:
        return read_cv_directive_type_one_or_none(con, term=self.directive_type_cv)

@beartype.beartype
def create_directives_from_json_dict(json_obj: dict):
        """
        Create a Directives from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Directives(**json_obj)


@beartype.beartype
def write_directives_obj(con: db.Connection, obj: Directives) -> int:
    """
    Write a Directives object to the database
    @param con: database connection
    @param obj: Directives object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'directives', dataclasses.asdict(obj))

@beartype.beartype
def write_directives(
            con: db.Connection,
            directive_type_cv: str,
            directive_description: str,
            directive_id: Optional[int] = None) -> int:
    """
    Write to the directives table in the database
    @param con: database connection
    @param directive_id 
    @param directive_type_cv 
    @param directive_description 
    @return id of the inserted/updated row
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    return db.upsert(con, 'directives', data)

@beartype.beartype
def write_directives_many(con: db.Connection, objs: List[Directives], upsert: bool = False) -> int:
    """
    Write a list of Directives objects to the database
    @param con: database connection
    @param objs: list of Directives objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'directives', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_directives(con: db.Connection, directive_id: int,
            directive_type_cv: Optional[str] = None,
            directive_description: Optional[str] = None) -> int:
    """
    Update a row in the directives table in the database
    @param con: database connection
    @param directive_id 
    @param directive_type_cv 
    @param directive_description 
    @return The number of rows updated
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    return db.update(con, 'directives', data)

@beartype.beartype
def read_directives(
            con: db.Connection,
            directive_type_cv: Optional[str] = None,
             directive_description: Optional[str] = None,
             directive_id: Optional[int] = None) -> Generator[Directives, None, None]:
    """
    Read from the directives table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param directive_id 
    @param directive_type_cv 
    @param directive_description 
    @return generator of Directives objects
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    result = db.query(con, 'directives', data)
    for row in result:
        yield Directives(**row.as_dict())

@beartype.beartype
def read_directives_fuzzy(con: db.Connection, directive_type_cv: Optional[str] = None,
             directive_description: Optional[str] = None,
             directive_id: Optional[int] = None) -> Generator[Directives, None, None]:
    """
    Read from the directives table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param directive_id 
    @param directive_type_cv 
    @param directive_description 
    @return generator of Directives objects
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    result = db.query_fuzzy(con, 'directives', data)
    for row in result:
        yield Directives(**row.as_dict())

@beartype.beartype
def read_directives_any(con: db.Connection, directive_type_cv: Optional[List[str]] = None,
             directive_description: Optional[List[str]] = None,
             directive_id: Optional[List[int]] = None) -> Generator[Directives, None, None]:
    """
    Read from the directives table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param directive_id 
    @param directive_type_cv 
    @param directive_description 
    @return generator of Directives objects
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    result = db.query_any(con, 'directives', data)
    for row in result:
        yield Directives(**row.as_dict())

@beartype.beartype
def read_directives_one_or_none(con: db.Connection, directive_type_cv: Optional[str] = None,
             directive_description: Optional[str] = None,
             directive_id: Optional[int] = None) -> Optional[Directives]:
    """
    Read from the directives table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    result = db.query_one_or_none(con, 'directives', data)
    if result is None:
        return None
    return Directives(**result)

@beartype.beartype
def read_directives_one(con: db.Connection, directive_type_cv: Optional[str] = None,
             directive_description: Optional[str] = None,
             directive_id: Optional[int] = None) -> Directives:
    """
    Read from the directives table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    result = db.query_one(con, 'directives', data)
    return Directives(**result)

@beartype.beartype
def read_directives_all(con: db.Connection, directive_type_cv: Optional[str] = None,
             directive_description: Optional[str] = None,
             directive_id: Optional[int] = None) -> List[Directives]:
    """
    Read from the directives table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'directive_id': directive_id,
        'directive_type_cv': directive_type_cv,
        'directive_description': directive_description,
    }
    result = db.query(con, 'directives', data)
    return [Directives(**row.as_dict()) for row in result]

@beartype.beartype
def read_directives_by_id(con: db.Connection, directive_id: int) -> Optional[Directives]:
    result = db.query_one(con, 'directives', {'directive_id': directive_id})
    if result is None:
        return None
    return Directives(**result)

@beartype.beartype
def delete_directives_by_id(con: db.Connection, directive_id: int):
    db.delete(con, 'directives', {'directive_id': directive_id})
# Associate the functions with the class
Directives.create_from_json_dict = create_directives_from_json_dict
Directives.write = write_directives
Directives.update = update_directives
Directives.write_many = write_directives_many
Directives.read = read_directives
Directives.read_fuzzy = read_directives_fuzzy
Directives.read_any = read_directives_any
Directives.read_one = read_directives_one
Directives.read_one_or_none = read_directives_one_or_none
Directives.read_all = read_directives_all
Directives.delete = delete_directives_by_id
Directives.read_by_id = read_directives_by_id
Directives.delete_by_id = delete_directives_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Mags:
    """
    @param mags_id 
    @param mag_name 
    @param mag_completeness 
    @param mag_contamination 
    @param mag_binning_event_id 
    @param mag_taxonomy_from_gtdbtk_domain 
    @param mag_taxonomy_from_gtdbtk_phylum 
    @param mag_taxonomy_from_gtdbtk_class 
    @param mag_taxonomy_from_gtdbtk_order 
    @param mag_taxonomy_from_gtdbtk_family 
    @param mag_taxonomy_from_gtdbtk_genus 
    @param mag_taxonomy_from_gtdbtk_species 
    @param mag_taxonomy_from_gtdbtk_strain 
    @param manual_curation 
    @param in_mag_collection 

    This is an automatically generated class
    """
    mags_id: Optional[int] = None # mags_id integer (default: )
    mag_name: Optional[str] = None # mag_name character varying (default: )
    mag_completeness: Optional[str] = None # mag_completeness character varying (default: )
    mag_contamination: Optional[str] = None # mag_contamination character varying (default: )
    mag_binning_event_id: Optional[int] = None # mag_binning_event_id integer (default: )
    mag_taxonomy_from_gtdbtk_domain: Optional[str] = None # mag_taxonomy_from_gtdbtk_domain character varying (default: )
    mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None # mag_taxonomy_from_gtdbtk_phylum character varying (default: )
    mag_taxonomy_from_gtdbtk_class: Optional[str] = None # mag_taxonomy_from_gtdbtk_class character varying (default: )
    mag_taxonomy_from_gtdbtk_order: Optional[str] = None # mag_taxonomy_from_gtdbtk_order character varying (default: )
    mag_taxonomy_from_gtdbtk_family: Optional[str] = None # mag_taxonomy_from_gtdbtk_family character varying (default: )
    mag_taxonomy_from_gtdbtk_genus: Optional[str] = None # mag_taxonomy_from_gtdbtk_genus character varying (default: )
    mag_taxonomy_from_gtdbtk_species: Optional[str] = None # mag_taxonomy_from_gtdbtk_species character varying (default: )
    mag_taxonomy_from_gtdbtk_strain: Optional[str] = None # mag_taxonomy_from_gtdbtk_strain character varying (default: )
    manual_curation: Optional[bool] = None # manual_curation boolean (default: )
    in_mag_collection: Optional[bool] = None # in_mag_collection boolean (default: )
    PRIMARY_KEY: ClassVar[str] = 'mags_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_mag_binning_event(self, con: db.Connection) -> Optional['BinningEvent']:
        return read_binning_event_one_or_none(con, mag_binning_event_id=self.mag_binning_event_id)

@beartype.beartype
def create_mags_from_json_dict(json_obj: dict):
        """
        Create a Mags from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Mags(**json_obj)


@beartype.beartype
def write_mags_obj(con: db.Connection, obj: Mags) -> int:
    """
    Write a Mags object to the database
    @param con: database connection
    @param obj: Mags object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'mags', dataclasses.asdict(obj))

@beartype.beartype
def write_mags(
            con: db.Connection,
            mags_id: Optional[int] = None,
            mag_name: Optional[str] = None,
            mag_completeness: Optional[str] = None,
            mag_contamination: Optional[str] = None,
            mag_binning_event_id: Optional[int] = None,
            mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
            manual_curation: Optional[bool] = None,
            in_mag_collection: Optional[bool] = None) -> int:
    """
    Write to the mags table in the database
    @param con: database connection
    @param mags_id 
    @param mag_name 
    @param mag_completeness 
    @param mag_contamination 
    @param mag_binning_event_id 
    @param mag_taxonomy_from_gtdbtk_domain 
    @param mag_taxonomy_from_gtdbtk_phylum 
    @param mag_taxonomy_from_gtdbtk_class 
    @param mag_taxonomy_from_gtdbtk_order 
    @param mag_taxonomy_from_gtdbtk_family 
    @param mag_taxonomy_from_gtdbtk_genus 
    @param mag_taxonomy_from_gtdbtk_species 
    @param mag_taxonomy_from_gtdbtk_strain 
    @param manual_curation 
    @param in_mag_collection 
    @return id of the inserted/updated row
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    return db.upsert(con, 'mags', data)

@beartype.beartype
def write_mags_many(con: db.Connection, objs: List[Mags], upsert: bool = False) -> int:
    """
    Write a list of Mags objects to the database
    @param con: database connection
    @param objs: list of Mags objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'mags', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_mags(con: db.Connection, mags_id: int,
            mag_name: Optional[str] = None,
            mag_completeness: Optional[str] = None,
            mag_contamination: Optional[str] = None,
            mag_binning_event_id: Optional[int] = None,
            mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
            mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
            manual_curation: Optional[bool] = None,
            in_mag_collection: Optional[bool] = None) -> int:
    """
    Update a row in the mags table in the database
    @param con: database connection
    @param mags_id 
    @param mag_name 
    @param mag_completeness 
    @param mag_contamination 
    @param mag_binning_event_id 
    @param mag_taxonomy_from_gtdbtk_domain 
    @param mag_taxonomy_from_gtdbtk_phylum 
    @param mag_taxonomy_from_gtdbtk_class 
    @param mag_taxonomy_from_gtdbtk_order 
    @param mag_taxonomy_from_gtdbtk_family 
    @param mag_taxonomy_from_gtdbtk_genus 
    @param mag_taxonomy_from_gtdbtk_species 
    @param mag_taxonomy_from_gtdbtk_strain 
    @param manual_curation 
    @param in_mag_collection 
    @return The number of rows updated
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    return db.update(con, 'mags', data)

@beartype.beartype
def read_mags(
            con: db.Connection,
            mags_id: Optional[int] = None,
             mag_name: Optional[str] = None,
             mag_completeness: Optional[str] = None,
             mag_contamination: Optional[str] = None,
             mag_binning_event_id: Optional[int] = None,
             mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
             manual_curation: Optional[bool] = None,
             in_mag_collection: Optional[bool] = None) -> Generator[Mags, None, None]:
    """
    Read from the mags table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mags_id 
    @param mag_name 
    @param mag_completeness 
    @param mag_contamination 
    @param mag_binning_event_id 
    @param mag_taxonomy_from_gtdbtk_domain 
    @param mag_taxonomy_from_gtdbtk_phylum 
    @param mag_taxonomy_from_gtdbtk_class 
    @param mag_taxonomy_from_gtdbtk_order 
    @param mag_taxonomy_from_gtdbtk_family 
    @param mag_taxonomy_from_gtdbtk_genus 
    @param mag_taxonomy_from_gtdbtk_species 
    @param mag_taxonomy_from_gtdbtk_strain 
    @param manual_curation 
    @param in_mag_collection 
    @return generator of Mags objects
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    result = db.query(con, 'mags', data)
    for row in result:
        yield Mags(**row.as_dict())

@beartype.beartype
def read_mags_fuzzy(con: db.Connection, mags_id: Optional[int] = None,
             mag_name: Optional[str] = None,
             mag_completeness: Optional[str] = None,
             mag_contamination: Optional[str] = None,
             mag_binning_event_id: Optional[int] = None,
             mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
             manual_curation: Optional[bool] = None,
             in_mag_collection: Optional[bool] = None) -> Generator[Mags, None, None]:
    """
    Read from the mags table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mags_id 
    @param mag_name 
    @param mag_completeness 
    @param mag_contamination 
    @param mag_binning_event_id 
    @param mag_taxonomy_from_gtdbtk_domain 
    @param mag_taxonomy_from_gtdbtk_phylum 
    @param mag_taxonomy_from_gtdbtk_class 
    @param mag_taxonomy_from_gtdbtk_order 
    @param mag_taxonomy_from_gtdbtk_family 
    @param mag_taxonomy_from_gtdbtk_genus 
    @param mag_taxonomy_from_gtdbtk_species 
    @param mag_taxonomy_from_gtdbtk_strain 
    @param manual_curation 
    @param in_mag_collection 
    @return generator of Mags objects
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    result = db.query_fuzzy(con, 'mags', data)
    for row in result:
        yield Mags(**row.as_dict())

@beartype.beartype
def read_mags_any(con: db.Connection, mags_id: Optional[List[int]] = None,
             mag_name: Optional[List[str]] = None,
             mag_completeness: Optional[List[str]] = None,
             mag_contamination: Optional[List[str]] = None,
             mag_binning_event_id: Optional[List[int]] = None,
             mag_taxonomy_from_gtdbtk_domain: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_phylum: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_class: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_order: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_family: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_genus: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_species: Optional[List[str]] = None,
             mag_taxonomy_from_gtdbtk_strain: Optional[List[str]] = None,
             manual_curation: Optional[List[bool]] = None,
             in_mag_collection: Optional[List[bool]] = None) -> Generator[Mags, None, None]:
    """
    Read from the mags table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mags_id 
    @param mag_name 
    @param mag_completeness 
    @param mag_contamination 
    @param mag_binning_event_id 
    @param mag_taxonomy_from_gtdbtk_domain 
    @param mag_taxonomy_from_gtdbtk_phylum 
    @param mag_taxonomy_from_gtdbtk_class 
    @param mag_taxonomy_from_gtdbtk_order 
    @param mag_taxonomy_from_gtdbtk_family 
    @param mag_taxonomy_from_gtdbtk_genus 
    @param mag_taxonomy_from_gtdbtk_species 
    @param mag_taxonomy_from_gtdbtk_strain 
    @param manual_curation 
    @param in_mag_collection 
    @return generator of Mags objects
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    result = db.query_any(con, 'mags', data)
    for row in result:
        yield Mags(**row.as_dict())

@beartype.beartype
def read_mags_one_or_none(con: db.Connection, mags_id: Optional[int] = None,
             mag_name: Optional[str] = None,
             mag_completeness: Optional[str] = None,
             mag_contamination: Optional[str] = None,
             mag_binning_event_id: Optional[int] = None,
             mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
             manual_curation: Optional[bool] = None,
             in_mag_collection: Optional[bool] = None) -> Optional[Mags]:
    """
    Read from the mags table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    result = db.query_one_or_none(con, 'mags', data)
    if result is None:
        return None
    return Mags(**result)

@beartype.beartype
def read_mags_one(con: db.Connection, mags_id: Optional[int] = None,
             mag_name: Optional[str] = None,
             mag_completeness: Optional[str] = None,
             mag_contamination: Optional[str] = None,
             mag_binning_event_id: Optional[int] = None,
             mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
             manual_curation: Optional[bool] = None,
             in_mag_collection: Optional[bool] = None) -> Mags:
    """
    Read from the mags table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    result = db.query_one(con, 'mags', data)
    return Mags(**result)

@beartype.beartype
def read_mags_all(con: db.Connection, mags_id: Optional[int] = None,
             mag_name: Optional[str] = None,
             mag_completeness: Optional[str] = None,
             mag_contamination: Optional[str] = None,
             mag_binning_event_id: Optional[int] = None,
             mag_taxonomy_from_gtdbtk_domain: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_phylum: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_class: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_order: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_family: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_genus: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_species: Optional[str] = None,
             mag_taxonomy_from_gtdbtk_strain: Optional[str] = None,
             manual_curation: Optional[bool] = None,
             in_mag_collection: Optional[bool] = None) -> List[Mags]:
    """
    Read from the mags table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'mags_id': mags_id,
        'mag_name': mag_name,
        'mag_completeness': mag_completeness,
        'mag_contamination': mag_contamination,
        'mag_binning_event_id': mag_binning_event_id,
        'mag_taxonomy_from_gtdbtk_domain': mag_taxonomy_from_gtdbtk_domain,
        'mag_taxonomy_from_gtdbtk_phylum': mag_taxonomy_from_gtdbtk_phylum,
        'mag_taxonomy_from_gtdbtk_class': mag_taxonomy_from_gtdbtk_class,
        'mag_taxonomy_from_gtdbtk_order': mag_taxonomy_from_gtdbtk_order,
        'mag_taxonomy_from_gtdbtk_family': mag_taxonomy_from_gtdbtk_family,
        'mag_taxonomy_from_gtdbtk_genus': mag_taxonomy_from_gtdbtk_genus,
        'mag_taxonomy_from_gtdbtk_species': mag_taxonomy_from_gtdbtk_species,
        'mag_taxonomy_from_gtdbtk_strain': mag_taxonomy_from_gtdbtk_strain,
        'manual_curation': manual_curation,
        'in_mag_collection': in_mag_collection,
    }
    result = db.query(con, 'mags', data)
    return [Mags(**row.as_dict()) for row in result]

@beartype.beartype
def read_mags_by_id(con: db.Connection, mags_id: int) -> Optional[Mags]:
    result = db.query_one(con, 'mags', {'mags_id': mags_id})
    if result is None:
        return None
    return Mags(**result)

@beartype.beartype
def delete_mags_by_id(con: db.Connection, mags_id: int):
    db.delete(con, 'mags', {'mags_id': mags_id})
# Associate the functions with the class
Mags.create_from_json_dict = create_mags_from_json_dict
Mags.write = write_mags
Mags.update = update_mags
Mags.write_many = write_mags_many
Mags.read = read_mags
Mags.read_fuzzy = read_mags_fuzzy
Mags.read_any = read_mags_any
Mags.read_one = read_mags_one
Mags.read_one_or_none = read_mags_one_or_none
Mags.read_all = read_mags_all
Mags.delete = delete_mags_by_id
Mags.read_by_id = read_mags_by_id
Mags.delete_by_id = delete_mags_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RawReads:
    """
    @param raw_reads_id 
    @param extracted_dnaid 
    @param sequencing_facility_id 
    @param raw_read_date 
    @param gbp_reads 
    @param sequencing_facility_id_sample_id 

    This is an automatically generated class
    """
    raw_reads_id: Optional[int] = None # raw_reads_id integer (default: )
    extracted_dnaid: Optional[int] = None # extracted_dnaid integer (default: )
    sequencing_facility_id: Optional[int] = None # sequencing_facility_id integer (default: )
    raw_read_date: Optional[datetime.datetime] = None # raw_read_date timestamp without time zone (default: )
    gbp_reads: Optional[float] = None # gbp_reads double precision (default: )
    sequencing_facility_id_sample_id: Optional[str] = None # sequencing_facility_id_sample_id character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'raw_reads_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.raw_read_date is not None:
            obj['raw_read_date'] = self.raw_read_date.isoformat()
        return obj

    @beartype.beartype
    def get_extracted_dnaid(self, con: db.Connection) -> Optional['ExtractedDna']:
        return read_extracted_dna_one_or_none(con, extracted_dnaid=self.extracted_dnaid)

    @beartype.beartype
    def get_sequencing_facility(self, con: db.Connection) -> Optional['SequencingFacility']:
        return read_sequencing_facility_one_or_none(con, sequencing_facility_id=self.sequencing_facility_id)

@beartype.beartype
def create_raw_reads_from_json_dict(json_obj: dict):
        """
        Create a RawReads from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'raw_read_date' in json_obj and json_obj['raw_read_date'] is not None:
            json_obj['raw_read_date'] = datetime.datetime.fromisoformat(json_obj['raw_read_date'])
        return RawReads(**json_obj)


@beartype.beartype
def write_raw_reads_obj(con: db.Connection, obj: RawReads) -> int:
    """
    Write a RawReads object to the database
    @param con: database connection
    @param obj: RawReads object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'raw_reads', dataclasses.asdict(obj))

@beartype.beartype
def write_raw_reads(
            con: db.Connection,
            raw_reads_id: Optional[int] = None,
            extracted_dnaid: Optional[int] = None,
            sequencing_facility_id: Optional[int] = None,
            raw_read_date: Optional[datetime.datetime] = None,
            gbp_reads: Optional[float] = None,
            sequencing_facility_id_sample_id: Optional[str] = None) -> int:
    """
    Write to the raw_reads table in the database
    @param con: database connection
    @param raw_reads_id 
    @param extracted_dnaid 
    @param sequencing_facility_id 
    @param raw_read_date 
    @param gbp_reads 
    @param sequencing_facility_id_sample_id 
    @return id of the inserted/updated row
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    return db.upsert(con, 'raw_reads', data)

@beartype.beartype
def write_raw_reads_many(con: db.Connection, objs: List[RawReads], upsert: bool = False) -> int:
    """
    Write a list of RawReads objects to the database
    @param con: database connection
    @param objs: list of RawReads objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'raw_reads', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_raw_reads(con: db.Connection, raw_reads_id: int,
            extracted_dnaid: Optional[int] = None,
            sequencing_facility_id: Optional[int] = None,
            raw_read_date: Optional[datetime.datetime] = None,
            gbp_reads: Optional[float] = None,
            sequencing_facility_id_sample_id: Optional[str] = None) -> int:
    """
    Update a row in the raw_reads table in the database
    @param con: database connection
    @param raw_reads_id 
    @param extracted_dnaid 
    @param sequencing_facility_id 
    @param raw_read_date 
    @param gbp_reads 
    @param sequencing_facility_id_sample_id 
    @return The number of rows updated
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    return db.update(con, 'raw_reads', data)

@beartype.beartype
def read_raw_reads(
            con: db.Connection,
            raw_reads_id: Optional[int] = None,
             extracted_dnaid: Optional[int] = None,
             sequencing_facility_id: Optional[int] = None,
             raw_read_date: Optional[datetime.datetime] = None,
             gbp_reads: Optional[float] = None,
             sequencing_facility_id_sample_id: Optional[str] = None) -> Generator[RawReads, None, None]:
    """
    Read from the raw_reads table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param raw_reads_id 
    @param extracted_dnaid 
    @param sequencing_facility_id 
    @param raw_read_date 
    @param gbp_reads 
    @param sequencing_facility_id_sample_id 
    @return generator of RawReads objects
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    result = db.query(con, 'raw_reads', data)
    for row in result:
        yield RawReads(**row.as_dict())

@beartype.beartype
def read_raw_reads_fuzzy(con: db.Connection, raw_reads_id: Optional[int] = None,
             extracted_dnaid: Optional[int] = None,
             sequencing_facility_id: Optional[int] = None,
             raw_read_date: Optional[datetime.datetime] = None,
             gbp_reads: Optional[float] = None,
             sequencing_facility_id_sample_id: Optional[str] = None) -> Generator[RawReads, None, None]:
    """
    Read from the raw_reads table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param raw_reads_id 
    @param extracted_dnaid 
    @param sequencing_facility_id 
    @param raw_read_date 
    @param gbp_reads 
    @param sequencing_facility_id_sample_id 
    @return generator of RawReads objects
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    result = db.query_fuzzy(con, 'raw_reads', data)
    for row in result:
        yield RawReads(**row.as_dict())

@beartype.beartype
def read_raw_reads_any(con: db.Connection, raw_reads_id: Optional[List[int]] = None,
             extracted_dnaid: Optional[List[int]] = None,
             sequencing_facility_id: Optional[List[int]] = None,
             raw_read_date: Optional[List[datetime.datetime]] = None,
             gbp_reads: Optional[List[float]] = None,
             sequencing_facility_id_sample_id: Optional[List[str]] = None) -> Generator[RawReads, None, None]:
    """
    Read from the raw_reads table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param raw_reads_id 
    @param extracted_dnaid 
    @param sequencing_facility_id 
    @param raw_read_date 
    @param gbp_reads 
    @param sequencing_facility_id_sample_id 
    @return generator of RawReads objects
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    result = db.query_any(con, 'raw_reads', data)
    for row in result:
        yield RawReads(**row.as_dict())

@beartype.beartype
def read_raw_reads_one_or_none(con: db.Connection, raw_reads_id: Optional[int] = None,
             extracted_dnaid: Optional[int] = None,
             sequencing_facility_id: Optional[int] = None,
             raw_read_date: Optional[datetime.datetime] = None,
             gbp_reads: Optional[float] = None,
             sequencing_facility_id_sample_id: Optional[str] = None) -> Optional[RawReads]:
    """
    Read from the raw_reads table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    result = db.query_one_or_none(con, 'raw_reads', data)
    if result is None:
        return None
    return RawReads(**result)

@beartype.beartype
def read_raw_reads_one(con: db.Connection, raw_reads_id: Optional[int] = None,
             extracted_dnaid: Optional[int] = None,
             sequencing_facility_id: Optional[int] = None,
             raw_read_date: Optional[datetime.datetime] = None,
             gbp_reads: Optional[float] = None,
             sequencing_facility_id_sample_id: Optional[str] = None) -> RawReads:
    """
    Read from the raw_reads table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    result = db.query_one(con, 'raw_reads', data)
    return RawReads(**result)

@beartype.beartype
def read_raw_reads_all(con: db.Connection, raw_reads_id: Optional[int] = None,
             extracted_dnaid: Optional[int] = None,
             sequencing_facility_id: Optional[int] = None,
             raw_read_date: Optional[datetime.datetime] = None,
             gbp_reads: Optional[float] = None,
             sequencing_facility_id_sample_id: Optional[str] = None) -> List[RawReads]:
    """
    Read from the raw_reads table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'raw_reads_id': raw_reads_id,
        'extracted_dnaid': extracted_dnaid,
        'sequencing_facility_id': sequencing_facility_id,
        'raw_read_date': raw_read_date,
        'gbp_reads': gbp_reads,
        'sequencing_facility_id_sample_id': sequencing_facility_id_sample_id,
    }
    result = db.query(con, 'raw_reads', data)
    return [RawReads(**row.as_dict()) for row in result]

@beartype.beartype
def read_raw_reads_by_id(con: db.Connection, raw_reads_id: int) -> Optional[RawReads]:
    result = db.query_one(con, 'raw_reads', {'raw_reads_id': raw_reads_id})
    if result is None:
        return None
    return RawReads(**result)

@beartype.beartype
def delete_raw_reads_by_id(con: db.Connection, raw_reads_id: int):
    db.delete(con, 'raw_reads', {'raw_reads_id': raw_reads_id})
# Associate the functions with the class
RawReads.create_from_json_dict = create_raw_reads_from_json_dict
RawReads.write = write_raw_reads
RawReads.update = update_raw_reads
RawReads.write_many = write_raw_reads_many
RawReads.read = read_raw_reads
RawReads.read_fuzzy = read_raw_reads_fuzzy
RawReads.read_any = read_raw_reads_any
RawReads.read_one = read_raw_reads_one
RawReads.read_one_or_none = read_raw_reads_one_or_none
RawReads.read_all = read_raw_reads_all
RawReads.delete = delete_raw_reads_by_id
RawReads.read_by_id = read_raw_reads_by_id
RawReads.delete_by_id = delete_raw_reads_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Genes:
    """
    @param gene_id 
    @param csu_gene_id 
    @param gene_start 
    @param gene_end 
    @param has_fna 
    @param has_faa 

    This is an automatically generated class
    """
    gene_id: Optional[int] = None # gene_id integer (default: )
    csu_gene_id: Optional[str] = None # csu_gene_id character varying (default: )
    gene_start: Optional[int] = None # gene_start integer (default: )
    gene_end: Optional[int] = None # gene_end integer (default: )
    has_fna: Optional[bool] = None # has_fna boolean (default: )
    has_faa: Optional[bool] = None # has_faa boolean (default: )
    PRIMARY_KEY: ClassVar[str] = 'gene_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_genes_from_json_dict(json_obj: dict):
        """
        Create a Genes from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Genes(**json_obj)


@beartype.beartype
def write_genes_obj(con: db.Connection, obj: Genes) -> int:
    """
    Write a Genes object to the database
    @param con: database connection
    @param obj: Genes object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'genes', dataclasses.asdict(obj))

@beartype.beartype
def write_genes(
            con: db.Connection,
            gene_id: Optional[int] = None,
            csu_gene_id: Optional[str] = None,
            gene_start: Optional[int] = None,
            gene_end: Optional[int] = None,
            has_fna: Optional[bool] = None,
            has_faa: Optional[bool] = None) -> int:
    """
    Write to the genes table in the database
    @param con: database connection
    @param gene_id 
    @param csu_gene_id 
    @param gene_start 
    @param gene_end 
    @param has_fna 
    @param has_faa 
    @return id of the inserted/updated row
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    return db.upsert(con, 'genes', data)

@beartype.beartype
def write_genes_many(con: db.Connection, objs: List[Genes], upsert: bool = False) -> int:
    """
    Write a list of Genes objects to the database
    @param con: database connection
    @param objs: list of Genes objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'genes', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_genes(con: db.Connection, gene_id: int,
            csu_gene_id: Optional[str] = None,
            gene_start: Optional[int] = None,
            gene_end: Optional[int] = None,
            has_fna: Optional[bool] = None,
            has_faa: Optional[bool] = None) -> int:
    """
    Update a row in the genes table in the database
    @param con: database connection
    @param gene_id 
    @param csu_gene_id 
    @param gene_start 
    @param gene_end 
    @param has_fna 
    @param has_faa 
    @return The number of rows updated
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    return db.update(con, 'genes', data)

@beartype.beartype
def read_genes(
            con: db.Connection,
            gene_id: Optional[int] = None,
             csu_gene_id: Optional[str] = None,
             gene_start: Optional[int] = None,
             gene_end: Optional[int] = None,
             has_fna: Optional[bool] = None,
             has_faa: Optional[bool] = None) -> Generator[Genes, None, None]:
    """
    Read from the genes table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param gene_id 
    @param csu_gene_id 
    @param gene_start 
    @param gene_end 
    @param has_fna 
    @param has_faa 
    @return generator of Genes objects
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    result = db.query(con, 'genes', data)
    for row in result:
        yield Genes(**row.as_dict())

@beartype.beartype
def read_genes_fuzzy(con: db.Connection, gene_id: Optional[int] = None,
             csu_gene_id: Optional[str] = None,
             gene_start: Optional[int] = None,
             gene_end: Optional[int] = None,
             has_fna: Optional[bool] = None,
             has_faa: Optional[bool] = None) -> Generator[Genes, None, None]:
    """
    Read from the genes table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param gene_id 
    @param csu_gene_id 
    @param gene_start 
    @param gene_end 
    @param has_fna 
    @param has_faa 
    @return generator of Genes objects
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    result = db.query_fuzzy(con, 'genes', data)
    for row in result:
        yield Genes(**row.as_dict())

@beartype.beartype
def read_genes_any(con: db.Connection, gene_id: Optional[List[int]] = None,
             csu_gene_id: Optional[List[str]] = None,
             gene_start: Optional[List[int]] = None,
             gene_end: Optional[List[int]] = None,
             has_fna: Optional[List[bool]] = None,
             has_faa: Optional[List[bool]] = None) -> Generator[Genes, None, None]:
    """
    Read from the genes table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param gene_id 
    @param csu_gene_id 
    @param gene_start 
    @param gene_end 
    @param has_fna 
    @param has_faa 
    @return generator of Genes objects
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    result = db.query_any(con, 'genes', data)
    for row in result:
        yield Genes(**row.as_dict())

@beartype.beartype
def read_genes_one_or_none(con: db.Connection, gene_id: Optional[int] = None,
             csu_gene_id: Optional[str] = None,
             gene_start: Optional[int] = None,
             gene_end: Optional[int] = None,
             has_fna: Optional[bool] = None,
             has_faa: Optional[bool] = None) -> Optional[Genes]:
    """
    Read from the genes table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    result = db.query_one_or_none(con, 'genes', data)
    if result is None:
        return None
    return Genes(**result)

@beartype.beartype
def read_genes_one(con: db.Connection, gene_id: Optional[int] = None,
             csu_gene_id: Optional[str] = None,
             gene_start: Optional[int] = None,
             gene_end: Optional[int] = None,
             has_fna: Optional[bool] = None,
             has_faa: Optional[bool] = None) -> Genes:
    """
    Read from the genes table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    result = db.query_one(con, 'genes', data)
    return Genes(**result)

@beartype.beartype
def read_genes_all(con: db.Connection, gene_id: Optional[int] = None,
             csu_gene_id: Optional[str] = None,
             gene_start: Optional[int] = None,
             gene_end: Optional[int] = None,
             has_fna: Optional[bool] = None,
             has_faa: Optional[bool] = None) -> List[Genes]:
    """
    Read from the genes table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'gene_id': gene_id,
        'csu_gene_id': csu_gene_id,
        'gene_start': gene_start,
        'gene_end': gene_end,
        'has_fna': has_fna,
        'has_faa': has_faa,
    }
    result = db.query(con, 'genes', data)
    return [Genes(**row.as_dict()) for row in result]

@beartype.beartype
def read_genes_by_id(con: db.Connection, gene_id: int) -> Optional[Genes]:
    result = db.query_one(con, 'genes', {'gene_id': gene_id})
    if result is None:
        return None
    return Genes(**result)

@beartype.beartype
def delete_genes_by_id(con: db.Connection, gene_id: int):
    db.delete(con, 'genes', {'gene_id': gene_id})
# Associate the functions with the class
Genes.create_from_json_dict = create_genes_from_json_dict
Genes.write = write_genes
Genes.update = update_genes
Genes.write_many = write_genes_many
Genes.read = read_genes
Genes.read_fuzzy = read_genes_fuzzy
Genes.read_any = read_genes_any
Genes.read_one = read_genes_one
Genes.read_one_or_none = read_genes_one_or_none
Genes.read_all = read_genes_all
Genes.delete = delete_genes_by_id
Genes.read_by_id = read_genes_by_id
Genes.delete_by_id = delete_genes_by_id



@beartype_wrap_init
@dataclasses.dataclass
class BridgeMagAnnotationEventGeneAnnotation:
    """
    @param bridge_id 
    @param gene_annotation_id 
    @param mag_annotation_event_id 

    This is an automatically generated class
    """
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    gene_annotation_id: Optional[int] = None # gene_annotation_id integer (default: )
    mag_annotation_event_id: Optional[int] = None # mag_annotation_event_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_gene_annotation(self, con: db.Connection) -> Optional['GeneAnnotations']:
        return read_gene_annotations_one_or_none(con, gene_annotation_id=self.gene_annotation_id)

    @beartype.beartype
    def get_mag_annotation_event(self, con: db.Connection) -> Optional['MagAnnotationEvent']:
        return read_mag_annotation_event_one_or_none(con, mag_annotation_event_id=self.mag_annotation_event_id)

@beartype.beartype
def create_bridge_mag_annotation_event_gene_annotation_from_json_dict(json_obj: dict):
        """
        Create a BridgeMagAnnotationEventGeneAnnotation from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return BridgeMagAnnotationEventGeneAnnotation(**json_obj)


@beartype.beartype
def write_bridge_mag_annotation_event_gene_annotation_obj(con: db.Connection, obj: BridgeMagAnnotationEventGeneAnnotation) -> int:
    """
    Write a BridgeMagAnnotationEventGeneAnnotation object to the database
    @param con: database connection
    @param obj: BridgeMagAnnotationEventGeneAnnotation object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'bridge_mag_annotation_event_gene_annotation', dataclasses.asdict(obj))

@beartype.beartype
def write_bridge_mag_annotation_event_gene_annotation(
            con: db.Connection,
            bridge_id: Optional[int] = None,
            gene_annotation_id: Optional[int] = None,
            mag_annotation_event_id: Optional[int] = None) -> int:
    """
    Write to the bridge_mag_annotation_event_gene_annotation table in the database
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param mag_annotation_event_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    return db.upsert(con, 'bridge_mag_annotation_event_gene_annotation', data)

@beartype.beartype
def write_bridge_mag_annotation_event_gene_annotation_many(con: db.Connection, objs: List[BridgeMagAnnotationEventGeneAnnotation], upsert: bool = False) -> int:
    """
    Write a list of BridgeMagAnnotationEventGeneAnnotation objects to the database
    @param con: database connection
    @param objs: list of BridgeMagAnnotationEventGeneAnnotation objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'bridge_mag_annotation_event_gene_annotation', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_bridge_mag_annotation_event_gene_annotation(con: db.Connection, bridge_id: int,
            gene_annotation_id: Optional[int] = None,
            mag_annotation_event_id: Optional[int] = None) -> int:
    """
    Update a row in the bridge_mag_annotation_event_gene_annotation table in the database
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param mag_annotation_event_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    return db.update(con, 'bridge_mag_annotation_event_gene_annotation', data)

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation(
            con: db.Connection,
            bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             mag_annotation_event_id: Optional[int] = None) -> Generator[BridgeMagAnnotationEventGeneAnnotation, None, None]:
    """
    Read from the bridge_mag_annotation_event_gene_annotation table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param mag_annotation_event_id 
    @return generator of BridgeMagAnnotationEventGeneAnnotation objects
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    result = db.query(con, 'bridge_mag_annotation_event_gene_annotation', data)
    for row in result:
        yield BridgeMagAnnotationEventGeneAnnotation(**row.as_dict())

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation_fuzzy(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             mag_annotation_event_id: Optional[int] = None) -> Generator[BridgeMagAnnotationEventGeneAnnotation, None, None]:
    """
    Read from the bridge_mag_annotation_event_gene_annotation table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param mag_annotation_event_id 
    @return generator of BridgeMagAnnotationEventGeneAnnotation objects
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    result = db.query_fuzzy(con, 'bridge_mag_annotation_event_gene_annotation', data)
    for row in result:
        yield BridgeMagAnnotationEventGeneAnnotation(**row.as_dict())

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation_any(con: db.Connection, bridge_id: Optional[List[int]] = None,
             gene_annotation_id: Optional[List[int]] = None,
             mag_annotation_event_id: Optional[List[int]] = None) -> Generator[BridgeMagAnnotationEventGeneAnnotation, None, None]:
    """
    Read from the bridge_mag_annotation_event_gene_annotation table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param gene_annotation_id 
    @param mag_annotation_event_id 
    @return generator of BridgeMagAnnotationEventGeneAnnotation objects
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    result = db.query_any(con, 'bridge_mag_annotation_event_gene_annotation', data)
    for row in result:
        yield BridgeMagAnnotationEventGeneAnnotation(**row.as_dict())

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation_one_or_none(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             mag_annotation_event_id: Optional[int] = None) -> Optional[BridgeMagAnnotationEventGeneAnnotation]:
    """
    Read from the bridge_mag_annotation_event_gene_annotation table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    result = db.query_one_or_none(con, 'bridge_mag_annotation_event_gene_annotation', data)
    if result is None:
        return None
    return BridgeMagAnnotationEventGeneAnnotation(**result)

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation_one(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             mag_annotation_event_id: Optional[int] = None) -> BridgeMagAnnotationEventGeneAnnotation:
    """
    Read from the bridge_mag_annotation_event_gene_annotation table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    result = db.query_one(con, 'bridge_mag_annotation_event_gene_annotation', data)
    return BridgeMagAnnotationEventGeneAnnotation(**result)

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation_all(con: db.Connection, bridge_id: Optional[int] = None,
             gene_annotation_id: Optional[int] = None,
             mag_annotation_event_id: Optional[int] = None) -> List[BridgeMagAnnotationEventGeneAnnotation]:
    """
    Read from the bridge_mag_annotation_event_gene_annotation table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'gene_annotation_id': gene_annotation_id,
        'mag_annotation_event_id': mag_annotation_event_id,
    }
    result = db.query(con, 'bridge_mag_annotation_event_gene_annotation', data)
    return [BridgeMagAnnotationEventGeneAnnotation(**row.as_dict()) for row in result]

@beartype.beartype
def read_bridge_mag_annotation_event_gene_annotation_by_id(con: db.Connection, bridge_id: int) -> Optional[BridgeMagAnnotationEventGeneAnnotation]:
    result = db.query_one(con, 'bridge_mag_annotation_event_gene_annotation', {'bridge_id': bridge_id})
    if result is None:
        return None
    return BridgeMagAnnotationEventGeneAnnotation(**result)

@beartype.beartype
def delete_bridge_mag_annotation_event_gene_annotation_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'bridge_mag_annotation_event_gene_annotation', {'bridge_id': bridge_id})
# Associate the functions with the class
BridgeMagAnnotationEventGeneAnnotation.create_from_json_dict = create_bridge_mag_annotation_event_gene_annotation_from_json_dict
BridgeMagAnnotationEventGeneAnnotation.write = write_bridge_mag_annotation_event_gene_annotation
BridgeMagAnnotationEventGeneAnnotation.update = update_bridge_mag_annotation_event_gene_annotation
BridgeMagAnnotationEventGeneAnnotation.write_many = write_bridge_mag_annotation_event_gene_annotation_many
BridgeMagAnnotationEventGeneAnnotation.read = read_bridge_mag_annotation_event_gene_annotation
BridgeMagAnnotationEventGeneAnnotation.read_fuzzy = read_bridge_mag_annotation_event_gene_annotation_fuzzy
BridgeMagAnnotationEventGeneAnnotation.read_any = read_bridge_mag_annotation_event_gene_annotation_any
BridgeMagAnnotationEventGeneAnnotation.read_one = read_bridge_mag_annotation_event_gene_annotation_one
BridgeMagAnnotationEventGeneAnnotation.read_one_or_none = read_bridge_mag_annotation_event_gene_annotation_one_or_none
BridgeMagAnnotationEventGeneAnnotation.read_all = read_bridge_mag_annotation_event_gene_annotation_all
BridgeMagAnnotationEventGeneAnnotation.delete = delete_bridge_mag_annotation_event_gene_annotation_by_id
BridgeMagAnnotationEventGeneAnnotation.read_by_id = read_bridge_mag_annotation_event_gene_annotation_by_id
BridgeMagAnnotationEventGeneAnnotation.delete_by_id = delete_bridge_mag_annotation_event_gene_annotation_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MagCollections:
    """
    @param mag_collections_id 
    @param mag_collections_name 
    @param final_genes_faa_file_path 
    @param final_genes_fna_file_path 
    @param final_genes_gff_file_path 
    @param final_scaffolds_fna_file_path 
    @param final_gbk_file_path 

    This is an automatically generated class
    """
    mag_collections_name: str # mag_collections_name character varying (default: )
    mag_collections_id: Optional[int] = None # mag_collections_id integer (default: )
    final_genes_faa_file_path: Optional[str] = None # final_genes_faa_file_path character varying (default: )
    final_genes_fna_file_path: Optional[str] = None # final_genes_fna_file_path character varying (default: )
    final_genes_gff_file_path: Optional[str] = None # final_genes_gff_file_path character varying (default: )
    final_scaffolds_fna_file_path: Optional[str] = None # final_scaffolds_fna_file_path character varying (default: )
    final_gbk_file_path: Optional[str] = None # final_gbk_file_path character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'mag_collections_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_mag_collections_from_json_dict(json_obj: dict):
        """
        Create a MagCollections from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MagCollections(**json_obj)


@beartype.beartype
def write_mag_collections_obj(con: db.Connection, obj: MagCollections) -> int:
    """
    Write a MagCollections object to the database
    @param con: database connection
    @param obj: MagCollections object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'mag_collections', dataclasses.asdict(obj))

@beartype.beartype
def write_mag_collections(
            con: db.Connection,
            mag_collections_name: str,
            mag_collections_id: Optional[int] = None,
            final_genes_faa_file_path: Optional[str] = None,
            final_genes_fna_file_path: Optional[str] = None,
            final_genes_gff_file_path: Optional[str] = None,
            final_scaffolds_fna_file_path: Optional[str] = None,
            final_gbk_file_path: Optional[str] = None) -> int:
    """
    Write to the mag_collections table in the database
    @param con: database connection
    @param mag_collections_id 
    @param mag_collections_name 
    @param final_genes_faa_file_path 
    @param final_genes_fna_file_path 
    @param final_genes_gff_file_path 
    @param final_scaffolds_fna_file_path 
    @param final_gbk_file_path 
    @return id of the inserted/updated row
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    return db.upsert(con, 'mag_collections', data)

@beartype.beartype
def write_mag_collections_many(con: db.Connection, objs: List[MagCollections], upsert: bool = False) -> int:
    """
    Write a list of MagCollections objects to the database
    @param con: database connection
    @param objs: list of MagCollections objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'mag_collections', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_mag_collections(con: db.Connection, mag_collections_id: int,
            mag_collections_name: Optional[str] = None,
            final_genes_faa_file_path: Optional[str] = None,
            final_genes_fna_file_path: Optional[str] = None,
            final_genes_gff_file_path: Optional[str] = None,
            final_scaffolds_fna_file_path: Optional[str] = None,
            final_gbk_file_path: Optional[str] = None) -> int:
    """
    Update a row in the mag_collections table in the database
    @param con: database connection
    @param mag_collections_id 
    @param mag_collections_name 
    @param final_genes_faa_file_path 
    @param final_genes_fna_file_path 
    @param final_genes_gff_file_path 
    @param final_scaffolds_fna_file_path 
    @param final_gbk_file_path 
    @return The number of rows updated
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    return db.update(con, 'mag_collections', data)

@beartype.beartype
def read_mag_collections(
            con: db.Connection,
            mag_collections_name: Optional[str] = None,
             mag_collections_id: Optional[int] = None,
             final_genes_faa_file_path: Optional[str] = None,
             final_genes_fna_file_path: Optional[str] = None,
             final_genes_gff_file_path: Optional[str] = None,
             final_scaffolds_fna_file_path: Optional[str] = None,
             final_gbk_file_path: Optional[str] = None) -> Generator[MagCollections, None, None]:
    """
    Read from the mag_collections table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_collections_id 
    @param mag_collections_name 
    @param final_genes_faa_file_path 
    @param final_genes_fna_file_path 
    @param final_genes_gff_file_path 
    @param final_scaffolds_fna_file_path 
    @param final_gbk_file_path 
    @return generator of MagCollections objects
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    result = db.query(con, 'mag_collections', data)
    for row in result:
        yield MagCollections(**row.as_dict())

@beartype.beartype
def read_mag_collections_fuzzy(con: db.Connection, mag_collections_name: Optional[str] = None,
             mag_collections_id: Optional[int] = None,
             final_genes_faa_file_path: Optional[str] = None,
             final_genes_fna_file_path: Optional[str] = None,
             final_genes_gff_file_path: Optional[str] = None,
             final_scaffolds_fna_file_path: Optional[str] = None,
             final_gbk_file_path: Optional[str] = None) -> Generator[MagCollections, None, None]:
    """
    Read from the mag_collections table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_collections_id 
    @param mag_collections_name 
    @param final_genes_faa_file_path 
    @param final_genes_fna_file_path 
    @param final_genes_gff_file_path 
    @param final_scaffolds_fna_file_path 
    @param final_gbk_file_path 
    @return generator of MagCollections objects
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    result = db.query_fuzzy(con, 'mag_collections', data)
    for row in result:
        yield MagCollections(**row.as_dict())

@beartype.beartype
def read_mag_collections_any(con: db.Connection, mag_collections_name: Optional[List[str]] = None,
             mag_collections_id: Optional[List[int]] = None,
             final_genes_faa_file_path: Optional[List[str]] = None,
             final_genes_fna_file_path: Optional[List[str]] = None,
             final_genes_gff_file_path: Optional[List[str]] = None,
             final_scaffolds_fna_file_path: Optional[List[str]] = None,
             final_gbk_file_path: Optional[List[str]] = None) -> Generator[MagCollections, None, None]:
    """
    Read from the mag_collections table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_collections_id 
    @param mag_collections_name 
    @param final_genes_faa_file_path 
    @param final_genes_fna_file_path 
    @param final_genes_gff_file_path 
    @param final_scaffolds_fna_file_path 
    @param final_gbk_file_path 
    @return generator of MagCollections objects
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    result = db.query_any(con, 'mag_collections', data)
    for row in result:
        yield MagCollections(**row.as_dict())

@beartype.beartype
def read_mag_collections_one_or_none(con: db.Connection, mag_collections_name: Optional[str] = None,
             mag_collections_id: Optional[int] = None,
             final_genes_faa_file_path: Optional[str] = None,
             final_genes_fna_file_path: Optional[str] = None,
             final_genes_gff_file_path: Optional[str] = None,
             final_scaffolds_fna_file_path: Optional[str] = None,
             final_gbk_file_path: Optional[str] = None) -> Optional[MagCollections]:
    """
    Read from the mag_collections table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    result = db.query_one_or_none(con, 'mag_collections', data)
    if result is None:
        return None
    return MagCollections(**result)

@beartype.beartype
def read_mag_collections_one(con: db.Connection, mag_collections_name: Optional[str] = None,
             mag_collections_id: Optional[int] = None,
             final_genes_faa_file_path: Optional[str] = None,
             final_genes_fna_file_path: Optional[str] = None,
             final_genes_gff_file_path: Optional[str] = None,
             final_scaffolds_fna_file_path: Optional[str] = None,
             final_gbk_file_path: Optional[str] = None) -> MagCollections:
    """
    Read from the mag_collections table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    result = db.query_one(con, 'mag_collections', data)
    return MagCollections(**result)

@beartype.beartype
def read_mag_collections_all(con: db.Connection, mag_collections_name: Optional[str] = None,
             mag_collections_id: Optional[int] = None,
             final_genes_faa_file_path: Optional[str] = None,
             final_genes_fna_file_path: Optional[str] = None,
             final_genes_gff_file_path: Optional[str] = None,
             final_scaffolds_fna_file_path: Optional[str] = None,
             final_gbk_file_path: Optional[str] = None) -> List[MagCollections]:
    """
    Read from the mag_collections table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'mag_collections_id': mag_collections_id,
        'mag_collections_name': mag_collections_name,
        'final_genes_faa_file_path': final_genes_faa_file_path,
        'final_genes_fna_file_path': final_genes_fna_file_path,
        'final_genes_gff_file_path': final_genes_gff_file_path,
        'final_scaffolds_fna_file_path': final_scaffolds_fna_file_path,
        'final_gbk_file_path': final_gbk_file_path,
    }
    result = db.query(con, 'mag_collections', data)
    return [MagCollections(**row.as_dict()) for row in result]

@beartype.beartype
def read_mag_collections_by_id(con: db.Connection, mag_collections_id: int) -> Optional[MagCollections]:
    result = db.query_one(con, 'mag_collections', {'mag_collections_id': mag_collections_id})
    if result is None:
        return None
    return MagCollections(**result)

@beartype.beartype
def delete_mag_collections_by_id(con: db.Connection, mag_collections_id: int):
    db.delete(con, 'mag_collections', {'mag_collections_id': mag_collections_id})
# Associate the functions with the class
MagCollections.create_from_json_dict = create_mag_collections_from_json_dict
MagCollections.write = write_mag_collections
MagCollections.update = update_mag_collections
MagCollections.write_many = write_mag_collections_many
MagCollections.read = read_mag_collections
MagCollections.read_fuzzy = read_mag_collections_fuzzy
MagCollections.read_any = read_mag_collections_any
MagCollections.read_one = read_mag_collections_one
MagCollections.read_one_or_none = read_mag_collections_one_or_none
MagCollections.read_all = read_mag_collections_all
MagCollections.delete = delete_mag_collections_by_id
MagCollections.read_by_id = read_mag_collections_by_id
MagCollections.delete_by_id = delete_mag_collections_by_id



@beartype_wrap_init
@dataclasses.dataclass
class BridgeQcdReadsAssemblyEvent:
    """
    @param id 
    @param qcd_reads_id 
    @param assembly_event_id 

    This is an automatically generated class
    """
    id: int # id integer (default: )
    qcd_reads_id: Optional[int] = None # qcd_reads_id integer (default: )
    assembly_event_id: Optional[int] = None # assembly_event_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_assembly_event(self, con: db.Connection) -> Optional['AssemblyEvent']:
        return read_assembly_event_one_or_none(con, assembly_event_id=self.assembly_event_id)

    @beartype.beartype
    def get_qcd_reads(self, con: db.Connection) -> Optional['QcdReads']:
        return read_qcd_reads_one_or_none(con, qcd_reads_id=self.qcd_reads_id)

@beartype.beartype
def create_bridge_qcd_reads_assembly_event_from_json_dict(json_obj: dict):
        """
        Create a BridgeQcdReadsAssemblyEvent from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return BridgeQcdReadsAssemblyEvent(**json_obj)


@beartype.beartype
def write_bridge_qcd_reads_assembly_event_obj(con: db.Connection, obj: BridgeQcdReadsAssemblyEvent) -> int:
    """
    Write a BridgeQcdReadsAssemblyEvent object to the database
    @param con: database connection
    @param obj: BridgeQcdReadsAssemblyEvent object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'bridge_qcd_reads_assembly_event', dataclasses.asdict(obj))

@beartype.beartype
def write_bridge_qcd_reads_assembly_event(
            con: db.Connection,
            id: int,
            qcd_reads_id: Optional[int] = None,
            assembly_event_id: Optional[int] = None) -> int:
    """
    Write to the bridge_qcd_reads_assembly_event table in the database
    @param con: database connection
    @param id 
    @param qcd_reads_id 
    @param assembly_event_id 
    @return id of the inserted/updated row
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    return db.upsert(con, 'bridge_qcd_reads_assembly_event', data)

@beartype.beartype
def write_bridge_qcd_reads_assembly_event_many(con: db.Connection, objs: List[BridgeQcdReadsAssemblyEvent], upsert: bool = False) -> int:
    """
    Write a list of BridgeQcdReadsAssemblyEvent objects to the database
    @param con: database connection
    @param objs: list of BridgeQcdReadsAssemblyEvent objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'bridge_qcd_reads_assembly_event', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_bridge_qcd_reads_assembly_event(con: db.Connection, id: int,
            qcd_reads_id: Optional[int] = None,
            assembly_event_id: Optional[int] = None) -> int:
    """
    Update a row in the bridge_qcd_reads_assembly_event table in the database
    @param con: database connection
    @param id 
    @param qcd_reads_id 
    @param assembly_event_id 
    @return The number of rows updated
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    return db.update(con, 'bridge_qcd_reads_assembly_event', data)

@beartype.beartype
def read_bridge_qcd_reads_assembly_event(
            con: db.Connection,
            id: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             assembly_event_id: Optional[int] = None) -> Generator[BridgeQcdReadsAssemblyEvent, None, None]:
    """
    Read from the bridge_qcd_reads_assembly_event table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param id 
    @param qcd_reads_id 
    @param assembly_event_id 
    @return generator of BridgeQcdReadsAssemblyEvent objects
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query(con, 'bridge_qcd_reads_assembly_event', data)
    for row in result:
        yield BridgeQcdReadsAssemblyEvent(**row.as_dict())

@beartype.beartype
def read_bridge_qcd_reads_assembly_event_fuzzy(con: db.Connection, id: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             assembly_event_id: Optional[int] = None) -> Generator[BridgeQcdReadsAssemblyEvent, None, None]:
    """
    Read from the bridge_qcd_reads_assembly_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param id 
    @param qcd_reads_id 
    @param assembly_event_id 
    @return generator of BridgeQcdReadsAssemblyEvent objects
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_fuzzy(con, 'bridge_qcd_reads_assembly_event', data)
    for row in result:
        yield BridgeQcdReadsAssemblyEvent(**row.as_dict())

@beartype.beartype
def read_bridge_qcd_reads_assembly_event_any(con: db.Connection, id: Optional[List[int]] = None,
             qcd_reads_id: Optional[List[int]] = None,
             assembly_event_id: Optional[List[int]] = None) -> Generator[BridgeQcdReadsAssemblyEvent, None, None]:
    """
    Read from the bridge_qcd_reads_assembly_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param id 
    @param qcd_reads_id 
    @param assembly_event_id 
    @return generator of BridgeQcdReadsAssemblyEvent objects
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_any(con, 'bridge_qcd_reads_assembly_event', data)
    for row in result:
        yield BridgeQcdReadsAssemblyEvent(**row.as_dict())

@beartype.beartype
def read_bridge_qcd_reads_assembly_event_one_or_none(con: db.Connection, id: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             assembly_event_id: Optional[int] = None) -> Optional[BridgeQcdReadsAssemblyEvent]:
    """
    Read from the bridge_qcd_reads_assembly_event table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_one_or_none(con, 'bridge_qcd_reads_assembly_event', data)
    if result is None:
        return None
    return BridgeQcdReadsAssemblyEvent(**result)

@beartype.beartype
def read_bridge_qcd_reads_assembly_event_one(con: db.Connection, id: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             assembly_event_id: Optional[int] = None) -> BridgeQcdReadsAssemblyEvent:
    """
    Read from the bridge_qcd_reads_assembly_event table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_one(con, 'bridge_qcd_reads_assembly_event', data)
    return BridgeQcdReadsAssemblyEvent(**result)

@beartype.beartype
def read_bridge_qcd_reads_assembly_event_all(con: db.Connection, id: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             assembly_event_id: Optional[int] = None) -> List[BridgeQcdReadsAssemblyEvent]:
    """
    Read from the bridge_qcd_reads_assembly_event table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'id': id,
        'qcd_reads_id': qcd_reads_id,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query(con, 'bridge_qcd_reads_assembly_event', data)
    return [BridgeQcdReadsAssemblyEvent(**row.as_dict()) for row in result]

@beartype.beartype
def read_bridge_qcd_reads_assembly_event_by_id(con: db.Connection, id: int) -> Optional[BridgeQcdReadsAssemblyEvent]:
    result = db.query_one(con, 'bridge_qcd_reads_assembly_event', {'id': id})
    if result is None:
        return None
    return BridgeQcdReadsAssemblyEvent(**result)

@beartype.beartype
def delete_bridge_qcd_reads_assembly_event_by_id(con: db.Connection, id: int):
    db.delete(con, 'bridge_qcd_reads_assembly_event', {'id': id})
# Associate the functions with the class
BridgeQcdReadsAssemblyEvent.create_from_json_dict = create_bridge_qcd_reads_assembly_event_from_json_dict
BridgeQcdReadsAssemblyEvent.write = write_bridge_qcd_reads_assembly_event
BridgeQcdReadsAssemblyEvent.update = update_bridge_qcd_reads_assembly_event
BridgeQcdReadsAssemblyEvent.write_many = write_bridge_qcd_reads_assembly_event_many
BridgeQcdReadsAssemblyEvent.read = read_bridge_qcd_reads_assembly_event
BridgeQcdReadsAssemblyEvent.read_fuzzy = read_bridge_qcd_reads_assembly_event_fuzzy
BridgeQcdReadsAssemblyEvent.read_any = read_bridge_qcd_reads_assembly_event_any
BridgeQcdReadsAssemblyEvent.read_one = read_bridge_qcd_reads_assembly_event_one
BridgeQcdReadsAssemblyEvent.read_one_or_none = read_bridge_qcd_reads_assembly_event_one_or_none
BridgeQcdReadsAssemblyEvent.read_all = read_bridge_qcd_reads_assembly_event_all
BridgeQcdReadsAssemblyEvent.delete = delete_bridge_qcd_reads_assembly_event_by_id
BridgeQcdReadsAssemblyEvent.read_by_id = read_bridge_qcd_reads_assembly_event_by_id
BridgeQcdReadsAssemblyEvent.delete_by_id = delete_bridge_qcd_reads_assembly_event_by_id



@beartype_wrap_init
@dataclasses.dataclass
class GeneAnnotations:
    """
    @param gene_annotation_id 
    @param cv_annotation_source 
    @param source_id 
    @param source_hit 

    This is an automatically generated class
    """
    gene_annotation_id: Optional[int] = None # gene_annotation_id integer (default: )
    cv_annotation_source: Optional[str] = None # cv_annotation_source character varying (default: )
    source_id: Optional[str] = None # source_id character varying (default: )
    source_hit: Optional[str] = None # source_hit character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'gene_annotation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_gene_annotations_from_json_dict(json_obj: dict):
        """
        Create a GeneAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return GeneAnnotations(**json_obj)


@beartype.beartype
def write_gene_annotations_obj(con: db.Connection, obj: GeneAnnotations) -> int:
    """
    Write a GeneAnnotations object to the database
    @param con: database connection
    @param obj: GeneAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'gene_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_gene_annotations(
            con: db.Connection,
            gene_annotation_id: Optional[int] = None,
            cv_annotation_source: Optional[str] = None,
            source_id: Optional[str] = None,
            source_hit: Optional[str] = None) -> int:
    """
    Write to the gene_annotations table in the database
    @param con: database connection
    @param gene_annotation_id 
    @param cv_annotation_source 
    @param source_id 
    @param source_hit 
    @return id of the inserted/updated row
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    return db.upsert(con, 'gene_annotations', data)

@beartype.beartype
def write_gene_annotations_many(con: db.Connection, objs: List[GeneAnnotations], upsert: bool = False) -> int:
    """
    Write a list of GeneAnnotations objects to the database
    @param con: database connection
    @param objs: list of GeneAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'gene_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_gene_annotations(con: db.Connection, gene_annotation_id: int,
            cv_annotation_source: Optional[str] = None,
            source_id: Optional[str] = None,
            source_hit: Optional[str] = None) -> int:
    """
    Update a row in the gene_annotations table in the database
    @param con: database connection
    @param gene_annotation_id 
    @param cv_annotation_source 
    @param source_id 
    @param source_hit 
    @return The number of rows updated
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    return db.update(con, 'gene_annotations', data)

@beartype.beartype
def read_gene_annotations(
            con: db.Connection,
            gene_annotation_id: Optional[int] = None,
             cv_annotation_source: Optional[str] = None,
             source_id: Optional[str] = None,
             source_hit: Optional[str] = None) -> Generator[GeneAnnotations, None, None]:
    """
    Read from the gene_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param gene_annotation_id 
    @param cv_annotation_source 
    @param source_id 
    @param source_hit 
    @return generator of GeneAnnotations objects
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    result = db.query(con, 'gene_annotations', data)
    for row in result:
        yield GeneAnnotations(**row.as_dict())

@beartype.beartype
def read_gene_annotations_fuzzy(con: db.Connection, gene_annotation_id: Optional[int] = None,
             cv_annotation_source: Optional[str] = None,
             source_id: Optional[str] = None,
             source_hit: Optional[str] = None) -> Generator[GeneAnnotations, None, None]:
    """
    Read from the gene_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param gene_annotation_id 
    @param cv_annotation_source 
    @param source_id 
    @param source_hit 
    @return generator of GeneAnnotations objects
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    result = db.query_fuzzy(con, 'gene_annotations', data)
    for row in result:
        yield GeneAnnotations(**row.as_dict())

@beartype.beartype
def read_gene_annotations_any(con: db.Connection, gene_annotation_id: Optional[List[int]] = None,
             cv_annotation_source: Optional[List[str]] = None,
             source_id: Optional[List[str]] = None,
             source_hit: Optional[List[str]] = None) -> Generator[GeneAnnotations, None, None]:
    """
    Read from the gene_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param gene_annotation_id 
    @param cv_annotation_source 
    @param source_id 
    @param source_hit 
    @return generator of GeneAnnotations objects
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    result = db.query_any(con, 'gene_annotations', data)
    for row in result:
        yield GeneAnnotations(**row.as_dict())

@beartype.beartype
def read_gene_annotations_one_or_none(con: db.Connection, gene_annotation_id: Optional[int] = None,
             cv_annotation_source: Optional[str] = None,
             source_id: Optional[str] = None,
             source_hit: Optional[str] = None) -> Optional[GeneAnnotations]:
    """
    Read from the gene_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    result = db.query_one_or_none(con, 'gene_annotations', data)
    if result is None:
        return None
    return GeneAnnotations(**result)

@beartype.beartype
def read_gene_annotations_one(con: db.Connection, gene_annotation_id: Optional[int] = None,
             cv_annotation_source: Optional[str] = None,
             source_id: Optional[str] = None,
             source_hit: Optional[str] = None) -> GeneAnnotations:
    """
    Read from the gene_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    result = db.query_one(con, 'gene_annotations', data)
    return GeneAnnotations(**result)

@beartype.beartype
def read_gene_annotations_all(con: db.Connection, gene_annotation_id: Optional[int] = None,
             cv_annotation_source: Optional[str] = None,
             source_id: Optional[str] = None,
             source_hit: Optional[str] = None) -> List[GeneAnnotations]:
    """
    Read from the gene_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'gene_annotation_id': gene_annotation_id,
        'cv_annotation_source': cv_annotation_source,
        'source_id': source_id,
        'source_hit': source_hit,
    }
    result = db.query(con, 'gene_annotations', data)
    return [GeneAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_gene_annotations_by_id(con: db.Connection, gene_annotation_id: int) -> Optional[GeneAnnotations]:
    result = db.query_one(con, 'gene_annotations', {'gene_annotation_id': gene_annotation_id})
    if result is None:
        return None
    return GeneAnnotations(**result)

@beartype.beartype
def delete_gene_annotations_by_id(con: db.Connection, gene_annotation_id: int):
    db.delete(con, 'gene_annotations', {'gene_annotation_id': gene_annotation_id})
# Associate the functions with the class
GeneAnnotations.create_from_json_dict = create_gene_annotations_from_json_dict
GeneAnnotations.write = write_gene_annotations
GeneAnnotations.update = update_gene_annotations
GeneAnnotations.write_many = write_gene_annotations_many
GeneAnnotations.read = read_gene_annotations
GeneAnnotations.read_fuzzy = read_gene_annotations_fuzzy
GeneAnnotations.read_any = read_gene_annotations_any
GeneAnnotations.read_one = read_gene_annotations_one
GeneAnnotations.read_one_or_none = read_gene_annotations_one_or_none
GeneAnnotations.read_all = read_gene_annotations_all
GeneAnnotations.delete = delete_gene_annotations_by_id
GeneAnnotations.read_by_id = read_gene_annotations_by_id
GeneAnnotations.delete_by_id = delete_gene_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Coverage:
    """
    @param coverage_id 
    @param mags_id 
    @param sampling_feature_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param coverage_value 

    This is an automatically generated class
    """
    coverage_id: Optional[int] = None # coverage_id integer (default: )
    mags_id: Optional[int] = None # mags_id integer (default: )
    sampling_feature_id: Optional[int] = None # sampling_feature_id integer (default: )
    result_date_time: Optional[datetime.datetime] = None # result_date_time timestamp without time zone (default: )
    result_date_time_utc_offset: Optional[int] = None # result_date_time_utc_offset integer (default: )
    coverage_value: Optional[float] = None # coverage_value double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'coverage_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.result_date_time is not None:
            obj['result_date_time'] = self.result_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_mags(self, con: db.Connection) -> Optional['Mags']:
        return read_mags_one_or_none(con, mags_id=self.mags_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['Specimens']:
        return read_specimens_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_coverage_from_json_dict(json_obj: dict):
        """
        Create a Coverage from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'result_date_time' in json_obj and json_obj['result_date_time'] is not None:
            json_obj['result_date_time'] = datetime.datetime.fromisoformat(json_obj['result_date_time'])
        return Coverage(**json_obj)


@beartype.beartype
def write_coverage_obj(con: db.Connection, obj: Coverage) -> int:
    """
    Write a Coverage object to the database
    @param con: database connection
    @param obj: Coverage object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'coverage', dataclasses.asdict(obj))

@beartype.beartype
def write_coverage(
            con: db.Connection,
            coverage_id: Optional[int] = None,
            mags_id: Optional[int] = None,
            sampling_feature_id: Optional[int] = None,
            result_date_time: Optional[datetime.datetime] = None,
            result_date_time_utc_offset: Optional[int] = None,
            coverage_value: Optional[float] = None) -> int:
    """
    Write to the coverage table in the database
    @param con: database connection
    @param coverage_id 
    @param mags_id 
    @param sampling_feature_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param coverage_value 
    @return id of the inserted/updated row
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    return db.upsert(con, 'coverage', data)

@beartype.beartype
def write_coverage_many(con: db.Connection, objs: List[Coverage], upsert: bool = False) -> int:
    """
    Write a list of Coverage objects to the database
    @param con: database connection
    @param objs: list of Coverage objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'coverage', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_coverage(con: db.Connection, coverage_id: int,
            mags_id: Optional[int] = None,
            sampling_feature_id: Optional[int] = None,
            result_date_time: Optional[datetime.datetime] = None,
            result_date_time_utc_offset: Optional[int] = None,
            coverage_value: Optional[float] = None) -> int:
    """
    Update a row in the coverage table in the database
    @param con: database connection
    @param coverage_id 
    @param mags_id 
    @param sampling_feature_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param coverage_value 
    @return The number of rows updated
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    return db.update(con, 'coverage', data)

@beartype.beartype
def read_coverage(
            con: db.Connection,
            coverage_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             coverage_value: Optional[float] = None) -> Generator[Coverage, None, None]:
    """
    Read from the coverage table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param coverage_id 
    @param mags_id 
    @param sampling_feature_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param coverage_value 
    @return generator of Coverage objects
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    result = db.query(con, 'coverage', data)
    for row in result:
        yield Coverage(**row.as_dict())

@beartype.beartype
def read_coverage_fuzzy(con: db.Connection, coverage_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             coverage_value: Optional[float] = None) -> Generator[Coverage, None, None]:
    """
    Read from the coverage table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param coverage_id 
    @param mags_id 
    @param sampling_feature_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param coverage_value 
    @return generator of Coverage objects
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    result = db.query_fuzzy(con, 'coverage', data)
    for row in result:
        yield Coverage(**row.as_dict())

@beartype.beartype
def read_coverage_any(con: db.Connection, coverage_id: Optional[List[int]] = None,
             mags_id: Optional[List[int]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             result_date_time: Optional[List[datetime.datetime]] = None,
             result_date_time_utc_offset: Optional[List[int]] = None,
             coverage_value: Optional[List[float]] = None) -> Generator[Coverage, None, None]:
    """
    Read from the coverage table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param coverage_id 
    @param mags_id 
    @param sampling_feature_id 
    @param result_date_time 
    @param result_date_time_utc_offset 
    @param coverage_value 
    @return generator of Coverage objects
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    result = db.query_any(con, 'coverage', data)
    for row in result:
        yield Coverage(**row.as_dict())

@beartype.beartype
def read_coverage_one_or_none(con: db.Connection, coverage_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             coverage_value: Optional[float] = None) -> Optional[Coverage]:
    """
    Read from the coverage table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    result = db.query_one_or_none(con, 'coverage', data)
    if result is None:
        return None
    return Coverage(**result)

@beartype.beartype
def read_coverage_one(con: db.Connection, coverage_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             coverage_value: Optional[float] = None) -> Coverage:
    """
    Read from the coverage table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    result = db.query_one(con, 'coverage', data)
    return Coverage(**result)

@beartype.beartype
def read_coverage_all(con: db.Connection, coverage_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             result_date_time: Optional[datetime.datetime] = None,
             result_date_time_utc_offset: Optional[int] = None,
             coverage_value: Optional[float] = None) -> List[Coverage]:
    """
    Read from the coverage table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'coverage_id': coverage_id,
        'mags_id': mags_id,
        'sampling_feature_id': sampling_feature_id,
        'result_date_time': result_date_time,
        'result_date_time_utc_offset': result_date_time_utc_offset,
        'coverage_value': coverage_value,
    }
    result = db.query(con, 'coverage', data)
    return [Coverage(**row.as_dict()) for row in result]

@beartype.beartype
def read_coverage_by_id(con: db.Connection, coverage_id: int) -> Optional[Coverage]:
    result = db.query_one(con, 'coverage', {'coverage_id': coverage_id})
    if result is None:
        return None
    return Coverage(**result)

@beartype.beartype
def delete_coverage_by_id(con: db.Connection, coverage_id: int):
    db.delete(con, 'coverage', {'coverage_id': coverage_id})
# Associate the functions with the class
Coverage.create_from_json_dict = create_coverage_from_json_dict
Coverage.write = write_coverage
Coverage.update = update_coverage
Coverage.write_many = write_coverage_many
Coverage.read = read_coverage
Coverage.read_fuzzy = read_coverage_fuzzy
Coverage.read_any = read_coverage_any
Coverage.read_one = read_coverage_one
Coverage.read_one_or_none = read_coverage_one_or_none
Coverage.read_all = read_coverage_all
Coverage.delete = delete_coverage_by_id
Coverage.read_by_id = read_coverage_by_id
Coverage.delete_by_id = delete_coverage_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Contigs:
    """
    @param contigs_id 
    @param contig_length 
    @param mag_binning_event_id 
    @param g_cpercentage 
    @param contig_coverage 
    @param fasta_file_path 
    @param fasta_file_name 

    This is an automatically generated class
    """
    contigs_id: Optional[int] = None # contigs_id integer (default: )
    contig_length: Optional[int] = None # contig_length integer (default: )
    mag_binning_event_id: Optional[int] = None # mag_binning_event_id integer (default: )
    g_cpercentage: Optional[float] = None # g_cpercentage double precision (default: )
    contig_coverage: Optional[float] = None # contig_coverage double precision (default: )
    fasta_file_path: Optional[str] = None # fasta_file_path character varying (default: )
    fasta_file_name: Optional[str] = None # fasta_file_name character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'contigs_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_mag_binning_event(self, con: db.Connection) -> Optional['BinningEvent']:
        return read_binning_event_one_or_none(con, mag_binning_event_id=self.mag_binning_event_id)

@beartype.beartype
def create_contigs_from_json_dict(json_obj: dict):
        """
        Create a Contigs from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Contigs(**json_obj)


@beartype.beartype
def write_contigs_obj(con: db.Connection, obj: Contigs) -> int:
    """
    Write a Contigs object to the database
    @param con: database connection
    @param obj: Contigs object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'contigs', dataclasses.asdict(obj))

@beartype.beartype
def write_contigs(
            con: db.Connection,
            contigs_id: Optional[int] = None,
            contig_length: Optional[int] = None,
            mag_binning_event_id: Optional[int] = None,
            g_cpercentage: Optional[float] = None,
            contig_coverage: Optional[float] = None,
            fasta_file_path: Optional[str] = None,
            fasta_file_name: Optional[str] = None) -> int:
    """
    Write to the contigs table in the database
    @param con: database connection
    @param contigs_id 
    @param contig_length 
    @param mag_binning_event_id 
    @param g_cpercentage 
    @param contig_coverage 
    @param fasta_file_path 
    @param fasta_file_name 
    @return id of the inserted/updated row
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    return db.upsert(con, 'contigs', data)

@beartype.beartype
def write_contigs_many(con: db.Connection, objs: List[Contigs], upsert: bool = False) -> int:
    """
    Write a list of Contigs objects to the database
    @param con: database connection
    @param objs: list of Contigs objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'contigs', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_contigs(con: db.Connection, contigs_id: int,
            contig_length: Optional[int] = None,
            mag_binning_event_id: Optional[int] = None,
            g_cpercentage: Optional[float] = None,
            contig_coverage: Optional[float] = None,
            fasta_file_path: Optional[str] = None,
            fasta_file_name: Optional[str] = None) -> int:
    """
    Update a row in the contigs table in the database
    @param con: database connection
    @param contigs_id 
    @param contig_length 
    @param mag_binning_event_id 
    @param g_cpercentage 
    @param contig_coverage 
    @param fasta_file_path 
    @param fasta_file_name 
    @return The number of rows updated
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    return db.update(con, 'contigs', data)

@beartype.beartype
def read_contigs(
            con: db.Connection,
            contigs_id: Optional[int] = None,
             contig_length: Optional[int] = None,
             mag_binning_event_id: Optional[int] = None,
             g_cpercentage: Optional[float] = None,
             contig_coverage: Optional[float] = None,
             fasta_file_path: Optional[str] = None,
             fasta_file_name: Optional[str] = None) -> Generator[Contigs, None, None]:
    """
    Read from the contigs table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param contigs_id 
    @param contig_length 
    @param mag_binning_event_id 
    @param g_cpercentage 
    @param contig_coverage 
    @param fasta_file_path 
    @param fasta_file_name 
    @return generator of Contigs objects
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    result = db.query(con, 'contigs', data)
    for row in result:
        yield Contigs(**row.as_dict())

@beartype.beartype
def read_contigs_fuzzy(con: db.Connection, contigs_id: Optional[int] = None,
             contig_length: Optional[int] = None,
             mag_binning_event_id: Optional[int] = None,
             g_cpercentage: Optional[float] = None,
             contig_coverage: Optional[float] = None,
             fasta_file_path: Optional[str] = None,
             fasta_file_name: Optional[str] = None) -> Generator[Contigs, None, None]:
    """
    Read from the contigs table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param contigs_id 
    @param contig_length 
    @param mag_binning_event_id 
    @param g_cpercentage 
    @param contig_coverage 
    @param fasta_file_path 
    @param fasta_file_name 
    @return generator of Contigs objects
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    result = db.query_fuzzy(con, 'contigs', data)
    for row in result:
        yield Contigs(**row.as_dict())

@beartype.beartype
def read_contigs_any(con: db.Connection, contigs_id: Optional[List[int]] = None,
             contig_length: Optional[List[int]] = None,
             mag_binning_event_id: Optional[List[int]] = None,
             g_cpercentage: Optional[List[float]] = None,
             contig_coverage: Optional[List[float]] = None,
             fasta_file_path: Optional[List[str]] = None,
             fasta_file_name: Optional[List[str]] = None) -> Generator[Contigs, None, None]:
    """
    Read from the contigs table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param contigs_id 
    @param contig_length 
    @param mag_binning_event_id 
    @param g_cpercentage 
    @param contig_coverage 
    @param fasta_file_path 
    @param fasta_file_name 
    @return generator of Contigs objects
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    result = db.query_any(con, 'contigs', data)
    for row in result:
        yield Contigs(**row.as_dict())

@beartype.beartype
def read_contigs_one_or_none(con: db.Connection, contigs_id: Optional[int] = None,
             contig_length: Optional[int] = None,
             mag_binning_event_id: Optional[int] = None,
             g_cpercentage: Optional[float] = None,
             contig_coverage: Optional[float] = None,
             fasta_file_path: Optional[str] = None,
             fasta_file_name: Optional[str] = None) -> Optional[Contigs]:
    """
    Read from the contigs table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    result = db.query_one_or_none(con, 'contigs', data)
    if result is None:
        return None
    return Contigs(**result)

@beartype.beartype
def read_contigs_one(con: db.Connection, contigs_id: Optional[int] = None,
             contig_length: Optional[int] = None,
             mag_binning_event_id: Optional[int] = None,
             g_cpercentage: Optional[float] = None,
             contig_coverage: Optional[float] = None,
             fasta_file_path: Optional[str] = None,
             fasta_file_name: Optional[str] = None) -> Contigs:
    """
    Read from the contigs table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    result = db.query_one(con, 'contigs', data)
    return Contigs(**result)

@beartype.beartype
def read_contigs_all(con: db.Connection, contigs_id: Optional[int] = None,
             contig_length: Optional[int] = None,
             mag_binning_event_id: Optional[int] = None,
             g_cpercentage: Optional[float] = None,
             contig_coverage: Optional[float] = None,
             fasta_file_path: Optional[str] = None,
             fasta_file_name: Optional[str] = None) -> List[Contigs]:
    """
    Read from the contigs table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'contigs_id': contigs_id,
        'contig_length': contig_length,
        'mag_binning_event_id': mag_binning_event_id,
        'g_cpercentage': g_cpercentage,
        'contig_coverage': contig_coverage,
        'fasta_file_path': fasta_file_path,
        'fasta_file_name': fasta_file_name,
    }
    result = db.query(con, 'contigs', data)
    return [Contigs(**row.as_dict()) for row in result]

@beartype.beartype
def read_contigs_by_id(con: db.Connection, contigs_id: int) -> Optional[Contigs]:
    result = db.query_one(con, 'contigs', {'contigs_id': contigs_id})
    if result is None:
        return None
    return Contigs(**result)

@beartype.beartype
def delete_contigs_by_id(con: db.Connection, contigs_id: int):
    db.delete(con, 'contigs', {'contigs_id': contigs_id})
# Associate the functions with the class
Contigs.create_from_json_dict = create_contigs_from_json_dict
Contigs.write = write_contigs
Contigs.update = update_contigs
Contigs.write_many = write_contigs_many
Contigs.read = read_contigs
Contigs.read_fuzzy = read_contigs_fuzzy
Contigs.read_any = read_contigs_any
Contigs.read_one = read_contigs_one
Contigs.read_one_or_none = read_contigs_one_or_none
Contigs.read_all = read_contigs_all
Contigs.delete = delete_contigs_by_id
Contigs.read_by_id = read_contigs_by_id
Contigs.delete_by_id = delete_contigs_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MagAnnotationEvent:
    """
    @param mag_annotation_event_id 
    @param annotation_method 
    @param mags_id 
    @param mag_annotation 
    @param event_date 
    @param event_date_utc_offset 
    @param version 
    @param genes_faa_file_path 
    @param genes_fna_file_path 
    @param genes_gff_file_path 
    @param scaffolds_fna_file_path 
    @param gbk_file_path 

    This is an automatically generated class
    """
    mag_annotation_event_id: Optional[int] = None # mag_annotation_event_id integer (default: )
    annotation_method: Optional[str] = None # annotation_method character varying (default: )
    mags_id: Optional[int] = None # mags_id integer (default: )
    mag_annotation: Optional[str] = None # mag_annotation character varying (default: )
    event_date: Optional[datetime.datetime] = None # event_date timestamp without time zone (default: )
    event_date_utc_offset: Optional[int] = None # event_date_utc_offset integer (default: )
    version: Optional[str] = None # version character varying (default: )
    genes_faa_file_path: Optional[str] = None # genes_faa_file_path character varying (default: )
    genes_fna_file_path: Optional[str] = None # genes_fna_file_path character varying (default: )
    genes_gff_file_path: Optional[str] = None # genes_gff_file_path character varying (default: )
    scaffolds_fna_file_path: Optional[str] = None # scaffolds_fna_file_path character varying (default: )
    gbk_file_path: Optional[str] = None # gbk_file_path character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'mag_annotation_event_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.event_date is not None:
            obj['event_date'] = self.event_date.isoformat()
        return obj

    @beartype.beartype
    def get_mags(self, con: db.Connection) -> Optional['Mags']:
        return read_mags_one_or_none(con, mags_id=self.mags_id)

@beartype.beartype
def create_mag_annotation_event_from_json_dict(json_obj: dict):
        """
        Create a MagAnnotationEvent from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'event_date' in json_obj and json_obj['event_date'] is not None:
            json_obj['event_date'] = datetime.datetime.fromisoformat(json_obj['event_date'])
        return MagAnnotationEvent(**json_obj)


@beartype.beartype
def write_mag_annotation_event_obj(con: db.Connection, obj: MagAnnotationEvent) -> int:
    """
    Write a MagAnnotationEvent object to the database
    @param con: database connection
    @param obj: MagAnnotationEvent object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'mag_annotation_event', dataclasses.asdict(obj))

@beartype.beartype
def write_mag_annotation_event(
            con: db.Connection,
            mag_annotation_event_id: Optional[int] = None,
            annotation_method: Optional[str] = None,
            mags_id: Optional[int] = None,
            mag_annotation: Optional[str] = None,
            event_date: Optional[datetime.datetime] = None,
            event_date_utc_offset: Optional[int] = None,
            version: Optional[str] = None,
            genes_faa_file_path: Optional[str] = None,
            genes_fna_file_path: Optional[str] = None,
            genes_gff_file_path: Optional[str] = None,
            scaffolds_fna_file_path: Optional[str] = None,
            gbk_file_path: Optional[str] = None) -> int:
    """
    Write to the mag_annotation_event table in the database
    @param con: database connection
    @param mag_annotation_event_id 
    @param annotation_method 
    @param mags_id 
    @param mag_annotation 
    @param event_date 
    @param event_date_utc_offset 
    @param version 
    @param genes_faa_file_path 
    @param genes_fna_file_path 
    @param genes_gff_file_path 
    @param scaffolds_fna_file_path 
    @param gbk_file_path 
    @return id of the inserted/updated row
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    return db.upsert(con, 'mag_annotation_event', data)

@beartype.beartype
def write_mag_annotation_event_many(con: db.Connection, objs: List[MagAnnotationEvent], upsert: bool = False) -> int:
    """
    Write a list of MagAnnotationEvent objects to the database
    @param con: database connection
    @param objs: list of MagAnnotationEvent objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'mag_annotation_event', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_mag_annotation_event(con: db.Connection, mag_annotation_event_id: int,
            annotation_method: Optional[str] = None,
            mags_id: Optional[int] = None,
            mag_annotation: Optional[str] = None,
            event_date: Optional[datetime.datetime] = None,
            event_date_utc_offset: Optional[int] = None,
            version: Optional[str] = None,
            genes_faa_file_path: Optional[str] = None,
            genes_fna_file_path: Optional[str] = None,
            genes_gff_file_path: Optional[str] = None,
            scaffolds_fna_file_path: Optional[str] = None,
            gbk_file_path: Optional[str] = None) -> int:
    """
    Update a row in the mag_annotation_event table in the database
    @param con: database connection
    @param mag_annotation_event_id 
    @param annotation_method 
    @param mags_id 
    @param mag_annotation 
    @param event_date 
    @param event_date_utc_offset 
    @param version 
    @param genes_faa_file_path 
    @param genes_fna_file_path 
    @param genes_gff_file_path 
    @param scaffolds_fna_file_path 
    @param gbk_file_path 
    @return The number of rows updated
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    return db.update(con, 'mag_annotation_event', data)

@beartype.beartype
def read_mag_annotation_event(
            con: db.Connection,
            mag_annotation_event_id: Optional[int] = None,
             annotation_method: Optional[str] = None,
             mags_id: Optional[int] = None,
             mag_annotation: Optional[str] = None,
             event_date: Optional[datetime.datetime] = None,
             event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             genes_faa_file_path: Optional[str] = None,
             genes_fna_file_path: Optional[str] = None,
             genes_gff_file_path: Optional[str] = None,
             scaffolds_fna_file_path: Optional[str] = None,
             gbk_file_path: Optional[str] = None) -> Generator[MagAnnotationEvent, None, None]:
    """
    Read from the mag_annotation_event table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_annotation_event_id 
    @param annotation_method 
    @param mags_id 
    @param mag_annotation 
    @param event_date 
    @param event_date_utc_offset 
    @param version 
    @param genes_faa_file_path 
    @param genes_fna_file_path 
    @param genes_gff_file_path 
    @param scaffolds_fna_file_path 
    @param gbk_file_path 
    @return generator of MagAnnotationEvent objects
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    result = db.query(con, 'mag_annotation_event', data)
    for row in result:
        yield MagAnnotationEvent(**row.as_dict())

@beartype.beartype
def read_mag_annotation_event_fuzzy(con: db.Connection, mag_annotation_event_id: Optional[int] = None,
             annotation_method: Optional[str] = None,
             mags_id: Optional[int] = None,
             mag_annotation: Optional[str] = None,
             event_date: Optional[datetime.datetime] = None,
             event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             genes_faa_file_path: Optional[str] = None,
             genes_fna_file_path: Optional[str] = None,
             genes_gff_file_path: Optional[str] = None,
             scaffolds_fna_file_path: Optional[str] = None,
             gbk_file_path: Optional[str] = None) -> Generator[MagAnnotationEvent, None, None]:
    """
    Read from the mag_annotation_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_annotation_event_id 
    @param annotation_method 
    @param mags_id 
    @param mag_annotation 
    @param event_date 
    @param event_date_utc_offset 
    @param version 
    @param genes_faa_file_path 
    @param genes_fna_file_path 
    @param genes_gff_file_path 
    @param scaffolds_fna_file_path 
    @param gbk_file_path 
    @return generator of MagAnnotationEvent objects
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    result = db.query_fuzzy(con, 'mag_annotation_event', data)
    for row in result:
        yield MagAnnotationEvent(**row.as_dict())

@beartype.beartype
def read_mag_annotation_event_any(con: db.Connection, mag_annotation_event_id: Optional[List[int]] = None,
             annotation_method: Optional[List[str]] = None,
             mags_id: Optional[List[int]] = None,
             mag_annotation: Optional[List[str]] = None,
             event_date: Optional[List[datetime.datetime]] = None,
             event_date_utc_offset: Optional[List[int]] = None,
             version: Optional[List[str]] = None,
             genes_faa_file_path: Optional[List[str]] = None,
             genes_fna_file_path: Optional[List[str]] = None,
             genes_gff_file_path: Optional[List[str]] = None,
             scaffolds_fna_file_path: Optional[List[str]] = None,
             gbk_file_path: Optional[List[str]] = None) -> Generator[MagAnnotationEvent, None, None]:
    """
    Read from the mag_annotation_event table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param mag_annotation_event_id 
    @param annotation_method 
    @param mags_id 
    @param mag_annotation 
    @param event_date 
    @param event_date_utc_offset 
    @param version 
    @param genes_faa_file_path 
    @param genes_fna_file_path 
    @param genes_gff_file_path 
    @param scaffolds_fna_file_path 
    @param gbk_file_path 
    @return generator of MagAnnotationEvent objects
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    result = db.query_any(con, 'mag_annotation_event', data)
    for row in result:
        yield MagAnnotationEvent(**row.as_dict())

@beartype.beartype
def read_mag_annotation_event_one_or_none(con: db.Connection, mag_annotation_event_id: Optional[int] = None,
             annotation_method: Optional[str] = None,
             mags_id: Optional[int] = None,
             mag_annotation: Optional[str] = None,
             event_date: Optional[datetime.datetime] = None,
             event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             genes_faa_file_path: Optional[str] = None,
             genes_fna_file_path: Optional[str] = None,
             genes_gff_file_path: Optional[str] = None,
             scaffolds_fna_file_path: Optional[str] = None,
             gbk_file_path: Optional[str] = None) -> Optional[MagAnnotationEvent]:
    """
    Read from the mag_annotation_event table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    result = db.query_one_or_none(con, 'mag_annotation_event', data)
    if result is None:
        return None
    return MagAnnotationEvent(**result)

@beartype.beartype
def read_mag_annotation_event_one(con: db.Connection, mag_annotation_event_id: Optional[int] = None,
             annotation_method: Optional[str] = None,
             mags_id: Optional[int] = None,
             mag_annotation: Optional[str] = None,
             event_date: Optional[datetime.datetime] = None,
             event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             genes_faa_file_path: Optional[str] = None,
             genes_fna_file_path: Optional[str] = None,
             genes_gff_file_path: Optional[str] = None,
             scaffolds_fna_file_path: Optional[str] = None,
             gbk_file_path: Optional[str] = None) -> MagAnnotationEvent:
    """
    Read from the mag_annotation_event table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    result = db.query_one(con, 'mag_annotation_event', data)
    return MagAnnotationEvent(**result)

@beartype.beartype
def read_mag_annotation_event_all(con: db.Connection, mag_annotation_event_id: Optional[int] = None,
             annotation_method: Optional[str] = None,
             mags_id: Optional[int] = None,
             mag_annotation: Optional[str] = None,
             event_date: Optional[datetime.datetime] = None,
             event_date_utc_offset: Optional[int] = None,
             version: Optional[str] = None,
             genes_faa_file_path: Optional[str] = None,
             genes_fna_file_path: Optional[str] = None,
             genes_gff_file_path: Optional[str] = None,
             scaffolds_fna_file_path: Optional[str] = None,
             gbk_file_path: Optional[str] = None) -> List[MagAnnotationEvent]:
    """
    Read from the mag_annotation_event table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'mag_annotation_event_id': mag_annotation_event_id,
        'annotation_method': annotation_method,
        'mags_id': mags_id,
        'mag_annotation': mag_annotation,
        'event_date': event_date,
        'event_date_utc_offset': event_date_utc_offset,
        'version': version,
        'genes_faa_file_path': genes_faa_file_path,
        'genes_fna_file_path': genes_fna_file_path,
        'genes_gff_file_path': genes_gff_file_path,
        'scaffolds_fna_file_path': scaffolds_fna_file_path,
        'gbk_file_path': gbk_file_path,
    }
    result = db.query(con, 'mag_annotation_event', data)
    return [MagAnnotationEvent(**row.as_dict()) for row in result]

@beartype.beartype
def read_mag_annotation_event_by_id(con: db.Connection, mag_annotation_event_id: int) -> Optional[MagAnnotationEvent]:
    result = db.query_one(con, 'mag_annotation_event', {'mag_annotation_event_id': mag_annotation_event_id})
    if result is None:
        return None
    return MagAnnotationEvent(**result)

@beartype.beartype
def delete_mag_annotation_event_by_id(con: db.Connection, mag_annotation_event_id: int):
    db.delete(con, 'mag_annotation_event', {'mag_annotation_event_id': mag_annotation_event_id})
# Associate the functions with the class
MagAnnotationEvent.create_from_json_dict = create_mag_annotation_event_from_json_dict
MagAnnotationEvent.write = write_mag_annotation_event
MagAnnotationEvent.update = update_mag_annotation_event
MagAnnotationEvent.write_many = write_mag_annotation_event_many
MagAnnotationEvent.read = read_mag_annotation_event
MagAnnotationEvent.read_fuzzy = read_mag_annotation_event_fuzzy
MagAnnotationEvent.read_any = read_mag_annotation_event_any
MagAnnotationEvent.read_one = read_mag_annotation_event_one
MagAnnotationEvent.read_one_or_none = read_mag_annotation_event_one_or_none
MagAnnotationEvent.read_all = read_mag_annotation_event_all
MagAnnotationEvent.delete = delete_mag_annotation_event_by_id
MagAnnotationEvent.read_by_id = read_mag_annotation_event_by_id
MagAnnotationEvent.delete_by_id = delete_mag_annotation_event_by_id



@beartype_wrap_init
@dataclasses.dataclass
class QcdReads:
    """
    @param qcd_reads_id 
    @param qc_processing_method 
    @param number_of_reads 
    @param raw_reads_id 
    @param processing_method_parameters 

    This is an automatically generated class
    """
    qcd_reads_id: Optional[int] = None # qcd_reads_id integer (default: )
    qc_processing_method: Optional[str] = None # qc_processing_method character varying (default: )
    number_of_reads: Optional[int] = None # number_of_reads integer (default: )
    raw_reads_id: Optional[int] = None # raw_reads_id integer (default: )
    processing_method_parameters: Optional[str] = None # processing_method_parameters character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'qcd_reads_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_raw_reads(self, con: db.Connection) -> Optional['RawReads']:
        return read_raw_reads_one_or_none(con, raw_reads_id=self.raw_reads_id)

@beartype.beartype
def create_qcd_reads_from_json_dict(json_obj: dict):
        """
        Create a QcdReads from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return QcdReads(**json_obj)


@beartype.beartype
def write_qcd_reads_obj(con: db.Connection, obj: QcdReads) -> int:
    """
    Write a QcdReads object to the database
    @param con: database connection
    @param obj: QcdReads object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'qcd_reads', dataclasses.asdict(obj))

@beartype.beartype
def write_qcd_reads(
            con: db.Connection,
            qcd_reads_id: Optional[int] = None,
            qc_processing_method: Optional[str] = None,
            number_of_reads: Optional[int] = None,
            raw_reads_id: Optional[int] = None,
            processing_method_parameters: Optional[str] = None) -> int:
    """
    Write to the qcd_reads table in the database
    @param con: database connection
    @param qcd_reads_id 
    @param qc_processing_method 
    @param number_of_reads 
    @param raw_reads_id 
    @param processing_method_parameters 
    @return id of the inserted/updated row
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    return db.upsert(con, 'qcd_reads', data)

@beartype.beartype
def write_qcd_reads_many(con: db.Connection, objs: List[QcdReads], upsert: bool = False) -> int:
    """
    Write a list of QcdReads objects to the database
    @param con: database connection
    @param objs: list of QcdReads objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'qcd_reads', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_qcd_reads(con: db.Connection, qcd_reads_id: int,
            qc_processing_method: Optional[str] = None,
            number_of_reads: Optional[int] = None,
            raw_reads_id: Optional[int] = None,
            processing_method_parameters: Optional[str] = None) -> int:
    """
    Update a row in the qcd_reads table in the database
    @param con: database connection
    @param qcd_reads_id 
    @param qc_processing_method 
    @param number_of_reads 
    @param raw_reads_id 
    @param processing_method_parameters 
    @return The number of rows updated
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    return db.update(con, 'qcd_reads', data)

@beartype.beartype
def read_qcd_reads(
            con: db.Connection,
            qcd_reads_id: Optional[int] = None,
             qc_processing_method: Optional[str] = None,
             number_of_reads: Optional[int] = None,
             raw_reads_id: Optional[int] = None,
             processing_method_parameters: Optional[str] = None) -> Generator[QcdReads, None, None]:
    """
    Read from the qcd_reads table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qcd_reads_id 
    @param qc_processing_method 
    @param number_of_reads 
    @param raw_reads_id 
    @param processing_method_parameters 
    @return generator of QcdReads objects
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    result = db.query(con, 'qcd_reads', data)
    for row in result:
        yield QcdReads(**row.as_dict())

@beartype.beartype
def read_qcd_reads_fuzzy(con: db.Connection, qcd_reads_id: Optional[int] = None,
             qc_processing_method: Optional[str] = None,
             number_of_reads: Optional[int] = None,
             raw_reads_id: Optional[int] = None,
             processing_method_parameters: Optional[str] = None) -> Generator[QcdReads, None, None]:
    """
    Read from the qcd_reads table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qcd_reads_id 
    @param qc_processing_method 
    @param number_of_reads 
    @param raw_reads_id 
    @param processing_method_parameters 
    @return generator of QcdReads objects
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    result = db.query_fuzzy(con, 'qcd_reads', data)
    for row in result:
        yield QcdReads(**row.as_dict())

@beartype.beartype
def read_qcd_reads_any(con: db.Connection, qcd_reads_id: Optional[List[int]] = None,
             qc_processing_method: Optional[List[str]] = None,
             number_of_reads: Optional[List[int]] = None,
             raw_reads_id: Optional[List[int]] = None,
             processing_method_parameters: Optional[List[str]] = None) -> Generator[QcdReads, None, None]:
    """
    Read from the qcd_reads table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qcd_reads_id 
    @param qc_processing_method 
    @param number_of_reads 
    @param raw_reads_id 
    @param processing_method_parameters 
    @return generator of QcdReads objects
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    result = db.query_any(con, 'qcd_reads', data)
    for row in result:
        yield QcdReads(**row.as_dict())

@beartype.beartype
def read_qcd_reads_one_or_none(con: db.Connection, qcd_reads_id: Optional[int] = None,
             qc_processing_method: Optional[str] = None,
             number_of_reads: Optional[int] = None,
             raw_reads_id: Optional[int] = None,
             processing_method_parameters: Optional[str] = None) -> Optional[QcdReads]:
    """
    Read from the qcd_reads table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    result = db.query_one_or_none(con, 'qcd_reads', data)
    if result is None:
        return None
    return QcdReads(**result)

@beartype.beartype
def read_qcd_reads_one(con: db.Connection, qcd_reads_id: Optional[int] = None,
             qc_processing_method: Optional[str] = None,
             number_of_reads: Optional[int] = None,
             raw_reads_id: Optional[int] = None,
             processing_method_parameters: Optional[str] = None) -> QcdReads:
    """
    Read from the qcd_reads table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    result = db.query_one(con, 'qcd_reads', data)
    return QcdReads(**result)

@beartype.beartype
def read_qcd_reads_all(con: db.Connection, qcd_reads_id: Optional[int] = None,
             qc_processing_method: Optional[str] = None,
             number_of_reads: Optional[int] = None,
             raw_reads_id: Optional[int] = None,
             processing_method_parameters: Optional[str] = None) -> List[QcdReads]:
    """
    Read from the qcd_reads table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'qcd_reads_id': qcd_reads_id,
        'qc_processing_method': qc_processing_method,
        'number_of_reads': number_of_reads,
        'raw_reads_id': raw_reads_id,
        'processing_method_parameters': processing_method_parameters,
    }
    result = db.query(con, 'qcd_reads', data)
    return [QcdReads(**row.as_dict()) for row in result]

@beartype.beartype
def read_qcd_reads_by_id(con: db.Connection, qcd_reads_id: int) -> Optional[QcdReads]:
    result = db.query_one(con, 'qcd_reads', {'qcd_reads_id': qcd_reads_id})
    if result is None:
        return None
    return QcdReads(**result)

@beartype.beartype
def delete_qcd_reads_by_id(con: db.Connection, qcd_reads_id: int):
    db.delete(con, 'qcd_reads', {'qcd_reads_id': qcd_reads_id})
# Associate the functions with the class
QcdReads.create_from_json_dict = create_qcd_reads_from_json_dict
QcdReads.write = write_qcd_reads
QcdReads.update = update_qcd_reads
QcdReads.write_many = write_qcd_reads_many
QcdReads.read = read_qcd_reads
QcdReads.read_fuzzy = read_qcd_reads_fuzzy
QcdReads.read_any = read_qcd_reads_any
QcdReads.read_one = read_qcd_reads_one
QcdReads.read_one_or_none = read_qcd_reads_one_or_none
QcdReads.read_all = read_qcd_reads_all
QcdReads.delete = delete_qcd_reads_by_id
QcdReads.read_by_id = read_qcd_reads_by_id
QcdReads.delete_by_id = delete_qcd_reads_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ExtractedDna:
    """
    @param extracted_dnaid 
    @param sampling_feature_id 
    @param extraction_kit_name 
    @param extraction_kit_id 
    @param dna_input_volume_ml 
    @param extraction_date 
    @param extraction_notes 

    This is an automatically generated class
    """
    extracted_dnaid: Optional[int] = None # extracted_dnaid integer (default: )
    sampling_feature_id: Optional[int] = None # sampling_feature_id integer (default: )
    extraction_kit_name: Optional[str] = None # extraction_kit_name character varying (default: )
    extraction_kit_id: Optional[str] = None # extraction_kit_id character varying (default: )
    dna_input_volume_ml: Optional[float] = None # dna_input_volume_ml double precision (default: )
    extraction_date: Optional[datetime.datetime] = None # extraction_date timestamp without time zone (default: )
    extraction_notes: Optional[str] = None # extraction_notes character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'extracted_dnaid'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.extraction_date is not None:
            obj['extraction_date'] = self.extraction_date.isoformat()
        return obj

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['Specimens']:
        return read_specimens_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_extracted_dna_from_json_dict(json_obj: dict):
        """
        Create a ExtractedDna from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'extraction_date' in json_obj and json_obj['extraction_date'] is not None:
            json_obj['extraction_date'] = datetime.datetime.fromisoformat(json_obj['extraction_date'])
        return ExtractedDna(**json_obj)


@beartype.beartype
def write_extracted_dna_obj(con: db.Connection, obj: ExtractedDna) -> int:
    """
    Write a ExtractedDna object to the database
    @param con: database connection
    @param obj: ExtractedDna object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'extracted_dna', dataclasses.asdict(obj))

@beartype.beartype
def write_extracted_dna(
            con: db.Connection,
            extracted_dnaid: Optional[int] = None,
            sampling_feature_id: Optional[int] = None,
            extraction_kit_name: Optional[str] = None,
            extraction_kit_id: Optional[str] = None,
            dna_input_volume_ml: Optional[float] = None,
            extraction_date: Optional[datetime.datetime] = None,
            extraction_notes: Optional[str] = None) -> int:
    """
    Write to the extracted_dna table in the database
    @param con: database connection
    @param extracted_dnaid 
    @param sampling_feature_id 
    @param extraction_kit_name 
    @param extraction_kit_id 
    @param dna_input_volume_ml 
    @param extraction_date 
    @param extraction_notes 
    @return id of the inserted/updated row
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    return db.upsert(con, 'extracted_dna', data)

@beartype.beartype
def write_extracted_dna_many(con: db.Connection, objs: List[ExtractedDna], upsert: bool = False) -> int:
    """
    Write a list of ExtractedDna objects to the database
    @param con: database connection
    @param objs: list of ExtractedDna objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'extracted_dna', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_extracted_dna(con: db.Connection, extracted_dnaid: int,
            sampling_feature_id: Optional[int] = None,
            extraction_kit_name: Optional[str] = None,
            extraction_kit_id: Optional[str] = None,
            dna_input_volume_ml: Optional[float] = None,
            extraction_date: Optional[datetime.datetime] = None,
            extraction_notes: Optional[str] = None) -> int:
    """
    Update a row in the extracted_dna table in the database
    @param con: database connection
    @param extracted_dnaid 
    @param sampling_feature_id 
    @param extraction_kit_name 
    @param extraction_kit_id 
    @param dna_input_volume_ml 
    @param extraction_date 
    @param extraction_notes 
    @return The number of rows updated
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    return db.update(con, 'extracted_dna', data)

@beartype.beartype
def read_extracted_dna(
            con: db.Connection,
            extracted_dnaid: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             extraction_kit_name: Optional[str] = None,
             extraction_kit_id: Optional[str] = None,
             dna_input_volume_ml: Optional[float] = None,
             extraction_date: Optional[datetime.datetime] = None,
             extraction_notes: Optional[str] = None) -> Generator[ExtractedDna, None, None]:
    """
    Read from the extracted_dna table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param extracted_dnaid 
    @param sampling_feature_id 
    @param extraction_kit_name 
    @param extraction_kit_id 
    @param dna_input_volume_ml 
    @param extraction_date 
    @param extraction_notes 
    @return generator of ExtractedDna objects
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    result = db.query(con, 'extracted_dna', data)
    for row in result:
        yield ExtractedDna(**row.as_dict())

@beartype.beartype
def read_extracted_dna_fuzzy(con: db.Connection, extracted_dnaid: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             extraction_kit_name: Optional[str] = None,
             extraction_kit_id: Optional[str] = None,
             dna_input_volume_ml: Optional[float] = None,
             extraction_date: Optional[datetime.datetime] = None,
             extraction_notes: Optional[str] = None) -> Generator[ExtractedDna, None, None]:
    """
    Read from the extracted_dna table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param extracted_dnaid 
    @param sampling_feature_id 
    @param extraction_kit_name 
    @param extraction_kit_id 
    @param dna_input_volume_ml 
    @param extraction_date 
    @param extraction_notes 
    @return generator of ExtractedDna objects
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    result = db.query_fuzzy(con, 'extracted_dna', data)
    for row in result:
        yield ExtractedDna(**row.as_dict())

@beartype.beartype
def read_extracted_dna_any(con: db.Connection, extracted_dnaid: Optional[List[int]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             extraction_kit_name: Optional[List[str]] = None,
             extraction_kit_id: Optional[List[str]] = None,
             dna_input_volume_ml: Optional[List[float]] = None,
             extraction_date: Optional[List[datetime.datetime]] = None,
             extraction_notes: Optional[List[str]] = None) -> Generator[ExtractedDna, None, None]:
    """
    Read from the extracted_dna table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param extracted_dnaid 
    @param sampling_feature_id 
    @param extraction_kit_name 
    @param extraction_kit_id 
    @param dna_input_volume_ml 
    @param extraction_date 
    @param extraction_notes 
    @return generator of ExtractedDna objects
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    result = db.query_any(con, 'extracted_dna', data)
    for row in result:
        yield ExtractedDna(**row.as_dict())

@beartype.beartype
def read_extracted_dna_one_or_none(con: db.Connection, extracted_dnaid: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             extraction_kit_name: Optional[str] = None,
             extraction_kit_id: Optional[str] = None,
             dna_input_volume_ml: Optional[float] = None,
             extraction_date: Optional[datetime.datetime] = None,
             extraction_notes: Optional[str] = None) -> Optional[ExtractedDna]:
    """
    Read from the extracted_dna table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    result = db.query_one_or_none(con, 'extracted_dna', data)
    if result is None:
        return None
    return ExtractedDna(**result)

@beartype.beartype
def read_extracted_dna_one(con: db.Connection, extracted_dnaid: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             extraction_kit_name: Optional[str] = None,
             extraction_kit_id: Optional[str] = None,
             dna_input_volume_ml: Optional[float] = None,
             extraction_date: Optional[datetime.datetime] = None,
             extraction_notes: Optional[str] = None) -> ExtractedDna:
    """
    Read from the extracted_dna table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    result = db.query_one(con, 'extracted_dna', data)
    return ExtractedDna(**result)

@beartype.beartype
def read_extracted_dna_all(con: db.Connection, extracted_dnaid: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             extraction_kit_name: Optional[str] = None,
             extraction_kit_id: Optional[str] = None,
             dna_input_volume_ml: Optional[float] = None,
             extraction_date: Optional[datetime.datetime] = None,
             extraction_notes: Optional[str] = None) -> List[ExtractedDna]:
    """
    Read from the extracted_dna table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'extracted_dnaid': extracted_dnaid,
        'sampling_feature_id': sampling_feature_id,
        'extraction_kit_name': extraction_kit_name,
        'extraction_kit_id': extraction_kit_id,
        'dna_input_volume_ml': dna_input_volume_ml,
        'extraction_date': extraction_date,
        'extraction_notes': extraction_notes,
    }
    result = db.query(con, 'extracted_dna', data)
    return [ExtractedDna(**row.as_dict()) for row in result]

@beartype.beartype
def read_extracted_dna_by_id(con: db.Connection, extracted_dnaid: int) -> Optional[ExtractedDna]:
    result = db.query_one(con, 'extracted_dna', {'extracted_dnaid': extracted_dnaid})
    if result is None:
        return None
    return ExtractedDna(**result)

@beartype.beartype
def delete_extracted_dna_by_id(con: db.Connection, extracted_dnaid: int):
    db.delete(con, 'extracted_dna', {'extracted_dnaid': extracted_dnaid})
# Associate the functions with the class
ExtractedDna.create_from_json_dict = create_extracted_dna_from_json_dict
ExtractedDna.write = write_extracted_dna
ExtractedDna.update = update_extracted_dna
ExtractedDna.write_many = write_extracted_dna_many
ExtractedDna.read = read_extracted_dna
ExtractedDna.read_fuzzy = read_extracted_dna_fuzzy
ExtractedDna.read_any = read_extracted_dna_any
ExtractedDna.read_one = read_extracted_dna_one
ExtractedDna.read_one_or_none = read_extracted_dna_one_or_none
ExtractedDna.read_all = read_extracted_dna_all
ExtractedDna.delete = delete_extracted_dna_by_id
ExtractedDna.read_by_id = read_extracted_dna_by_id
ExtractedDna.delete_by_id = delete_extracted_dna_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CategoricalResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: str # data_value character varying (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['CategoricalResults']:
        return read_categorical_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_categorical_result_values_from_json_dict(json_obj: dict):
        """
        Create a CategoricalResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return CategoricalResultValues(**json_obj)


@beartype.beartype
def write_categorical_result_values_obj(con: db.Connection, obj: CategoricalResultValues) -> int:
    """
    Write a CategoricalResultValues object to the database
    @param con: database connection
    @param obj: CategoricalResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'categorical_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_categorical_result_values(
            con: db.Connection,
            result_id: int,
            data_value: str,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the categorical_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    return db.upsert(con, 'categorical_result_values', data)

@beartype.beartype
def write_categorical_result_values_many(con: db.Connection, objs: List[CategoricalResultValues], upsert: bool = False) -> int:
    """
    Write a list of CategoricalResultValues objects to the database
    @param con: database connection
    @param objs: list of CategoricalResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'categorical_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_categorical_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[str] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None) -> int:
    """
    Update a row in the categorical_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    return db.update(con, 'categorical_result_values', data)

@beartype.beartype
def read_categorical_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[str] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[CategoricalResultValues, None, None]:
    """
    Read from the categorical_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @return generator of CategoricalResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    result = db.query(con, 'categorical_result_values', data)
    for row in result:
        yield CategoricalResultValues(**row.as_dict())

@beartype.beartype
def read_categorical_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[str] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[CategoricalResultValues, None, None]:
    """
    Read from the categorical_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @return generator of CategoricalResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    result = db.query_fuzzy(con, 'categorical_result_values', data)
    for row in result:
        yield CategoricalResultValues(**row.as_dict())

@beartype.beartype
def read_categorical_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[str]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[CategoricalResultValues, None, None]:
    """
    Read from the categorical_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @return generator of CategoricalResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    result = db.query_any(con, 'categorical_result_values', data)
    for row in result:
        yield CategoricalResultValues(**row.as_dict())

@beartype.beartype
def read_categorical_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[str] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[CategoricalResultValues]:
    """
    Read from the categorical_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    result = db.query_one_or_none(con, 'categorical_result_values', data)
    if result is None:
        return None
    return CategoricalResultValues(**result)

@beartype.beartype
def read_categorical_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[str] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             value_id: Optional[int] = None) -> CategoricalResultValues:
    """
    Read from the categorical_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    result = db.query_one(con, 'categorical_result_values', data)
    return CategoricalResultValues(**result)

@beartype.beartype
def read_categorical_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[str] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             value_id: Optional[int] = None) -> List[CategoricalResultValues]:
    """
    Read from the categorical_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
    }
    result = db.query(con, 'categorical_result_values', data)
    return [CategoricalResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_categorical_result_values_by_id(con: db.Connection, value_id: int) -> Optional[CategoricalResultValues]:
    result = db.query_one(con, 'categorical_result_values', {'value_id': value_id})
    if result is None:
        return None
    return CategoricalResultValues(**result)

@beartype.beartype
def delete_categorical_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'categorical_result_values', {'value_id': value_id})
# Associate the functions with the class
CategoricalResultValues.create_from_json_dict = create_categorical_result_values_from_json_dict
CategoricalResultValues.write = write_categorical_result_values
CategoricalResultValues.update = update_categorical_result_values
CategoricalResultValues.write_many = write_categorical_result_values_many
CategoricalResultValues.read = read_categorical_result_values
CategoricalResultValues.read_fuzzy = read_categorical_result_values_fuzzy
CategoricalResultValues.read_any = read_categorical_result_values_any
CategoricalResultValues.read_one = read_categorical_result_values_one
CategoricalResultValues.read_one_or_none = read_categorical_result_values_one_or_none
CategoricalResultValues.read_all = read_categorical_result_values_all
CategoricalResultValues.delete = delete_categorical_result_values_by_id
CategoricalResultValues.read_by_id = read_categorical_result_values_by_id
CategoricalResultValues.delete_by_id = delete_categorical_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MethodCitations:
    """
    @param bridge_id 
    @param method_id 
    @param relationship_type_cv 
    @param citation_id 

    This is an automatically generated class
    """
    method_id: int # method_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    citation_id: int # citation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_method(self, con: db.Connection) -> Optional['Methods']:
        return read_methods_one_or_none(con, method_id=self.method_id)

@beartype.beartype
def create_method_citations_from_json_dict(json_obj: dict):
        """
        Create a MethodCitations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MethodCitations(**json_obj)


@beartype.beartype
def write_method_citations_obj(con: db.Connection, obj: MethodCitations) -> int:
    """
    Write a MethodCitations object to the database
    @param con: database connection
    @param obj: MethodCitations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'method_citations', dataclasses.asdict(obj))

@beartype.beartype
def write_method_citations(
            con: db.Connection,
            method_id: int,
            relationship_type_cv: str,
            citation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the method_citations table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param relationship_type_cv 
    @param citation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    return db.upsert(con, 'method_citations', data)

@beartype.beartype
def write_method_citations_many(con: db.Connection, objs: List[MethodCitations], upsert: bool = False) -> int:
    """
    Write a list of MethodCitations objects to the database
    @param con: database connection
    @param objs: list of MethodCitations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'method_citations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_method_citations(con: db.Connection, bridge_id: int,
            method_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Update a row in the method_citations table in the database
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param relationship_type_cv 
    @param citation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    return db.update(con, 'method_citations', data)

@beartype.beartype
def read_method_citations(
            con: db.Connection,
            method_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[MethodCitations, None, None]:
    """
    Read from the method_citations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param relationship_type_cv 
    @param citation_id 
    @return generator of MethodCitations objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query(con, 'method_citations', data)
    for row in result:
        yield MethodCitations(**row.as_dict())

@beartype.beartype
def read_method_citations_fuzzy(con: db.Connection, method_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[MethodCitations, None, None]:
    """
    Read from the method_citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param relationship_type_cv 
    @param citation_id 
    @return generator of MethodCitations objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_fuzzy(con, 'method_citations', data)
    for row in result:
        yield MethodCitations(**row.as_dict())

@beartype.beartype
def read_method_citations_any(con: db.Connection, method_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             citation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[MethodCitations, None, None]:
    """
    Read from the method_citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param method_id 
    @param relationship_type_cv 
    @param citation_id 
    @return generator of MethodCitations objects
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_any(con, 'method_citations', data)
    for row in result:
        yield MethodCitations(**row.as_dict())

@beartype.beartype
def read_method_citations_one_or_none(con: db.Connection, method_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[MethodCitations]:
    """
    Read from the method_citations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_one_or_none(con, 'method_citations', data)
    if result is None:
        return None
    return MethodCitations(**result)

@beartype.beartype
def read_method_citations_one(con: db.Connection, method_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> MethodCitations:
    """
    Read from the method_citations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_one(con, 'method_citations', data)
    return MethodCitations(**result)

@beartype.beartype
def read_method_citations_all(con: db.Connection, method_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[MethodCitations]:
    """
    Read from the method_citations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'method_id': method_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query(con, 'method_citations', data)
    return [MethodCitations(**row.as_dict()) for row in result]

@beartype.beartype
def read_method_citations_by_id(con: db.Connection, bridge_id: int) -> Optional[MethodCitations]:
    result = db.query_one(con, 'method_citations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return MethodCitations(**result)

@beartype.beartype
def delete_method_citations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'method_citations', {'bridge_id': bridge_id})
# Associate the functions with the class
MethodCitations.create_from_json_dict = create_method_citations_from_json_dict
MethodCitations.write = write_method_citations
MethodCitations.update = update_method_citations
MethodCitations.write_many = write_method_citations_many
MethodCitations.read = read_method_citations
MethodCitations.read_fuzzy = read_method_citations_fuzzy
MethodCitations.read_any = read_method_citations_any
MethodCitations.read_one = read_method_citations_one
MethodCitations.read_one_or_none = read_method_citations_one_or_none
MethodCitations.read_all = read_method_citations_all
MethodCitations.delete = delete_method_citations_by_id
MethodCitations.read_by_id = read_method_citations_by_id
MethodCitations.delete_by_id = delete_method_citations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedAnnotations:
    """
    Stores information about relationships among Annotations

    @param relation_id 
    @param annotation_id 
    @param relationship_type_cv 
    @param related_annotation_id 

    This is an automatically generated class
    """
    annotation_id: int # annotation_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_annotation_id: int # related_annotation_id integer (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.annotation_id)

    @beartype.beartype
    def get_related_annotation(self, con: db.Connection) -> Optional['Annotations']:
        return read_annotations_one_or_none(con, annotation_id=self.related_annotation_id)

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

@beartype.beartype
def create_related_annotations_from_json_dict(json_obj: dict):
        """
        Create a RelatedAnnotations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedAnnotations(**json_obj)


@beartype.beartype
def write_related_annotations_obj(con: db.Connection, obj: RelatedAnnotations) -> int:
    """
    Write a RelatedAnnotations object to the database
    @param con: database connection
    @param obj: RelatedAnnotations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_annotations', dataclasses.asdict(obj))

@beartype.beartype
def write_related_annotations(
            con: db.Connection,
            annotation_id: int,
            relationship_type_cv: str,
            related_annotation_id: int,
            relation_id: Optional[int] = None) -> int:
    """
    Write to the related_annotations table in the database
    @param con: database connection
    @param relation_id 
    @param annotation_id 
    @param relationship_type_cv 
    @param related_annotation_id 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    return db.upsert(con, 'related_annotations', data)

@beartype.beartype
def write_related_annotations_many(con: db.Connection, objs: List[RelatedAnnotations], upsert: bool = False) -> int:
    """
    Write a list of RelatedAnnotations objects to the database
    @param con: database connection
    @param objs: list of RelatedAnnotations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_annotations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_annotations(con: db.Connection, relation_id: int,
            annotation_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_annotation_id: Optional[int] = None) -> int:
    """
    Update a row in the related_annotations table in the database
    @param con: database connection
    @param relation_id 
    @param annotation_id 
    @param relationship_type_cv 
    @param related_annotation_id 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    return db.update(con, 'related_annotations', data)

@beartype.beartype
def read_related_annotations(
            con: db.Connection,
            annotation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_annotation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Generator[RelatedAnnotations, None, None]:
    """
    Read from the related_annotations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param annotation_id 
    @param relationship_type_cv 
    @param related_annotation_id 
    @return generator of RelatedAnnotations objects
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    result = db.query(con, 'related_annotations', data)
    for row in result:
        yield RelatedAnnotations(**row.as_dict())

@beartype.beartype
def read_related_annotations_fuzzy(con: db.Connection, annotation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_annotation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Generator[RelatedAnnotations, None, None]:
    """
    Read from the related_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param annotation_id 
    @param relationship_type_cv 
    @param related_annotation_id 
    @return generator of RelatedAnnotations objects
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    result = db.query_fuzzy(con, 'related_annotations', data)
    for row in result:
        yield RelatedAnnotations(**row.as_dict())

@beartype.beartype
def read_related_annotations_any(con: db.Connection, annotation_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_annotation_id: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None) -> Generator[RelatedAnnotations, None, None]:
    """
    Read from the related_annotations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param annotation_id 
    @param relationship_type_cv 
    @param related_annotation_id 
    @return generator of RelatedAnnotations objects
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    result = db.query_any(con, 'related_annotations', data)
    for row in result:
        yield RelatedAnnotations(**row.as_dict())

@beartype.beartype
def read_related_annotations_one_or_none(con: db.Connection, annotation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_annotation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Optional[RelatedAnnotations]:
    """
    Read from the related_annotations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    result = db.query_one_or_none(con, 'related_annotations', data)
    if result is None:
        return None
    return RelatedAnnotations(**result)

@beartype.beartype
def read_related_annotations_one(con: db.Connection, annotation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_annotation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> RelatedAnnotations:
    """
    Read from the related_annotations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    result = db.query_one(con, 'related_annotations', data)
    return RelatedAnnotations(**result)

@beartype.beartype
def read_related_annotations_all(con: db.Connection, annotation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_annotation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> List[RelatedAnnotations]:
    """
    Read from the related_annotations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'annotation_id': annotation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_annotation_id': related_annotation_id,
    }
    result = db.query(con, 'related_annotations', data)
    return [RelatedAnnotations(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_annotations_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedAnnotations]:
    result = db.query_one(con, 'related_annotations', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedAnnotations(**result)

@beartype.beartype
def delete_related_annotations_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_annotations', {'relation_id': relation_id})
# Associate the functions with the class
RelatedAnnotations.create_from_json_dict = create_related_annotations_from_json_dict
RelatedAnnotations.write = write_related_annotations
RelatedAnnotations.update = update_related_annotations
RelatedAnnotations.write_many = write_related_annotations_many
RelatedAnnotations.read = read_related_annotations
RelatedAnnotations.read_fuzzy = read_related_annotations_fuzzy
RelatedAnnotations.read_any = read_related_annotations_any
RelatedAnnotations.read_one = read_related_annotations_one
RelatedAnnotations.read_one_or_none = read_related_annotations_one_or_none
RelatedAnnotations.read_all = read_related_annotations_all
RelatedAnnotations.delete = delete_related_annotations_by_id
RelatedAnnotations.read_by_id = read_related_annotations_by_id
RelatedAnnotations.delete_by_id = delete_related_annotations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedCitations:
    """
    Information about relationships among citations

    @param relation_id 
    @param citation_id 
    @param relationship_type_cv 
    @param related_citation_id 

    This is an automatically generated class
    """
    citation_id: int # citation_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_citation_id: int # related_citation_id integer (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_related_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.related_citation_id)

@beartype.beartype
def create_related_citations_from_json_dict(json_obj: dict):
        """
        Create a RelatedCitations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedCitations(**json_obj)


@beartype.beartype
def write_related_citations_obj(con: db.Connection, obj: RelatedCitations) -> int:
    """
    Write a RelatedCitations object to the database
    @param con: database connection
    @param obj: RelatedCitations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_citations', dataclasses.asdict(obj))

@beartype.beartype
def write_related_citations(
            con: db.Connection,
            citation_id: int,
            relationship_type_cv: str,
            related_citation_id: int,
            relation_id: Optional[int] = None) -> int:
    """
    Write to the related_citations table in the database
    @param con: database connection
    @param relation_id 
    @param citation_id 
    @param relationship_type_cv 
    @param related_citation_id 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    return db.upsert(con, 'related_citations', data)

@beartype.beartype
def write_related_citations_many(con: db.Connection, objs: List[RelatedCitations], upsert: bool = False) -> int:
    """
    Write a list of RelatedCitations objects to the database
    @param con: database connection
    @param objs: list of RelatedCitations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_citations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_citations(con: db.Connection, relation_id: int,
            citation_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_citation_id: Optional[int] = None) -> int:
    """
    Update a row in the related_citations table in the database
    @param con: database connection
    @param relation_id 
    @param citation_id 
    @param relationship_type_cv 
    @param related_citation_id 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    return db.update(con, 'related_citations', data)

@beartype.beartype
def read_related_citations(
            con: db.Connection,
            citation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_citation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Generator[RelatedCitations, None, None]:
    """
    Read from the related_citations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param citation_id 
    @param relationship_type_cv 
    @param related_citation_id 
    @return generator of RelatedCitations objects
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    result = db.query(con, 'related_citations', data)
    for row in result:
        yield RelatedCitations(**row.as_dict())

@beartype.beartype
def read_related_citations_fuzzy(con: db.Connection, citation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_citation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Generator[RelatedCitations, None, None]:
    """
    Read from the related_citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param citation_id 
    @param relationship_type_cv 
    @param related_citation_id 
    @return generator of RelatedCitations objects
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    result = db.query_fuzzy(con, 'related_citations', data)
    for row in result:
        yield RelatedCitations(**row.as_dict())

@beartype.beartype
def read_related_citations_any(con: db.Connection, citation_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_citation_id: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None) -> Generator[RelatedCitations, None, None]:
    """
    Read from the related_citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param citation_id 
    @param relationship_type_cv 
    @param related_citation_id 
    @return generator of RelatedCitations objects
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    result = db.query_any(con, 'related_citations', data)
    for row in result:
        yield RelatedCitations(**row.as_dict())

@beartype.beartype
def read_related_citations_one_or_none(con: db.Connection, citation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_citation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> Optional[RelatedCitations]:
    """
    Read from the related_citations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    result = db.query_one_or_none(con, 'related_citations', data)
    if result is None:
        return None
    return RelatedCitations(**result)

@beartype.beartype
def read_related_citations_one(con: db.Connection, citation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_citation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> RelatedCitations:
    """
    Read from the related_citations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    result = db.query_one(con, 'related_citations', data)
    return RelatedCitations(**result)

@beartype.beartype
def read_related_citations_all(con: db.Connection, citation_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_citation_id: Optional[int] = None,
             relation_id: Optional[int] = None) -> List[RelatedCitations]:
    """
    Read from the related_citations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'citation_id': citation_id,
        'relationship_type_cv': relationship_type_cv,
        'related_citation_id': related_citation_id,
    }
    result = db.query(con, 'related_citations', data)
    return [RelatedCitations(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_citations_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedCitations]:
    result = db.query_one(con, 'related_citations', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedCitations(**result)

@beartype.beartype
def delete_related_citations_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_citations', {'relation_id': relation_id})
# Associate the functions with the class
RelatedCitations.create_from_json_dict = create_related_citations_from_json_dict
RelatedCitations.write = write_related_citations
RelatedCitations.update = update_related_citations
RelatedCitations.write_many = write_related_citations_many
RelatedCitations.read = read_related_citations
RelatedCitations.read_fuzzy = read_related_citations_fuzzy
RelatedCitations.read_any = read_related_citations_any
RelatedCitations.read_one = read_related_citations_one
RelatedCitations.read_one_or_none = read_related_citations_one_or_none
RelatedCitations.read_all = read_related_citations_all
RelatedCitations.delete = delete_related_citations_by_id
RelatedCitations.read_by_id = read_related_citations_by_id
RelatedCitations.delete_by_id = delete_related_citations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedDatasets:
    """
    Information about relationships among DataSets

    @param relation_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param related_dataset_id 
    @param version_code 

    This is an automatically generated class
    """
    data_set_id: int # data_set_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_dataset_id: int # related_dataset_id integer (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    version_code: Optional[str] = None # version_code character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_data_set(self, con: db.Connection) -> Optional['Datasets']:
        return read_datasets_one_or_none(con, dataset_id=self.data_set_id)

    @beartype.beartype
    def get_related_dataset(self, con: db.Connection) -> Optional['Datasets']:
        return read_datasets_one_or_none(con, dataset_id=self.related_dataset_id)

@beartype.beartype
def create_related_datasets_from_json_dict(json_obj: dict):
        """
        Create a RelatedDatasets from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedDatasets(**json_obj)


@beartype.beartype
def write_related_datasets_obj(con: db.Connection, obj: RelatedDatasets) -> int:
    """
    Write a RelatedDatasets object to the database
    @param con: database connection
    @param obj: RelatedDatasets object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_datasets', dataclasses.asdict(obj))

@beartype.beartype
def write_related_datasets(
            con: db.Connection,
            data_set_id: int,
            relationship_type_cv: str,
            related_dataset_id: int,
            relation_id: Optional[int] = None,
            version_code: Optional[str] = None) -> int:
    """
    Write to the related_datasets table in the database
    @param con: database connection
    @param relation_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param related_dataset_id 
    @param version_code 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    return db.upsert(con, 'related_datasets', data)

@beartype.beartype
def write_related_datasets_many(con: db.Connection, objs: List[RelatedDatasets], upsert: bool = False) -> int:
    """
    Write a list of RelatedDatasets objects to the database
    @param con: database connection
    @param objs: list of RelatedDatasets objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_datasets', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_datasets(con: db.Connection, relation_id: int,
            data_set_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_dataset_id: Optional[int] = None,
            version_code: Optional[str] = None) -> int:
    """
    Update a row in the related_datasets table in the database
    @param con: database connection
    @param relation_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param related_dataset_id 
    @param version_code 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    return db.update(con, 'related_datasets', data)

@beartype.beartype
def read_related_datasets(
            con: db.Connection,
            data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_dataset_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None) -> Generator[RelatedDatasets, None, None]:
    """
    Read from the related_datasets table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param related_dataset_id 
    @param version_code 
    @return generator of RelatedDatasets objects
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    result = db.query(con, 'related_datasets', data)
    for row in result:
        yield RelatedDatasets(**row.as_dict())

@beartype.beartype
def read_related_datasets_fuzzy(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_dataset_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None) -> Generator[RelatedDatasets, None, None]:
    """
    Read from the related_datasets table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param related_dataset_id 
    @param version_code 
    @return generator of RelatedDatasets objects
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    result = db.query_fuzzy(con, 'related_datasets', data)
    for row in result:
        yield RelatedDatasets(**row.as_dict())

@beartype.beartype
def read_related_datasets_any(con: db.Connection, data_set_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_dataset_id: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None,
             version_code: Optional[List[str]] = None) -> Generator[RelatedDatasets, None, None]:
    """
    Read from the related_datasets table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param related_dataset_id 
    @param version_code 
    @return generator of RelatedDatasets objects
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    result = db.query_any(con, 'related_datasets', data)
    for row in result:
        yield RelatedDatasets(**row.as_dict())

@beartype.beartype
def read_related_datasets_one_or_none(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_dataset_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None) -> Optional[RelatedDatasets]:
    """
    Read from the related_datasets table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    result = db.query_one_or_none(con, 'related_datasets', data)
    if result is None:
        return None
    return RelatedDatasets(**result)

@beartype.beartype
def read_related_datasets_one(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_dataset_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None) -> RelatedDatasets:
    """
    Read from the related_datasets table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    result = db.query_one(con, 'related_datasets', data)
    return RelatedDatasets(**result)

@beartype.beartype
def read_related_datasets_all(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_dataset_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None) -> List[RelatedDatasets]:
    """
    Read from the related_datasets table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'related_dataset_id': related_dataset_id,
        'version_code': version_code,
    }
    result = db.query(con, 'related_datasets', data)
    return [RelatedDatasets(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_datasets_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedDatasets]:
    result = db.query_one(con, 'related_datasets', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedDatasets(**result)

@beartype.beartype
def delete_related_datasets_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_datasets', {'relation_id': relation_id})
# Associate the functions with the class
RelatedDatasets.create_from_json_dict = create_related_datasets_from_json_dict
RelatedDatasets.write = write_related_datasets
RelatedDatasets.update = update_related_datasets
RelatedDatasets.write_many = write_related_datasets_many
RelatedDatasets.read = read_related_datasets
RelatedDatasets.read_fuzzy = read_related_datasets_fuzzy
RelatedDatasets.read_any = read_related_datasets_any
RelatedDatasets.read_one = read_related_datasets_one
RelatedDatasets.read_one_or_none = read_related_datasets_one_or_none
RelatedDatasets.read_all = read_related_datasets_all
RelatedDatasets.delete = delete_related_datasets_by_id
RelatedDatasets.read_by_id = read_related_datasets_by_id
RelatedDatasets.delete_by_id = delete_related_datasets_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedResults:
    """
    Information about relationships among Results

    @param relation_id 
    @param result_id 
    @param relationship_type_cv 
    @param related_result_id 
    @param version_code 
    @param related_result_sequence_number 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_result_id: int # related_result_id bigint (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    version_code: Optional[str] = None # version_code character varying (default: )
    related_result_sequence_number: Optional[int] = None # related_result_sequence_number integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_related_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.related_result_id)

@beartype.beartype
def create_related_results_from_json_dict(json_obj: dict):
        """
        Create a RelatedResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedResults(**json_obj)


@beartype.beartype
def write_related_results_obj(con: db.Connection, obj: RelatedResults) -> int:
    """
    Write a RelatedResults object to the database
    @param con: database connection
    @param obj: RelatedResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_results', dataclasses.asdict(obj))

@beartype.beartype
def write_related_results(
            con: db.Connection,
            result_id: int,
            relationship_type_cv: str,
            related_result_id: int,
            relation_id: Optional[int] = None,
            version_code: Optional[str] = None,
            related_result_sequence_number: Optional[int] = None) -> int:
    """
    Write to the related_results table in the database
    @param con: database connection
    @param relation_id 
    @param result_id 
    @param relationship_type_cv 
    @param related_result_id 
    @param version_code 
    @param related_result_sequence_number 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    return db.upsert(con, 'related_results', data)

@beartype.beartype
def write_related_results_many(con: db.Connection, objs: List[RelatedResults], upsert: bool = False) -> int:
    """
    Write a list of RelatedResults objects to the database
    @param con: database connection
    @param objs: list of RelatedResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_results(con: db.Connection, relation_id: int,
            result_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_result_id: Optional[int] = None,
            version_code: Optional[str] = None,
            related_result_sequence_number: Optional[int] = None) -> int:
    """
    Update a row in the related_results table in the database
    @param con: database connection
    @param relation_id 
    @param result_id 
    @param relationship_type_cv 
    @param related_result_id 
    @param version_code 
    @param related_result_sequence_number 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    return db.update(con, 'related_results', data)

@beartype.beartype
def read_related_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_result_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None,
             related_result_sequence_number: Optional[int] = None) -> Generator[RelatedResults, None, None]:
    """
    Read from the related_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param result_id 
    @param relationship_type_cv 
    @param related_result_id 
    @param version_code 
    @param related_result_sequence_number 
    @return generator of RelatedResults objects
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    result = db.query(con, 'related_results', data)
    for row in result:
        yield RelatedResults(**row.as_dict())

@beartype.beartype
def read_related_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_result_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None,
             related_result_sequence_number: Optional[int] = None) -> Generator[RelatedResults, None, None]:
    """
    Read from the related_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param result_id 
    @param relationship_type_cv 
    @param related_result_id 
    @param version_code 
    @param related_result_sequence_number 
    @return generator of RelatedResults objects
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    result = db.query_fuzzy(con, 'related_results', data)
    for row in result:
        yield RelatedResults(**row.as_dict())

@beartype.beartype
def read_related_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_result_id: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None,
             version_code: Optional[List[str]] = None,
             related_result_sequence_number: Optional[List[int]] = None) -> Generator[RelatedResults, None, None]:
    """
    Read from the related_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param result_id 
    @param relationship_type_cv 
    @param related_result_id 
    @param version_code 
    @param related_result_sequence_number 
    @return generator of RelatedResults objects
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    result = db.query_any(con, 'related_results', data)
    for row in result:
        yield RelatedResults(**row.as_dict())

@beartype.beartype
def read_related_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_result_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None,
             related_result_sequence_number: Optional[int] = None) -> Optional[RelatedResults]:
    """
    Read from the related_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    result = db.query_one_or_none(con, 'related_results', data)
    if result is None:
        return None
    return RelatedResults(**result)

@beartype.beartype
def read_related_results_one(con: db.Connection, result_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_result_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None,
             related_result_sequence_number: Optional[int] = None) -> RelatedResults:
    """
    Read from the related_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    result = db.query_one(con, 'related_results', data)
    return RelatedResults(**result)

@beartype.beartype
def read_related_results_all(con: db.Connection, result_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_result_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             version_code: Optional[str] = None,
             related_result_sequence_number: Optional[int] = None) -> List[RelatedResults]:
    """
    Read from the related_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'result_id': result_id,
        'relationship_type_cv': relationship_type_cv,
        'related_result_id': related_result_id,
        'version_code': version_code,
        'related_result_sequence_number': related_result_sequence_number,
    }
    result = db.query(con, 'related_results', data)
    return [RelatedResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_results_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedResults]:
    result = db.query_one(con, 'related_results', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedResults(**result)

@beartype.beartype
def delete_related_results_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_results', {'relation_id': relation_id})
# Associate the functions with the class
RelatedResults.create_from_json_dict = create_related_results_from_json_dict
RelatedResults.write = write_related_results
RelatedResults.update = update_related_results
RelatedResults.write_many = write_related_results_many
RelatedResults.read = read_related_results
RelatedResults.read_fuzzy = read_related_results_fuzzy
RelatedResults.read_any = read_related_results_any
RelatedResults.read_one = read_related_results_one
RelatedResults.read_one_or_none = read_related_results_one_or_none
RelatedResults.read_all = read_related_results_all
RelatedResults.delete = delete_related_results_by_id
RelatedResults.read_by_id = read_related_results_by_id
RelatedResults.delete_by_id = delete_related_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DerivationEquations:
    """
    DerivationEquations include calibration equations, normalizations, etc. on one or more RelatedResults to produce a DerivedResult.

    @param derivation_equation_id 
    @param derivation_equation 

    This is an automatically generated class
    """
    derivation_equation: str # derivation_equation character varying (default: )
    derivation_equation_id: Optional[int] = None # derivation_equation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'derivation_equation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_derivation_equations_from_json_dict(json_obj: dict):
        """
        Create a DerivationEquations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DerivationEquations(**json_obj)


@beartype.beartype
def write_derivation_equations_obj(con: db.Connection, obj: DerivationEquations) -> int:
    """
    Write a DerivationEquations object to the database
    @param con: database connection
    @param obj: DerivationEquations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'derivation_equations', dataclasses.asdict(obj))

@beartype.beartype
def write_derivation_equations(
            con: db.Connection,
            derivation_equation: str,
            derivation_equation_id: Optional[int] = None) -> int:
    """
    Write to the derivation_equations table in the database
    @param con: database connection
    @param derivation_equation_id 
    @param derivation_equation 
    @return id of the inserted/updated row
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    return db.upsert(con, 'derivation_equations', data)

@beartype.beartype
def write_derivation_equations_many(con: db.Connection, objs: List[DerivationEquations], upsert: bool = False) -> int:
    """
    Write a list of DerivationEquations objects to the database
    @param con: database connection
    @param objs: list of DerivationEquations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'derivation_equations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_derivation_equations(con: db.Connection, derivation_equation_id: int,
            derivation_equation: Optional[str] = None) -> int:
    """
    Update a row in the derivation_equations table in the database
    @param con: database connection
    @param derivation_equation_id 
    @param derivation_equation 
    @return The number of rows updated
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    return db.update(con, 'derivation_equations', data)

@beartype.beartype
def read_derivation_equations(
            con: db.Connection,
            derivation_equation: Optional[str] = None,
             derivation_equation_id: Optional[int] = None) -> Generator[DerivationEquations, None, None]:
    """
    Read from the derivation_equations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param derivation_equation_id 
    @param derivation_equation 
    @return generator of DerivationEquations objects
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    result = db.query(con, 'derivation_equations', data)
    for row in result:
        yield DerivationEquations(**row.as_dict())

@beartype.beartype
def read_derivation_equations_fuzzy(con: db.Connection, derivation_equation: Optional[str] = None,
             derivation_equation_id: Optional[int] = None) -> Generator[DerivationEquations, None, None]:
    """
    Read from the derivation_equations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param derivation_equation_id 
    @param derivation_equation 
    @return generator of DerivationEquations objects
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    result = db.query_fuzzy(con, 'derivation_equations', data)
    for row in result:
        yield DerivationEquations(**row.as_dict())

@beartype.beartype
def read_derivation_equations_any(con: db.Connection, derivation_equation: Optional[List[str]] = None,
             derivation_equation_id: Optional[List[int]] = None) -> Generator[DerivationEquations, None, None]:
    """
    Read from the derivation_equations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param derivation_equation_id 
    @param derivation_equation 
    @return generator of DerivationEquations objects
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    result = db.query_any(con, 'derivation_equations', data)
    for row in result:
        yield DerivationEquations(**row.as_dict())

@beartype.beartype
def read_derivation_equations_one_or_none(con: db.Connection, derivation_equation: Optional[str] = None,
             derivation_equation_id: Optional[int] = None) -> Optional[DerivationEquations]:
    """
    Read from the derivation_equations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    result = db.query_one_or_none(con, 'derivation_equations', data)
    if result is None:
        return None
    return DerivationEquations(**result)

@beartype.beartype
def read_derivation_equations_one(con: db.Connection, derivation_equation: Optional[str] = None,
             derivation_equation_id: Optional[int] = None) -> DerivationEquations:
    """
    Read from the derivation_equations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    result = db.query_one(con, 'derivation_equations', data)
    return DerivationEquations(**result)

@beartype.beartype
def read_derivation_equations_all(con: db.Connection, derivation_equation: Optional[str] = None,
             derivation_equation_id: Optional[int] = None) -> List[DerivationEquations]:
    """
    Read from the derivation_equations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'derivation_equation_id': derivation_equation_id,
        'derivation_equation': derivation_equation,
    }
    result = db.query(con, 'derivation_equations', data)
    return [DerivationEquations(**row.as_dict()) for row in result]

@beartype.beartype
def read_derivation_equations_by_id(con: db.Connection, derivation_equation_id: int) -> Optional[DerivationEquations]:
    result = db.query_one(con, 'derivation_equations', {'derivation_equation_id': derivation_equation_id})
    if result is None:
        return None
    return DerivationEquations(**result)

@beartype.beartype
def delete_derivation_equations_by_id(con: db.Connection, derivation_equation_id: int):
    db.delete(con, 'derivation_equations', {'derivation_equation_id': derivation_equation_id})
# Associate the functions with the class
DerivationEquations.create_from_json_dict = create_derivation_equations_from_json_dict
DerivationEquations.write = write_derivation_equations
DerivationEquations.update = update_derivation_equations
DerivationEquations.write_many = write_derivation_equations_many
DerivationEquations.read = read_derivation_equations
DerivationEquations.read_fuzzy = read_derivation_equations_fuzzy
DerivationEquations.read_any = read_derivation_equations_any
DerivationEquations.read_one = read_derivation_equations_one
DerivationEquations.read_one_or_none = read_derivation_equations_one_or_none
DerivationEquations.read_all = read_derivation_equations_all
DerivationEquations.delete = delete_derivation_equations_by_id
DerivationEquations.read_by_id = read_derivation_equations_by_id
DerivationEquations.delete_by_id = delete_derivation_equations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SequencingFacility:
    """
    @param sequencing_facility_id 
    @param sequencing_facility_name 

    This is an automatically generated class
    """
    sequencing_facility_id: int # sequencing_facility_id integer (default: )
    sequencing_facility_name: Optional[str] = None # sequencing_facility_name character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'sequencing_facility_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_sequencing_facility_from_json_dict(json_obj: dict):
        """
        Create a SequencingFacility from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SequencingFacility(**json_obj)


@beartype.beartype
def write_sequencing_facility_obj(con: db.Connection, obj: SequencingFacility) -> int:
    """
    Write a SequencingFacility object to the database
    @param con: database connection
    @param obj: SequencingFacility object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sequencing_facility', dataclasses.asdict(obj))

@beartype.beartype
def write_sequencing_facility(
            con: db.Connection,
            sequencing_facility_id: int,
            sequencing_facility_name: Optional[str] = None) -> int:
    """
    Write to the sequencing_facility table in the database
    @param con: database connection
    @param sequencing_facility_id 
    @param sequencing_facility_name 
    @return id of the inserted/updated row
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    return db.upsert(con, 'sequencing_facility', data)

@beartype.beartype
def write_sequencing_facility_many(con: db.Connection, objs: List[SequencingFacility], upsert: bool = False) -> int:
    """
    Write a list of SequencingFacility objects to the database
    @param con: database connection
    @param objs: list of SequencingFacility objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sequencing_facility', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sequencing_facility(con: db.Connection, sequencing_facility_id: int,
            sequencing_facility_name: Optional[str] = None) -> int:
    """
    Update a row in the sequencing_facility table in the database
    @param con: database connection
    @param sequencing_facility_id 
    @param sequencing_facility_name 
    @return The number of rows updated
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    return db.update(con, 'sequencing_facility', data)

@beartype.beartype
def read_sequencing_facility(
            con: db.Connection,
            sequencing_facility_id: Optional[int] = None,
             sequencing_facility_name: Optional[str] = None) -> Generator[SequencingFacility, None, None]:
    """
    Read from the sequencing_facility table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sequencing_facility_id 
    @param sequencing_facility_name 
    @return generator of SequencingFacility objects
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    result = db.query(con, 'sequencing_facility', data)
    for row in result:
        yield SequencingFacility(**row.as_dict())

@beartype.beartype
def read_sequencing_facility_fuzzy(con: db.Connection, sequencing_facility_id: Optional[int] = None,
             sequencing_facility_name: Optional[str] = None) -> Generator[SequencingFacility, None, None]:
    """
    Read from the sequencing_facility table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sequencing_facility_id 
    @param sequencing_facility_name 
    @return generator of SequencingFacility objects
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    result = db.query_fuzzy(con, 'sequencing_facility', data)
    for row in result:
        yield SequencingFacility(**row.as_dict())

@beartype.beartype
def read_sequencing_facility_any(con: db.Connection, sequencing_facility_id: Optional[List[int]] = None,
             sequencing_facility_name: Optional[List[str]] = None) -> Generator[SequencingFacility, None, None]:
    """
    Read from the sequencing_facility table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sequencing_facility_id 
    @param sequencing_facility_name 
    @return generator of SequencingFacility objects
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    result = db.query_any(con, 'sequencing_facility', data)
    for row in result:
        yield SequencingFacility(**row.as_dict())

@beartype.beartype
def read_sequencing_facility_one_or_none(con: db.Connection, sequencing_facility_id: Optional[int] = None,
             sequencing_facility_name: Optional[str] = None) -> Optional[SequencingFacility]:
    """
    Read from the sequencing_facility table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    result = db.query_one_or_none(con, 'sequencing_facility', data)
    if result is None:
        return None
    return SequencingFacility(**result)

@beartype.beartype
def read_sequencing_facility_one(con: db.Connection, sequencing_facility_id: Optional[int] = None,
             sequencing_facility_name: Optional[str] = None) -> SequencingFacility:
    """
    Read from the sequencing_facility table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    result = db.query_one(con, 'sequencing_facility', data)
    return SequencingFacility(**result)

@beartype.beartype
def read_sequencing_facility_all(con: db.Connection, sequencing_facility_id: Optional[int] = None,
             sequencing_facility_name: Optional[str] = None) -> List[SequencingFacility]:
    """
    Read from the sequencing_facility table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'sequencing_facility_id': sequencing_facility_id,
        'sequencing_facility_name': sequencing_facility_name,
    }
    result = db.query(con, 'sequencing_facility', data)
    return [SequencingFacility(**row.as_dict()) for row in result]

@beartype.beartype
def read_sequencing_facility_by_id(con: db.Connection, sequencing_facility_id: int) -> Optional[SequencingFacility]:
    result = db.query_one(con, 'sequencing_facility', {'sequencing_facility_id': sequencing_facility_id})
    if result is None:
        return None
    return SequencingFacility(**result)

@beartype.beartype
def delete_sequencing_facility_by_id(con: db.Connection, sequencing_facility_id: int):
    db.delete(con, 'sequencing_facility', {'sequencing_facility_id': sequencing_facility_id})
# Associate the functions with the class
SequencingFacility.create_from_json_dict = create_sequencing_facility_from_json_dict
SequencingFacility.write = write_sequencing_facility
SequencingFacility.update = update_sequencing_facility
SequencingFacility.write_many = write_sequencing_facility_many
SequencingFacility.read = read_sequencing_facility
SequencingFacility.read_fuzzy = read_sequencing_facility_fuzzy
SequencingFacility.read_any = read_sequencing_facility_any
SequencingFacility.read_one = read_sequencing_facility_one
SequencingFacility.read_one_or_none = read_sequencing_facility_one_or_none
SequencingFacility.read_all = read_sequencing_facility_all
SequencingFacility.delete = delete_sequencing_facility_by_id
SequencingFacility.read_by_id = read_sequencing_facility_by_id
SequencingFacility.delete_by_id = delete_sequencing_facility_by_id



@beartype_wrap_init
@dataclasses.dataclass
class AuthorLists:
    """
    Relationship between Citations and their Authors

    @param bridge_id 
    @param citation_id 
    @param person_id 
    @param author_order 

    This is an automatically generated class
    """
    citation_id: int # citation_id integer (default: )
    person_id: int # person_id integer (default: )
    author_order: int # author_order integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_person(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.person_id)

@beartype.beartype
def create_author_lists_from_json_dict(json_obj: dict):
        """
        Create a AuthorLists from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return AuthorLists(**json_obj)


@beartype.beartype
def write_author_lists_obj(con: db.Connection, obj: AuthorLists) -> int:
    """
    Write a AuthorLists object to the database
    @param con: database connection
    @param obj: AuthorLists object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'author_lists', dataclasses.asdict(obj))

@beartype.beartype
def write_author_lists(
            con: db.Connection,
            citation_id: int,
            person_id: int,
            author_order: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the author_lists table in the database
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param person_id 
    @param author_order 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    return db.upsert(con, 'author_lists', data)

@beartype.beartype
def write_author_lists_many(con: db.Connection, objs: List[AuthorLists], upsert: bool = False) -> int:
    """
    Write a list of AuthorLists objects to the database
    @param con: database connection
    @param objs: list of AuthorLists objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'author_lists', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_author_lists(con: db.Connection, bridge_id: int,
            citation_id: Optional[int] = None,
            person_id: Optional[int] = None,
            author_order: Optional[int] = None) -> int:
    """
    Update a row in the author_lists table in the database
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param person_id 
    @param author_order 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    return db.update(con, 'author_lists', data)

@beartype.beartype
def read_author_lists(
            con: db.Connection,
            citation_id: Optional[int] = None,
             person_id: Optional[int] = None,
             author_order: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[AuthorLists, None, None]:
    """
    Read from the author_lists table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param person_id 
    @param author_order 
    @return generator of AuthorLists objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    result = db.query(con, 'author_lists', data)
    for row in result:
        yield AuthorLists(**row.as_dict())

@beartype.beartype
def read_author_lists_fuzzy(con: db.Connection, citation_id: Optional[int] = None,
             person_id: Optional[int] = None,
             author_order: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[AuthorLists, None, None]:
    """
    Read from the author_lists table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param person_id 
    @param author_order 
    @return generator of AuthorLists objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    result = db.query_fuzzy(con, 'author_lists', data)
    for row in result:
        yield AuthorLists(**row.as_dict())

@beartype.beartype
def read_author_lists_any(con: db.Connection, citation_id: Optional[List[int]] = None,
             person_id: Optional[List[int]] = None,
             author_order: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[AuthorLists, None, None]:
    """
    Read from the author_lists table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param citation_id 
    @param person_id 
    @param author_order 
    @return generator of AuthorLists objects
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    result = db.query_any(con, 'author_lists', data)
    for row in result:
        yield AuthorLists(**row.as_dict())

@beartype.beartype
def read_author_lists_one_or_none(con: db.Connection, citation_id: Optional[int] = None,
             person_id: Optional[int] = None,
             author_order: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[AuthorLists]:
    """
    Read from the author_lists table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    result = db.query_one_or_none(con, 'author_lists', data)
    if result is None:
        return None
    return AuthorLists(**result)

@beartype.beartype
def read_author_lists_one(con: db.Connection, citation_id: Optional[int] = None,
             person_id: Optional[int] = None,
             author_order: Optional[int] = None,
             bridge_id: Optional[int] = None) -> AuthorLists:
    """
    Read from the author_lists table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    result = db.query_one(con, 'author_lists', data)
    return AuthorLists(**result)

@beartype.beartype
def read_author_lists_all(con: db.Connection, citation_id: Optional[int] = None,
             person_id: Optional[int] = None,
             author_order: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[AuthorLists]:
    """
    Read from the author_lists table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'citation_id': citation_id,
        'person_id': person_id,
        'author_order': author_order,
    }
    result = db.query(con, 'author_lists', data)
    return [AuthorLists(**row.as_dict()) for row in result]

@beartype.beartype
def read_author_lists_by_id(con: db.Connection, bridge_id: int) -> Optional[AuthorLists]:
    result = db.query_one(con, 'author_lists', {'bridge_id': bridge_id})
    if result is None:
        return None
    return AuthorLists(**result)

@beartype.beartype
def delete_author_lists_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'author_lists', {'bridge_id': bridge_id})
# Associate the functions with the class
AuthorLists.create_from_json_dict = create_author_lists_from_json_dict
AuthorLists.write = write_author_lists
AuthorLists.update = update_author_lists
AuthorLists.write_many = write_author_lists_many
AuthorLists.read = read_author_lists
AuthorLists.read_fuzzy = read_author_lists_fuzzy
AuthorLists.read_any = read_author_lists_any
AuthorLists.read_one = read_author_lists_one
AuthorLists.read_one_or_none = read_author_lists_one_or_none
AuthorLists.read_all = read_author_lists_all
AuthorLists.delete = delete_author_lists_by_id
AuthorLists.read_by_id = read_author_lists_by_id
AuthorLists.delete_by_id = delete_author_lists_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DatasetCitations:
    """
    Relationship between DataSets and Citations

    @param bridge_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param citation_id 

    This is an automatically generated class
    """
    data_set_id: int # data_set_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    citation_id: int # citation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_data_set(self, con: db.Connection) -> Optional['Datasets']:
        return read_datasets_one_or_none(con, dataset_id=self.data_set_id)

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

@beartype.beartype
def create_dataset_citations_from_json_dict(json_obj: dict):
        """
        Create a DatasetCitations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DatasetCitations(**json_obj)


@beartype.beartype
def write_dataset_citations_obj(con: db.Connection, obj: DatasetCitations) -> int:
    """
    Write a DatasetCitations object to the database
    @param con: database connection
    @param obj: DatasetCitations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'dataset_citations', dataclasses.asdict(obj))

@beartype.beartype
def write_dataset_citations(
            con: db.Connection,
            data_set_id: int,
            relationship_type_cv: str,
            citation_id: int,
            bridge_id: Optional[int] = None) -> int:
    """
    Write to the dataset_citations table in the database
    @param con: database connection
    @param bridge_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param citation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    return db.upsert(con, 'dataset_citations', data)

@beartype.beartype
def write_dataset_citations_many(con: db.Connection, objs: List[DatasetCitations], upsert: bool = False) -> int:
    """
    Write a list of DatasetCitations objects to the database
    @param con: database connection
    @param objs: list of DatasetCitations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'dataset_citations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_dataset_citations(con: db.Connection, bridge_id: int,
            data_set_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Update a row in the dataset_citations table in the database
    @param con: database connection
    @param bridge_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param citation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    return db.update(con, 'dataset_citations', data)

@beartype.beartype
def read_dataset_citations(
            con: db.Connection,
            data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[DatasetCitations, None, None]:
    """
    Read from the dataset_citations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param citation_id 
    @return generator of DatasetCitations objects
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query(con, 'dataset_citations', data)
    for row in result:
        yield DatasetCitations(**row.as_dict())

@beartype.beartype
def read_dataset_citations_fuzzy(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Generator[DatasetCitations, None, None]:
    """
    Read from the dataset_citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param citation_id 
    @return generator of DatasetCitations objects
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_fuzzy(con, 'dataset_citations', data)
    for row in result:
        yield DatasetCitations(**row.as_dict())

@beartype.beartype
def read_dataset_citations_any(con: db.Connection, data_set_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             citation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None) -> Generator[DatasetCitations, None, None]:
    """
    Read from the dataset_citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param data_set_id 
    @param relationship_type_cv 
    @param citation_id 
    @return generator of DatasetCitations objects
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_any(con, 'dataset_citations', data)
    for row in result:
        yield DatasetCitations(**row.as_dict())

@beartype.beartype
def read_dataset_citations_one_or_none(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> Optional[DatasetCitations]:
    """
    Read from the dataset_citations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_one_or_none(con, 'dataset_citations', data)
    if result is None:
        return None
    return DatasetCitations(**result)

@beartype.beartype
def read_dataset_citations_one(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> DatasetCitations:
    """
    Read from the dataset_citations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query_one(con, 'dataset_citations', data)
    return DatasetCitations(**result)

@beartype.beartype
def read_dataset_citations_all(con: db.Connection, data_set_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             citation_id: Optional[int] = None,
             bridge_id: Optional[int] = None) -> List[DatasetCitations]:
    """
    Read from the dataset_citations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'data_set_id': data_set_id,
        'relationship_type_cv': relationship_type_cv,
        'citation_id': citation_id,
    }
    result = db.query(con, 'dataset_citations', data)
    return [DatasetCitations(**row.as_dict()) for row in result]

@beartype.beartype
def read_dataset_citations_by_id(con: db.Connection, bridge_id: int) -> Optional[DatasetCitations]:
    result = db.query_one(con, 'dataset_citations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return DatasetCitations(**result)

@beartype.beartype
def delete_dataset_citations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'dataset_citations', {'bridge_id': bridge_id})
# Associate the functions with the class
DatasetCitations.create_from_json_dict = create_dataset_citations_from_json_dict
DatasetCitations.write = write_dataset_citations
DatasetCitations.update = update_dataset_citations
DatasetCitations.write_many = write_dataset_citations_many
DatasetCitations.read = read_dataset_citations
DatasetCitations.read_fuzzy = read_dataset_citations_fuzzy
DatasetCitations.read_any = read_dataset_citations_any
DatasetCitations.read_one = read_dataset_citations_one
DatasetCitations.read_one_or_none = read_dataset_citations_one_or_none
DatasetCitations.read_all = read_dataset_citations_all
DatasetCitations.delete = delete_dataset_citations_by_id
DatasetCitations.read_by_id = read_dataset_citations_by_id
DatasetCitations.delete_by_id = delete_dataset_citations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MeasurementResults:
    """
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    x_location: Optional[float] = None # x_location double precision (default: )
    x_location_units_id: Optional[int] = None # x_location_units_id integer (default: )
    y_location: Optional[float] = None # y_location double precision (default: )
    y_location_units_id: Optional[int] = None # y_location_units_id integer (default: )
    z_location: Optional[float] = None # z_location double precision (default: )
    z_location_units_id: Optional[int] = None # z_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    time_aggregation_interval: Optional[float] = None # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: Optional[int] = None # time_aggregation_interval_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_measurement_results_from_json_dict(json_obj: dict):
        """
        Create a MeasurementResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return MeasurementResults(**json_obj)


@beartype.beartype
def write_measurement_results_obj(con: db.Connection, obj: MeasurementResults) -> int:
    """
    Write a MeasurementResults object to the database
    @param con: database connection
    @param obj: MeasurementResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'measurement_results', dataclasses.asdict(obj))

@beartype.beartype
def write_measurement_results(
            con: db.Connection,
            result_id: int,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Write to the measurement_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'measurement_results', data)

@beartype.beartype
def write_measurement_results_many(con: db.Connection, objs: List[MeasurementResults], upsert: bool = False) -> int:
    """
    Write a list of MeasurementResults objects to the database
    @param con: database connection
    @param objs: list of MeasurementResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'measurement_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_measurement_results(con: db.Connection, result_id: int,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the measurement_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'measurement_results', data)

@beartype.beartype
def read_measurement_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None) -> Generator[MeasurementResults, None, None]:
    """
    Read from the measurement_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of MeasurementResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'measurement_results', data)
    for row in result:
        yield MeasurementResults(**row.as_dict())

@beartype.beartype
def read_measurement_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None) -> Generator[MeasurementResults, None, None]:
    """
    Read from the measurement_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of MeasurementResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'measurement_results', data)
    for row in result:
        yield MeasurementResults(**row.as_dict())

@beartype.beartype
def read_measurement_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None) -> Generator[MeasurementResults, None, None]:
    """
    Read from the measurement_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of MeasurementResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'measurement_results', data)
    for row in result:
        yield MeasurementResults(**row.as_dict())

@beartype.beartype
def read_measurement_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None) -> Optional[MeasurementResults]:
    """
    Read from the measurement_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'measurement_results', data)
    if result is None:
        return None
    return MeasurementResults(**result)

@beartype.beartype
def read_measurement_results_one(con: db.Connection, result_id: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None) -> MeasurementResults:
    """
    Read from the measurement_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'measurement_results', data)
    return MeasurementResults(**result)

@beartype.beartype
def read_measurement_results_all(con: db.Connection, result_id: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None) -> List[MeasurementResults]:
    """
    Read from the measurement_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'measurement_results', data)
    return [MeasurementResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_measurement_results_by_id(con: db.Connection, result_id: int) -> Optional[MeasurementResults]:
    result = db.query_one(con, 'measurement_results', {'result_id': result_id})
    if result is None:
        return None
    return MeasurementResults(**result)

@beartype.beartype
def delete_measurement_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'measurement_results', {'result_id': result_id})
# Associate the functions with the class
MeasurementResults.create_from_json_dict = create_measurement_results_from_json_dict
MeasurementResults.write = write_measurement_results
MeasurementResults.update = update_measurement_results
MeasurementResults.write_many = write_measurement_results_many
MeasurementResults.read = read_measurement_results
MeasurementResults.read_fuzzy = read_measurement_results_fuzzy
MeasurementResults.read_any = read_measurement_results_any
MeasurementResults.read_one = read_measurement_results_one
MeasurementResults.read_one_or_none = read_measurement_results_one_or_none
MeasurementResults.read_all = read_measurement_results_all
MeasurementResults.delete = delete_measurement_results_by_id
MeasurementResults.read_by_id = read_measurement_results_by_id
MeasurementResults.delete_by_id = delete_measurement_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PointCoverageResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    x_location: float # x_location double precision (default: )
    x_location_units_id: int # x_location_units_id integer (default: )
    y_location: float # y_location double precision (default: )
    y_location_units_id: int # y_location_units_id integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['PointCoverageResults']:
        return read_point_coverage_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_point_coverage_result_values_from_json_dict(json_obj: dict):
        """
        Create a PointCoverageResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return PointCoverageResultValues(**json_obj)


@beartype.beartype
def write_point_coverage_result_values_obj(con: db.Connection, obj: PointCoverageResultValues) -> int:
    """
    Write a PointCoverageResultValues object to the database
    @param con: database connection
    @param obj: PointCoverageResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'point_coverage_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_point_coverage_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            x_location: float,
            x_location_units_id: int,
            y_location: float,
            y_location_units_id: int,
            censor_code_cv: str,
            quality_code_cv: str,
            value_id: Optional[int] = None) -> int:
    """
    Write to the point_coverage_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    return db.upsert(con, 'point_coverage_result_values', data)

@beartype.beartype
def write_point_coverage_result_values_many(con: db.Connection, objs: List[PointCoverageResultValues], upsert: bool = False) -> int:
    """
    Write a list of PointCoverageResultValues objects to the database
    @param con: database connection
    @param objs: list of PointCoverageResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'point_coverage_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_point_coverage_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None) -> int:
    """
    Update a row in the point_coverage_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    return db.update(con, 'point_coverage_result_values', data)

@beartype.beartype
def read_point_coverage_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> Generator[PointCoverageResultValues, None, None]:
    """
    Read from the point_coverage_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @return generator of PointCoverageResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query(con, 'point_coverage_result_values', data)
    for row in result:
        yield PointCoverageResultValues(**row.as_dict())

@beartype.beartype
def read_point_coverage_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> Generator[PointCoverageResultValues, None, None]:
    """
    Read from the point_coverage_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @return generator of PointCoverageResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_fuzzy(con, 'point_coverage_result_values', data)
    for row in result:
        yield PointCoverageResultValues(**row.as_dict())

@beartype.beartype
def read_point_coverage_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             value_id: Optional[List[int]] = None) -> Generator[PointCoverageResultValues, None, None]:
    """
    Read from the point_coverage_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @return generator of PointCoverageResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_any(con, 'point_coverage_result_values', data)
    for row in result:
        yield PointCoverageResultValues(**row.as_dict())

@beartype.beartype
def read_point_coverage_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> Optional[PointCoverageResultValues]:
    """
    Read from the point_coverage_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_one_or_none(con, 'point_coverage_result_values', data)
    if result is None:
        return None
    return PointCoverageResultValues(**result)

@beartype.beartype
def read_point_coverage_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> PointCoverageResultValues:
    """
    Read from the point_coverage_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_one(con, 'point_coverage_result_values', data)
    return PointCoverageResultValues(**result)

@beartype.beartype
def read_point_coverage_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> List[PointCoverageResultValues]:
    """
    Read from the point_coverage_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query(con, 'point_coverage_result_values', data)
    return [PointCoverageResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_point_coverage_result_values_by_id(con: db.Connection, value_id: int) -> Optional[PointCoverageResultValues]:
    result = db.query_one(con, 'point_coverage_result_values', {'value_id': value_id})
    if result is None:
        return None
    return PointCoverageResultValues(**result)

@beartype.beartype
def delete_point_coverage_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'point_coverage_result_values', {'value_id': value_id})
# Associate the functions with the class
PointCoverageResultValues.create_from_json_dict = create_point_coverage_result_values_from_json_dict
PointCoverageResultValues.write = write_point_coverage_result_values
PointCoverageResultValues.update = update_point_coverage_result_values
PointCoverageResultValues.write_many = write_point_coverage_result_values_many
PointCoverageResultValues.read = read_point_coverage_result_values
PointCoverageResultValues.read_fuzzy = read_point_coverage_result_values_fuzzy
PointCoverageResultValues.read_any = read_point_coverage_result_values_any
PointCoverageResultValues.read_one = read_point_coverage_result_values_one
PointCoverageResultValues.read_one_or_none = read_point_coverage_result_values_one_or_none
PointCoverageResultValues.read_all = read_point_coverage_result_values_all
PointCoverageResultValues.delete = delete_point_coverage_result_values_by_id
PointCoverageResultValues.read_by_id = read_point_coverage_result_values_by_id
PointCoverageResultValues.delete_by_id = delete_point_coverage_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ProfileResultValues:
    """
    Numeric values of Depth Profile Results.

    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    z_location: float # z_location double precision (default: )
    z_aggregation_interval: float # z_aggregation_interval double precision (default: )
    z_location_units_id: int # z_location_units_id integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['ProfileResults']:
        return read_profile_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_profile_result_values_from_json_dict(json_obj: dict):
        """
        Create a ProfileResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return ProfileResultValues(**json_obj)


@beartype.beartype
def write_profile_result_values_obj(con: db.Connection, obj: ProfileResultValues) -> int:
    """
    Write a ProfileResultValues object to the database
    @param con: database connection
    @param obj: ProfileResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'profile_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_profile_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            z_location: float,
            z_aggregation_interval: float,
            z_location_units_id: int,
            censor_code_cv: str,
            quality_code_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the profile_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'profile_result_values', data)

@beartype.beartype
def write_profile_result_values_many(con: db.Connection, objs: List[ProfileResultValues], upsert: bool = False) -> int:
    """
    Write a list of ProfileResultValues objects to the database
    @param con: database connection
    @param objs: list of ProfileResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'profile_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_profile_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            z_location: Optional[float] = None,
            z_aggregation_interval: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the profile_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'profile_result_values', data)

@beartype.beartype
def read_profile_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             z_location: Optional[float] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[ProfileResultValues, None, None]:
    """
    Read from the profile_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of ProfileResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'profile_result_values', data)
    for row in result:
        yield ProfileResultValues(**row.as_dict())

@beartype.beartype
def read_profile_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             z_location: Optional[float] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[ProfileResultValues, None, None]:
    """
    Read from the profile_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of ProfileResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'profile_result_values', data)
    for row in result:
        yield ProfileResultValues(**row.as_dict())

@beartype.beartype
def read_profile_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_aggregation_interval: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[ProfileResultValues, None, None]:
    """
    Read from the profile_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of ProfileResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'profile_result_values', data)
    for row in result:
        yield ProfileResultValues(**row.as_dict())

@beartype.beartype
def read_profile_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             z_location: Optional[float] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[ProfileResultValues]:
    """
    Read from the profile_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'profile_result_values', data)
    if result is None:
        return None
    return ProfileResultValues(**result)

@beartype.beartype
def read_profile_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             z_location: Optional[float] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> ProfileResultValues:
    """
    Read from the profile_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'profile_result_values', data)
    return ProfileResultValues(**result)

@beartype.beartype
def read_profile_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             z_location: Optional[float] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> List[ProfileResultValues]:
    """
    Read from the profile_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'profile_result_values', data)
    return [ProfileResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_profile_result_values_by_id(con: db.Connection, value_id: int) -> Optional[ProfileResultValues]:
    result = db.query_one(con, 'profile_result_values', {'value_id': value_id})
    if result is None:
        return None
    return ProfileResultValues(**result)

@beartype.beartype
def delete_profile_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'profile_result_values', {'value_id': value_id})
# Associate the functions with the class
ProfileResultValues.create_from_json_dict = create_profile_result_values_from_json_dict
ProfileResultValues.write = write_profile_result_values
ProfileResultValues.update = update_profile_result_values
ProfileResultValues.write_many = write_profile_result_values_many
ProfileResultValues.read = read_profile_result_values
ProfileResultValues.read_fuzzy = read_profile_result_values_fuzzy
ProfileResultValues.read_any = read_profile_result_values_any
ProfileResultValues.read_one = read_profile_result_values_one
ProfileResultValues.read_one_or_none = read_profile_result_values_one_or_none
ProfileResultValues.read_all = read_profile_result_values_all
ProfileResultValues.delete = delete_profile_result_values_by_id
ProfileResultValues.read_by_id = read_profile_result_values_by_id
ProfileResultValues.delete_by_id = delete_profile_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ProfileResults:
    """
    Information about Profile Results

    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    x_location: Optional[float] = None # x_location double precision (default: )
    x_location_units_id: Optional[int] = None # x_location_units_id integer (default: )
    y_location: Optional[float] = None # y_location double precision (default: )
    y_location_units_id: Optional[int] = None # y_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_z_spacing: Optional[float] = None # intended_z_spacing double precision (default: )
    intended_z_spacing_units_id: Optional[int] = None # intended_z_spacing_units_id integer (default: )
    intended_time_spacing: Optional[float] = None # intended_time_spacing double precision (default: )
    intended_time_spacing_units_id: Optional[int] = None # intended_time_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_profile_results_from_json_dict(json_obj: dict):
        """
        Create a ProfileResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ProfileResults(**json_obj)


@beartype.beartype
def write_profile_results_obj(con: db.Connection, obj: ProfileResults) -> int:
    """
    Write a ProfileResults object to the database
    @param con: database connection
    @param obj: ProfileResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'profile_results', dataclasses.asdict(obj))

@beartype.beartype
def write_profile_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_z_spacing: Optional[float] = None,
            intended_z_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the profile_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'profile_results', data)

@beartype.beartype
def write_profile_results_many(con: db.Connection, objs: List[ProfileResults], upsert: bool = False) -> int:
    """
    Write a list of ProfileResults objects to the database
    @param con: database connection
    @param objs: list of ProfileResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'profile_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_profile_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_z_spacing: Optional[float] = None,
            intended_z_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the profile_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'profile_results', data)

@beartype.beartype
def read_profile_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[ProfileResults, None, None]:
    """
    Read from the profile_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of ProfileResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'profile_results', data)
    for row in result:
        yield ProfileResults(**row.as_dict())

@beartype.beartype
def read_profile_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[ProfileResults, None, None]:
    """
    Read from the profile_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of ProfileResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'profile_results', data)
    for row in result:
        yield ProfileResults(**row.as_dict())

@beartype.beartype
def read_profile_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_z_spacing: Optional[List[float]] = None,
             intended_z_spacing_units_id: Optional[List[int]] = None,
             intended_time_spacing: Optional[List[float]] = None,
             intended_time_spacing_units_id: Optional[List[int]] = None) -> Generator[ProfileResults, None, None]:
    """
    Read from the profile_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of ProfileResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'profile_results', data)
    for row in result:
        yield ProfileResults(**row.as_dict())

@beartype.beartype
def read_profile_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Optional[ProfileResults]:
    """
    Read from the profile_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'profile_results', data)
    if result is None:
        return None
    return ProfileResults(**result)

@beartype.beartype
def read_profile_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> ProfileResults:
    """
    Read from the profile_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'profile_results', data)
    return ProfileResults(**result)

@beartype.beartype
def read_profile_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> List[ProfileResults]:
    """
    Read from the profile_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'profile_results', data)
    return [ProfileResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_profile_results_by_id(con: db.Connection, result_id: int) -> Optional[ProfileResults]:
    result = db.query_one(con, 'profile_results', {'result_id': result_id})
    if result is None:
        return None
    return ProfileResults(**result)

@beartype.beartype
def delete_profile_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'profile_results', {'result_id': result_id})
# Associate the functions with the class
ProfileResults.create_from_json_dict = create_profile_results_from_json_dict
ProfileResults.write = write_profile_results
ProfileResults.update = update_profile_results
ProfileResults.write_many = write_profile_results_many
ProfileResults.read = read_profile_results
ProfileResults.read_fuzzy = read_profile_results_fuzzy
ProfileResults.read_any = read_profile_results_any
ProfileResults.read_one = read_profile_results_one
ProfileResults.read_one_or_none = read_profile_results_one_or_none
ProfileResults.read_all = read_profile_results_all
ProfileResults.delete = delete_profile_results_by_id
ProfileResults.read_by_id = read_profile_results_by_id
ProfileResults.delete_by_id = delete_profile_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SectionResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_aggregation_interval 
    @param x_location_units_id 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    x_location: float # x_location double precision (default: )
    x_aggregation_interval: float # x_aggregation_interval double precision (default: )
    x_location_units_id: int # x_location_units_id integer (default: )
    z_location: int # z_location bigint (default: )
    z_aggregation_interval: float # z_aggregation_interval double precision (default: )
    z_location_units_id: int # z_location_units_id integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['SectionResults']:
        return read_section_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_section_result_values_from_json_dict(json_obj: dict):
        """
        Create a SectionResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return SectionResultValues(**json_obj)


@beartype.beartype
def write_section_result_values_obj(con: db.Connection, obj: SectionResultValues) -> int:
    """
    Write a SectionResultValues object to the database
    @param con: database connection
    @param obj: SectionResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'section_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_section_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            x_location: float,
            x_aggregation_interval: float,
            x_location_units_id: int,
            z_location: int,
            z_aggregation_interval: float,
            z_location_units_id: int,
            censor_code_cv: str,
            quality_code_cv: str,
            aggregation_statistic_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the section_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_aggregation_interval 
    @param x_location_units_id 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'section_result_values', data)

@beartype.beartype
def write_section_result_values_many(con: db.Connection, objs: List[SectionResultValues], upsert: bool = False) -> int:
    """
    Write a list of SectionResultValues objects to the database
    @param con: database connection
    @param objs: list of SectionResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'section_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_section_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            x_location: Optional[float] = None,
            x_aggregation_interval: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            z_location: Optional[int] = None,
            z_aggregation_interval: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None,
            aggregation_statistic_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the section_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_aggregation_interval 
    @param x_location_units_id 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'section_result_values', data)

@beartype.beartype
def read_section_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_aggregation_interval: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             z_location: Optional[int] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[SectionResultValues, None, None]:
    """
    Read from the section_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_aggregation_interval 
    @param x_location_units_id 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of SectionResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'section_result_values', data)
    for row in result:
        yield SectionResultValues(**row.as_dict())

@beartype.beartype
def read_section_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_aggregation_interval: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             z_location: Optional[int] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[SectionResultValues, None, None]:
    """
    Read from the section_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_aggregation_interval 
    @param x_location_units_id 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of SectionResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'section_result_values', data)
    for row in result:
        yield SectionResultValues(**row.as_dict())

@beartype.beartype
def read_section_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             x_location: Optional[List[float]] = None,
             x_aggregation_interval: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             z_location: Optional[List[int]] = None,
             z_aggregation_interval: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[SectionResultValues, None, None]:
    """
    Read from the section_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_aggregation_interval 
    @param x_location_units_id 
    @param z_location 
    @param z_aggregation_interval 
    @param z_location_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of SectionResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'section_result_values', data)
    for row in result:
        yield SectionResultValues(**row.as_dict())

@beartype.beartype
def read_section_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_aggregation_interval: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             z_location: Optional[int] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[SectionResultValues]:
    """
    Read from the section_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'section_result_values', data)
    if result is None:
        return None
    return SectionResultValues(**result)

@beartype.beartype
def read_section_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_aggregation_interval: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             z_location: Optional[int] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> SectionResultValues:
    """
    Read from the section_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'section_result_values', data)
    return SectionResultValues(**result)

@beartype.beartype
def read_section_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_aggregation_interval: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             z_location: Optional[int] = None,
             z_aggregation_interval: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> List[SectionResultValues]:
    """
    Read from the section_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_aggregation_interval': x_aggregation_interval,
        'x_location_units_id': x_location_units_id,
        'z_location': z_location,
        'z_aggregation_interval': z_aggregation_interval,
        'z_location_units_id': z_location_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'section_result_values', data)
    return [SectionResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_section_result_values_by_id(con: db.Connection, value_id: int) -> Optional[SectionResultValues]:
    result = db.query_one(con, 'section_result_values', {'value_id': value_id})
    if result is None:
        return None
    return SectionResultValues(**result)

@beartype.beartype
def delete_section_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'section_result_values', {'value_id': value_id})
# Associate the functions with the class
SectionResultValues.create_from_json_dict = create_section_result_values_from_json_dict
SectionResultValues.write = write_section_result_values
SectionResultValues.update = update_section_result_values
SectionResultValues.write_many = write_section_result_values_many
SectionResultValues.read = read_section_result_values
SectionResultValues.read_fuzzy = read_section_result_values_fuzzy
SectionResultValues.read_any = read_section_result_values_any
SectionResultValues.read_one = read_section_result_values_one
SectionResultValues.read_one_or_none = read_section_result_values_one_or_none
SectionResultValues.read_all = read_section_result_values_all
SectionResultValues.delete = delete_section_result_values_by_id
SectionResultValues.read_by_id = read_section_result_values_by_id
SectionResultValues.delete_by_id = delete_section_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SectionResults:
    """
    @param result_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    y_location: Optional[float] = None # y_location double precision (default: )
    y_location_units_id: Optional[int] = None # y_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_x_spacing: Optional[float] = None # intended_x_spacing double precision (default: )
    intended_x_spacing_units_id: Optional[int] = None # intended_x_spacing_units_id integer (default: )
    intended_z_spacing: Optional[float] = None # intended_z_spacing double precision (default: )
    intended_z_spacing_units_id: Optional[int] = None # intended_z_spacing_units_id integer (default: )
    intended_time_spacing: Optional[float] = None # intended_time_spacing double precision (default: )
    intended_time_spacing_units_id: Optional[int] = None # intended_time_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_section_results_from_json_dict(json_obj: dict):
        """
        Create a SectionResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SectionResults(**json_obj)


@beartype.beartype
def write_section_results_obj(con: db.Connection, obj: SectionResults) -> int:
    """
    Write a SectionResults object to the database
    @param con: database connection
    @param obj: SectionResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'section_results', dataclasses.asdict(obj))

@beartype.beartype
def write_section_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_x_spacing: Optional[float] = None,
            intended_x_spacing_units_id: Optional[int] = None,
            intended_z_spacing: Optional[float] = None,
            intended_z_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the section_results table in the database
    @param con: database connection
    @param result_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'section_results', data)

@beartype.beartype
def write_section_results_many(con: db.Connection, objs: List[SectionResults], upsert: bool = False) -> int:
    """
    Write a list of SectionResults objects to the database
    @param con: database connection
    @param objs: list of SectionResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'section_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_section_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_x_spacing: Optional[float] = None,
            intended_x_spacing_units_id: Optional[int] = None,
            intended_z_spacing: Optional[float] = None,
            intended_z_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the section_results table in the database
    @param con: database connection
    @param result_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'section_results', data)

@beartype.beartype
def read_section_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[SectionResults, None, None]:
    """
    Read from the section_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of SectionResults objects
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'section_results', data)
    for row in result:
        yield SectionResults(**row.as_dict())

@beartype.beartype
def read_section_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[SectionResults, None, None]:
    """
    Read from the section_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of SectionResults objects
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'section_results', data)
    for row in result:
        yield SectionResults(**row.as_dict())

@beartype.beartype
def read_section_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_x_spacing: Optional[List[float]] = None,
             intended_x_spacing_units_id: Optional[List[int]] = None,
             intended_z_spacing: Optional[List[float]] = None,
             intended_z_spacing_units_id: Optional[List[int]] = None,
             intended_time_spacing: Optional[List[float]] = None,
             intended_time_spacing_units_id: Optional[List[int]] = None) -> Generator[SectionResults, None, None]:
    """
    Read from the section_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param y_location 
    @param y_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_z_spacing 
    @param intended_z_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of SectionResults objects
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'section_results', data)
    for row in result:
        yield SectionResults(**row.as_dict())

@beartype.beartype
def read_section_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Optional[SectionResults]:
    """
    Read from the section_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'section_results', data)
    if result is None:
        return None
    return SectionResults(**result)

@beartype.beartype
def read_section_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> SectionResults:
    """
    Read from the section_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'section_results', data)
    return SectionResults(**result)

@beartype.beartype
def read_section_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_z_spacing: Optional[float] = None,
             intended_z_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> List[SectionResults]:
    """
    Read from the section_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_z_spacing': intended_z_spacing,
        'intended_z_spacing_units_id': intended_z_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'section_results', data)
    return [SectionResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_section_results_by_id(con: db.Connection, result_id: int) -> Optional[SectionResults]:
    result = db.query_one(con, 'section_results', {'result_id': result_id})
    if result is None:
        return None
    return SectionResults(**result)

@beartype.beartype
def delete_section_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'section_results', {'result_id': result_id})
# Associate the functions with the class
SectionResults.create_from_json_dict = create_section_results_from_json_dict
SectionResults.write = write_section_results
SectionResults.update = update_section_results
SectionResults.write_many = write_section_results_many
SectionResults.read = read_section_results
SectionResults.read_fuzzy = read_section_results_fuzzy
SectionResults.read_any = read_section_results_any
SectionResults.read_one = read_section_results_one
SectionResults.read_one_or_none = read_section_results_one_or_none
SectionResults.read_all = read_section_results_all
SectionResults.delete = delete_section_results_by_id
SectionResults.read_by_id = read_section_results_by_id
SectionResults.delete_by_id = delete_section_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpectraResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param excitation_wavelength 
    @param emission_wavelength 
    @param wavelength_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    excitation_wavelength: float # excitation_wavelength double precision (default: )
    emission_wavelength: float # emission_wavelength double precision (default: )
    wavelength_units_id: int # wavelength_units_id integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['SpectraResults']:
        return read_spectra_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_spectra_result_values_from_json_dict(json_obj: dict):
        """
        Create a SpectraResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return SpectraResultValues(**json_obj)


@beartype.beartype
def write_spectra_result_values_obj(con: db.Connection, obj: SpectraResultValues) -> int:
    """
    Write a SpectraResultValues object to the database
    @param con: database connection
    @param obj: SpectraResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'spectra_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_spectra_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            excitation_wavelength: float,
            emission_wavelength: float,
            wavelength_units_id: int,
            censor_code_cv: str,
            quality_code_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the spectra_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param excitation_wavelength 
    @param emission_wavelength 
    @param wavelength_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'spectra_result_values', data)

@beartype.beartype
def write_spectra_result_values_many(con: db.Connection, objs: List[SpectraResultValues], upsert: bool = False) -> int:
    """
    Write a list of SpectraResultValues objects to the database
    @param con: database connection
    @param objs: list of SpectraResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'spectra_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_spectra_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            excitation_wavelength: Optional[float] = None,
            emission_wavelength: Optional[float] = None,
            wavelength_units_id: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the spectra_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param excitation_wavelength 
    @param emission_wavelength 
    @param wavelength_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'spectra_result_values', data)

@beartype.beartype
def read_spectra_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             excitation_wavelength: Optional[float] = None,
             emission_wavelength: Optional[float] = None,
             wavelength_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[SpectraResultValues, None, None]:
    """
    Read from the spectra_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param excitation_wavelength 
    @param emission_wavelength 
    @param wavelength_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of SpectraResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'spectra_result_values', data)
    for row in result:
        yield SpectraResultValues(**row.as_dict())

@beartype.beartype
def read_spectra_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             excitation_wavelength: Optional[float] = None,
             emission_wavelength: Optional[float] = None,
             wavelength_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[SpectraResultValues, None, None]:
    """
    Read from the spectra_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param excitation_wavelength 
    @param emission_wavelength 
    @param wavelength_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of SpectraResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'spectra_result_values', data)
    for row in result:
        yield SpectraResultValues(**row.as_dict())

@beartype.beartype
def read_spectra_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             excitation_wavelength: Optional[List[float]] = None,
             emission_wavelength: Optional[List[float]] = None,
             wavelength_units_id: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[SpectraResultValues, None, None]:
    """
    Read from the spectra_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param excitation_wavelength 
    @param emission_wavelength 
    @param wavelength_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of SpectraResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'spectra_result_values', data)
    for row in result:
        yield SpectraResultValues(**row.as_dict())

@beartype.beartype
def read_spectra_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             excitation_wavelength: Optional[float] = None,
             emission_wavelength: Optional[float] = None,
             wavelength_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[SpectraResultValues]:
    """
    Read from the spectra_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'spectra_result_values', data)
    if result is None:
        return None
    return SpectraResultValues(**result)

@beartype.beartype
def read_spectra_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             excitation_wavelength: Optional[float] = None,
             emission_wavelength: Optional[float] = None,
             wavelength_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> SpectraResultValues:
    """
    Read from the spectra_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'spectra_result_values', data)
    return SpectraResultValues(**result)

@beartype.beartype
def read_spectra_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             excitation_wavelength: Optional[float] = None,
             emission_wavelength: Optional[float] = None,
             wavelength_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> List[SpectraResultValues]:
    """
    Read from the spectra_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'excitation_wavelength': excitation_wavelength,
        'emission_wavelength': emission_wavelength,
        'wavelength_units_id': wavelength_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'spectra_result_values', data)
    return [SpectraResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_spectra_result_values_by_id(con: db.Connection, value_id: int) -> Optional[SpectraResultValues]:
    result = db.query_one(con, 'spectra_result_values', {'value_id': value_id})
    if result is None:
        return None
    return SpectraResultValues(**result)

@beartype.beartype
def delete_spectra_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'spectra_result_values', {'value_id': value_id})
# Associate the functions with the class
SpectraResultValues.create_from_json_dict = create_spectra_result_values_from_json_dict
SpectraResultValues.write = write_spectra_result_values
SpectraResultValues.update = update_spectra_result_values
SpectraResultValues.write_many = write_spectra_result_values_many
SpectraResultValues.read = read_spectra_result_values
SpectraResultValues.read_fuzzy = read_spectra_result_values_fuzzy
SpectraResultValues.read_any = read_spectra_result_values_any
SpectraResultValues.read_one = read_spectra_result_values_one
SpectraResultValues.read_one_or_none = read_spectra_result_values_one_or_none
SpectraResultValues.read_all = read_spectra_result_values_all
SpectraResultValues.delete = delete_spectra_result_values_by_id
SpectraResultValues.read_by_id = read_spectra_result_values_by_id
SpectraResultValues.delete_by_id = delete_spectra_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CategoricalResults:
    """
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param quality_code_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    x_location: Optional[float] = None # x_location double precision (default: )
    x_location_units_id: Optional[int] = None # x_location_units_id integer (default: )
    y_location: Optional[float] = None # y_location double precision (default: )
    y_location_units_id: Optional[int] = None # y_location_units_id integer (default: )
    z_location: Optional[float] = None # z_location double precision (default: )
    z_location_units_id: Optional[int] = None # z_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_categorical_results_from_json_dict(json_obj: dict):
        """
        Create a CategoricalResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CategoricalResults(**json_obj)


@beartype.beartype
def write_categorical_results_obj(con: db.Connection, obj: CategoricalResults) -> int:
    """
    Write a CategoricalResults object to the database
    @param con: database connection
    @param obj: CategoricalResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'categorical_results', dataclasses.asdict(obj))

@beartype.beartype
def write_categorical_results(
            con: db.Connection,
            result_id: int,
            quality_code_cv: str,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None) -> int:
    """
    Write to the categorical_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param quality_code_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    return db.upsert(con, 'categorical_results', data)

@beartype.beartype
def write_categorical_results_many(con: db.Connection, objs: List[CategoricalResults], upsert: bool = False) -> int:
    """
    Write a list of CategoricalResults objects to the database
    @param con: database connection
    @param objs: list of CategoricalResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'categorical_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_categorical_results(con: db.Connection, result_id: int,
            quality_code_cv: Optional[str] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None) -> int:
    """
    Update a row in the categorical_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param quality_code_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    return db.update(con, 'categorical_results', data)

@beartype.beartype
def read_categorical_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             quality_code_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None) -> Generator[CategoricalResults, None, None]:
    """
    Read from the categorical_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param quality_code_cv 
    @return generator of CategoricalResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query(con, 'categorical_results', data)
    for row in result:
        yield CategoricalResults(**row.as_dict())

@beartype.beartype
def read_categorical_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             quality_code_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None) -> Generator[CategoricalResults, None, None]:
    """
    Read from the categorical_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param quality_code_cv 
    @return generator of CategoricalResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_fuzzy(con, 'categorical_results', data)
    for row in result:
        yield CategoricalResults(**row.as_dict())

@beartype.beartype
def read_categorical_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             quality_code_cv: Optional[List[str]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None) -> Generator[CategoricalResults, None, None]:
    """
    Read from the categorical_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param quality_code_cv 
    @return generator of CategoricalResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_any(con, 'categorical_results', data)
    for row in result:
        yield CategoricalResults(**row.as_dict())

@beartype.beartype
def read_categorical_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             quality_code_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None) -> Optional[CategoricalResults]:
    """
    Read from the categorical_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_one_or_none(con, 'categorical_results', data)
    if result is None:
        return None
    return CategoricalResults(**result)

@beartype.beartype
def read_categorical_results_one(con: db.Connection, result_id: Optional[int] = None,
             quality_code_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None) -> CategoricalResults:
    """
    Read from the categorical_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_one(con, 'categorical_results', data)
    return CategoricalResults(**result)

@beartype.beartype
def read_categorical_results_all(con: db.Connection, result_id: Optional[int] = None,
             quality_code_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None) -> List[CategoricalResults]:
    """
    Read from the categorical_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query(con, 'categorical_results', data)
    return [CategoricalResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_categorical_results_by_id(con: db.Connection, result_id: int) -> Optional[CategoricalResults]:
    result = db.query_one(con, 'categorical_results', {'result_id': result_id})
    if result is None:
        return None
    return CategoricalResults(**result)

@beartype.beartype
def delete_categorical_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'categorical_results', {'result_id': result_id})
# Associate the functions with the class
CategoricalResults.create_from_json_dict = create_categorical_results_from_json_dict
CategoricalResults.write = write_categorical_results
CategoricalResults.update = update_categorical_results
CategoricalResults.write_many = write_categorical_results_many
CategoricalResults.read = read_categorical_results
CategoricalResults.read_fuzzy = read_categorical_results_fuzzy
CategoricalResults.read_any = read_categorical_results_any
CategoricalResults.read_one = read_categorical_results_one
CategoricalResults.read_one_or_none = read_categorical_results_one_or_none
CategoricalResults.read_all = read_categorical_results_all
CategoricalResults.delete = delete_categorical_results_by_id
CategoricalResults.read_by_id = read_categorical_results_by_id
CategoricalResults.delete_by_id = delete_categorical_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class MeasurementResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param aggregation_statistic_cv 
    @param censor_code_cv 
    @param quality_code_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['MeasurementResults']:
        return read_measurement_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_measurement_result_values_from_json_dict(json_obj: dict):
        """
        Create a MeasurementResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return MeasurementResultValues(**json_obj)


@beartype.beartype
def write_measurement_result_values_obj(con: db.Connection, obj: MeasurementResultValues) -> int:
    """
    Write a MeasurementResultValues object to the database
    @param con: database connection
    @param obj: MeasurementResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'measurement_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_measurement_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            aggregation_statistic_cv: str,
            censor_code_cv: str,
            quality_code_cv: str,
            value_id: Optional[int] = None) -> int:
    """
    Write to the measurement_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param aggregation_statistic_cv 
    @param censor_code_cv 
    @param quality_code_cv 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    return db.upsert(con, 'measurement_result_values', data)

@beartype.beartype
def write_measurement_result_values_many(con: db.Connection, objs: List[MeasurementResultValues], upsert: bool = False) -> int:
    """
    Write a list of MeasurementResultValues objects to the database
    @param con: database connection
    @param objs: list of MeasurementResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'measurement_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_measurement_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            aggregation_statistic_cv: Optional[str] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None) -> int:
    """
    Update a row in the measurement_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param aggregation_statistic_cv 
    @param censor_code_cv 
    @param quality_code_cv 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    return db.update(con, 'measurement_result_values', data)

@beartype.beartype
def read_measurement_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> Generator[MeasurementResultValues, None, None]:
    """
    Read from the measurement_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param aggregation_statistic_cv 
    @param censor_code_cv 
    @param quality_code_cv 
    @return generator of MeasurementResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query(con, 'measurement_result_values', data)
    for row in result:
        yield MeasurementResultValues(**row.as_dict())

@beartype.beartype
def read_measurement_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> Generator[MeasurementResultValues, None, None]:
    """
    Read from the measurement_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param aggregation_statistic_cv 
    @param censor_code_cv 
    @param quality_code_cv 
    @return generator of MeasurementResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_fuzzy(con, 'measurement_result_values', data)
    for row in result:
        yield MeasurementResultValues(**row.as_dict())

@beartype.beartype
def read_measurement_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             value_id: Optional[List[int]] = None) -> Generator[MeasurementResultValues, None, None]:
    """
    Read from the measurement_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param aggregation_statistic_cv 
    @param censor_code_cv 
    @param quality_code_cv 
    @return generator of MeasurementResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_any(con, 'measurement_result_values', data)
    for row in result:
        yield MeasurementResultValues(**row.as_dict())

@beartype.beartype
def read_measurement_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> Optional[MeasurementResultValues]:
    """
    Read from the measurement_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_one_or_none(con, 'measurement_result_values', data)
    if result is None:
        return None
    return MeasurementResultValues(**result)

@beartype.beartype
def read_measurement_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> MeasurementResultValues:
    """
    Read from the measurement_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query_one(con, 'measurement_result_values', data)
    return MeasurementResultValues(**result)

@beartype.beartype
def read_measurement_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             value_id: Optional[int] = None) -> List[MeasurementResultValues]:
    """
    Read from the measurement_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
    }
    result = db.query(con, 'measurement_result_values', data)
    return [MeasurementResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_measurement_result_values_by_id(con: db.Connection, value_id: int) -> Optional[MeasurementResultValues]:
    result = db.query_one(con, 'measurement_result_values', {'value_id': value_id})
    if result is None:
        return None
    return MeasurementResultValues(**result)

@beartype.beartype
def delete_measurement_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'measurement_result_values', {'value_id': value_id})
# Associate the functions with the class
MeasurementResultValues.create_from_json_dict = create_measurement_result_values_from_json_dict
MeasurementResultValues.write = write_measurement_result_values
MeasurementResultValues.update = update_measurement_result_values
MeasurementResultValues.write_many = write_measurement_result_values_many
MeasurementResultValues.read = read_measurement_result_values
MeasurementResultValues.read_fuzzy = read_measurement_result_values_fuzzy
MeasurementResultValues.read_any = read_measurement_result_values_any
MeasurementResultValues.read_one = read_measurement_result_values_one
MeasurementResultValues.read_one_or_none = read_measurement_result_values_one_or_none
MeasurementResultValues.read_all = read_measurement_result_values_all
MeasurementResultValues.delete = delete_measurement_result_values_by_id
MeasurementResultValues.read_by_id = read_measurement_result_values_by_id
MeasurementResultValues.delete_by_id = delete_measurement_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PointCoverageResults:
    """
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_y_spacing 
    @param intended_y_spacing_units_id 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    z_location: Optional[float] = None # z_location double precision (default: )
    z_location_units_id: Optional[int] = None # z_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_x_spacing: Optional[float] = None # intended_x_spacing double precision (default: )
    intended_x_spacing_units_id: Optional[int] = None # intended_x_spacing_units_id integer (default: )
    intended_y_spacing: Optional[float] = None # intended_y_spacing double precision (default: )
    intended_y_spacing_units_id: Optional[int] = None # intended_y_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_point_coverage_results_from_json_dict(json_obj: dict):
        """
        Create a PointCoverageResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return PointCoverageResults(**json_obj)


@beartype.beartype
def write_point_coverage_results_obj(con: db.Connection, obj: PointCoverageResults) -> int:
    """
    Write a PointCoverageResults object to the database
    @param con: database connection
    @param obj: PointCoverageResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'point_coverage_results', dataclasses.asdict(obj))

@beartype.beartype
def write_point_coverage_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_x_spacing: Optional[float] = None,
            intended_x_spacing_units_id: Optional[int] = None,
            intended_y_spacing: Optional[float] = None,
            intended_y_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the point_coverage_results table in the database
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_y_spacing 
    @param intended_y_spacing_units_id 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'point_coverage_results', data)

@beartype.beartype
def write_point_coverage_results_many(con: db.Connection, objs: List[PointCoverageResults], upsert: bool = False) -> int:
    """
    Write a list of PointCoverageResults objects to the database
    @param con: database connection
    @param objs: list of PointCoverageResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'point_coverage_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_point_coverage_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_x_spacing: Optional[float] = None,
            intended_x_spacing_units_id: Optional[int] = None,
            intended_y_spacing: Optional[float] = None,
            intended_y_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the point_coverage_results table in the database
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_y_spacing 
    @param intended_y_spacing_units_id 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'point_coverage_results', data)

@beartype.beartype
def read_point_coverage_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_y_spacing: Optional[float] = None,
             intended_y_spacing_units_id: Optional[int] = None) -> Generator[PointCoverageResults, None, None]:
    """
    Read from the point_coverage_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_y_spacing 
    @param intended_y_spacing_units_id 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of PointCoverageResults objects
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'point_coverage_results', data)
    for row in result:
        yield PointCoverageResults(**row.as_dict())

@beartype.beartype
def read_point_coverage_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_y_spacing: Optional[float] = None,
             intended_y_spacing_units_id: Optional[int] = None) -> Generator[PointCoverageResults, None, None]:
    """
    Read from the point_coverage_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_y_spacing 
    @param intended_y_spacing_units_id 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of PointCoverageResults objects
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'point_coverage_results', data)
    for row in result:
        yield PointCoverageResults(**row.as_dict())

@beartype.beartype
def read_point_coverage_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_x_spacing: Optional[List[float]] = None,
             intended_x_spacing_units_id: Optional[List[int]] = None,
             intended_y_spacing: Optional[List[float]] = None,
             intended_y_spacing_units_id: Optional[List[int]] = None) -> Generator[PointCoverageResults, None, None]:
    """
    Read from the point_coverage_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_x_spacing 
    @param intended_x_spacing_units_id 
    @param intended_y_spacing 
    @param intended_y_spacing_units_id 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of PointCoverageResults objects
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'point_coverage_results', data)
    for row in result:
        yield PointCoverageResults(**row.as_dict())

@beartype.beartype
def read_point_coverage_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_y_spacing: Optional[float] = None,
             intended_y_spacing_units_id: Optional[int] = None) -> Optional[PointCoverageResults]:
    """
    Read from the point_coverage_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'point_coverage_results', data)
    if result is None:
        return None
    return PointCoverageResults(**result)

@beartype.beartype
def read_point_coverage_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_y_spacing: Optional[float] = None,
             intended_y_spacing_units_id: Optional[int] = None) -> PointCoverageResults:
    """
    Read from the point_coverage_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'point_coverage_results', data)
    return PointCoverageResults(**result)

@beartype.beartype
def read_point_coverage_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_x_spacing: Optional[float] = None,
             intended_x_spacing_units_id: Optional[int] = None,
             intended_y_spacing: Optional[float] = None,
             intended_y_spacing_units_id: Optional[int] = None) -> List[PointCoverageResults]:
    """
    Read from the point_coverage_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_x_spacing': intended_x_spacing,
        'intended_x_spacing_units_id': intended_x_spacing_units_id,
        'intended_y_spacing': intended_y_spacing,
        'intended_y_spacing_units_id': intended_y_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'point_coverage_results', data)
    return [PointCoverageResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_point_coverage_results_by_id(con: db.Connection, result_id: int) -> Optional[PointCoverageResults]:
    result = db.query_one(con, 'point_coverage_results', {'result_id': result_id})
    if result is None:
        return None
    return PointCoverageResults(**result)

@beartype.beartype
def delete_point_coverage_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'point_coverage_results', {'result_id': result_id})
# Associate the functions with the class
PointCoverageResults.create_from_json_dict = create_point_coverage_results_from_json_dict
PointCoverageResults.write = write_point_coverage_results
PointCoverageResults.update = update_point_coverage_results
PointCoverageResults.write_many = write_point_coverage_results_many
PointCoverageResults.read = read_point_coverage_results
PointCoverageResults.read_fuzzy = read_point_coverage_results_fuzzy
PointCoverageResults.read_any = read_point_coverage_results_any
PointCoverageResults.read_one = read_point_coverage_results_one
PointCoverageResults.read_one_or_none = read_point_coverage_results_one_or_none
PointCoverageResults.read_all = read_point_coverage_results_all
PointCoverageResults.delete = delete_point_coverage_results_by_id
PointCoverageResults.read_by_id = read_point_coverage_results_by_id
PointCoverageResults.delete_by_id = delete_point_coverage_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TrajectoryResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param trajectory_distance 
    @param trajectory_distance_aggregation_interval 
    @param trajectory_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    x_location: float # x_location double precision (default: )
    x_location_units_id: int # x_location_units_id integer (default: )
    y_location: float # y_location double precision (default: )
    y_location_units_id: int # y_location_units_id integer (default: )
    z_location: float # z_location double precision (default: )
    z_location_units_id: int # z_location_units_id integer (default: )
    trajectory_distance: float # trajectory_distance double precision (default: )
    trajectory_distance_aggregation_interval: float # trajectory_distance_aggregation_interval double precision (default: )
    trajectory_distance_units_id: int # trajectory_distance_units_id integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['TrajectoryResults']:
        return read_trajectory_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_trajectory_result_values_from_json_dict(json_obj: dict):
        """
        Create a TrajectoryResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return TrajectoryResultValues(**json_obj)


@beartype.beartype
def write_trajectory_result_values_obj(con: db.Connection, obj: TrajectoryResultValues) -> int:
    """
    Write a TrajectoryResultValues object to the database
    @param con: database connection
    @param obj: TrajectoryResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'trajectory_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_trajectory_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            x_location: float,
            x_location_units_id: int,
            y_location: float,
            y_location_units_id: int,
            z_location: float,
            z_location_units_id: int,
            trajectory_distance: float,
            trajectory_distance_aggregation_interval: float,
            trajectory_distance_units_id: int,
            censor_code_cv: str,
            quality_code_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the trajectory_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param trajectory_distance 
    @param trajectory_distance_aggregation_interval 
    @param trajectory_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'trajectory_result_values', data)

@beartype.beartype
def write_trajectory_result_values_many(con: db.Connection, objs: List[TrajectoryResultValues], upsert: bool = False) -> int:
    """
    Write a list of TrajectoryResultValues objects to the database
    @param con: database connection
    @param objs: list of TrajectoryResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'trajectory_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_trajectory_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            trajectory_distance: Optional[float] = None,
            trajectory_distance_aggregation_interval: Optional[float] = None,
            trajectory_distance_units_id: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the trajectory_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param trajectory_distance 
    @param trajectory_distance_aggregation_interval 
    @param trajectory_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'trajectory_result_values', data)

@beartype.beartype
def read_trajectory_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             trajectory_distance: Optional[float] = None,
             trajectory_distance_aggregation_interval: Optional[float] = None,
             trajectory_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[TrajectoryResultValues, None, None]:
    """
    Read from the trajectory_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param trajectory_distance 
    @param trajectory_distance_aggregation_interval 
    @param trajectory_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TrajectoryResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'trajectory_result_values', data)
    for row in result:
        yield TrajectoryResultValues(**row.as_dict())

@beartype.beartype
def read_trajectory_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             trajectory_distance: Optional[float] = None,
             trajectory_distance_aggregation_interval: Optional[float] = None,
             trajectory_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[TrajectoryResultValues, None, None]:
    """
    Read from the trajectory_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param trajectory_distance 
    @param trajectory_distance_aggregation_interval 
    @param trajectory_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TrajectoryResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'trajectory_result_values', data)
    for row in result:
        yield TrajectoryResultValues(**row.as_dict())

@beartype.beartype
def read_trajectory_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             trajectory_distance: Optional[List[float]] = None,
             trajectory_distance_aggregation_interval: Optional[List[float]] = None,
             trajectory_distance_units_id: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[TrajectoryResultValues, None, None]:
    """
    Read from the trajectory_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param trajectory_distance 
    @param trajectory_distance_aggregation_interval 
    @param trajectory_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TrajectoryResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'trajectory_result_values', data)
    for row in result:
        yield TrajectoryResultValues(**row.as_dict())

@beartype.beartype
def read_trajectory_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             trajectory_distance: Optional[float] = None,
             trajectory_distance_aggregation_interval: Optional[float] = None,
             trajectory_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[TrajectoryResultValues]:
    """
    Read from the trajectory_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'trajectory_result_values', data)
    if result is None:
        return None
    return TrajectoryResultValues(**result)

@beartype.beartype
def read_trajectory_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             trajectory_distance: Optional[float] = None,
             trajectory_distance_aggregation_interval: Optional[float] = None,
             trajectory_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> TrajectoryResultValues:
    """
    Read from the trajectory_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'trajectory_result_values', data)
    return TrajectoryResultValues(**result)

@beartype.beartype
def read_trajectory_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             trajectory_distance: Optional[float] = None,
             trajectory_distance_aggregation_interval: Optional[float] = None,
             trajectory_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> List[TrajectoryResultValues]:
    """
    Read from the trajectory_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'trajectory_distance': trajectory_distance,
        'trajectory_distance_aggregation_interval': trajectory_distance_aggregation_interval,
        'trajectory_distance_units_id': trajectory_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'trajectory_result_values', data)
    return [TrajectoryResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_trajectory_result_values_by_id(con: db.Connection, value_id: int) -> Optional[TrajectoryResultValues]:
    result = db.query_one(con, 'trajectory_result_values', {'value_id': value_id})
    if result is None:
        return None
    return TrajectoryResultValues(**result)

@beartype.beartype
def delete_trajectory_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'trajectory_result_values', {'value_id': value_id})
# Associate the functions with the class
TrajectoryResultValues.create_from_json_dict = create_trajectory_result_values_from_json_dict
TrajectoryResultValues.write = write_trajectory_result_values
TrajectoryResultValues.update = update_trajectory_result_values
TrajectoryResultValues.write_many = write_trajectory_result_values_many
TrajectoryResultValues.read = read_trajectory_result_values
TrajectoryResultValues.read_fuzzy = read_trajectory_result_values_fuzzy
TrajectoryResultValues.read_any = read_trajectory_result_values_any
TrajectoryResultValues.read_one = read_trajectory_result_values_one
TrajectoryResultValues.read_one_or_none = read_trajectory_result_values_one_or_none
TrajectoryResultValues.read_all = read_trajectory_result_values_all
TrajectoryResultValues.delete = delete_trajectory_result_values_by_id
TrajectoryResultValues.read_by_id = read_trajectory_result_values_by_id
TrajectoryResultValues.delete_by_id = delete_trajectory_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TrajectoryResults:
    """
    @param result_id 
    @param spatial_reference_id 
    @param intended_trajectory_spacing 
    @param intended_trajectory_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_trajectory_spacing: Optional[float] = None # intended_trajectory_spacing double precision (default: )
    intended_trajectory_spacing_units_id: Optional[int] = None # intended_trajectory_spacing_units_id integer (default: )
    intended_time_spacing: Optional[float] = None # intended_time_spacing double precision (default: )
    intended_time_spacing_units_id: Optional[int] = None # intended_time_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_trajectory_results_from_json_dict(json_obj: dict):
        """
        Create a TrajectoryResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TrajectoryResults(**json_obj)


@beartype.beartype
def write_trajectory_results_obj(con: db.Connection, obj: TrajectoryResults) -> int:
    """
    Write a TrajectoryResults object to the database
    @param con: database connection
    @param obj: TrajectoryResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'trajectory_results', dataclasses.asdict(obj))

@beartype.beartype
def write_trajectory_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            spatial_reference_id: Optional[int] = None,
            intended_trajectory_spacing: Optional[float] = None,
            intended_trajectory_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the trajectory_results table in the database
    @param con: database connection
    @param result_id 
    @param spatial_reference_id 
    @param intended_trajectory_spacing 
    @param intended_trajectory_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'trajectory_results', data)

@beartype.beartype
def write_trajectory_results_many(con: db.Connection, objs: List[TrajectoryResults], upsert: bool = False) -> int:
    """
    Write a list of TrajectoryResults objects to the database
    @param con: database connection
    @param objs: list of TrajectoryResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'trajectory_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_trajectory_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            spatial_reference_id: Optional[int] = None,
            intended_trajectory_spacing: Optional[float] = None,
            intended_trajectory_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the trajectory_results table in the database
    @param con: database connection
    @param result_id 
    @param spatial_reference_id 
    @param intended_trajectory_spacing 
    @param intended_trajectory_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'trajectory_results', data)

@beartype.beartype
def read_trajectory_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             intended_trajectory_spacing: Optional[float] = None,
             intended_trajectory_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[TrajectoryResults, None, None]:
    """
    Read from the trajectory_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param spatial_reference_id 
    @param intended_trajectory_spacing 
    @param intended_trajectory_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TrajectoryResults objects
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'trajectory_results', data)
    for row in result:
        yield TrajectoryResults(**row.as_dict())

@beartype.beartype
def read_trajectory_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             intended_trajectory_spacing: Optional[float] = None,
             intended_trajectory_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[TrajectoryResults, None, None]:
    """
    Read from the trajectory_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param spatial_reference_id 
    @param intended_trajectory_spacing 
    @param intended_trajectory_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TrajectoryResults objects
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'trajectory_results', data)
    for row in result:
        yield TrajectoryResults(**row.as_dict())

@beartype.beartype
def read_trajectory_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_trajectory_spacing: Optional[List[float]] = None,
             intended_trajectory_spacing_units_id: Optional[List[int]] = None,
             intended_time_spacing: Optional[List[float]] = None,
             intended_time_spacing_units_id: Optional[List[int]] = None) -> Generator[TrajectoryResults, None, None]:
    """
    Read from the trajectory_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param spatial_reference_id 
    @param intended_trajectory_spacing 
    @param intended_trajectory_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TrajectoryResults objects
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'trajectory_results', data)
    for row in result:
        yield TrajectoryResults(**row.as_dict())

@beartype.beartype
def read_trajectory_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             intended_trajectory_spacing: Optional[float] = None,
             intended_trajectory_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Optional[TrajectoryResults]:
    """
    Read from the trajectory_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'trajectory_results', data)
    if result is None:
        return None
    return TrajectoryResults(**result)

@beartype.beartype
def read_trajectory_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             intended_trajectory_spacing: Optional[float] = None,
             intended_trajectory_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> TrajectoryResults:
    """
    Read from the trajectory_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'trajectory_results', data)
    return TrajectoryResults(**result)

@beartype.beartype
def read_trajectory_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             intended_trajectory_spacing: Optional[float] = None,
             intended_trajectory_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> List[TrajectoryResults]:
    """
    Read from the trajectory_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_trajectory_spacing': intended_trajectory_spacing,
        'intended_trajectory_spacing_units_id': intended_trajectory_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'trajectory_results', data)
    return [TrajectoryResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_trajectory_results_by_id(con: db.Connection, result_id: int) -> Optional[TrajectoryResults]:
    result = db.query_one(con, 'trajectory_results', {'result_id': result_id})
    if result is None:
        return None
    return TrajectoryResults(**result)

@beartype.beartype
def delete_trajectory_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'trajectory_results', {'result_id': result_id})
# Associate the functions with the class
TrajectoryResults.create_from_json_dict = create_trajectory_results_from_json_dict
TrajectoryResults.write = write_trajectory_results
TrajectoryResults.update = update_trajectory_results
TrajectoryResults.write_many = write_trajectory_results_many
TrajectoryResults.read = read_trajectory_results
TrajectoryResults.read_fuzzy = read_trajectory_results_fuzzy
TrajectoryResults.read_any = read_trajectory_results_any
TrajectoryResults.read_one = read_trajectory_results_one
TrajectoryResults.read_one_or_none = read_trajectory_results_one_or_none
TrajectoryResults.read_all = read_trajectory_results_all
TrajectoryResults.delete = delete_trajectory_results_by_id
TrajectoryResults.read_by_id = read_trajectory_results_by_id
TrajectoryResults.delete_by_id = delete_trajectory_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TransectResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param transect_distance 
    @param transect_distance_aggregation_interval 
    @param transect_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    x_location: float # x_location double precision (default: )
    x_location_units_id: int # x_location_units_id integer (default: )
    y_location: float # y_location double precision (default: )
    y_location_units_id: int # y_location_units_id integer (default: )
    transect_distance: float # transect_distance double precision (default: )
    transect_distance_aggregation_interval: float # transect_distance_aggregation_interval double precision (default: )
    transect_distance_units_id: int # transect_distance_units_id integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['TransectResults']:
        return read_transect_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_transect_result_values_from_json_dict(json_obj: dict):
        """
        Create a TransectResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return TransectResultValues(**json_obj)


@beartype.beartype
def write_transect_result_values_obj(con: db.Connection, obj: TransectResultValues) -> int:
    """
    Write a TransectResultValues object to the database
    @param con: database connection
    @param obj: TransectResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'transect_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_transect_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            x_location: float,
            x_location_units_id: int,
            y_location: float,
            y_location_units_id: int,
            transect_distance: float,
            transect_distance_aggregation_interval: float,
            transect_distance_units_id: int,
            censor_code_cv: str,
            quality_code_cv: str,
            aggregation_statistic_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the transect_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param transect_distance 
    @param transect_distance_aggregation_interval 
    @param transect_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'transect_result_values', data)

@beartype.beartype
def write_transect_result_values_many(con: db.Connection, objs: List[TransectResultValues], upsert: bool = False) -> int:
    """
    Write a list of TransectResultValues objects to the database
    @param con: database connection
    @param objs: list of TransectResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'transect_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_transect_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            transect_distance: Optional[float] = None,
            transect_distance_aggregation_interval: Optional[float] = None,
            transect_distance_units_id: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None,
            aggregation_statistic_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the transect_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param transect_distance 
    @param transect_distance_aggregation_interval 
    @param transect_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'transect_result_values', data)

@beartype.beartype
def read_transect_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             transect_distance: Optional[float] = None,
             transect_distance_aggregation_interval: Optional[float] = None,
             transect_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[TransectResultValues, None, None]:
    """
    Read from the transect_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param transect_distance 
    @param transect_distance_aggregation_interval 
    @param transect_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TransectResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'transect_result_values', data)
    for row in result:
        yield TransectResultValues(**row.as_dict())

@beartype.beartype
def read_transect_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             transect_distance: Optional[float] = None,
             transect_distance_aggregation_interval: Optional[float] = None,
             transect_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[TransectResultValues, None, None]:
    """
    Read from the transect_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param transect_distance 
    @param transect_distance_aggregation_interval 
    @param transect_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TransectResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'transect_result_values', data)
    for row in result:
        yield TransectResultValues(**row.as_dict())

@beartype.beartype
def read_transect_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             transect_distance: Optional[List[float]] = None,
             transect_distance_aggregation_interval: Optional[List[float]] = None,
             transect_distance_units_id: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[TransectResultValues, None, None]:
    """
    Read from the transect_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param transect_distance 
    @param transect_distance_aggregation_interval 
    @param transect_distance_units_id 
    @param censor_code_cv 
    @param quality_code_cv 
    @param aggregation_statistic_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TransectResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'transect_result_values', data)
    for row in result:
        yield TransectResultValues(**row.as_dict())

@beartype.beartype
def read_transect_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             transect_distance: Optional[float] = None,
             transect_distance_aggregation_interval: Optional[float] = None,
             transect_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[TransectResultValues]:
    """
    Read from the transect_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'transect_result_values', data)
    if result is None:
        return None
    return TransectResultValues(**result)

@beartype.beartype
def read_transect_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             transect_distance: Optional[float] = None,
             transect_distance_aggregation_interval: Optional[float] = None,
             transect_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> TransectResultValues:
    """
    Read from the transect_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'transect_result_values', data)
    return TransectResultValues(**result)

@beartype.beartype
def read_transect_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             transect_distance: Optional[float] = None,
             transect_distance_aggregation_interval: Optional[float] = None,
             transect_distance_units_id: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             aggregation_statistic_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> List[TransectResultValues]:
    """
    Read from the transect_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'transect_distance': transect_distance,
        'transect_distance_aggregation_interval': transect_distance_aggregation_interval,
        'transect_distance_units_id': transect_distance_units_id,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'aggregation_statistic_cv': aggregation_statistic_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'transect_result_values', data)
    return [TransectResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_transect_result_values_by_id(con: db.Connection, value_id: int) -> Optional[TransectResultValues]:
    result = db.query_one(con, 'transect_result_values', {'value_id': value_id})
    if result is None:
        return None
    return TransectResultValues(**result)

@beartype.beartype
def delete_transect_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'transect_result_values', {'value_id': value_id})
# Associate the functions with the class
TransectResultValues.create_from_json_dict = create_transect_result_values_from_json_dict
TransectResultValues.write = write_transect_result_values
TransectResultValues.update = update_transect_result_values
TransectResultValues.write_many = write_transect_result_values_many
TransectResultValues.read = read_transect_result_values
TransectResultValues.read_fuzzy = read_transect_result_values_fuzzy
TransectResultValues.read_any = read_transect_result_values_any
TransectResultValues.read_one = read_transect_result_values_one
TransectResultValues.read_one_or_none = read_transect_result_values_one_or_none
TransectResultValues.read_all = read_transect_result_values_all
TransectResultValues.delete = delete_transect_result_values_by_id
TransectResultValues.read_by_id = read_transect_result_values_by_id
TransectResultValues.delete_by_id = delete_transect_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TransectResults:
    """
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_transect_spacing 
    @param intended_transect_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    z_location: Optional[float] = None # z_location double precision (default: )
    z_location_units_id: Optional[int] = None # z_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_transect_spacing: Optional[float] = None # intended_transect_spacing double precision (default: )
    intended_transect_spacing_units_id: Optional[int] = None # intended_transect_spacing_units_id integer (default: )
    intended_time_spacing: Optional[float] = None # intended_time_spacing double precision (default: )
    intended_time_spacing_units_id: Optional[int] = None # intended_time_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_transect_results_from_json_dict(json_obj: dict):
        """
        Create a TransectResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TransectResults(**json_obj)


@beartype.beartype
def write_transect_results_obj(con: db.Connection, obj: TransectResults) -> int:
    """
    Write a TransectResults object to the database
    @param con: database connection
    @param obj: TransectResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'transect_results', dataclasses.asdict(obj))

@beartype.beartype
def write_transect_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_transect_spacing: Optional[float] = None,
            intended_transect_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the transect_results table in the database
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_transect_spacing 
    @param intended_transect_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'transect_results', data)

@beartype.beartype
def write_transect_results_many(con: db.Connection, objs: List[TransectResults], upsert: bool = False) -> int:
    """
    Write a list of TransectResults objects to the database
    @param con: database connection
    @param objs: list of TransectResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'transect_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_transect_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_transect_spacing: Optional[float] = None,
            intended_transect_spacing_units_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the transect_results table in the database
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_transect_spacing 
    @param intended_transect_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'transect_results', data)

@beartype.beartype
def read_transect_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_transect_spacing: Optional[float] = None,
             intended_transect_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[TransectResults, None, None]:
    """
    Read from the transect_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_transect_spacing 
    @param intended_transect_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TransectResults objects
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'transect_results', data)
    for row in result:
        yield TransectResults(**row.as_dict())

@beartype.beartype
def read_transect_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_transect_spacing: Optional[float] = None,
             intended_transect_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[TransectResults, None, None]:
    """
    Read from the transect_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_transect_spacing 
    @param intended_transect_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TransectResults objects
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'transect_results', data)
    for row in result:
        yield TransectResults(**row.as_dict())

@beartype.beartype
def read_transect_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_transect_spacing: Optional[List[float]] = None,
             intended_transect_spacing_units_id: Optional[List[int]] = None,
             intended_time_spacing: Optional[List[float]] = None,
             intended_time_spacing_units_id: Optional[List[int]] = None) -> Generator[TransectResults, None, None]:
    """
    Read from the transect_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_transect_spacing 
    @param intended_transect_spacing_units_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TransectResults objects
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'transect_results', data)
    for row in result:
        yield TransectResults(**row.as_dict())

@beartype.beartype
def read_transect_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_transect_spacing: Optional[float] = None,
             intended_transect_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Optional[TransectResults]:
    """
    Read from the transect_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'transect_results', data)
    if result is None:
        return None
    return TransectResults(**result)

@beartype.beartype
def read_transect_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_transect_spacing: Optional[float] = None,
             intended_transect_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> TransectResults:
    """
    Read from the transect_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'transect_results', data)
    return TransectResults(**result)

@beartype.beartype
def read_transect_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_transect_spacing: Optional[float] = None,
             intended_transect_spacing_units_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> List[TransectResults]:
    """
    Read from the transect_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_transect_spacing': intended_transect_spacing,
        'intended_transect_spacing_units_id': intended_transect_spacing_units_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'transect_results', data)
    return [TransectResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_transect_results_by_id(con: db.Connection, result_id: int) -> Optional[TransectResults]:
    result = db.query_one(con, 'transect_results', {'result_id': result_id})
    if result is None:
        return None
    return TransectResults(**result)

@beartype.beartype
def delete_transect_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'transect_results', {'result_id': result_id})
# Associate the functions with the class
TransectResults.create_from_json_dict = create_transect_results_from_json_dict
TransectResults.write = write_transect_results
TransectResults.update = update_transect_results
TransectResults.write_many = write_transect_results_many
TransectResults.read = read_transect_results
TransectResults.read_fuzzy = read_transect_results_fuzzy
TransectResults.read_any = read_transect_results_any
TransectResults.read_one = read_transect_results_one
TransectResults.read_one_or_none = read_transect_results_one_or_none
TransectResults.read_all = read_transect_results_all
TransectResults.delete = delete_transect_results_by_id
TransectResults.read_by_id = read_transect_results_by_id
TransectResults.delete_by_id = delete_transect_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpectraResults:
    """
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_wavelength_spacing 
    @param intended_wavelength_spacing_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    x_location: Optional[float] = None # x_location double precision (default: )
    x_location_units_id: Optional[int] = None # x_location_units_id integer (default: )
    y_location: Optional[float] = None # y_location double precision (default: )
    y_location_units_id: Optional[int] = None # y_location_units_id integer (default: )
    z_location: Optional[float] = None # z_location double precision (default: )
    z_location_units_id: Optional[int] = None # z_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_wavelength_spacing: Optional[float] = None # intended_wavelength_spacing double precision (default: )
    intended_wavelength_spacing_units_id: Optional[int] = None # intended_wavelength_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_spectra_results_from_json_dict(json_obj: dict):
        """
        Create a SpectraResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpectraResults(**json_obj)


@beartype.beartype
def write_spectra_results_obj(con: db.Connection, obj: SpectraResults) -> int:
    """
    Write a SpectraResults object to the database
    @param con: database connection
    @param obj: SpectraResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'spectra_results', dataclasses.asdict(obj))

@beartype.beartype
def write_spectra_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_wavelength_spacing: Optional[float] = None,
            intended_wavelength_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the spectra_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_wavelength_spacing 
    @param intended_wavelength_spacing_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'spectra_results', data)

@beartype.beartype
def write_spectra_results_many(con: db.Connection, objs: List[SpectraResults], upsert: bool = False) -> int:
    """
    Write a list of SpectraResults objects to the database
    @param con: database connection
    @param objs: list of SpectraResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'spectra_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_spectra_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_wavelength_spacing: Optional[float] = None,
            intended_wavelength_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the spectra_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_wavelength_spacing 
    @param intended_wavelength_spacing_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'spectra_results', data)

@beartype.beartype
def read_spectra_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_wavelength_spacing: Optional[float] = None,
             intended_wavelength_spacing_units_id: Optional[int] = None) -> Generator[SpectraResults, None, None]:
    """
    Read from the spectra_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_wavelength_spacing 
    @param intended_wavelength_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of SpectraResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'spectra_results', data)
    for row in result:
        yield SpectraResults(**row.as_dict())

@beartype.beartype
def read_spectra_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_wavelength_spacing: Optional[float] = None,
             intended_wavelength_spacing_units_id: Optional[int] = None) -> Generator[SpectraResults, None, None]:
    """
    Read from the spectra_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_wavelength_spacing 
    @param intended_wavelength_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of SpectraResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'spectra_results', data)
    for row in result:
        yield SpectraResults(**row.as_dict())

@beartype.beartype
def read_spectra_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_wavelength_spacing: Optional[List[float]] = None,
             intended_wavelength_spacing_units_id: Optional[List[int]] = None) -> Generator[SpectraResults, None, None]:
    """
    Read from the spectra_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_wavelength_spacing 
    @param intended_wavelength_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of SpectraResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'spectra_results', data)
    for row in result:
        yield SpectraResults(**row.as_dict())

@beartype.beartype
def read_spectra_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_wavelength_spacing: Optional[float] = None,
             intended_wavelength_spacing_units_id: Optional[int] = None) -> Optional[SpectraResults]:
    """
    Read from the spectra_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'spectra_results', data)
    if result is None:
        return None
    return SpectraResults(**result)

@beartype.beartype
def read_spectra_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_wavelength_spacing: Optional[float] = None,
             intended_wavelength_spacing_units_id: Optional[int] = None) -> SpectraResults:
    """
    Read from the spectra_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'spectra_results', data)
    return SpectraResults(**result)

@beartype.beartype
def read_spectra_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_wavelength_spacing: Optional[float] = None,
             intended_wavelength_spacing_units_id: Optional[int] = None) -> List[SpectraResults]:
    """
    Read from the spectra_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_wavelength_spacing': intended_wavelength_spacing,
        'intended_wavelength_spacing_units_id': intended_wavelength_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'spectra_results', data)
    return [SpectraResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_spectra_results_by_id(con: db.Connection, result_id: int) -> Optional[SpectraResults]:
    result = db.query_one(con, 'spectra_results', {'result_id': result_id})
    if result is None:
        return None
    return SpectraResults(**result)

@beartype.beartype
def delete_spectra_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'spectra_results', {'result_id': result_id})
# Associate the functions with the class
SpectraResults.create_from_json_dict = create_spectra_results_from_json_dict
SpectraResults.write = write_spectra_results
SpectraResults.update = update_spectra_results
SpectraResults.write_many = write_spectra_results_many
SpectraResults.read = read_spectra_results
SpectraResults.read_fuzzy = read_spectra_results_fuzzy
SpectraResults.read_any = read_spectra_results_any
SpectraResults.read_one = read_spectra_results_one
SpectraResults.read_one_or_none = read_spectra_results_one_or_none
SpectraResults.read_all = read_spectra_results_all
SpectraResults.delete = delete_spectra_results_by_id
SpectraResults.read_by_id = read_spectra_results_by_id
SpectraResults.delete_by_id = delete_spectra_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CalculatedDatastreamExpression:
    """
    @param calculated_datastream_expression_id 
    @param datastream_id 
    @param python_expression 

    This is an automatically generated class
    """
    calculated_datastream_expression_id: int # calculated_datastream_expression_id integer (default: )
    datastream_id: int # datastream_id integer (default: )
    python_expression: str # python_expression character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'calculated_datastream_expression_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_datastream(self, con: db.Connection) -> Optional['SamplingFeatureTimeseriesDatastreams']:
        return read_sampling_feature_timeseries_datastreams_one_or_none(con, datastream_id=self.datastream_id)

@beartype.beartype
def create_calculated_datastream_expression_from_json_dict(json_obj: dict):
        """
        Create a CalculatedDatastreamExpression from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CalculatedDatastreamExpression(**json_obj)


@beartype.beartype
def write_calculated_datastream_expression_obj(con: db.Connection, obj: CalculatedDatastreamExpression) -> int:
    """
    Write a CalculatedDatastreamExpression object to the database
    @param con: database connection
    @param obj: CalculatedDatastreamExpression object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'calculated_datastream_expression', dataclasses.asdict(obj))

@beartype.beartype
def write_calculated_datastream_expression(
            con: db.Connection,
            calculated_datastream_expression_id: int,
            datastream_id: int,
            python_expression: str) -> int:
    """
    Write to the calculated_datastream_expression table in the database
    @param con: database connection
    @param calculated_datastream_expression_id 
    @param datastream_id 
    @param python_expression 
    @return id of the inserted/updated row
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    return db.upsert(con, 'calculated_datastream_expression', data)

@beartype.beartype
def write_calculated_datastream_expression_many(con: db.Connection, objs: List[CalculatedDatastreamExpression], upsert: bool = False) -> int:
    """
    Write a list of CalculatedDatastreamExpression objects to the database
    @param con: database connection
    @param objs: list of CalculatedDatastreamExpression objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'calculated_datastream_expression', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_calculated_datastream_expression(con: db.Connection, calculated_datastream_expression_id: int,
            datastream_id: Optional[int] = None,
            python_expression: Optional[str] = None) -> int:
    """
    Update a row in the calculated_datastream_expression table in the database
    @param con: database connection
    @param calculated_datastream_expression_id 
    @param datastream_id 
    @param python_expression 
    @return The number of rows updated
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    return db.update(con, 'calculated_datastream_expression', data)

@beartype.beartype
def read_calculated_datastream_expression(
            con: db.Connection,
            calculated_datastream_expression_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             python_expression: Optional[str] = None) -> Generator[CalculatedDatastreamExpression, None, None]:
    """
    Read from the calculated_datastream_expression table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param calculated_datastream_expression_id 
    @param datastream_id 
    @param python_expression 
    @return generator of CalculatedDatastreamExpression objects
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    result = db.query(con, 'calculated_datastream_expression', data)
    for row in result:
        yield CalculatedDatastreamExpression(**row.as_dict())

@beartype.beartype
def read_calculated_datastream_expression_fuzzy(con: db.Connection, calculated_datastream_expression_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             python_expression: Optional[str] = None) -> Generator[CalculatedDatastreamExpression, None, None]:
    """
    Read from the calculated_datastream_expression table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param calculated_datastream_expression_id 
    @param datastream_id 
    @param python_expression 
    @return generator of CalculatedDatastreamExpression objects
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    result = db.query_fuzzy(con, 'calculated_datastream_expression', data)
    for row in result:
        yield CalculatedDatastreamExpression(**row.as_dict())

@beartype.beartype
def read_calculated_datastream_expression_any(con: db.Connection, calculated_datastream_expression_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             python_expression: Optional[List[str]] = None) -> Generator[CalculatedDatastreamExpression, None, None]:
    """
    Read from the calculated_datastream_expression table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param calculated_datastream_expression_id 
    @param datastream_id 
    @param python_expression 
    @return generator of CalculatedDatastreamExpression objects
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    result = db.query_any(con, 'calculated_datastream_expression', data)
    for row in result:
        yield CalculatedDatastreamExpression(**row.as_dict())

@beartype.beartype
def read_calculated_datastream_expression_one_or_none(con: db.Connection, calculated_datastream_expression_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             python_expression: Optional[str] = None) -> Optional[CalculatedDatastreamExpression]:
    """
    Read from the calculated_datastream_expression table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    result = db.query_one_or_none(con, 'calculated_datastream_expression', data)
    if result is None:
        return None
    return CalculatedDatastreamExpression(**result)

@beartype.beartype
def read_calculated_datastream_expression_one(con: db.Connection, calculated_datastream_expression_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             python_expression: Optional[str] = None) -> CalculatedDatastreamExpression:
    """
    Read from the calculated_datastream_expression table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    result = db.query_one(con, 'calculated_datastream_expression', data)
    return CalculatedDatastreamExpression(**result)

@beartype.beartype
def read_calculated_datastream_expression_all(con: db.Connection, calculated_datastream_expression_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             python_expression: Optional[str] = None) -> List[CalculatedDatastreamExpression]:
    """
    Read from the calculated_datastream_expression table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'calculated_datastream_expression_id': calculated_datastream_expression_id,
        'datastream_id': datastream_id,
        'python_expression': python_expression,
    }
    result = db.query(con, 'calculated_datastream_expression', data)
    return [CalculatedDatastreamExpression(**row.as_dict()) for row in result]

@beartype.beartype
def read_calculated_datastream_expression_by_id(con: db.Connection, calculated_datastream_expression_id: int) -> Optional[CalculatedDatastreamExpression]:
    result = db.query_one(con, 'calculated_datastream_expression', {'calculated_datastream_expression_id': calculated_datastream_expression_id})
    if result is None:
        return None
    return CalculatedDatastreamExpression(**result)

@beartype.beartype
def delete_calculated_datastream_expression_by_id(con: db.Connection, calculated_datastream_expression_id: int):
    db.delete(con, 'calculated_datastream_expression', {'calculated_datastream_expression_id': calculated_datastream_expression_id})
# Associate the functions with the class
CalculatedDatastreamExpression.create_from_json_dict = create_calculated_datastream_expression_from_json_dict
CalculatedDatastreamExpression.write = write_calculated_datastream_expression
CalculatedDatastreamExpression.update = update_calculated_datastream_expression
CalculatedDatastreamExpression.write_many = write_calculated_datastream_expression_many
CalculatedDatastreamExpression.read = read_calculated_datastream_expression
CalculatedDatastreamExpression.read_fuzzy = read_calculated_datastream_expression_fuzzy
CalculatedDatastreamExpression.read_any = read_calculated_datastream_expression_any
CalculatedDatastreamExpression.read_one = read_calculated_datastream_expression_one
CalculatedDatastreamExpression.read_one_or_none = read_calculated_datastream_expression_one_or_none
CalculatedDatastreamExpression.read_all = read_calculated_datastream_expression_all
CalculatedDatastreamExpression.delete = delete_calculated_datastream_expression_by_id
CalculatedDatastreamExpression.read_by_id = read_calculated_datastream_expression_by_id
CalculatedDatastreamExpression.delete_by_id = delete_calculated_datastream_expression_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DatasourceDescription:
    """
    @param datasource_id 
    @param datasource_timezone 
    @param sampling_feature_id 
    @param datasource_path 
    @param feeder_database 
    @param feeder_schema 
    @param datasource_characterization 
    @param datatable_name 
    @param odmx_database 
    @param materialized_view_schema 

    This is an automatically generated class
    """
    datasource_timezone: str # datasource_timezone character varying (default: )
    sampling_feature_id: int # sampling_feature_id integer (default: )
    feeder_database: str # feeder_database character varying (default: )
    feeder_schema: str # feeder_schema character varying (default: )
    datatable_name: str # datatable_name character varying (default: )
    odmx_database: str # odmx_database character varying (default: )
    materialized_view_schema: str # materialized_view_schema character varying (default: )
    datasource_id: Optional[int] = None # datasource_id integer (default: )
    datasource_path: Optional[str] = None # datasource_path character varying (default: )
    datasource_characterization: Optional[str] = None # datasource_characterization character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'datasource_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_datasource_description_from_json_dict(json_obj: dict):
        """
        Create a DatasourceDescription from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DatasourceDescription(**json_obj)


@beartype.beartype
def write_datasource_description_obj(con: db.Connection, obj: DatasourceDescription) -> int:
    """
    Write a DatasourceDescription object to the database
    @param con: database connection
    @param obj: DatasourceDescription object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datasource_description', dataclasses.asdict(obj))

@beartype.beartype
def write_datasource_description(
            con: db.Connection,
            datasource_timezone: str,
            sampling_feature_id: int,
            feeder_database: str,
            feeder_schema: str,
            datatable_name: str,
            odmx_database: str,
            materialized_view_schema: str,
            datasource_id: Optional[int] = None,
            datasource_path: Optional[str] = None,
            datasource_characterization: Optional[str] = None) -> int:
    """
    Write to the datasource_description table in the database
    @param con: database connection
    @param datasource_id 
    @param datasource_timezone 
    @param sampling_feature_id 
    @param datasource_path 
    @param feeder_database 
    @param feeder_schema 
    @param datasource_characterization 
    @param datatable_name 
    @param odmx_database 
    @param materialized_view_schema 
    @return id of the inserted/updated row
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    return db.upsert(con, 'datasource_description', data)

@beartype.beartype
def write_datasource_description_many(con: db.Connection, objs: List[DatasourceDescription], upsert: bool = False) -> int:
    """
    Write a list of DatasourceDescription objects to the database
    @param con: database connection
    @param objs: list of DatasourceDescription objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datasource_description', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datasource_description(con: db.Connection, datasource_id: int,
            datasource_timezone: Optional[str] = None,
            sampling_feature_id: Optional[int] = None,
            feeder_database: Optional[str] = None,
            feeder_schema: Optional[str] = None,
            datatable_name: Optional[str] = None,
            odmx_database: Optional[str] = None,
            materialized_view_schema: Optional[str] = None,
            datasource_path: Optional[str] = None,
            datasource_characterization: Optional[str] = None) -> int:
    """
    Update a row in the datasource_description table in the database
    @param con: database connection
    @param datasource_id 
    @param datasource_timezone 
    @param sampling_feature_id 
    @param datasource_path 
    @param feeder_database 
    @param feeder_schema 
    @param datasource_characterization 
    @param datatable_name 
    @param odmx_database 
    @param materialized_view_schema 
    @return The number of rows updated
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    return db.update(con, 'datasource_description', data)

@beartype.beartype
def read_datasource_description(
            con: db.Connection,
            datasource_timezone: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             feeder_database: Optional[str] = None,
             feeder_schema: Optional[str] = None,
             datatable_name: Optional[str] = None,
             odmx_database: Optional[str] = None,
             materialized_view_schema: Optional[str] = None,
             datasource_id: Optional[int] = None,
             datasource_path: Optional[str] = None,
             datasource_characterization: Optional[str] = None) -> Generator[DatasourceDescription, None, None]:
    """
    Read from the datasource_description table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datasource_id 
    @param datasource_timezone 
    @param sampling_feature_id 
    @param datasource_path 
    @param feeder_database 
    @param feeder_schema 
    @param datasource_characterization 
    @param datatable_name 
    @param odmx_database 
    @param materialized_view_schema 
    @return generator of DatasourceDescription objects
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    result = db.query(con, 'datasource_description', data)
    for row in result:
        yield DatasourceDescription(**row.as_dict())

@beartype.beartype
def read_datasource_description_fuzzy(con: db.Connection, datasource_timezone: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             feeder_database: Optional[str] = None,
             feeder_schema: Optional[str] = None,
             datatable_name: Optional[str] = None,
             odmx_database: Optional[str] = None,
             materialized_view_schema: Optional[str] = None,
             datasource_id: Optional[int] = None,
             datasource_path: Optional[str] = None,
             datasource_characterization: Optional[str] = None) -> Generator[DatasourceDescription, None, None]:
    """
    Read from the datasource_description table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datasource_id 
    @param datasource_timezone 
    @param sampling_feature_id 
    @param datasource_path 
    @param feeder_database 
    @param feeder_schema 
    @param datasource_characterization 
    @param datatable_name 
    @param odmx_database 
    @param materialized_view_schema 
    @return generator of DatasourceDescription objects
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    result = db.query_fuzzy(con, 'datasource_description', data)
    for row in result:
        yield DatasourceDescription(**row.as_dict())

@beartype.beartype
def read_datasource_description_any(con: db.Connection, datasource_timezone: Optional[List[str]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             feeder_database: Optional[List[str]] = None,
             feeder_schema: Optional[List[str]] = None,
             datatable_name: Optional[List[str]] = None,
             odmx_database: Optional[List[str]] = None,
             materialized_view_schema: Optional[List[str]] = None,
             datasource_id: Optional[List[int]] = None,
             datasource_path: Optional[List[str]] = None,
             datasource_characterization: Optional[List[str]] = None) -> Generator[DatasourceDescription, None, None]:
    """
    Read from the datasource_description table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datasource_id 
    @param datasource_timezone 
    @param sampling_feature_id 
    @param datasource_path 
    @param feeder_database 
    @param feeder_schema 
    @param datasource_characterization 
    @param datatable_name 
    @param odmx_database 
    @param materialized_view_schema 
    @return generator of DatasourceDescription objects
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    result = db.query_any(con, 'datasource_description', data)
    for row in result:
        yield DatasourceDescription(**row.as_dict())

@beartype.beartype
def read_datasource_description_one_or_none(con: db.Connection, datasource_timezone: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             feeder_database: Optional[str] = None,
             feeder_schema: Optional[str] = None,
             datatable_name: Optional[str] = None,
             odmx_database: Optional[str] = None,
             materialized_view_schema: Optional[str] = None,
             datasource_id: Optional[int] = None,
             datasource_path: Optional[str] = None,
             datasource_characterization: Optional[str] = None) -> Optional[DatasourceDescription]:
    """
    Read from the datasource_description table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    result = db.query_one_or_none(con, 'datasource_description', data)
    if result is None:
        return None
    return DatasourceDescription(**result)

@beartype.beartype
def read_datasource_description_one(con: db.Connection, datasource_timezone: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             feeder_database: Optional[str] = None,
             feeder_schema: Optional[str] = None,
             datatable_name: Optional[str] = None,
             odmx_database: Optional[str] = None,
             materialized_view_schema: Optional[str] = None,
             datasource_id: Optional[int] = None,
             datasource_path: Optional[str] = None,
             datasource_characterization: Optional[str] = None) -> DatasourceDescription:
    """
    Read from the datasource_description table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    result = db.query_one(con, 'datasource_description', data)
    return DatasourceDescription(**result)

@beartype.beartype
def read_datasource_description_all(con: db.Connection, datasource_timezone: Optional[str] = None,
             sampling_feature_id: Optional[int] = None,
             feeder_database: Optional[str] = None,
             feeder_schema: Optional[str] = None,
             datatable_name: Optional[str] = None,
             odmx_database: Optional[str] = None,
             materialized_view_schema: Optional[str] = None,
             datasource_id: Optional[int] = None,
             datasource_path: Optional[str] = None,
             datasource_characterization: Optional[str] = None) -> List[DatasourceDescription]:
    """
    Read from the datasource_description table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'datasource_id': datasource_id,
        'datasource_timezone': datasource_timezone,
        'sampling_feature_id': sampling_feature_id,
        'datasource_path': datasource_path,
        'feeder_database': feeder_database,
        'feeder_schema': feeder_schema,
        'datasource_characterization': datasource_characterization,
        'datatable_name': datatable_name,
        'odmx_database': odmx_database,
        'materialized_view_schema': materialized_view_schema,
    }
    result = db.query(con, 'datasource_description', data)
    return [DatasourceDescription(**row.as_dict()) for row in result]

@beartype.beartype
def read_datasource_description_by_id(con: db.Connection, datasource_id: int) -> Optional[DatasourceDescription]:
    result = db.query_one(con, 'datasource_description', {'datasource_id': datasource_id})
    if result is None:
        return None
    return DatasourceDescription(**result)

@beartype.beartype
def delete_datasource_description_by_id(con: db.Connection, datasource_id: int):
    db.delete(con, 'datasource_description', {'datasource_id': datasource_id})
# Associate the functions with the class
DatasourceDescription.create_from_json_dict = create_datasource_description_from_json_dict
DatasourceDescription.write = write_datasource_description
DatasourceDescription.update = update_datasource_description
DatasourceDescription.write_many = write_datasource_description_many
DatasourceDescription.read = read_datasource_description
DatasourceDescription.read_fuzzy = read_datasource_description_fuzzy
DatasourceDescription.read_any = read_datasource_description_any
DatasourceDescription.read_one = read_datasource_description_one
DatasourceDescription.read_one_or_none = read_datasource_description_one_or_none
DatasourceDescription.read_all = read_datasource_description_all
DatasourceDescription.delete = delete_datasource_description_by_id
DatasourceDescription.read_by_id = read_datasource_description_by_id
DatasourceDescription.delete_by_id = delete_datasource_description_by_id



@beartype_wrap_init
@dataclasses.dataclass
class CalibrationMultiplierOffset:
    """
    Table holding time dependent calibration multiplier and offset dates

    @param calibration_id 
    @param data_source_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param calibration_multiplier 
    @param calibration_offset 

    This is an automatically generated class
    """
    data_source_id: int # data_source_id integer (default: )
    sensor_id: int # sensor_id integer (default: )
    parameter_name_in_table: str # parameter_name_in_table character varying (default: )
    start_date_time_utc: int # start_date_time_utc bigint (default: )
    end_date_time_utc: int # end_date_time_utc bigint (default: )
    calibration_multiplier: float # calibration_multiplier double precision (default: )
    calibration_offset: float # calibration_offset double precision (default: )
    calibration_id: Optional[int] = None # calibration_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'calibration_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_calibration_multiplier_offset_from_json_dict(json_obj: dict):
        """
        Create a CalibrationMultiplierOffset from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return CalibrationMultiplierOffset(**json_obj)


@beartype.beartype
def write_calibration_multiplier_offset_obj(con: db.Connection, obj: CalibrationMultiplierOffset) -> int:
    """
    Write a CalibrationMultiplierOffset object to the database
    @param con: database connection
    @param obj: CalibrationMultiplierOffset object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'calibration_multiplier_offset', dataclasses.asdict(obj))

@beartype.beartype
def write_calibration_multiplier_offset(
            con: db.Connection,
            data_source_id: int,
            sensor_id: int,
            parameter_name_in_table: str,
            start_date_time_utc: int,
            end_date_time_utc: int,
            calibration_multiplier: float,
            calibration_offset: float,
            calibration_id: Optional[int] = None) -> int:
    """
    Write to the calibration_multiplier_offset table in the database
    @param con: database connection
    @param calibration_id 
    @param data_source_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param calibration_multiplier 
    @param calibration_offset 
    @return id of the inserted/updated row
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    return db.upsert(con, 'calibration_multiplier_offset', data)

@beartype.beartype
def write_calibration_multiplier_offset_many(con: db.Connection, objs: List[CalibrationMultiplierOffset], upsert: bool = False) -> int:
    """
    Write a list of CalibrationMultiplierOffset objects to the database
    @param con: database connection
    @param objs: list of CalibrationMultiplierOffset objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'calibration_multiplier_offset', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_calibration_multiplier_offset(con: db.Connection, calibration_id: int,
            data_source_id: Optional[int] = None,
            sensor_id: Optional[int] = None,
            parameter_name_in_table: Optional[str] = None,
            start_date_time_utc: Optional[int] = None,
            end_date_time_utc: Optional[int] = None,
            calibration_multiplier: Optional[float] = None,
            calibration_offset: Optional[float] = None) -> int:
    """
    Update a row in the calibration_multiplier_offset table in the database
    @param con: database connection
    @param calibration_id 
    @param data_source_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param calibration_multiplier 
    @param calibration_offset 
    @return The number of rows updated
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    return db.update(con, 'calibration_multiplier_offset', data)

@beartype.beartype
def read_calibration_multiplier_offset(
            con: db.Connection,
            data_source_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             calibration_multiplier: Optional[float] = None,
             calibration_offset: Optional[float] = None,
             calibration_id: Optional[int] = None) -> Generator[CalibrationMultiplierOffset, None, None]:
    """
    Read from the calibration_multiplier_offset table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param calibration_id 
    @param data_source_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param calibration_multiplier 
    @param calibration_offset 
    @return generator of CalibrationMultiplierOffset objects
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    result = db.query(con, 'calibration_multiplier_offset', data)
    for row in result:
        yield CalibrationMultiplierOffset(**row.as_dict())

@beartype.beartype
def read_calibration_multiplier_offset_fuzzy(con: db.Connection, data_source_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             calibration_multiplier: Optional[float] = None,
             calibration_offset: Optional[float] = None,
             calibration_id: Optional[int] = None) -> Generator[CalibrationMultiplierOffset, None, None]:
    """
    Read from the calibration_multiplier_offset table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param calibration_id 
    @param data_source_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param calibration_multiplier 
    @param calibration_offset 
    @return generator of CalibrationMultiplierOffset objects
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    result = db.query_fuzzy(con, 'calibration_multiplier_offset', data)
    for row in result:
        yield CalibrationMultiplierOffset(**row.as_dict())

@beartype.beartype
def read_calibration_multiplier_offset_any(con: db.Connection, data_source_id: Optional[List[int]] = None,
             sensor_id: Optional[List[int]] = None,
             parameter_name_in_table: Optional[List[str]] = None,
             start_date_time_utc: Optional[List[int]] = None,
             end_date_time_utc: Optional[List[int]] = None,
             calibration_multiplier: Optional[List[float]] = None,
             calibration_offset: Optional[List[float]] = None,
             calibration_id: Optional[List[int]] = None) -> Generator[CalibrationMultiplierOffset, None, None]:
    """
    Read from the calibration_multiplier_offset table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param calibration_id 
    @param data_source_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param calibration_multiplier 
    @param calibration_offset 
    @return generator of CalibrationMultiplierOffset objects
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    result = db.query_any(con, 'calibration_multiplier_offset', data)
    for row in result:
        yield CalibrationMultiplierOffset(**row.as_dict())

@beartype.beartype
def read_calibration_multiplier_offset_one_or_none(con: db.Connection, data_source_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             calibration_multiplier: Optional[float] = None,
             calibration_offset: Optional[float] = None,
             calibration_id: Optional[int] = None) -> Optional[CalibrationMultiplierOffset]:
    """
    Read from the calibration_multiplier_offset table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    result = db.query_one_or_none(con, 'calibration_multiplier_offset', data)
    if result is None:
        return None
    return CalibrationMultiplierOffset(**result)

@beartype.beartype
def read_calibration_multiplier_offset_one(con: db.Connection, data_source_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             calibration_multiplier: Optional[float] = None,
             calibration_offset: Optional[float] = None,
             calibration_id: Optional[int] = None) -> CalibrationMultiplierOffset:
    """
    Read from the calibration_multiplier_offset table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    result = db.query_one(con, 'calibration_multiplier_offset', data)
    return CalibrationMultiplierOffset(**result)

@beartype.beartype
def read_calibration_multiplier_offset_all(con: db.Connection, data_source_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             calibration_multiplier: Optional[float] = None,
             calibration_offset: Optional[float] = None,
             calibration_id: Optional[int] = None) -> List[CalibrationMultiplierOffset]:
    """
    Read from the calibration_multiplier_offset table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'calibration_id': calibration_id,
        'data_source_id': data_source_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'calibration_multiplier': calibration_multiplier,
        'calibration_offset': calibration_offset,
    }
    result = db.query(con, 'calibration_multiplier_offset', data)
    return [CalibrationMultiplierOffset(**row.as_dict()) for row in result]

@beartype.beartype
def read_calibration_multiplier_offset_by_id(con: db.Connection, calibration_id: int) -> Optional[CalibrationMultiplierOffset]:
    result = db.query_one(con, 'calibration_multiplier_offset', {'calibration_id': calibration_id})
    if result is None:
        return None
    return CalibrationMultiplierOffset(**result)

@beartype.beartype
def delete_calibration_multiplier_offset_by_id(con: db.Connection, calibration_id: int):
    db.delete(con, 'calibration_multiplier_offset', {'calibration_id': calibration_id})
# Associate the functions with the class
CalibrationMultiplierOffset.create_from_json_dict = create_calibration_multiplier_offset_from_json_dict
CalibrationMultiplierOffset.write = write_calibration_multiplier_offset
CalibrationMultiplierOffset.update = update_calibration_multiplier_offset
CalibrationMultiplierOffset.write_many = write_calibration_multiplier_offset_many
CalibrationMultiplierOffset.read = read_calibration_multiplier_offset
CalibrationMultiplierOffset.read_fuzzy = read_calibration_multiplier_offset_fuzzy
CalibrationMultiplierOffset.read_any = read_calibration_multiplier_offset_any
CalibrationMultiplierOffset.read_one = read_calibration_multiplier_offset_one
CalibrationMultiplierOffset.read_one_or_none = read_calibration_multiplier_offset_one_or_none
CalibrationMultiplierOffset.read_all = read_calibration_multiplier_offset_all
CalibrationMultiplierOffset.delete = delete_calibration_multiplier_offset_by_id
CalibrationMultiplierOffset.read_by_id = read_calibration_multiplier_offset_by_id
CalibrationMultiplierOffset.delete_by_id = delete_calibration_multiplier_offset_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ConversionMultiplierOffset:
    """
    @param conversion_multiplier_offset_id 
    @param datasource_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param conversion_multiplier 
    @param conversion_offset 

    This is an automatically generated class
    """
    conversion_multiplier_offset_id: int # conversion_multiplier_offset_id integer (default: )
    datasource_id: int # datasource_id integer (default: )
    sensor_id: int # sensor_id bigint (default: )
    parameter_name_in_table: str # parameter_name_in_table character varying (default: )
    start_date_time_utc: int # start_date_time_utc bigint (default: )
    end_date_time_utc: int # end_date_time_utc bigint (default: )
    conversion_multiplier: float # conversion_multiplier double precision (default: )
    conversion_offset: float # conversion_offset double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'conversion_multiplier_offset_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_conversion_multiplier_offset_from_json_dict(json_obj: dict):
        """
        Create a ConversionMultiplierOffset from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ConversionMultiplierOffset(**json_obj)


@beartype.beartype
def write_conversion_multiplier_offset_obj(con: db.Connection, obj: ConversionMultiplierOffset) -> int:
    """
    Write a ConversionMultiplierOffset object to the database
    @param con: database connection
    @param obj: ConversionMultiplierOffset object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'conversion_multiplier_offset', dataclasses.asdict(obj))

@beartype.beartype
def write_conversion_multiplier_offset(
            con: db.Connection,
            conversion_multiplier_offset_id: int,
            datasource_id: int,
            sensor_id: int,
            parameter_name_in_table: str,
            start_date_time_utc: int,
            end_date_time_utc: int,
            conversion_multiplier: float,
            conversion_offset: float) -> int:
    """
    Write to the conversion_multiplier_offset table in the database
    @param con: database connection
    @param conversion_multiplier_offset_id 
    @param datasource_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param conversion_multiplier 
    @param conversion_offset 
    @return id of the inserted/updated row
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    return db.upsert(con, 'conversion_multiplier_offset', data)

@beartype.beartype
def write_conversion_multiplier_offset_many(con: db.Connection, objs: List[ConversionMultiplierOffset], upsert: bool = False) -> int:
    """
    Write a list of ConversionMultiplierOffset objects to the database
    @param con: database connection
    @param objs: list of ConversionMultiplierOffset objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'conversion_multiplier_offset', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_conversion_multiplier_offset(con: db.Connection, conversion_multiplier_offset_id: int,
            datasource_id: Optional[int] = None,
            sensor_id: Optional[int] = None,
            parameter_name_in_table: Optional[str] = None,
            start_date_time_utc: Optional[int] = None,
            end_date_time_utc: Optional[int] = None,
            conversion_multiplier: Optional[float] = None,
            conversion_offset: Optional[float] = None) -> int:
    """
    Update a row in the conversion_multiplier_offset table in the database
    @param con: database connection
    @param conversion_multiplier_offset_id 
    @param datasource_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param conversion_multiplier 
    @param conversion_offset 
    @return The number of rows updated
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    return db.update(con, 'conversion_multiplier_offset', data)

@beartype.beartype
def read_conversion_multiplier_offset(
            con: db.Connection,
            conversion_multiplier_offset_id: Optional[int] = None,
             datasource_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None) -> Generator[ConversionMultiplierOffset, None, None]:
    """
    Read from the conversion_multiplier_offset table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param conversion_multiplier_offset_id 
    @param datasource_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param conversion_multiplier 
    @param conversion_offset 
    @return generator of ConversionMultiplierOffset objects
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    result = db.query(con, 'conversion_multiplier_offset', data)
    for row in result:
        yield ConversionMultiplierOffset(**row.as_dict())

@beartype.beartype
def read_conversion_multiplier_offset_fuzzy(con: db.Connection, conversion_multiplier_offset_id: Optional[int] = None,
             datasource_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None) -> Generator[ConversionMultiplierOffset, None, None]:
    """
    Read from the conversion_multiplier_offset table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param conversion_multiplier_offset_id 
    @param datasource_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param conversion_multiplier 
    @param conversion_offset 
    @return generator of ConversionMultiplierOffset objects
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    result = db.query_fuzzy(con, 'conversion_multiplier_offset', data)
    for row in result:
        yield ConversionMultiplierOffset(**row.as_dict())

@beartype.beartype
def read_conversion_multiplier_offset_any(con: db.Connection, conversion_multiplier_offset_id: Optional[List[int]] = None,
             datasource_id: Optional[List[int]] = None,
             sensor_id: Optional[List[int]] = None,
             parameter_name_in_table: Optional[List[str]] = None,
             start_date_time_utc: Optional[List[int]] = None,
             end_date_time_utc: Optional[List[int]] = None,
             conversion_multiplier: Optional[List[float]] = None,
             conversion_offset: Optional[List[float]] = None) -> Generator[ConversionMultiplierOffset, None, None]:
    """
    Read from the conversion_multiplier_offset table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param conversion_multiplier_offset_id 
    @param datasource_id 
    @param sensor_id 
    @param parameter_name_in_table 
    @param start_date_time_utc 
    @param end_date_time_utc 
    @param conversion_multiplier 
    @param conversion_offset 
    @return generator of ConversionMultiplierOffset objects
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    result = db.query_any(con, 'conversion_multiplier_offset', data)
    for row in result:
        yield ConversionMultiplierOffset(**row.as_dict())

@beartype.beartype
def read_conversion_multiplier_offset_one_or_none(con: db.Connection, conversion_multiplier_offset_id: Optional[int] = None,
             datasource_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None) -> Optional[ConversionMultiplierOffset]:
    """
    Read from the conversion_multiplier_offset table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    result = db.query_one_or_none(con, 'conversion_multiplier_offset', data)
    if result is None:
        return None
    return ConversionMultiplierOffset(**result)

@beartype.beartype
def read_conversion_multiplier_offset_one(con: db.Connection, conversion_multiplier_offset_id: Optional[int] = None,
             datasource_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None) -> ConversionMultiplierOffset:
    """
    Read from the conversion_multiplier_offset table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    result = db.query_one(con, 'conversion_multiplier_offset', data)
    return ConversionMultiplierOffset(**result)

@beartype.beartype
def read_conversion_multiplier_offset_all(con: db.Connection, conversion_multiplier_offset_id: Optional[int] = None,
             datasource_id: Optional[int] = None,
             sensor_id: Optional[int] = None,
             parameter_name_in_table: Optional[str] = None,
             start_date_time_utc: Optional[int] = None,
             end_date_time_utc: Optional[int] = None,
             conversion_multiplier: Optional[float] = None,
             conversion_offset: Optional[float] = None) -> List[ConversionMultiplierOffset]:
    """
    Read from the conversion_multiplier_offset table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'conversion_multiplier_offset_id': conversion_multiplier_offset_id,
        'datasource_id': datasource_id,
        'sensor_id': sensor_id,
        'parameter_name_in_table': parameter_name_in_table,
        'start_date_time_utc': start_date_time_utc,
        'end_date_time_utc': end_date_time_utc,
        'conversion_multiplier': conversion_multiplier,
        'conversion_offset': conversion_offset,
    }
    result = db.query(con, 'conversion_multiplier_offset', data)
    return [ConversionMultiplierOffset(**row.as_dict()) for row in result]

@beartype.beartype
def read_conversion_multiplier_offset_by_id(con: db.Connection, conversion_multiplier_offset_id: int) -> Optional[ConversionMultiplierOffset]:
    result = db.query_one(con, 'conversion_multiplier_offset', {'conversion_multiplier_offset_id': conversion_multiplier_offset_id})
    if result is None:
        return None
    return ConversionMultiplierOffset(**result)

@beartype.beartype
def delete_conversion_multiplier_offset_by_id(con: db.Connection, conversion_multiplier_offset_id: int):
    db.delete(con, 'conversion_multiplier_offset', {'conversion_multiplier_offset_id': conversion_multiplier_offset_id})
# Associate the functions with the class
ConversionMultiplierOffset.create_from_json_dict = create_conversion_multiplier_offset_from_json_dict
ConversionMultiplierOffset.write = write_conversion_multiplier_offset
ConversionMultiplierOffset.update = update_conversion_multiplier_offset
ConversionMultiplierOffset.write_many = write_conversion_multiplier_offset_many
ConversionMultiplierOffset.read = read_conversion_multiplier_offset
ConversionMultiplierOffset.read_fuzzy = read_conversion_multiplier_offset_fuzzy
ConversionMultiplierOffset.read_any = read_conversion_multiplier_offset_any
ConversionMultiplierOffset.read_one = read_conversion_multiplier_offset_one
ConversionMultiplierOffset.read_one_or_none = read_conversion_multiplier_offset_one_or_none
ConversionMultiplierOffset.read_all = read_conversion_multiplier_offset_all
ConversionMultiplierOffset.delete = delete_conversion_multiplier_offset_by_id
ConversionMultiplierOffset.read_by_id = read_conversion_multiplier_offset_by_id
ConversionMultiplierOffset.delete_by_id = delete_conversion_multiplier_offset_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DataChannel:
    """
    @param data_channel_id 
    @param source_datastream_id 

    This is an automatically generated class
    """
    source_datastream_id: int # source_datastream_id integer (default: )
    data_channel_id: Optional[int] = None # data_channel_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'data_channel_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_data_channel_from_json_dict(json_obj: dict):
        """
        Create a DataChannel from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DataChannel(**json_obj)


@beartype.beartype
def write_data_channel_obj(con: db.Connection, obj: DataChannel) -> int:
    """
    Write a DataChannel object to the database
    @param con: database connection
    @param obj: DataChannel object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'data_channel', dataclasses.asdict(obj))

@beartype.beartype
def write_data_channel(
            con: db.Connection,
            source_datastream_id: int,
            data_channel_id: Optional[int] = None) -> int:
    """
    Write to the data_channel table in the database
    @param con: database connection
    @param data_channel_id 
    @param source_datastream_id 
    @return id of the inserted/updated row
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    return db.upsert(con, 'data_channel', data)

@beartype.beartype
def write_data_channel_many(con: db.Connection, objs: List[DataChannel], upsert: bool = False) -> int:
    """
    Write a list of DataChannel objects to the database
    @param con: database connection
    @param objs: list of DataChannel objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'data_channel', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_data_channel(con: db.Connection, data_channel_id: int,
            source_datastream_id: Optional[int] = None) -> int:
    """
    Update a row in the data_channel table in the database
    @param con: database connection
    @param data_channel_id 
    @param source_datastream_id 
    @return The number of rows updated
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    return db.update(con, 'data_channel', data)

@beartype.beartype
def read_data_channel(
            con: db.Connection,
            source_datastream_id: Optional[int] = None,
             data_channel_id: Optional[int] = None) -> Generator[DataChannel, None, None]:
    """
    Read from the data_channel table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param data_channel_id 
    @param source_datastream_id 
    @return generator of DataChannel objects
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    result = db.query(con, 'data_channel', data)
    for row in result:
        yield DataChannel(**row.as_dict())

@beartype.beartype
def read_data_channel_fuzzy(con: db.Connection, source_datastream_id: Optional[int] = None,
             data_channel_id: Optional[int] = None) -> Generator[DataChannel, None, None]:
    """
    Read from the data_channel table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param data_channel_id 
    @param source_datastream_id 
    @return generator of DataChannel objects
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    result = db.query_fuzzy(con, 'data_channel', data)
    for row in result:
        yield DataChannel(**row.as_dict())

@beartype.beartype
def read_data_channel_any(con: db.Connection, source_datastream_id: Optional[List[int]] = None,
             data_channel_id: Optional[List[int]] = None) -> Generator[DataChannel, None, None]:
    """
    Read from the data_channel table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param data_channel_id 
    @param source_datastream_id 
    @return generator of DataChannel objects
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    result = db.query_any(con, 'data_channel', data)
    for row in result:
        yield DataChannel(**row.as_dict())

@beartype.beartype
def read_data_channel_one_or_none(con: db.Connection, source_datastream_id: Optional[int] = None,
             data_channel_id: Optional[int] = None) -> Optional[DataChannel]:
    """
    Read from the data_channel table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    result = db.query_one_or_none(con, 'data_channel', data)
    if result is None:
        return None
    return DataChannel(**result)

@beartype.beartype
def read_data_channel_one(con: db.Connection, source_datastream_id: Optional[int] = None,
             data_channel_id: Optional[int] = None) -> DataChannel:
    """
    Read from the data_channel table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    result = db.query_one(con, 'data_channel', data)
    return DataChannel(**result)

@beartype.beartype
def read_data_channel_all(con: db.Connection, source_datastream_id: Optional[int] = None,
             data_channel_id: Optional[int] = None) -> List[DataChannel]:
    """
    Read from the data_channel table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'data_channel_id': data_channel_id,
        'source_datastream_id': source_datastream_id,
    }
    result = db.query(con, 'data_channel', data)
    return [DataChannel(**row.as_dict()) for row in result]

@beartype.beartype
def read_data_channel_by_id(con: db.Connection, data_channel_id: int) -> Optional[DataChannel]:
    result = db.query_one(con, 'data_channel', {'data_channel_id': data_channel_id})
    if result is None:
        return None
    return DataChannel(**result)

@beartype.beartype
def delete_data_channel_by_id(con: db.Connection, data_channel_id: int):
    db.delete(con, 'data_channel', {'data_channel_id': data_channel_id})
# Associate the functions with the class
DataChannel.create_from_json_dict = create_data_channel_from_json_dict
DataChannel.write = write_data_channel
DataChannel.update = update_data_channel
DataChannel.write_many = write_data_channel_many
DataChannel.read = read_data_channel
DataChannel.read_fuzzy = read_data_channel_fuzzy
DataChannel.read_any = read_data_channel_any
DataChannel.read_one = read_data_channel_one
DataChannel.read_one_or_none = read_data_channel_one_or_none
DataChannel.read_all = read_data_channel_all
DataChannel.delete = delete_data_channel_by_id
DataChannel.read_by_id = read_data_channel_by_id
DataChannel.delete_by_id = delete_data_channel_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TimeseriesResultValues:
    """
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    data_value: float # data_value double precision (default: )
    value_date_time: datetime.datetime # value_date_time timestamp without time zone (default: )
    value_date_time_utc_offset: int # value_date_time_utc_offset integer (default: )
    censor_code_cv: str # censor_code_cv character varying (default: )
    quality_code_cv: str # quality_code_cv character varying (default: )
    time_aggregation_interval: float # time_aggregation_interval double precision (default: )
    time_aggregation_interval_units_id: int # time_aggregation_interval_units_id integer (default: )
    value_id: Optional[int] = None # value_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'value_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['value_date_time'] = self.value_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_censor_code_cv(self, con: db.Connection) -> Optional['CvCensorCode']:
        return read_cv_censor_code_one_or_none(con, term=self.censor_code_cv)

    @beartype.beartype
    def get_quality_code_cv(self, con: db.Connection) -> Optional['CvQualityCode']:
        return read_cv_quality_code_one_or_none(con, term=self.quality_code_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['TimeseriesResults']:
        return read_timeseries_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_timeseries_result_values_from_json_dict(json_obj: dict):
        """
        Create a TimeseriesResultValues from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['value_date_time'] = datetime.datetime.fromisoformat(json_obj['value_date_time'])
        return TimeseriesResultValues(**json_obj)


@beartype.beartype
def write_timeseries_result_values_obj(con: db.Connection, obj: TimeseriesResultValues) -> int:
    """
    Write a TimeseriesResultValues object to the database
    @param con: database connection
    @param obj: TimeseriesResultValues object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'timeseries_result_values', dataclasses.asdict(obj))

@beartype.beartype
def write_timeseries_result_values(
            con: db.Connection,
            result_id: int,
            data_value: float,
            value_date_time: datetime.datetime,
            value_date_time_utc_offset: int,
            censor_code_cv: str,
            quality_code_cv: str,
            time_aggregation_interval: float,
            time_aggregation_interval_units_id: int,
            value_id: Optional[int] = None) -> int:
    """
    Write to the timeseries_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return id of the inserted/updated row
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.upsert(con, 'timeseries_result_values', data)

@beartype.beartype
def write_timeseries_result_values_many(con: db.Connection, objs: List[TimeseriesResultValues], upsert: bool = False) -> int:
    """
    Write a list of TimeseriesResultValues objects to the database
    @param con: database connection
    @param objs: list of TimeseriesResultValues objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'timeseries_result_values', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_timeseries_result_values(con: db.Connection, value_id: int,
            result_id: Optional[int] = None,
            data_value: Optional[float] = None,
            value_date_time: Optional[datetime.datetime] = None,
            value_date_time_utc_offset: Optional[int] = None,
            censor_code_cv: Optional[str] = None,
            quality_code_cv: Optional[str] = None,
            time_aggregation_interval: Optional[float] = None,
            time_aggregation_interval_units_id: Optional[int] = None) -> int:
    """
    Update a row in the timeseries_result_values table in the database
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return The number of rows updated
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    return db.update(con, 'timeseries_result_values', data)

@beartype.beartype
def read_timeseries_result_values(
            con: db.Connection,
            result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[TimeseriesResultValues, None, None]:
    """
    Read from the timeseries_result_values table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TimeseriesResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'timeseries_result_values', data)
    for row in result:
        yield TimeseriesResultValues(**row.as_dict())

@beartype.beartype
def read_timeseries_result_values_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Generator[TimeseriesResultValues, None, None]:
    """
    Read from the timeseries_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TimeseriesResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_fuzzy(con, 'timeseries_result_values', data)
    for row in result:
        yield TimeseriesResultValues(**row.as_dict())

@beartype.beartype
def read_timeseries_result_values_any(con: db.Connection, result_id: Optional[List[int]] = None,
             data_value: Optional[List[float]] = None,
             value_date_time: Optional[List[datetime.datetime]] = None,
             value_date_time_utc_offset: Optional[List[int]] = None,
             censor_code_cv: Optional[List[str]] = None,
             quality_code_cv: Optional[List[str]] = None,
             time_aggregation_interval: Optional[List[float]] = None,
             time_aggregation_interval_units_id: Optional[List[int]] = None,
             value_id: Optional[List[int]] = None) -> Generator[TimeseriesResultValues, None, None]:
    """
    Read from the timeseries_result_values table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param value_id 
    @param result_id 
    @param data_value 
    @param value_date_time 
    @param value_date_time_utc_offset 
    @param censor_code_cv 
    @param quality_code_cv 
    @param time_aggregation_interval 
    @param time_aggregation_interval_units_id 
    @return generator of TimeseriesResultValues objects
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_any(con, 'timeseries_result_values', data)
    for row in result:
        yield TimeseriesResultValues(**row.as_dict())

@beartype.beartype
def read_timeseries_result_values_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> Optional[TimeseriesResultValues]:
    """
    Read from the timeseries_result_values table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one_or_none(con, 'timeseries_result_values', data)
    if result is None:
        return None
    return TimeseriesResultValues(**result)

@beartype.beartype
def read_timeseries_result_values_one(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> TimeseriesResultValues:
    """
    Read from the timeseries_result_values table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query_one(con, 'timeseries_result_values', data)
    return TimeseriesResultValues(**result)

@beartype.beartype
def read_timeseries_result_values_all(con: db.Connection, result_id: Optional[int] = None,
             data_value: Optional[float] = None,
             value_date_time: Optional[datetime.datetime] = None,
             value_date_time_utc_offset: Optional[int] = None,
             censor_code_cv: Optional[str] = None,
             quality_code_cv: Optional[str] = None,
             time_aggregation_interval: Optional[float] = None,
             time_aggregation_interval_units_id: Optional[int] = None,
             value_id: Optional[int] = None) -> List[TimeseriesResultValues]:
    """
    Read from the timeseries_result_values table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'value_id': value_id,
        'result_id': result_id,
        'data_value': data_value,
        'value_date_time': value_date_time,
        'value_date_time_utc_offset': value_date_time_utc_offset,
        'censor_code_cv': censor_code_cv,
        'quality_code_cv': quality_code_cv,
        'time_aggregation_interval': time_aggregation_interval,
        'time_aggregation_interval_units_id': time_aggregation_interval_units_id,
    }
    result = db.query(con, 'timeseries_result_values', data)
    return [TimeseriesResultValues(**row.as_dict()) for row in result]

@beartype.beartype
def read_timeseries_result_values_by_id(con: db.Connection, value_id: int) -> Optional[TimeseriesResultValues]:
    result = db.query_one(con, 'timeseries_result_values', {'value_id': value_id})
    if result is None:
        return None
    return TimeseriesResultValues(**result)

@beartype.beartype
def delete_timeseries_result_values_by_id(con: db.Connection, value_id: int):
    db.delete(con, 'timeseries_result_values', {'value_id': value_id})
# Associate the functions with the class
TimeseriesResultValues.create_from_json_dict = create_timeseries_result_values_from_json_dict
TimeseriesResultValues.write = write_timeseries_result_values
TimeseriesResultValues.update = update_timeseries_result_values
TimeseriesResultValues.write_many = write_timeseries_result_values_many
TimeseriesResultValues.read = read_timeseries_result_values
TimeseriesResultValues.read_fuzzy = read_timeseries_result_values_fuzzy
TimeseriesResultValues.read_any = read_timeseries_result_values_any
TimeseriesResultValues.read_one = read_timeseries_result_values_one
TimeseriesResultValues.read_one_or_none = read_timeseries_result_values_one_or_none
TimeseriesResultValues.read_all = read_timeseries_result_values_all
TimeseriesResultValues.delete = delete_timeseries_result_values_by_id
TimeseriesResultValues.read_by_id = read_timeseries_result_values_by_id
TimeseriesResultValues.delete_by_id = delete_timeseries_result_values_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TimeseriesResults:
    """
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 

    This is an automatically generated class
    """
    result_id: int # result_id bigint (default: )
    aggregation_statistic_cv: str # aggregation_statistic_cv character varying (default: )
    x_location: Optional[float] = None # x_location double precision (default: )
    x_location_units_id: Optional[int] = None # x_location_units_id integer (default: )
    y_location: Optional[float] = None # y_location double precision (default: )
    y_location_units_id: Optional[int] = None # y_location_units_id integer (default: )
    z_location: Optional[float] = None # z_location double precision (default: )
    z_location_units_id: Optional[int] = None # z_location_units_id integer (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    intended_time_spacing: Optional[float] = None # intended_time_spacing double precision (default: )
    intended_time_spacing_units_id: Optional[int] = None # intended_time_spacing_units_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_aggregation_statistic_cv(self, con: db.Connection) -> Optional['CvAggregationStatistic']:
        return read_cv_aggregation_statistic_one_or_none(con, term=self.aggregation_statistic_cv)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

    @beartype.beartype
    def get_spatial_reference(self, con: db.Connection) -> Optional['SpatialReferences']:
        return read_spatial_references_one_or_none(con, spatial_reference_id=self.spatial_reference_id)

@beartype.beartype
def create_timeseries_results_from_json_dict(json_obj: dict):
        """
        Create a TimeseriesResults from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TimeseriesResults(**json_obj)


@beartype.beartype
def write_timeseries_results_obj(con: db.Connection, obj: TimeseriesResults) -> int:
    """
    Write a TimeseriesResults object to the database
    @param con: database connection
    @param obj: TimeseriesResults object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'timeseries_results', dataclasses.asdict(obj))

@beartype.beartype
def write_timeseries_results(
            con: db.Connection,
            result_id: int,
            aggregation_statistic_cv: str,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Write to the timeseries_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return id of the inserted/updated row
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.upsert(con, 'timeseries_results', data)

@beartype.beartype
def write_timeseries_results_many(con: db.Connection, objs: List[TimeseriesResults], upsert: bool = False) -> int:
    """
    Write a list of TimeseriesResults objects to the database
    @param con: database connection
    @param objs: list of TimeseriesResults objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'timeseries_results', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_timeseries_results(con: db.Connection, result_id: int,
            aggregation_statistic_cv: Optional[str] = None,
            x_location: Optional[float] = None,
            x_location_units_id: Optional[int] = None,
            y_location: Optional[float] = None,
            y_location_units_id: Optional[int] = None,
            z_location: Optional[float] = None,
            z_location_units_id: Optional[int] = None,
            spatial_reference_id: Optional[int] = None,
            intended_time_spacing: Optional[float] = None,
            intended_time_spacing_units_id: Optional[int] = None) -> int:
    """
    Update a row in the timeseries_results table in the database
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return The number of rows updated
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    return db.update(con, 'timeseries_results', data)

@beartype.beartype
def read_timeseries_results(
            con: db.Connection,
            result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[TimeseriesResults, None, None]:
    """
    Read from the timeseries_results table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TimeseriesResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'timeseries_results', data)
    for row in result:
        yield TimeseriesResults(**row.as_dict())

@beartype.beartype
def read_timeseries_results_fuzzy(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Generator[TimeseriesResults, None, None]:
    """
    Read from the timeseries_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TimeseriesResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_fuzzy(con, 'timeseries_results', data)
    for row in result:
        yield TimeseriesResults(**row.as_dict())

@beartype.beartype
def read_timeseries_results_any(con: db.Connection, result_id: Optional[List[int]] = None,
             aggregation_statistic_cv: Optional[List[str]] = None,
             x_location: Optional[List[float]] = None,
             x_location_units_id: Optional[List[int]] = None,
             y_location: Optional[List[float]] = None,
             y_location_units_id: Optional[List[int]] = None,
             z_location: Optional[List[float]] = None,
             z_location_units_id: Optional[List[int]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             intended_time_spacing: Optional[List[float]] = None,
             intended_time_spacing_units_id: Optional[List[int]] = None) -> Generator[TimeseriesResults, None, None]:
    """
    Read from the timeseries_results table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_id 
    @param x_location 
    @param x_location_units_id 
    @param y_location 
    @param y_location_units_id 
    @param z_location 
    @param z_location_units_id 
    @param spatial_reference_id 
    @param intended_time_spacing 
    @param intended_time_spacing_units_id 
    @param aggregation_statistic_cv 
    @return generator of TimeseriesResults objects
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_any(con, 'timeseries_results', data)
    for row in result:
        yield TimeseriesResults(**row.as_dict())

@beartype.beartype
def read_timeseries_results_one_or_none(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> Optional[TimeseriesResults]:
    """
    Read from the timeseries_results table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one_or_none(con, 'timeseries_results', data)
    if result is None:
        return None
    return TimeseriesResults(**result)

@beartype.beartype
def read_timeseries_results_one(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> TimeseriesResults:
    """
    Read from the timeseries_results table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query_one(con, 'timeseries_results', data)
    return TimeseriesResults(**result)

@beartype.beartype
def read_timeseries_results_all(con: db.Connection, result_id: Optional[int] = None,
             aggregation_statistic_cv: Optional[str] = None,
             x_location: Optional[float] = None,
             x_location_units_id: Optional[int] = None,
             y_location: Optional[float] = None,
             y_location_units_id: Optional[int] = None,
             z_location: Optional[float] = None,
             z_location_units_id: Optional[int] = None,
             spatial_reference_id: Optional[int] = None,
             intended_time_spacing: Optional[float] = None,
             intended_time_spacing_units_id: Optional[int] = None) -> List[TimeseriesResults]:
    """
    Read from the timeseries_results table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_id': result_id,
        'x_location': x_location,
        'x_location_units_id': x_location_units_id,
        'y_location': y_location,
        'y_location_units_id': y_location_units_id,
        'z_location': z_location,
        'z_location_units_id': z_location_units_id,
        'spatial_reference_id': spatial_reference_id,
        'intended_time_spacing': intended_time_spacing,
        'intended_time_spacing_units_id': intended_time_spacing_units_id,
        'aggregation_statistic_cv': aggregation_statistic_cv,
    }
    result = db.query(con, 'timeseries_results', data)
    return [TimeseriesResults(**row.as_dict()) for row in result]

@beartype.beartype
def read_timeseries_results_by_id(con: db.Connection, result_id: int) -> Optional[TimeseriesResults]:
    result = db.query_one(con, 'timeseries_results', {'result_id': result_id})
    if result is None:
        return None
    return TimeseriesResults(**result)

@beartype.beartype
def delete_timeseries_results_by_id(con: db.Connection, result_id: int):
    db.delete(con, 'timeseries_results', {'result_id': result_id})
# Associate the functions with the class
TimeseriesResults.create_from_json_dict = create_timeseries_results_from_json_dict
TimeseriesResults.write = write_timeseries_results
TimeseriesResults.update = update_timeseries_results
TimeseriesResults.write_many = write_timeseries_results_many
TimeseriesResults.read = read_timeseries_results
TimeseriesResults.read_fuzzy = read_timeseries_results_fuzzy
TimeseriesResults.read_any = read_timeseries_results_any
TimeseriesResults.read_one = read_timeseries_results_one
TimeseriesResults.read_one_or_none = read_timeseries_results_one_or_none
TimeseriesResults.read_all = read_timeseries_results_all
TimeseriesResults.delete = delete_timeseries_results_by_id
TimeseriesResults.read_by_id = read_timeseries_results_by_id
TimeseriesResults.delete_by_id = delete_timeseries_results_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DatastreamProvenanceFiles:
    """
    A link between files, datastreamids and instruments

    @param datastream_provenance_file_id 
    @param datastream_id 
    @param equipment_id 
    @param file_storage_name 
    @param file_storage_path 

    This is an automatically generated class
    """
    file_storage_name: str # file_storage_name character varying (default: )
    datastream_provenance_file_id: Optional[int] = None # datastream_provenance_file_id integer (default: )
    datastream_id: Optional[int] = None # datastream_id integer (default: )
    equipment_id: Optional[int] = None # equipment_id integer (default: )
    file_storage_path: Optional[str] = None # file_storage_path character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'datastream_provenance_file_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

    @beartype.beartype
    def get_datastream(self, con: db.Connection) -> Optional['SamplingFeatureTimeseriesDatastreams']:
        return read_sampling_feature_timeseries_datastreams_one_or_none(con, datastream_id=self.datastream_id)

@beartype.beartype
def create_datastream_provenance_files_from_json_dict(json_obj: dict):
        """
        Create a DatastreamProvenanceFiles from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DatastreamProvenanceFiles(**json_obj)


@beartype.beartype
def write_datastream_provenance_files_obj(con: db.Connection, obj: DatastreamProvenanceFiles) -> int:
    """
    Write a DatastreamProvenanceFiles object to the database
    @param con: database connection
    @param obj: DatastreamProvenanceFiles object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datastream_provenance_files', dataclasses.asdict(obj))

@beartype.beartype
def write_datastream_provenance_files(
            con: db.Connection,
            file_storage_name: str,
            datastream_provenance_file_id: Optional[int] = None,
            datastream_id: Optional[int] = None,
            equipment_id: Optional[int] = None,
            file_storage_path: Optional[str] = None) -> int:
    """
    Write to the datastream_provenance_files table in the database
    @param con: database connection
    @param datastream_provenance_file_id 
    @param datastream_id 
    @param equipment_id 
    @param file_storage_name 
    @param file_storage_path 
    @return id of the inserted/updated row
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    return db.upsert(con, 'datastream_provenance_files', data)

@beartype.beartype
def write_datastream_provenance_files_many(con: db.Connection, objs: List[DatastreamProvenanceFiles], upsert: bool = False) -> int:
    """
    Write a list of DatastreamProvenanceFiles objects to the database
    @param con: database connection
    @param objs: list of DatastreamProvenanceFiles objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datastream_provenance_files', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datastream_provenance_files(con: db.Connection, datastream_provenance_file_id: int,
            file_storage_name: Optional[str] = None,
            datastream_id: Optional[int] = None,
            equipment_id: Optional[int] = None,
            file_storage_path: Optional[str] = None) -> int:
    """
    Update a row in the datastream_provenance_files table in the database
    @param con: database connection
    @param datastream_provenance_file_id 
    @param datastream_id 
    @param equipment_id 
    @param file_storage_name 
    @param file_storage_path 
    @return The number of rows updated
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    return db.update(con, 'datastream_provenance_files', data)

@beartype.beartype
def read_datastream_provenance_files(
            con: db.Connection,
            file_storage_name: Optional[str] = None,
             datastream_provenance_file_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             file_storage_path: Optional[str] = None) -> Generator[DatastreamProvenanceFiles, None, None]:
    """
    Read from the datastream_provenance_files table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_provenance_file_id 
    @param datastream_id 
    @param equipment_id 
    @param file_storage_name 
    @param file_storage_path 
    @return generator of DatastreamProvenanceFiles objects
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    result = db.query(con, 'datastream_provenance_files', data)
    for row in result:
        yield DatastreamProvenanceFiles(**row.as_dict())

@beartype.beartype
def read_datastream_provenance_files_fuzzy(con: db.Connection, file_storage_name: Optional[str] = None,
             datastream_provenance_file_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             file_storage_path: Optional[str] = None) -> Generator[DatastreamProvenanceFiles, None, None]:
    """
    Read from the datastream_provenance_files table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_provenance_file_id 
    @param datastream_id 
    @param equipment_id 
    @param file_storage_name 
    @param file_storage_path 
    @return generator of DatastreamProvenanceFiles objects
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    result = db.query_fuzzy(con, 'datastream_provenance_files', data)
    for row in result:
        yield DatastreamProvenanceFiles(**row.as_dict())

@beartype.beartype
def read_datastream_provenance_files_any(con: db.Connection, file_storage_name: Optional[List[str]] = None,
             datastream_provenance_file_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             equipment_id: Optional[List[int]] = None,
             file_storage_path: Optional[List[str]] = None) -> Generator[DatastreamProvenanceFiles, None, None]:
    """
    Read from the datastream_provenance_files table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_provenance_file_id 
    @param datastream_id 
    @param equipment_id 
    @param file_storage_name 
    @param file_storage_path 
    @return generator of DatastreamProvenanceFiles objects
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    result = db.query_any(con, 'datastream_provenance_files', data)
    for row in result:
        yield DatastreamProvenanceFiles(**row.as_dict())

@beartype.beartype
def read_datastream_provenance_files_one_or_none(con: db.Connection, file_storage_name: Optional[str] = None,
             datastream_provenance_file_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             file_storage_path: Optional[str] = None) -> Optional[DatastreamProvenanceFiles]:
    """
    Read from the datastream_provenance_files table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    result = db.query_one_or_none(con, 'datastream_provenance_files', data)
    if result is None:
        return None
    return DatastreamProvenanceFiles(**result)

@beartype.beartype
def read_datastream_provenance_files_one(con: db.Connection, file_storage_name: Optional[str] = None,
             datastream_provenance_file_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             file_storage_path: Optional[str] = None) -> DatastreamProvenanceFiles:
    """
    Read from the datastream_provenance_files table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    result = db.query_one(con, 'datastream_provenance_files', data)
    return DatastreamProvenanceFiles(**result)

@beartype.beartype
def read_datastream_provenance_files_all(con: db.Connection, file_storage_name: Optional[str] = None,
             datastream_provenance_file_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             equipment_id: Optional[int] = None,
             file_storage_path: Optional[str] = None) -> List[DatastreamProvenanceFiles]:
    """
    Read from the datastream_provenance_files table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'datastream_provenance_file_id': datastream_provenance_file_id,
        'datastream_id': datastream_id,
        'equipment_id': equipment_id,
        'file_storage_name': file_storage_name,
        'file_storage_path': file_storage_path,
    }
    result = db.query(con, 'datastream_provenance_files', data)
    return [DatastreamProvenanceFiles(**row.as_dict()) for row in result]

@beartype.beartype
def read_datastream_provenance_files_by_id(con: db.Connection, datastream_provenance_file_id: int) -> Optional[DatastreamProvenanceFiles]:
    result = db.query_one(con, 'datastream_provenance_files', {'datastream_provenance_file_id': datastream_provenance_file_id})
    if result is None:
        return None
    return DatastreamProvenanceFiles(**result)

@beartype.beartype
def delete_datastream_provenance_files_by_id(con: db.Connection, datastream_provenance_file_id: int):
    db.delete(con, 'datastream_provenance_files', {'datastream_provenance_file_id': datastream_provenance_file_id})
# Associate the functions with the class
DatastreamProvenanceFiles.create_from_json_dict = create_datastream_provenance_files_from_json_dict
DatastreamProvenanceFiles.write = write_datastream_provenance_files
DatastreamProvenanceFiles.update = update_datastream_provenance_files
DatastreamProvenanceFiles.write_many = write_datastream_provenance_files_many
DatastreamProvenanceFiles.read = read_datastream_provenance_files
DatastreamProvenanceFiles.read_fuzzy = read_datastream_provenance_files_fuzzy
DatastreamProvenanceFiles.read_any = read_datastream_provenance_files_any
DatastreamProvenanceFiles.read_one = read_datastream_provenance_files_one
DatastreamProvenanceFiles.read_one_or_none = read_datastream_provenance_files_one_or_none
DatastreamProvenanceFiles.read_all = read_datastream_provenance_files_all
DatastreamProvenanceFiles.delete = delete_datastream_provenance_files_by_id
DatastreamProvenanceFiles.read_by_id = read_datastream_provenance_files_by_id
DatastreamProvenanceFiles.delete_by_id = delete_datastream_provenance_files_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PhenocamCalculatedChannel:
    """
    A table which holds detail on calculated phenocamchannels

    @param phenocam_calculated_channel_id 
    @param phenocam_location_id 
    @param phenocam_cube_id 
    @param datastream_id 
    @param calculationarea_xcoord_top_left 
    @param calculationarea_ycoord_top_left 
    @param calculationarea_xcoord_top_right 
    @param calculationarea_ycoord_top_right 
    @param calculationarea_xcoord_bottom_right 
    @param calculationarea_ycoord_bottom_right 
    @param calculationarea_xcoord_bottom_left 
    @param calculationarea_ycoord_bottom_left 
    @param phenocam_channel 

    This is an automatically generated class
    """
    phenocam_location_id: int # phenocam_location_id bigint (default: )
    phenocam_cube_id: int # phenocam_cube_id bigint (default: )
    datastream_id: int # datastream_id integer (default: )
    calculationarea_xcoord_top_left: int # calculationarea_xcoord_top_left integer (default: )
    calculationarea_ycoord_top_left: int # calculationarea_ycoord_top_left integer (default: )
    calculationarea_xcoord_top_right: int # calculationarea_xcoord_top_right integer (default: )
    calculationarea_ycoord_top_right: int # calculationarea_ycoord_top_right integer (default: )
    calculationarea_xcoord_bottom_right: int # calculationarea_xcoord_bottom_right integer (default: )
    calculationarea_ycoord_bottom_right: int # calculationarea_ycoord_bottom_right integer (default: )
    calculationarea_xcoord_bottom_left: int # calculationarea_xcoord_bottom_left integer (default: )
    calculationarea_ycoord_bottom_left: int # calculationarea_ycoord_bottom_left integer (default: )
    phenocam_channel: str # phenocam_channel character varying (default: )
    phenocam_calculated_channel_id: Optional[int] = None # phenocam_calculated_channel_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'phenocam_calculated_channel_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_datastream(self, con: db.Connection) -> Optional['SamplingFeatureTimeseriesDatastreams']:
        return read_sampling_feature_timeseries_datastreams_one_or_none(con, datastream_id=self.datastream_id)

@beartype.beartype
def create_phenocam_calculated_channel_from_json_dict(json_obj: dict):
        """
        Create a PhenocamCalculatedChannel from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return PhenocamCalculatedChannel(**json_obj)


@beartype.beartype
def write_phenocam_calculated_channel_obj(con: db.Connection, obj: PhenocamCalculatedChannel) -> int:
    """
    Write a PhenocamCalculatedChannel object to the database
    @param con: database connection
    @param obj: PhenocamCalculatedChannel object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'phenocam_calculated_channel', dataclasses.asdict(obj))

@beartype.beartype
def write_phenocam_calculated_channel(
            con: db.Connection,
            phenocam_location_id: int,
            phenocam_cube_id: int,
            datastream_id: int,
            calculationarea_xcoord_top_left: int,
            calculationarea_ycoord_top_left: int,
            calculationarea_xcoord_top_right: int,
            calculationarea_ycoord_top_right: int,
            calculationarea_xcoord_bottom_right: int,
            calculationarea_ycoord_bottom_right: int,
            calculationarea_xcoord_bottom_left: int,
            calculationarea_ycoord_bottom_left: int,
            phenocam_channel: str,
            phenocam_calculated_channel_id: Optional[int] = None) -> int:
    """
    Write to the phenocam_calculated_channel table in the database
    @param con: database connection
    @param phenocam_calculated_channel_id 
    @param phenocam_location_id 
    @param phenocam_cube_id 
    @param datastream_id 
    @param calculationarea_xcoord_top_left 
    @param calculationarea_ycoord_top_left 
    @param calculationarea_xcoord_top_right 
    @param calculationarea_ycoord_top_right 
    @param calculationarea_xcoord_bottom_right 
    @param calculationarea_ycoord_bottom_right 
    @param calculationarea_xcoord_bottom_left 
    @param calculationarea_ycoord_bottom_left 
    @param phenocam_channel 
    @return id of the inserted/updated row
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    return db.upsert(con, 'phenocam_calculated_channel', data)

@beartype.beartype
def write_phenocam_calculated_channel_many(con: db.Connection, objs: List[PhenocamCalculatedChannel], upsert: bool = False) -> int:
    """
    Write a list of PhenocamCalculatedChannel objects to the database
    @param con: database connection
    @param objs: list of PhenocamCalculatedChannel objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'phenocam_calculated_channel', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_phenocam_calculated_channel(con: db.Connection, phenocam_calculated_channel_id: int,
            phenocam_location_id: Optional[int] = None,
            phenocam_cube_id: Optional[int] = None,
            datastream_id: Optional[int] = None,
            calculationarea_xcoord_top_left: Optional[int] = None,
            calculationarea_ycoord_top_left: Optional[int] = None,
            calculationarea_xcoord_top_right: Optional[int] = None,
            calculationarea_ycoord_top_right: Optional[int] = None,
            calculationarea_xcoord_bottom_right: Optional[int] = None,
            calculationarea_ycoord_bottom_right: Optional[int] = None,
            calculationarea_xcoord_bottom_left: Optional[int] = None,
            calculationarea_ycoord_bottom_left: Optional[int] = None,
            phenocam_channel: Optional[str] = None) -> int:
    """
    Update a row in the phenocam_calculated_channel table in the database
    @param con: database connection
    @param phenocam_calculated_channel_id 
    @param phenocam_location_id 
    @param phenocam_cube_id 
    @param datastream_id 
    @param calculationarea_xcoord_top_left 
    @param calculationarea_ycoord_top_left 
    @param calculationarea_xcoord_top_right 
    @param calculationarea_ycoord_top_right 
    @param calculationarea_xcoord_bottom_right 
    @param calculationarea_ycoord_bottom_right 
    @param calculationarea_xcoord_bottom_left 
    @param calculationarea_ycoord_bottom_left 
    @param phenocam_channel 
    @return The number of rows updated
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    return db.update(con, 'phenocam_calculated_channel', data)

@beartype.beartype
def read_phenocam_calculated_channel(
            con: db.Connection,
            phenocam_location_id: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             calculationarea_xcoord_top_left: Optional[int] = None,
             calculationarea_ycoord_top_left: Optional[int] = None,
             calculationarea_xcoord_top_right: Optional[int] = None,
             calculationarea_ycoord_top_right: Optional[int] = None,
             calculationarea_xcoord_bottom_right: Optional[int] = None,
             calculationarea_ycoord_bottom_right: Optional[int] = None,
             calculationarea_xcoord_bottom_left: Optional[int] = None,
             calculationarea_ycoord_bottom_left: Optional[int] = None,
             phenocam_channel: Optional[str] = None,
             phenocam_calculated_channel_id: Optional[int] = None) -> Generator[PhenocamCalculatedChannel, None, None]:
    """
    Read from the phenocam_calculated_channel table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_calculated_channel_id 
    @param phenocam_location_id 
    @param phenocam_cube_id 
    @param datastream_id 
    @param calculationarea_xcoord_top_left 
    @param calculationarea_ycoord_top_left 
    @param calculationarea_xcoord_top_right 
    @param calculationarea_ycoord_top_right 
    @param calculationarea_xcoord_bottom_right 
    @param calculationarea_ycoord_bottom_right 
    @param calculationarea_xcoord_bottom_left 
    @param calculationarea_ycoord_bottom_left 
    @param phenocam_channel 
    @return generator of PhenocamCalculatedChannel objects
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    result = db.query(con, 'phenocam_calculated_channel', data)
    for row in result:
        yield PhenocamCalculatedChannel(**row.as_dict())

@beartype.beartype
def read_phenocam_calculated_channel_fuzzy(con: db.Connection, phenocam_location_id: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             calculationarea_xcoord_top_left: Optional[int] = None,
             calculationarea_ycoord_top_left: Optional[int] = None,
             calculationarea_xcoord_top_right: Optional[int] = None,
             calculationarea_ycoord_top_right: Optional[int] = None,
             calculationarea_xcoord_bottom_right: Optional[int] = None,
             calculationarea_ycoord_bottom_right: Optional[int] = None,
             calculationarea_xcoord_bottom_left: Optional[int] = None,
             calculationarea_ycoord_bottom_left: Optional[int] = None,
             phenocam_channel: Optional[str] = None,
             phenocam_calculated_channel_id: Optional[int] = None) -> Generator[PhenocamCalculatedChannel, None, None]:
    """
    Read from the phenocam_calculated_channel table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_calculated_channel_id 
    @param phenocam_location_id 
    @param phenocam_cube_id 
    @param datastream_id 
    @param calculationarea_xcoord_top_left 
    @param calculationarea_ycoord_top_left 
    @param calculationarea_xcoord_top_right 
    @param calculationarea_ycoord_top_right 
    @param calculationarea_xcoord_bottom_right 
    @param calculationarea_ycoord_bottom_right 
    @param calculationarea_xcoord_bottom_left 
    @param calculationarea_ycoord_bottom_left 
    @param phenocam_channel 
    @return generator of PhenocamCalculatedChannel objects
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    result = db.query_fuzzy(con, 'phenocam_calculated_channel', data)
    for row in result:
        yield PhenocamCalculatedChannel(**row.as_dict())

@beartype.beartype
def read_phenocam_calculated_channel_any(con: db.Connection, phenocam_location_id: Optional[List[int]] = None,
             phenocam_cube_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             calculationarea_xcoord_top_left: Optional[List[int]] = None,
             calculationarea_ycoord_top_left: Optional[List[int]] = None,
             calculationarea_xcoord_top_right: Optional[List[int]] = None,
             calculationarea_ycoord_top_right: Optional[List[int]] = None,
             calculationarea_xcoord_bottom_right: Optional[List[int]] = None,
             calculationarea_ycoord_bottom_right: Optional[List[int]] = None,
             calculationarea_xcoord_bottom_left: Optional[List[int]] = None,
             calculationarea_ycoord_bottom_left: Optional[List[int]] = None,
             phenocam_channel: Optional[List[str]] = None,
             phenocam_calculated_channel_id: Optional[List[int]] = None) -> Generator[PhenocamCalculatedChannel, None, None]:
    """
    Read from the phenocam_calculated_channel table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_calculated_channel_id 
    @param phenocam_location_id 
    @param phenocam_cube_id 
    @param datastream_id 
    @param calculationarea_xcoord_top_left 
    @param calculationarea_ycoord_top_left 
    @param calculationarea_xcoord_top_right 
    @param calculationarea_ycoord_top_right 
    @param calculationarea_xcoord_bottom_right 
    @param calculationarea_ycoord_bottom_right 
    @param calculationarea_xcoord_bottom_left 
    @param calculationarea_ycoord_bottom_left 
    @param phenocam_channel 
    @return generator of PhenocamCalculatedChannel objects
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    result = db.query_any(con, 'phenocam_calculated_channel', data)
    for row in result:
        yield PhenocamCalculatedChannel(**row.as_dict())

@beartype.beartype
def read_phenocam_calculated_channel_one_or_none(con: db.Connection, phenocam_location_id: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             calculationarea_xcoord_top_left: Optional[int] = None,
             calculationarea_ycoord_top_left: Optional[int] = None,
             calculationarea_xcoord_top_right: Optional[int] = None,
             calculationarea_ycoord_top_right: Optional[int] = None,
             calculationarea_xcoord_bottom_right: Optional[int] = None,
             calculationarea_ycoord_bottom_right: Optional[int] = None,
             calculationarea_xcoord_bottom_left: Optional[int] = None,
             calculationarea_ycoord_bottom_left: Optional[int] = None,
             phenocam_channel: Optional[str] = None,
             phenocam_calculated_channel_id: Optional[int] = None) -> Optional[PhenocamCalculatedChannel]:
    """
    Read from the phenocam_calculated_channel table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    result = db.query_one_or_none(con, 'phenocam_calculated_channel', data)
    if result is None:
        return None
    return PhenocamCalculatedChannel(**result)

@beartype.beartype
def read_phenocam_calculated_channel_one(con: db.Connection, phenocam_location_id: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             calculationarea_xcoord_top_left: Optional[int] = None,
             calculationarea_ycoord_top_left: Optional[int] = None,
             calculationarea_xcoord_top_right: Optional[int] = None,
             calculationarea_ycoord_top_right: Optional[int] = None,
             calculationarea_xcoord_bottom_right: Optional[int] = None,
             calculationarea_ycoord_bottom_right: Optional[int] = None,
             calculationarea_xcoord_bottom_left: Optional[int] = None,
             calculationarea_ycoord_bottom_left: Optional[int] = None,
             phenocam_channel: Optional[str] = None,
             phenocam_calculated_channel_id: Optional[int] = None) -> PhenocamCalculatedChannel:
    """
    Read from the phenocam_calculated_channel table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    result = db.query_one(con, 'phenocam_calculated_channel', data)
    return PhenocamCalculatedChannel(**result)

@beartype.beartype
def read_phenocam_calculated_channel_all(con: db.Connection, phenocam_location_id: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             calculationarea_xcoord_top_left: Optional[int] = None,
             calculationarea_ycoord_top_left: Optional[int] = None,
             calculationarea_xcoord_top_right: Optional[int] = None,
             calculationarea_ycoord_top_right: Optional[int] = None,
             calculationarea_xcoord_bottom_right: Optional[int] = None,
             calculationarea_ycoord_bottom_right: Optional[int] = None,
             calculationarea_xcoord_bottom_left: Optional[int] = None,
             calculationarea_ycoord_bottom_left: Optional[int] = None,
             phenocam_channel: Optional[str] = None,
             phenocam_calculated_channel_id: Optional[int] = None) -> List[PhenocamCalculatedChannel]:
    """
    Read from the phenocam_calculated_channel table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'phenocam_calculated_channel_id': phenocam_calculated_channel_id,
        'phenocam_location_id': phenocam_location_id,
        'phenocam_cube_id': phenocam_cube_id,
        'datastream_id': datastream_id,
        'calculationarea_xcoord_top_left': calculationarea_xcoord_top_left,
        'calculationarea_ycoord_top_left': calculationarea_ycoord_top_left,
        'calculationarea_xcoord_top_right': calculationarea_xcoord_top_right,
        'calculationarea_ycoord_top_right': calculationarea_ycoord_top_right,
        'calculationarea_xcoord_bottom_right': calculationarea_xcoord_bottom_right,
        'calculationarea_ycoord_bottom_right': calculationarea_ycoord_bottom_right,
        'calculationarea_xcoord_bottom_left': calculationarea_xcoord_bottom_left,
        'calculationarea_ycoord_bottom_left': calculationarea_ycoord_bottom_left,
        'phenocam_channel': phenocam_channel,
    }
    result = db.query(con, 'phenocam_calculated_channel', data)
    return [PhenocamCalculatedChannel(**row.as_dict()) for row in result]

@beartype.beartype
def read_phenocam_calculated_channel_by_id(con: db.Connection, phenocam_calculated_channel_id: int) -> Optional[PhenocamCalculatedChannel]:
    result = db.query_one(con, 'phenocam_calculated_channel', {'phenocam_calculated_channel_id': phenocam_calculated_channel_id})
    if result is None:
        return None
    return PhenocamCalculatedChannel(**result)

@beartype.beartype
def delete_phenocam_calculated_channel_by_id(con: db.Connection, phenocam_calculated_channel_id: int):
    db.delete(con, 'phenocam_calculated_channel', {'phenocam_calculated_channel_id': phenocam_calculated_channel_id})
# Associate the functions with the class
PhenocamCalculatedChannel.create_from_json_dict = create_phenocam_calculated_channel_from_json_dict
PhenocamCalculatedChannel.write = write_phenocam_calculated_channel
PhenocamCalculatedChannel.update = update_phenocam_calculated_channel
PhenocamCalculatedChannel.write_many = write_phenocam_calculated_channel_many
PhenocamCalculatedChannel.read = read_phenocam_calculated_channel
PhenocamCalculatedChannel.read_fuzzy = read_phenocam_calculated_channel_fuzzy
PhenocamCalculatedChannel.read_any = read_phenocam_calculated_channel_any
PhenocamCalculatedChannel.read_one = read_phenocam_calculated_channel_one
PhenocamCalculatedChannel.read_one_or_none = read_phenocam_calculated_channel_one_or_none
PhenocamCalculatedChannel.read_all = read_phenocam_calculated_channel_all
PhenocamCalculatedChannel.delete = delete_phenocam_calculated_channel_by_id
PhenocamCalculatedChannel.read_by_id = read_phenocam_calculated_channel_by_id
PhenocamCalculatedChannel.delete_by_id = delete_phenocam_calculated_channel_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PhenocamImgs:
    """
    @param phenocam_image_id 
    @param phenocam_dataset_id 
    @param phenocam_equipment_id 
    @param phenocam_image_name 
    @param observation_time_utc 
    @param google_drive_id 
    @param image_width 
    @param image_height 
    @param image_rotation 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param flag 

    This is an automatically generated class
    """
    phenocam_dataset_id: int # phenocam_dataset_id integer (default: )
    google_drive_id: str # google_drive_id character varying (default: )
    image_width: int # image_width integer (default: )
    image_height: int # image_height integer (default: )
    phenocam_image_id: Optional[int] = None # phenocam_image_id bigint (default: )
    phenocam_equipment_id: Optional[int] = None # phenocam_equipment_id integer (default: )
    phenocam_image_name: Optional[str] = None # phenocam_image_name character varying (default: )
    observation_time_utc: Optional[datetime.datetime] = None # observation_time_utc timestamp without time zone (default: )
    image_rotation: Optional[float] = None # image_rotation double precision (default: )
    exposure_time: Optional[float] = None # exposure_time double precision (default: )
    aperture: Optional[float] = None # aperture double precision (default: )
    flash_used: Optional[bool] = None # flash_used boolean (default: )
    focal_length: Optional[float] = None # focal_length double precision (default: )
    iso_speed: Optional[int] = None # iso_speed integer (default: )
    metering_mode: Optional[str] = None # metering_mode character varying (default: )
    sensor: Optional[str] = None # sensor character varying (default: )
    exposure_mode: Optional[str] = None # exposure_mode character varying (default: )
    color_space: Optional[str] = None # color_space character varying (default: )
    white_balance: Optional[str] = None # white_balance character varying (default: )
    exposure_bias: Optional[float] = None # exposure_bias double precision (default: )
    max_aperture_value: Optional[float] = None # max_aperture_value double precision (default: )
    flag: Optional[str] = None # flag character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'phenocam_image_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.observation_time_utc is not None:
            obj['observation_time_utc'] = self.observation_time_utc.isoformat()
        return obj

    @beartype.beartype
    def get_phenocam_dataset(self, con: db.Connection) -> Optional['PhenocamData']:
        return read_phenocam_data_one_or_none(con, phenocam_dataset_id=self.phenocam_dataset_id)

@beartype.beartype
def create_phenocam_imgs_from_json_dict(json_obj: dict):
        """
        Create a PhenocamImgs from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'observation_time_utc' in json_obj and json_obj['observation_time_utc'] is not None:
            json_obj['observation_time_utc'] = datetime.datetime.fromisoformat(json_obj['observation_time_utc'])
        return PhenocamImgs(**json_obj)


@beartype.beartype
def write_phenocam_imgs_obj(con: db.Connection, obj: PhenocamImgs) -> int:
    """
    Write a PhenocamImgs object to the database
    @param con: database connection
    @param obj: PhenocamImgs object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'phenocam_imgs', dataclasses.asdict(obj))

@beartype.beartype
def write_phenocam_imgs(
            con: db.Connection,
            phenocam_dataset_id: int,
            google_drive_id: str,
            image_width: int,
            image_height: int,
            phenocam_image_id: Optional[int] = None,
            phenocam_equipment_id: Optional[int] = None,
            phenocam_image_name: Optional[str] = None,
            observation_time_utc: Optional[datetime.datetime] = None,
            image_rotation: Optional[float] = None,
            exposure_time: Optional[float] = None,
            aperture: Optional[float] = None,
            flash_used: Optional[bool] = None,
            focal_length: Optional[float] = None,
            iso_speed: Optional[int] = None,
            metering_mode: Optional[str] = None,
            sensor: Optional[str] = None,
            exposure_mode: Optional[str] = None,
            color_space: Optional[str] = None,
            white_balance: Optional[str] = None,
            exposure_bias: Optional[float] = None,
            max_aperture_value: Optional[float] = None,
            flag: Optional[str] = None) -> int:
    """
    Write to the phenocam_imgs table in the database
    @param con: database connection
    @param phenocam_image_id 
    @param phenocam_dataset_id 
    @param phenocam_equipment_id 
    @param phenocam_image_name 
    @param observation_time_utc 
    @param google_drive_id 
    @param image_width 
    @param image_height 
    @param image_rotation 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param flag 
    @return id of the inserted/updated row
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    return db.upsert(con, 'phenocam_imgs', data)

@beartype.beartype
def write_phenocam_imgs_many(con: db.Connection, objs: List[PhenocamImgs], upsert: bool = False) -> int:
    """
    Write a list of PhenocamImgs objects to the database
    @param con: database connection
    @param objs: list of PhenocamImgs objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'phenocam_imgs', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_phenocam_imgs(con: db.Connection, phenocam_image_id: int,
            phenocam_dataset_id: Optional[int] = None,
            google_drive_id: Optional[str] = None,
            image_width: Optional[int] = None,
            image_height: Optional[int] = None,
            phenocam_equipment_id: Optional[int] = None,
            phenocam_image_name: Optional[str] = None,
            observation_time_utc: Optional[datetime.datetime] = None,
            image_rotation: Optional[float] = None,
            exposure_time: Optional[float] = None,
            aperture: Optional[float] = None,
            flash_used: Optional[bool] = None,
            focal_length: Optional[float] = None,
            iso_speed: Optional[int] = None,
            metering_mode: Optional[str] = None,
            sensor: Optional[str] = None,
            exposure_mode: Optional[str] = None,
            color_space: Optional[str] = None,
            white_balance: Optional[str] = None,
            exposure_bias: Optional[float] = None,
            max_aperture_value: Optional[float] = None,
            flag: Optional[str] = None) -> int:
    """
    Update a row in the phenocam_imgs table in the database
    @param con: database connection
    @param phenocam_image_id 
    @param phenocam_dataset_id 
    @param phenocam_equipment_id 
    @param phenocam_image_name 
    @param observation_time_utc 
    @param google_drive_id 
    @param image_width 
    @param image_height 
    @param image_rotation 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param flag 
    @return The number of rows updated
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    return db.update(con, 'phenocam_imgs', data)

@beartype.beartype
def read_phenocam_imgs(
            con: db.Connection,
            phenocam_dataset_id: Optional[int] = None,
             google_drive_id: Optional[str] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             phenocam_image_id: Optional[int] = None,
             phenocam_equipment_id: Optional[int] = None,
             phenocam_image_name: Optional[str] = None,
             observation_time_utc: Optional[datetime.datetime] = None,
             image_rotation: Optional[float] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             flag: Optional[str] = None) -> Generator[PhenocamImgs, None, None]:
    """
    Read from the phenocam_imgs table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_image_id 
    @param phenocam_dataset_id 
    @param phenocam_equipment_id 
    @param phenocam_image_name 
    @param observation_time_utc 
    @param google_drive_id 
    @param image_width 
    @param image_height 
    @param image_rotation 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param flag 
    @return generator of PhenocamImgs objects
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    result = db.query(con, 'phenocam_imgs', data)
    for row in result:
        yield PhenocamImgs(**row.as_dict())

@beartype.beartype
def read_phenocam_imgs_fuzzy(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             google_drive_id: Optional[str] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             phenocam_image_id: Optional[int] = None,
             phenocam_equipment_id: Optional[int] = None,
             phenocam_image_name: Optional[str] = None,
             observation_time_utc: Optional[datetime.datetime] = None,
             image_rotation: Optional[float] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             flag: Optional[str] = None) -> Generator[PhenocamImgs, None, None]:
    """
    Read from the phenocam_imgs table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_image_id 
    @param phenocam_dataset_id 
    @param phenocam_equipment_id 
    @param phenocam_image_name 
    @param observation_time_utc 
    @param google_drive_id 
    @param image_width 
    @param image_height 
    @param image_rotation 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param flag 
    @return generator of PhenocamImgs objects
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    result = db.query_fuzzy(con, 'phenocam_imgs', data)
    for row in result:
        yield PhenocamImgs(**row.as_dict())

@beartype.beartype
def read_phenocam_imgs_any(con: db.Connection, phenocam_dataset_id: Optional[List[int]] = None,
             google_drive_id: Optional[List[str]] = None,
             image_width: Optional[List[int]] = None,
             image_height: Optional[List[int]] = None,
             phenocam_image_id: Optional[List[int]] = None,
             phenocam_equipment_id: Optional[List[int]] = None,
             phenocam_image_name: Optional[List[str]] = None,
             observation_time_utc: Optional[List[datetime.datetime]] = None,
             image_rotation: Optional[List[float]] = None,
             exposure_time: Optional[List[float]] = None,
             aperture: Optional[List[float]] = None,
             flash_used: Optional[List[bool]] = None,
             focal_length: Optional[List[float]] = None,
             iso_speed: Optional[List[int]] = None,
             metering_mode: Optional[List[str]] = None,
             sensor: Optional[List[str]] = None,
             exposure_mode: Optional[List[str]] = None,
             color_space: Optional[List[str]] = None,
             white_balance: Optional[List[str]] = None,
             exposure_bias: Optional[List[float]] = None,
             max_aperture_value: Optional[List[float]] = None,
             flag: Optional[List[str]] = None) -> Generator[PhenocamImgs, None, None]:
    """
    Read from the phenocam_imgs table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_image_id 
    @param phenocam_dataset_id 
    @param phenocam_equipment_id 
    @param phenocam_image_name 
    @param observation_time_utc 
    @param google_drive_id 
    @param image_width 
    @param image_height 
    @param image_rotation 
    @param exposure_time 
    @param aperture 
    @param flash_used 
    @param focal_length 
    @param iso_speed 
    @param metering_mode 
    @param sensor 
    @param exposure_mode 
    @param color_space 
    @param white_balance 
    @param exposure_bias 
    @param max_aperture_value 
    @param flag 
    @return generator of PhenocamImgs objects
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    result = db.query_any(con, 'phenocam_imgs', data)
    for row in result:
        yield PhenocamImgs(**row.as_dict())

@beartype.beartype
def read_phenocam_imgs_one_or_none(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             google_drive_id: Optional[str] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             phenocam_image_id: Optional[int] = None,
             phenocam_equipment_id: Optional[int] = None,
             phenocam_image_name: Optional[str] = None,
             observation_time_utc: Optional[datetime.datetime] = None,
             image_rotation: Optional[float] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             flag: Optional[str] = None) -> Optional[PhenocamImgs]:
    """
    Read from the phenocam_imgs table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    result = db.query_one_or_none(con, 'phenocam_imgs', data)
    if result is None:
        return None
    return PhenocamImgs(**result)

@beartype.beartype
def read_phenocam_imgs_one(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             google_drive_id: Optional[str] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             phenocam_image_id: Optional[int] = None,
             phenocam_equipment_id: Optional[int] = None,
             phenocam_image_name: Optional[str] = None,
             observation_time_utc: Optional[datetime.datetime] = None,
             image_rotation: Optional[float] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             flag: Optional[str] = None) -> PhenocamImgs:
    """
    Read from the phenocam_imgs table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    result = db.query_one(con, 'phenocam_imgs', data)
    return PhenocamImgs(**result)

@beartype.beartype
def read_phenocam_imgs_all(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             google_drive_id: Optional[str] = None,
             image_width: Optional[int] = None,
             image_height: Optional[int] = None,
             phenocam_image_id: Optional[int] = None,
             phenocam_equipment_id: Optional[int] = None,
             phenocam_image_name: Optional[str] = None,
             observation_time_utc: Optional[datetime.datetime] = None,
             image_rotation: Optional[float] = None,
             exposure_time: Optional[float] = None,
             aperture: Optional[float] = None,
             flash_used: Optional[bool] = None,
             focal_length: Optional[float] = None,
             iso_speed: Optional[int] = None,
             metering_mode: Optional[str] = None,
             sensor: Optional[str] = None,
             exposure_mode: Optional[str] = None,
             color_space: Optional[str] = None,
             white_balance: Optional[str] = None,
             exposure_bias: Optional[float] = None,
             max_aperture_value: Optional[float] = None,
             flag: Optional[str] = None) -> List[PhenocamImgs]:
    """
    Read from the phenocam_imgs table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'phenocam_image_id': phenocam_image_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'phenocam_equipment_id': phenocam_equipment_id,
        'phenocam_image_name': phenocam_image_name,
        'observation_time_utc': observation_time_utc,
        'google_drive_id': google_drive_id,
        'image_width': image_width,
        'image_height': image_height,
        'image_rotation': image_rotation,
        'exposure_time': exposure_time,
        'aperture': aperture,
        'flash_used': flash_used,
        'focal_length': focal_length,
        'iso_speed': iso_speed,
        'metering_mode': metering_mode,
        'sensor': sensor,
        'exposure_mode': exposure_mode,
        'color_space': color_space,
        'white_balance': white_balance,
        'exposure_bias': exposure_bias,
        'max_aperture_value': max_aperture_value,
        'flag': flag,
    }
    result = db.query(con, 'phenocam_imgs', data)
    return [PhenocamImgs(**row.as_dict()) for row in result]

@beartype.beartype
def read_phenocam_imgs_by_id(con: db.Connection, phenocam_image_id: int) -> Optional[PhenocamImgs]:
    result = db.query_one(con, 'phenocam_imgs', {'phenocam_image_id': phenocam_image_id})
    if result is None:
        return None
    return PhenocamImgs(**result)

@beartype.beartype
def delete_phenocam_imgs_by_id(con: db.Connection, phenocam_image_id: int):
    db.delete(con, 'phenocam_imgs', {'phenocam_image_id': phenocam_image_id})
# Associate the functions with the class
PhenocamImgs.create_from_json_dict = create_phenocam_imgs_from_json_dict
PhenocamImgs.write = write_phenocam_imgs
PhenocamImgs.update = update_phenocam_imgs
PhenocamImgs.write_many = write_phenocam_imgs_many
PhenocamImgs.read = read_phenocam_imgs
PhenocamImgs.read_fuzzy = read_phenocam_imgs_fuzzy
PhenocamImgs.read_any = read_phenocam_imgs_any
PhenocamImgs.read_one = read_phenocam_imgs_one
PhenocamImgs.read_one_or_none = read_phenocam_imgs_one_or_none
PhenocamImgs.read_all = read_phenocam_imgs_all
PhenocamImgs.delete = delete_phenocam_imgs_by_id
PhenocamImgs.read_by_id = read_phenocam_imgs_by_id
PhenocamImgs.delete_by_id = delete_phenocam_imgs_by_id



@beartype_wrap_init
@dataclasses.dataclass
class QaqcLog:
    """
    This table holds a log of qaqc issues. It is used for logging when things happen, and can be used in the alert architecture

    @param qaqc_log_id 
    @param datastream_id 
    @param utc_time_start 
    @param utc_time_end 
    @param utc_time_entry 
    @param qa_flag 

    This is an automatically generated class
    """
    qaqc_log_id: int # qaqc_log_id integer (default: )
    datastream_id: int # datastream_id integer (default: )
    utc_time_start: int # utc_time_start bigint (default: )
    utc_time_end: int # utc_time_end bigint (default: )
    utc_time_entry: int # utc_time_entry bigint (default: )
    qa_flag: str # qa_flag character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'qaqc_log_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_qaqc_log_from_json_dict(json_obj: dict):
        """
        Create a QaqcLog from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return QaqcLog(**json_obj)


@beartype.beartype
def write_qaqc_log_obj(con: db.Connection, obj: QaqcLog) -> int:
    """
    Write a QaqcLog object to the database
    @param con: database connection
    @param obj: QaqcLog object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'qaqc_log', dataclasses.asdict(obj))

@beartype.beartype
def write_qaqc_log(
            con: db.Connection,
            qaqc_log_id: int,
            datastream_id: int,
            utc_time_start: int,
            utc_time_end: int,
            utc_time_entry: int,
            qa_flag: str) -> int:
    """
    Write to the qaqc_log table in the database
    @param con: database connection
    @param qaqc_log_id 
    @param datastream_id 
    @param utc_time_start 
    @param utc_time_end 
    @param utc_time_entry 
    @param qa_flag 
    @return id of the inserted/updated row
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    return db.upsert(con, 'qaqc_log', data)

@beartype.beartype
def write_qaqc_log_many(con: db.Connection, objs: List[QaqcLog], upsert: bool = False) -> int:
    """
    Write a list of QaqcLog objects to the database
    @param con: database connection
    @param objs: list of QaqcLog objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'qaqc_log', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_qaqc_log(con: db.Connection, qaqc_log_id: int,
            datastream_id: Optional[int] = None,
            utc_time_start: Optional[int] = None,
            utc_time_end: Optional[int] = None,
            utc_time_entry: Optional[int] = None,
            qa_flag: Optional[str] = None) -> int:
    """
    Update a row in the qaqc_log table in the database
    @param con: database connection
    @param qaqc_log_id 
    @param datastream_id 
    @param utc_time_start 
    @param utc_time_end 
    @param utc_time_entry 
    @param qa_flag 
    @return The number of rows updated
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    return db.update(con, 'qaqc_log', data)

@beartype.beartype
def read_qaqc_log(
            con: db.Connection,
            qaqc_log_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             utc_time_start: Optional[int] = None,
             utc_time_end: Optional[int] = None,
             utc_time_entry: Optional[int] = None,
             qa_flag: Optional[str] = None) -> Generator[QaqcLog, None, None]:
    """
    Read from the qaqc_log table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qaqc_log_id 
    @param datastream_id 
    @param utc_time_start 
    @param utc_time_end 
    @param utc_time_entry 
    @param qa_flag 
    @return generator of QaqcLog objects
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    result = db.query(con, 'qaqc_log', data)
    for row in result:
        yield QaqcLog(**row.as_dict())

@beartype.beartype
def read_qaqc_log_fuzzy(con: db.Connection, qaqc_log_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             utc_time_start: Optional[int] = None,
             utc_time_end: Optional[int] = None,
             utc_time_entry: Optional[int] = None,
             qa_flag: Optional[str] = None) -> Generator[QaqcLog, None, None]:
    """
    Read from the qaqc_log table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qaqc_log_id 
    @param datastream_id 
    @param utc_time_start 
    @param utc_time_end 
    @param utc_time_entry 
    @param qa_flag 
    @return generator of QaqcLog objects
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    result = db.query_fuzzy(con, 'qaqc_log', data)
    for row in result:
        yield QaqcLog(**row.as_dict())

@beartype.beartype
def read_qaqc_log_any(con: db.Connection, qaqc_log_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             utc_time_start: Optional[List[int]] = None,
             utc_time_end: Optional[List[int]] = None,
             utc_time_entry: Optional[List[int]] = None,
             qa_flag: Optional[List[str]] = None) -> Generator[QaqcLog, None, None]:
    """
    Read from the qaqc_log table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qaqc_log_id 
    @param datastream_id 
    @param utc_time_start 
    @param utc_time_end 
    @param utc_time_entry 
    @param qa_flag 
    @return generator of QaqcLog objects
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    result = db.query_any(con, 'qaqc_log', data)
    for row in result:
        yield QaqcLog(**row.as_dict())

@beartype.beartype
def read_qaqc_log_one_or_none(con: db.Connection, qaqc_log_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             utc_time_start: Optional[int] = None,
             utc_time_end: Optional[int] = None,
             utc_time_entry: Optional[int] = None,
             qa_flag: Optional[str] = None) -> Optional[QaqcLog]:
    """
    Read from the qaqc_log table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    result = db.query_one_or_none(con, 'qaqc_log', data)
    if result is None:
        return None
    return QaqcLog(**result)

@beartype.beartype
def read_qaqc_log_one(con: db.Connection, qaqc_log_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             utc_time_start: Optional[int] = None,
             utc_time_end: Optional[int] = None,
             utc_time_entry: Optional[int] = None,
             qa_flag: Optional[str] = None) -> QaqcLog:
    """
    Read from the qaqc_log table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    result = db.query_one(con, 'qaqc_log', data)
    return QaqcLog(**result)

@beartype.beartype
def read_qaqc_log_all(con: db.Connection, qaqc_log_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             utc_time_start: Optional[int] = None,
             utc_time_end: Optional[int] = None,
             utc_time_entry: Optional[int] = None,
             qa_flag: Optional[str] = None) -> List[QaqcLog]:
    """
    Read from the qaqc_log table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'qaqc_log_id': qaqc_log_id,
        'datastream_id': datastream_id,
        'utc_time_start': utc_time_start,
        'utc_time_end': utc_time_end,
        'utc_time_entry': utc_time_entry,
        'qa_flag': qa_flag,
    }
    result = db.query(con, 'qaqc_log', data)
    return [QaqcLog(**row.as_dict()) for row in result]

@beartype.beartype
def read_qaqc_log_by_id(con: db.Connection, qaqc_log_id: int) -> Optional[QaqcLog]:
    result = db.query_one(con, 'qaqc_log', {'qaqc_log_id': qaqc_log_id})
    if result is None:
        return None
    return QaqcLog(**result)

@beartype.beartype
def delete_qaqc_log_by_id(con: db.Connection, qaqc_log_id: int):
    db.delete(con, 'qaqc_log', {'qaqc_log_id': qaqc_log_id})
# Associate the functions with the class
QaqcLog.create_from_json_dict = create_qaqc_log_from_json_dict
QaqcLog.write = write_qaqc_log
QaqcLog.update = update_qaqc_log
QaqcLog.write_many = write_qaqc_log_many
QaqcLog.read = read_qaqc_log
QaqcLog.read_fuzzy = read_qaqc_log_fuzzy
QaqcLog.read_any = read_qaqc_log_any
QaqcLog.read_one = read_qaqc_log_one
QaqcLog.read_one_or_none = read_qaqc_log_one_or_none
QaqcLog.read_all = read_qaqc_log_all
QaqcLog.delete = delete_qaqc_log_by_id
QaqcLog.read_by_id = read_qaqc_log_by_id
QaqcLog.delete_by_id = delete_qaqc_log_by_id



@beartype_wrap_init
@dataclasses.dataclass
class QaqcDetail:
    """
    A table which provides for a free form entry of the QAQC Detail which can be used for reportin

    @param qaq_detail_log_id 
    @param qaqc_log_id 
    @param qaqc_detail 

    This is an automatically generated class
    """
    qaqc_log_id: int # qaqc_log_id integer (default: )
    qaqc_detail: str # qaqc_detail character varying (default: )
    qaq_detail_log_id: Optional[int] = None # qaq_detail_log_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'qaq_detail_log_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_qaqc_log(self, con: db.Connection) -> Optional['QaqcLog']:
        return read_qaqc_log_one_or_none(con, qaqc_log_id=self.qaqc_log_id)

@beartype.beartype
def create_qaqc_detail_from_json_dict(json_obj: dict):
        """
        Create a QaqcDetail from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return QaqcDetail(**json_obj)


@beartype.beartype
def write_qaqc_detail_obj(con: db.Connection, obj: QaqcDetail) -> int:
    """
    Write a QaqcDetail object to the database
    @param con: database connection
    @param obj: QaqcDetail object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'qaqc_detail', dataclasses.asdict(obj))

@beartype.beartype
def write_qaqc_detail(
            con: db.Connection,
            qaqc_log_id: int,
            qaqc_detail: str,
            qaq_detail_log_id: Optional[int] = None) -> int:
    """
    Write to the qaqc_detail table in the database
    @param con: database connection
    @param qaq_detail_log_id 
    @param qaqc_log_id 
    @param qaqc_detail 
    @return id of the inserted/updated row
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    return db.upsert(con, 'qaqc_detail', data)

@beartype.beartype
def write_qaqc_detail_many(con: db.Connection, objs: List[QaqcDetail], upsert: bool = False) -> int:
    """
    Write a list of QaqcDetail objects to the database
    @param con: database connection
    @param objs: list of QaqcDetail objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'qaqc_detail', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_qaqc_detail(con: db.Connection, qaq_detail_log_id: int,
            qaqc_log_id: Optional[int] = None,
            qaqc_detail: Optional[str] = None) -> int:
    """
    Update a row in the qaqc_detail table in the database
    @param con: database connection
    @param qaq_detail_log_id 
    @param qaqc_log_id 
    @param qaqc_detail 
    @return The number of rows updated
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    return db.update(con, 'qaqc_detail', data)

@beartype.beartype
def read_qaqc_detail(
            con: db.Connection,
            qaqc_log_id: Optional[int] = None,
             qaqc_detail: Optional[str] = None,
             qaq_detail_log_id: Optional[int] = None) -> Generator[QaqcDetail, None, None]:
    """
    Read from the qaqc_detail table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qaq_detail_log_id 
    @param qaqc_log_id 
    @param qaqc_detail 
    @return generator of QaqcDetail objects
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    result = db.query(con, 'qaqc_detail', data)
    for row in result:
        yield QaqcDetail(**row.as_dict())

@beartype.beartype
def read_qaqc_detail_fuzzy(con: db.Connection, qaqc_log_id: Optional[int] = None,
             qaqc_detail: Optional[str] = None,
             qaq_detail_log_id: Optional[int] = None) -> Generator[QaqcDetail, None, None]:
    """
    Read from the qaqc_detail table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qaq_detail_log_id 
    @param qaqc_log_id 
    @param qaqc_detail 
    @return generator of QaqcDetail objects
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    result = db.query_fuzzy(con, 'qaqc_detail', data)
    for row in result:
        yield QaqcDetail(**row.as_dict())

@beartype.beartype
def read_qaqc_detail_any(con: db.Connection, qaqc_log_id: Optional[List[int]] = None,
             qaqc_detail: Optional[List[str]] = None,
             qaq_detail_log_id: Optional[List[int]] = None) -> Generator[QaqcDetail, None, None]:
    """
    Read from the qaqc_detail table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param qaq_detail_log_id 
    @param qaqc_log_id 
    @param qaqc_detail 
    @return generator of QaqcDetail objects
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    result = db.query_any(con, 'qaqc_detail', data)
    for row in result:
        yield QaqcDetail(**row.as_dict())

@beartype.beartype
def read_qaqc_detail_one_or_none(con: db.Connection, qaqc_log_id: Optional[int] = None,
             qaqc_detail: Optional[str] = None,
             qaq_detail_log_id: Optional[int] = None) -> Optional[QaqcDetail]:
    """
    Read from the qaqc_detail table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    result = db.query_one_or_none(con, 'qaqc_detail', data)
    if result is None:
        return None
    return QaqcDetail(**result)

@beartype.beartype
def read_qaqc_detail_one(con: db.Connection, qaqc_log_id: Optional[int] = None,
             qaqc_detail: Optional[str] = None,
             qaq_detail_log_id: Optional[int] = None) -> QaqcDetail:
    """
    Read from the qaqc_detail table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    result = db.query_one(con, 'qaqc_detail', data)
    return QaqcDetail(**result)

@beartype.beartype
def read_qaqc_detail_all(con: db.Connection, qaqc_log_id: Optional[int] = None,
             qaqc_detail: Optional[str] = None,
             qaq_detail_log_id: Optional[int] = None) -> List[QaqcDetail]:
    """
    Read from the qaqc_detail table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'qaq_detail_log_id': qaq_detail_log_id,
        'qaqc_log_id': qaqc_log_id,
        'qaqc_detail': qaqc_detail,
    }
    result = db.query(con, 'qaqc_detail', data)
    return [QaqcDetail(**row.as_dict()) for row in result]

@beartype.beartype
def read_qaqc_detail_by_id(con: db.Connection, qaq_detail_log_id: int) -> Optional[QaqcDetail]:
    result = db.query_one(con, 'qaqc_detail', {'qaq_detail_log_id': qaq_detail_log_id})
    if result is None:
        return None
    return QaqcDetail(**result)

@beartype.beartype
def delete_qaqc_detail_by_id(con: db.Connection, qaq_detail_log_id: int):
    db.delete(con, 'qaqc_detail', {'qaq_detail_log_id': qaq_detail_log_id})
# Associate the functions with the class
QaqcDetail.create_from_json_dict = create_qaqc_detail_from_json_dict
QaqcDetail.write = write_qaqc_detail
QaqcDetail.update = update_qaqc_detail
QaqcDetail.write_many = write_qaqc_detail_many
QaqcDetail.read = read_qaqc_detail
QaqcDetail.read_fuzzy = read_qaqc_detail_fuzzy
QaqcDetail.read_any = read_qaqc_detail_any
QaqcDetail.read_one = read_qaqc_detail_one
QaqcDetail.read_one_or_none = read_qaqc_detail_one_or_none
QaqcDetail.read_all = read_qaqc_detail_all
QaqcDetail.delete = delete_qaqc_detail_by_id
QaqcDetail.read_by_id = read_qaqc_detail_by_id
QaqcDetail.delete_by_id = delete_qaqc_detail_by_id



@beartype_wrap_init
@dataclasses.dataclass
class VariableQaMinMax:
    """
    This table has the min and max values used for the QA/QC effort

    @param variable_qa_min_max_id 
    @param variable_id 
    @param variable_term 
    @param min_valid_range 
    @param max_valid_range 

    This is an automatically generated class
    """
    variable_id: int # variable_id integer (default: )
    variable_term: str # variable_term character varying (default: )
    min_valid_range: float # min_valid_range double precision (default: )
    max_valid_range: float # max_valid_range double precision (default: )
    variable_qa_min_max_id: Optional[int] = None # variable_qa_min_max_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'variable_qa_min_max_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_variable_qa_min_max_from_json_dict(json_obj: dict):
        """
        Create a VariableQaMinMax from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return VariableQaMinMax(**json_obj)


@beartype.beartype
def write_variable_qa_min_max_obj(con: db.Connection, obj: VariableQaMinMax) -> int:
    """
    Write a VariableQaMinMax object to the database
    @param con: database connection
    @param obj: VariableQaMinMax object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'variable_qa_min_max', dataclasses.asdict(obj))

@beartype.beartype
def write_variable_qa_min_max(
            con: db.Connection,
            variable_id: int,
            variable_term: str,
            min_valid_range: float,
            max_valid_range: float,
            variable_qa_min_max_id: Optional[int] = None) -> int:
    """
    Write to the variable_qa_min_max table in the database
    @param con: database connection
    @param variable_qa_min_max_id 
    @param variable_id 
    @param variable_term 
    @param min_valid_range 
    @param max_valid_range 
    @return id of the inserted/updated row
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    return db.upsert(con, 'variable_qa_min_max', data)

@beartype.beartype
def write_variable_qa_min_max_many(con: db.Connection, objs: List[VariableQaMinMax], upsert: bool = False) -> int:
    """
    Write a list of VariableQaMinMax objects to the database
    @param con: database connection
    @param objs: list of VariableQaMinMax objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'variable_qa_min_max', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_variable_qa_min_max(con: db.Connection, variable_qa_min_max_id: int,
            variable_id: Optional[int] = None,
            variable_term: Optional[str] = None,
            min_valid_range: Optional[float] = None,
            max_valid_range: Optional[float] = None) -> int:
    """
    Update a row in the variable_qa_min_max table in the database
    @param con: database connection
    @param variable_qa_min_max_id 
    @param variable_id 
    @param variable_term 
    @param min_valid_range 
    @param max_valid_range 
    @return The number of rows updated
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    return db.update(con, 'variable_qa_min_max', data)

@beartype.beartype
def read_variable_qa_min_max(
            con: db.Connection,
            variable_id: Optional[int] = None,
             variable_term: Optional[str] = None,
             min_valid_range: Optional[float] = None,
             max_valid_range: Optional[float] = None,
             variable_qa_min_max_id: Optional[int] = None) -> Generator[VariableQaMinMax, None, None]:
    """
    Read from the variable_qa_min_max table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_qa_min_max_id 
    @param variable_id 
    @param variable_term 
    @param min_valid_range 
    @param max_valid_range 
    @return generator of VariableQaMinMax objects
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    result = db.query(con, 'variable_qa_min_max', data)
    for row in result:
        yield VariableQaMinMax(**row.as_dict())

@beartype.beartype
def read_variable_qa_min_max_fuzzy(con: db.Connection, variable_id: Optional[int] = None,
             variable_term: Optional[str] = None,
             min_valid_range: Optional[float] = None,
             max_valid_range: Optional[float] = None,
             variable_qa_min_max_id: Optional[int] = None) -> Generator[VariableQaMinMax, None, None]:
    """
    Read from the variable_qa_min_max table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_qa_min_max_id 
    @param variable_id 
    @param variable_term 
    @param min_valid_range 
    @param max_valid_range 
    @return generator of VariableQaMinMax objects
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    result = db.query_fuzzy(con, 'variable_qa_min_max', data)
    for row in result:
        yield VariableQaMinMax(**row.as_dict())

@beartype.beartype
def read_variable_qa_min_max_any(con: db.Connection, variable_id: Optional[List[int]] = None,
             variable_term: Optional[List[str]] = None,
             min_valid_range: Optional[List[float]] = None,
             max_valid_range: Optional[List[float]] = None,
             variable_qa_min_max_id: Optional[List[int]] = None) -> Generator[VariableQaMinMax, None, None]:
    """
    Read from the variable_qa_min_max table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_qa_min_max_id 
    @param variable_id 
    @param variable_term 
    @param min_valid_range 
    @param max_valid_range 
    @return generator of VariableQaMinMax objects
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    result = db.query_any(con, 'variable_qa_min_max', data)
    for row in result:
        yield VariableQaMinMax(**row.as_dict())

@beartype.beartype
def read_variable_qa_min_max_one_or_none(con: db.Connection, variable_id: Optional[int] = None,
             variable_term: Optional[str] = None,
             min_valid_range: Optional[float] = None,
             max_valid_range: Optional[float] = None,
             variable_qa_min_max_id: Optional[int] = None) -> Optional[VariableQaMinMax]:
    """
    Read from the variable_qa_min_max table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    result = db.query_one_or_none(con, 'variable_qa_min_max', data)
    if result is None:
        return None
    return VariableQaMinMax(**result)

@beartype.beartype
def read_variable_qa_min_max_one(con: db.Connection, variable_id: Optional[int] = None,
             variable_term: Optional[str] = None,
             min_valid_range: Optional[float] = None,
             max_valid_range: Optional[float] = None,
             variable_qa_min_max_id: Optional[int] = None) -> VariableQaMinMax:
    """
    Read from the variable_qa_min_max table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    result = db.query_one(con, 'variable_qa_min_max', data)
    return VariableQaMinMax(**result)

@beartype.beartype
def read_variable_qa_min_max_all(con: db.Connection, variable_id: Optional[int] = None,
             variable_term: Optional[str] = None,
             min_valid_range: Optional[float] = None,
             max_valid_range: Optional[float] = None,
             variable_qa_min_max_id: Optional[int] = None) -> List[VariableQaMinMax]:
    """
    Read from the variable_qa_min_max table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'variable_qa_min_max_id': variable_qa_min_max_id,
        'variable_id': variable_id,
        'variable_term': variable_term,
        'min_valid_range': min_valid_range,
        'max_valid_range': max_valid_range,
    }
    result = db.query(con, 'variable_qa_min_max', data)
    return [VariableQaMinMax(**row.as_dict()) for row in result]

@beartype.beartype
def read_variable_qa_min_max_by_id(con: db.Connection, variable_qa_min_max_id: int) -> Optional[VariableQaMinMax]:
    result = db.query_one(con, 'variable_qa_min_max', {'variable_qa_min_max_id': variable_qa_min_max_id})
    if result is None:
        return None
    return VariableQaMinMax(**result)

@beartype.beartype
def delete_variable_qa_min_max_by_id(con: db.Connection, variable_qa_min_max_id: int):
    db.delete(con, 'variable_qa_min_max', {'variable_qa_min_max_id': variable_qa_min_max_id})
# Associate the functions with the class
VariableQaMinMax.create_from_json_dict = create_variable_qa_min_max_from_json_dict
VariableQaMinMax.write = write_variable_qa_min_max
VariableQaMinMax.update = update_variable_qa_min_max
VariableQaMinMax.write_many = write_variable_qa_min_max_many
VariableQaMinMax.read = read_variable_qa_min_max
VariableQaMinMax.read_fuzzy = read_variable_qa_min_max_fuzzy
VariableQaMinMax.read_any = read_variable_qa_min_max_any
VariableQaMinMax.read_one = read_variable_qa_min_max_one
VariableQaMinMax.read_one_or_none = read_variable_qa_min_max_one_or_none
VariableQaMinMax.read_all = read_variable_qa_min_max_all
VariableQaMinMax.delete = delete_variable_qa_min_max_by_id
VariableQaMinMax.read_by_id = read_variable_qa_min_max_by_id
VariableQaMinMax.delete_by_id = delete_variable_qa_min_max_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DatastreamPersonBridge:
    """
    @param bridge_id 
    @param datastream_id 
    @param person_id 
    @param person_role 

    This is an automatically generated class
    """
    bridge_id: int # bridge_id integer (default: )
    datastream_id: int # datastream_id integer (default: )
    person_id: int # person_id integer (default: )
    person_role: str # person_role character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_person_role(self, con: db.Connection) -> Optional['CvPersonsRole']:
        return read_cv_persons_role_one_or_none(con, term=self.person_role)

    @beartype.beartype
    def get_person(self, con: db.Connection) -> Optional['Persons']:
        return read_persons_one_or_none(con, person_id=self.person_id)

    @beartype.beartype
    def get_datastream(self, con: db.Connection) -> Optional['SamplingFeatureTimeseriesDatastreams']:
        return read_sampling_feature_timeseries_datastreams_one_or_none(con, datastream_id=self.datastream_id)

@beartype.beartype
def create_datastream_person_bridge_from_json_dict(json_obj: dict):
        """
        Create a DatastreamPersonBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DatastreamPersonBridge(**json_obj)


@beartype.beartype
def write_datastream_person_bridge_obj(con: db.Connection, obj: DatastreamPersonBridge) -> int:
    """
    Write a DatastreamPersonBridge object to the database
    @param con: database connection
    @param obj: DatastreamPersonBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datastream_person_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_datastream_person_bridge(
            con: db.Connection,
            bridge_id: int,
            datastream_id: int,
            person_id: int,
            person_role: str) -> int:
    """
    Write to the datastream_person_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param datastream_id 
    @param person_id 
    @param person_role 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    return db.upsert(con, 'datastream_person_bridge', data)

@beartype.beartype
def write_datastream_person_bridge_many(con: db.Connection, objs: List[DatastreamPersonBridge], upsert: bool = False) -> int:
    """
    Write a list of DatastreamPersonBridge objects to the database
    @param con: database connection
    @param objs: list of DatastreamPersonBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datastream_person_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datastream_person_bridge(con: db.Connection, bridge_id: int,
            datastream_id: Optional[int] = None,
            person_id: Optional[int] = None,
            person_role: Optional[str] = None) -> int:
    """
    Update a row in the datastream_person_bridge table in the database
    @param con: database connection
    @param bridge_id 
    @param datastream_id 
    @param person_id 
    @param person_role 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    return db.update(con, 'datastream_person_bridge', data)

@beartype.beartype
def read_datastream_person_bridge(
            con: db.Connection,
            bridge_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role: Optional[str] = None) -> Generator[DatastreamPersonBridge, None, None]:
    """
    Read from the datastream_person_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param datastream_id 
    @param person_id 
    @param person_role 
    @return generator of DatastreamPersonBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    result = db.query(con, 'datastream_person_bridge', data)
    for row in result:
        yield DatastreamPersonBridge(**row.as_dict())

@beartype.beartype
def read_datastream_person_bridge_fuzzy(con: db.Connection, bridge_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role: Optional[str] = None) -> Generator[DatastreamPersonBridge, None, None]:
    """
    Read from the datastream_person_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param datastream_id 
    @param person_id 
    @param person_role 
    @return generator of DatastreamPersonBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    result = db.query_fuzzy(con, 'datastream_person_bridge', data)
    for row in result:
        yield DatastreamPersonBridge(**row.as_dict())

@beartype.beartype
def read_datastream_person_bridge_any(con: db.Connection, bridge_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             person_id: Optional[List[int]] = None,
             person_role: Optional[List[str]] = None) -> Generator[DatastreamPersonBridge, None, None]:
    """
    Read from the datastream_person_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param datastream_id 
    @param person_id 
    @param person_role 
    @return generator of DatastreamPersonBridge objects
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    result = db.query_any(con, 'datastream_person_bridge', data)
    for row in result:
        yield DatastreamPersonBridge(**row.as_dict())

@beartype.beartype
def read_datastream_person_bridge_one_or_none(con: db.Connection, bridge_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role: Optional[str] = None) -> Optional[DatastreamPersonBridge]:
    """
    Read from the datastream_person_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    result = db.query_one_or_none(con, 'datastream_person_bridge', data)
    if result is None:
        return None
    return DatastreamPersonBridge(**result)

@beartype.beartype
def read_datastream_person_bridge_one(con: db.Connection, bridge_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role: Optional[str] = None) -> DatastreamPersonBridge:
    """
    Read from the datastream_person_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    result = db.query_one(con, 'datastream_person_bridge', data)
    return DatastreamPersonBridge(**result)

@beartype.beartype
def read_datastream_person_bridge_all(con: db.Connection, bridge_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             person_id: Optional[int] = None,
             person_role: Optional[str] = None) -> List[DatastreamPersonBridge]:
    """
    Read from the datastream_person_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'datastream_id': datastream_id,
        'person_id': person_id,
        'person_role': person_role,
    }
    result = db.query(con, 'datastream_person_bridge', data)
    return [DatastreamPersonBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_datastream_person_bridge_by_id(con: db.Connection, bridge_id: int) -> Optional[DatastreamPersonBridge]:
    result = db.query_one(con, 'datastream_person_bridge', {'bridge_id': bridge_id})
    if result is None:
        return None
    return DatastreamPersonBridge(**result)

@beartype.beartype
def delete_datastream_person_bridge_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'datastream_person_bridge', {'bridge_id': bridge_id})
# Associate the functions with the class
DatastreamPersonBridge.create_from_json_dict = create_datastream_person_bridge_from_json_dict
DatastreamPersonBridge.write = write_datastream_person_bridge
DatastreamPersonBridge.update = update_datastream_person_bridge
DatastreamPersonBridge.write_many = write_datastream_person_bridge_many
DatastreamPersonBridge.read = read_datastream_person_bridge
DatastreamPersonBridge.read_fuzzy = read_datastream_person_bridge_fuzzy
DatastreamPersonBridge.read_any = read_datastream_person_bridge_any
DatastreamPersonBridge.read_one = read_datastream_person_bridge_one
DatastreamPersonBridge.read_one_or_none = read_datastream_person_bridge_one_or_none
DatastreamPersonBridge.read_all = read_datastream_person_bridge_all
DatastreamPersonBridge.delete = delete_datastream_person_bridge_by_id
DatastreamPersonBridge.read_by_id = read_datastream_person_bridge_by_id
DatastreamPersonBridge.delete_by_id = delete_datastream_person_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class TimeseriesDatastreamTemplate:
    """
    This table is a template for timeseriesdatastreams

    @param utc_time 
    @param data_value 
    @param qa_flag 

    This is an automatically generated class
    """
    utc_time: int # utc_time bigint (default: )
    qa_flag: str # qa_flag character varying (default: )
    data_value: Optional[float] = None # data_value double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'utc_time'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_timeseries_datastream_template_from_json_dict(json_obj: dict):
        """
        Create a TimeseriesDatastreamTemplate from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return TimeseriesDatastreamTemplate(**json_obj)


@beartype.beartype
def write_timeseries_datastream_template_obj(con: db.Connection, obj: TimeseriesDatastreamTemplate) -> int:
    """
    Write a TimeseriesDatastreamTemplate object to the database
    @param con: database connection
    @param obj: TimeseriesDatastreamTemplate object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'timeseries_datastream_template', dataclasses.asdict(obj))

@beartype.beartype
def write_timeseries_datastream_template(
            con: db.Connection,
            utc_time: int,
            qa_flag: str,
            data_value: Optional[float] = None) -> int:
    """
    Write to the timeseries_datastream_template table in the database
    @param con: database connection
    @param utc_time 
    @param data_value 
    @param qa_flag 
    @return id of the inserted/updated row
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    return db.upsert(con, 'timeseries_datastream_template', data)

@beartype.beartype
def write_timeseries_datastream_template_many(con: db.Connection, objs: List[TimeseriesDatastreamTemplate], upsert: bool = False) -> int:
    """
    Write a list of TimeseriesDatastreamTemplate objects to the database
    @param con: database connection
    @param objs: list of TimeseriesDatastreamTemplate objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'timeseries_datastream_template', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_timeseries_datastream_template(con: db.Connection, utc_time: int,
            qa_flag: Optional[str] = None,
            data_value: Optional[float] = None) -> int:
    """
    Update a row in the timeseries_datastream_template table in the database
    @param con: database connection
    @param utc_time 
    @param data_value 
    @param qa_flag 
    @return The number of rows updated
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    return db.update(con, 'timeseries_datastream_template', data)

@beartype.beartype
def read_timeseries_datastream_template(
            con: db.Connection,
            utc_time: Optional[int] = None,
             qa_flag: Optional[str] = None,
             data_value: Optional[float] = None) -> Generator[TimeseriesDatastreamTemplate, None, None]:
    """
    Read from the timeseries_datastream_template table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param utc_time 
    @param data_value 
    @param qa_flag 
    @return generator of TimeseriesDatastreamTemplate objects
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    result = db.query(con, 'timeseries_datastream_template', data)
    for row in result:
        yield TimeseriesDatastreamTemplate(**row.as_dict())

@beartype.beartype
def read_timeseries_datastream_template_fuzzy(con: db.Connection, utc_time: Optional[int] = None,
             qa_flag: Optional[str] = None,
             data_value: Optional[float] = None) -> Generator[TimeseriesDatastreamTemplate, None, None]:
    """
    Read from the timeseries_datastream_template table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param utc_time 
    @param data_value 
    @param qa_flag 
    @return generator of TimeseriesDatastreamTemplate objects
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    result = db.query_fuzzy(con, 'timeseries_datastream_template', data)
    for row in result:
        yield TimeseriesDatastreamTemplate(**row.as_dict())

@beartype.beartype
def read_timeseries_datastream_template_any(con: db.Connection, utc_time: Optional[List[int]] = None,
             qa_flag: Optional[List[str]] = None,
             data_value: Optional[List[float]] = None) -> Generator[TimeseriesDatastreamTemplate, None, None]:
    """
    Read from the timeseries_datastream_template table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param utc_time 
    @param data_value 
    @param qa_flag 
    @return generator of TimeseriesDatastreamTemplate objects
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    result = db.query_any(con, 'timeseries_datastream_template', data)
    for row in result:
        yield TimeseriesDatastreamTemplate(**row.as_dict())

@beartype.beartype
def read_timeseries_datastream_template_one_or_none(con: db.Connection, utc_time: Optional[int] = None,
             qa_flag: Optional[str] = None,
             data_value: Optional[float] = None) -> Optional[TimeseriesDatastreamTemplate]:
    """
    Read from the timeseries_datastream_template table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    result = db.query_one_or_none(con, 'timeseries_datastream_template', data)
    if result is None:
        return None
    return TimeseriesDatastreamTemplate(**result)

@beartype.beartype
def read_timeseries_datastream_template_one(con: db.Connection, utc_time: Optional[int] = None,
             qa_flag: Optional[str] = None,
             data_value: Optional[float] = None) -> TimeseriesDatastreamTemplate:
    """
    Read from the timeseries_datastream_template table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    result = db.query_one(con, 'timeseries_datastream_template', data)
    return TimeseriesDatastreamTemplate(**result)

@beartype.beartype
def read_timeseries_datastream_template_all(con: db.Connection, utc_time: Optional[int] = None,
             qa_flag: Optional[str] = None,
             data_value: Optional[float] = None) -> List[TimeseriesDatastreamTemplate]:
    """
    Read from the timeseries_datastream_template table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'utc_time': utc_time,
        'data_value': data_value,
        'qa_flag': qa_flag,
    }
    result = db.query(con, 'timeseries_datastream_template', data)
    return [TimeseriesDatastreamTemplate(**row.as_dict()) for row in result]

@beartype.beartype
def read_timeseries_datastream_template_by_id(con: db.Connection, utc_time: int) -> Optional[TimeseriesDatastreamTemplate]:
    result = db.query_one(con, 'timeseries_datastream_template', {'utc_time': utc_time})
    if result is None:
        return None
    return TimeseriesDatastreamTemplate(**result)

@beartype.beartype
def delete_timeseries_datastream_template_by_id(con: db.Connection, utc_time: int):
    db.delete(con, 'timeseries_datastream_template', {'utc_time': utc_time})
# Associate the functions with the class
TimeseriesDatastreamTemplate.create_from_json_dict = create_timeseries_datastream_template_from_json_dict
TimeseriesDatastreamTemplate.write = write_timeseries_datastream_template
TimeseriesDatastreamTemplate.update = update_timeseries_datastream_template
TimeseriesDatastreamTemplate.write_many = write_timeseries_datastream_template_many
TimeseriesDatastreamTemplate.read = read_timeseries_datastream_template
TimeseriesDatastreamTemplate.read_fuzzy = read_timeseries_datastream_template_fuzzy
TimeseriesDatastreamTemplate.read_any = read_timeseries_datastream_template_any
TimeseriesDatastreamTemplate.read_one = read_timeseries_datastream_template_one
TimeseriesDatastreamTemplate.read_one_or_none = read_timeseries_datastream_template_one_or_none
TimeseriesDatastreamTemplate.read_all = read_timeseries_datastream_template_all
TimeseriesDatastreamTemplate.delete = delete_timeseries_datastream_template_by_id
TimeseriesDatastreamTemplate.read_by_id = read_timeseries_datastream_template_by_id
TimeseriesDatastreamTemplate.delete_by_id = delete_timeseries_datastream_template_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SamplingFeatureTimeseriesDatastreams:
    """
    This table contains timeseriesdata associated with different samplingfeatures

    @param datastream_id 
    @param datastream_uuid 
    @param equipment_id 
    @param sampling_feature_id 
    @param datastream_type 
    @param variable_id 
    @param units_id 
    @param datastream_database 
    @param datastream_tablename 
    @param first_measurement_date 
    @param last_measurement_date 
    @param total_measurement_numbers 
    @param datastream_attribute 
    @param datastream_access_level 
    @param datastream_source_category 
    @param datastream_classifier 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    datastream_type: str # datastream_type character varying (default: )
    variable_id: int # variable_id integer (default: )
    units_id: int # units_id integer (default: )
    datastream_tablename: str # datastream_tablename character varying (default: )
    datastream_id: Optional[int] = None # datastream_id integer (default: )
    datastream_uuid: Optional[str] = None # datastream_uuid character varying (default: )
    equipment_id: Optional[int] = None # equipment_id integer (default: )
    datastream_database: Optional[str] = None # datastream_database character varying (default: )
    first_measurement_date: Optional[datetime.datetime] = None # first_measurement_date timestamp without time zone (default: )
    last_measurement_date: Optional[datetime.datetime] = None # last_measurement_date timestamp without time zone (default: )
    total_measurement_numbers: Optional[int] = None # total_measurement_numbers bigint (default: )
    datastream_attribute: Optional[str] = None # datastream_attribute character varying (default: )
    datastream_access_level: Optional[str] = None # datastream_access_level character varying (default: )
    datastream_source_category: Optional[str] = None # datastream_source_category character varying (default: )
    datastream_classifier: Optional[str] = None # datastream_classifier character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'datastream_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.first_measurement_date is not None:
            obj['first_measurement_date'] = self.first_measurement_date.isoformat()
        if self.last_measurement_date is not None:
            obj['last_measurement_date'] = self.last_measurement_date.isoformat()
        return obj

    @beartype.beartype
    def get_datastream_access_level(self, con: db.Connection) -> Optional['CvDatastreamAccessLevel']:
        return read_cv_datastream_access_level_one_or_none(con, term=self.datastream_access_level)

    @beartype.beartype
    def get_datastream_classifier(self, con: db.Connection) -> Optional['CvDatastreamClassifier']:
        return read_cv_datastream_classifier_one_or_none(con, term=self.datastream_classifier)

    @beartype.beartype
    def get_datastream_source_category(self, con: db.Connection) -> Optional['CvDatastreamSourceCategory']:
        return read_cv_datastream_source_category_one_or_none(con, term=self.datastream_source_category)

    @beartype.beartype
    def get_datastream_type(self, con: db.Connection) -> Optional['CvDatastreamType']:
        return read_cv_datastream_type_one_or_none(con, term=self.datastream_type)

    @beartype.beartype
    def get_units(self, con: db.Connection) -> Optional['CvUnits']:
        return read_cv_units_one_or_none(con, units_id=self.units_id)

    @beartype.beartype
    def get_equipment(self, con: db.Connection) -> Optional['Equipment']:
        return read_equipment_one_or_none(con, equipment_id=self.equipment_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

    @beartype.beartype
    def get_variable(self, con: db.Connection) -> Optional['Variables']:
        return read_variables_one_or_none(con, variable_id=self.variable_id)

@beartype.beartype
def create_sampling_feature_timeseries_datastreams_from_json_dict(json_obj: dict):
        """
        Create a SamplingFeatureTimeseriesDatastreams from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'first_measurement_date' in json_obj and json_obj['first_measurement_date'] is not None:
            json_obj['first_measurement_date'] = datetime.datetime.fromisoformat(json_obj['first_measurement_date'])
        if 'last_measurement_date' in json_obj and json_obj['last_measurement_date'] is not None:
            json_obj['last_measurement_date'] = datetime.datetime.fromisoformat(json_obj['last_measurement_date'])
        return SamplingFeatureTimeseriesDatastreams(**json_obj)


@beartype.beartype
def write_sampling_feature_timeseries_datastreams_obj(con: db.Connection, obj: SamplingFeatureTimeseriesDatastreams) -> int:
    """
    Write a SamplingFeatureTimeseriesDatastreams object to the database
    @param con: database connection
    @param obj: SamplingFeatureTimeseriesDatastreams object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampling_feature_timeseries_datastreams', dataclasses.asdict(obj))

@beartype.beartype
def write_sampling_feature_timeseries_datastreams(
            con: db.Connection,
            sampling_feature_id: int,
            datastream_type: str,
            variable_id: int,
            units_id: int,
            datastream_tablename: str,
            datastream_id: Optional[int] = None,
            datastream_uuid: Optional[str] = None,
            equipment_id: Optional[int] = None,
            datastream_database: Optional[str] = None,
            first_measurement_date: Optional[datetime.datetime] = None,
            last_measurement_date: Optional[datetime.datetime] = None,
            total_measurement_numbers: Optional[int] = None,
            datastream_attribute: Optional[str] = None,
            datastream_access_level: Optional[str] = None,
            datastream_source_category: Optional[str] = None,
            datastream_classifier: Optional[str] = None) -> int:
    """
    Write to the sampling_feature_timeseries_datastreams table in the database
    @param con: database connection
    @param datastream_id 
    @param datastream_uuid 
    @param equipment_id 
    @param sampling_feature_id 
    @param datastream_type 
    @param variable_id 
    @param units_id 
    @param datastream_database 
    @param datastream_tablename 
    @param first_measurement_date 
    @param last_measurement_date 
    @param total_measurement_numbers 
    @param datastream_attribute 
    @param datastream_access_level 
    @param datastream_source_category 
    @param datastream_classifier 
    @return id of the inserted/updated row
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    return db.upsert(con, 'sampling_feature_timeseries_datastreams', data)

@beartype.beartype
def write_sampling_feature_timeseries_datastreams_many(con: db.Connection, objs: List[SamplingFeatureTimeseriesDatastreams], upsert: bool = False) -> int:
    """
    Write a list of SamplingFeatureTimeseriesDatastreams objects to the database
    @param con: database connection
    @param objs: list of SamplingFeatureTimeseriesDatastreams objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampling_feature_timeseries_datastreams', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampling_feature_timeseries_datastreams(con: db.Connection, datastream_id: int,
            sampling_feature_id: Optional[int] = None,
            datastream_type: Optional[str] = None,
            variable_id: Optional[int] = None,
            units_id: Optional[int] = None,
            datastream_tablename: Optional[str] = None,
            datastream_uuid: Optional[str] = None,
            equipment_id: Optional[int] = None,
            datastream_database: Optional[str] = None,
            first_measurement_date: Optional[datetime.datetime] = None,
            last_measurement_date: Optional[datetime.datetime] = None,
            total_measurement_numbers: Optional[int] = None,
            datastream_attribute: Optional[str] = None,
            datastream_access_level: Optional[str] = None,
            datastream_source_category: Optional[str] = None,
            datastream_classifier: Optional[str] = None) -> int:
    """
    Update a row in the sampling_feature_timeseries_datastreams table in the database
    @param con: database connection
    @param datastream_id 
    @param datastream_uuid 
    @param equipment_id 
    @param sampling_feature_id 
    @param datastream_type 
    @param variable_id 
    @param units_id 
    @param datastream_database 
    @param datastream_tablename 
    @param first_measurement_date 
    @param last_measurement_date 
    @param total_measurement_numbers 
    @param datastream_attribute 
    @param datastream_access_level 
    @param datastream_source_category 
    @param datastream_classifier 
    @return The number of rows updated
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    return db.update(con, 'sampling_feature_timeseries_datastreams', data)

@beartype.beartype
def read_sampling_feature_timeseries_datastreams(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             datastream_type: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             datastream_tablename: Optional[str] = None,
             datastream_id: Optional[int] = None,
             datastream_uuid: Optional[str] = None,
             equipment_id: Optional[int] = None,
             datastream_database: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             total_measurement_numbers: Optional[int] = None,
             datastream_attribute: Optional[str] = None,
             datastream_access_level: Optional[str] = None,
             datastream_source_category: Optional[str] = None,
             datastream_classifier: Optional[str] = None) -> Generator[SamplingFeatureTimeseriesDatastreams, None, None]:
    """
    Read from the sampling_feature_timeseries_datastreams table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_id 
    @param datastream_uuid 
    @param equipment_id 
    @param sampling_feature_id 
    @param datastream_type 
    @param variable_id 
    @param units_id 
    @param datastream_database 
    @param datastream_tablename 
    @param first_measurement_date 
    @param last_measurement_date 
    @param total_measurement_numbers 
    @param datastream_attribute 
    @param datastream_access_level 
    @param datastream_source_category 
    @param datastream_classifier 
    @return generator of SamplingFeatureTimeseriesDatastreams objects
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    result = db.query(con, 'sampling_feature_timeseries_datastreams', data)
    for row in result:
        yield SamplingFeatureTimeseriesDatastreams(**row.as_dict())

@beartype.beartype
def read_sampling_feature_timeseries_datastreams_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             datastream_type: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             datastream_tablename: Optional[str] = None,
             datastream_id: Optional[int] = None,
             datastream_uuid: Optional[str] = None,
             equipment_id: Optional[int] = None,
             datastream_database: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             total_measurement_numbers: Optional[int] = None,
             datastream_attribute: Optional[str] = None,
             datastream_access_level: Optional[str] = None,
             datastream_source_category: Optional[str] = None,
             datastream_classifier: Optional[str] = None) -> Generator[SamplingFeatureTimeseriesDatastreams, None, None]:
    """
    Read from the sampling_feature_timeseries_datastreams table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_id 
    @param datastream_uuid 
    @param equipment_id 
    @param sampling_feature_id 
    @param datastream_type 
    @param variable_id 
    @param units_id 
    @param datastream_database 
    @param datastream_tablename 
    @param first_measurement_date 
    @param last_measurement_date 
    @param total_measurement_numbers 
    @param datastream_attribute 
    @param datastream_access_level 
    @param datastream_source_category 
    @param datastream_classifier 
    @return generator of SamplingFeatureTimeseriesDatastreams objects
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    result = db.query_fuzzy(con, 'sampling_feature_timeseries_datastreams', data)
    for row in result:
        yield SamplingFeatureTimeseriesDatastreams(**row.as_dict())

@beartype.beartype
def read_sampling_feature_timeseries_datastreams_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             datastream_type: Optional[List[str]] = None,
             variable_id: Optional[List[int]] = None,
             units_id: Optional[List[int]] = None,
             datastream_tablename: Optional[List[str]] = None,
             datastream_id: Optional[List[int]] = None,
             datastream_uuid: Optional[List[str]] = None,
             equipment_id: Optional[List[int]] = None,
             datastream_database: Optional[List[str]] = None,
             first_measurement_date: Optional[List[datetime.datetime]] = None,
             last_measurement_date: Optional[List[datetime.datetime]] = None,
             total_measurement_numbers: Optional[List[int]] = None,
             datastream_attribute: Optional[List[str]] = None,
             datastream_access_level: Optional[List[str]] = None,
             datastream_source_category: Optional[List[str]] = None,
             datastream_classifier: Optional[List[str]] = None) -> Generator[SamplingFeatureTimeseriesDatastreams, None, None]:
    """
    Read from the sampling_feature_timeseries_datastreams table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_id 
    @param datastream_uuid 
    @param equipment_id 
    @param sampling_feature_id 
    @param datastream_type 
    @param variable_id 
    @param units_id 
    @param datastream_database 
    @param datastream_tablename 
    @param first_measurement_date 
    @param last_measurement_date 
    @param total_measurement_numbers 
    @param datastream_attribute 
    @param datastream_access_level 
    @param datastream_source_category 
    @param datastream_classifier 
    @return generator of SamplingFeatureTimeseriesDatastreams objects
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    result = db.query_any(con, 'sampling_feature_timeseries_datastreams', data)
    for row in result:
        yield SamplingFeatureTimeseriesDatastreams(**row.as_dict())

@beartype.beartype
def read_sampling_feature_timeseries_datastreams_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             datastream_type: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             datastream_tablename: Optional[str] = None,
             datastream_id: Optional[int] = None,
             datastream_uuid: Optional[str] = None,
             equipment_id: Optional[int] = None,
             datastream_database: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             total_measurement_numbers: Optional[int] = None,
             datastream_attribute: Optional[str] = None,
             datastream_access_level: Optional[str] = None,
             datastream_source_category: Optional[str] = None,
             datastream_classifier: Optional[str] = None) -> Optional[SamplingFeatureTimeseriesDatastreams]:
    """
    Read from the sampling_feature_timeseries_datastreams table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    result = db.query_one_or_none(con, 'sampling_feature_timeseries_datastreams', data)
    if result is None:
        return None
    return SamplingFeatureTimeseriesDatastreams(**result)

@beartype.beartype
def read_sampling_feature_timeseries_datastreams_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             datastream_type: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             datastream_tablename: Optional[str] = None,
             datastream_id: Optional[int] = None,
             datastream_uuid: Optional[str] = None,
             equipment_id: Optional[int] = None,
             datastream_database: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             total_measurement_numbers: Optional[int] = None,
             datastream_attribute: Optional[str] = None,
             datastream_access_level: Optional[str] = None,
             datastream_source_category: Optional[str] = None,
             datastream_classifier: Optional[str] = None) -> SamplingFeatureTimeseriesDatastreams:
    """
    Read from the sampling_feature_timeseries_datastreams table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    result = db.query_one(con, 'sampling_feature_timeseries_datastreams', data)
    return SamplingFeatureTimeseriesDatastreams(**result)

@beartype.beartype
def read_sampling_feature_timeseries_datastreams_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             datastream_type: Optional[str] = None,
             variable_id: Optional[int] = None,
             units_id: Optional[int] = None,
             datastream_tablename: Optional[str] = None,
             datastream_id: Optional[int] = None,
             datastream_uuid: Optional[str] = None,
             equipment_id: Optional[int] = None,
             datastream_database: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             total_measurement_numbers: Optional[int] = None,
             datastream_attribute: Optional[str] = None,
             datastream_access_level: Optional[str] = None,
             datastream_source_category: Optional[str] = None,
             datastream_classifier: Optional[str] = None) -> List[SamplingFeatureTimeseriesDatastreams]:
    """
    Read from the sampling_feature_timeseries_datastreams table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'datastream_id': datastream_id,
        'datastream_uuid': datastream_uuid,
        'equipment_id': equipment_id,
        'sampling_feature_id': sampling_feature_id,
        'datastream_type': datastream_type,
        'variable_id': variable_id,
        'units_id': units_id,
        'datastream_database': datastream_database,
        'datastream_tablename': datastream_tablename,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'total_measurement_numbers': total_measurement_numbers,
        'datastream_attribute': datastream_attribute,
        'datastream_access_level': datastream_access_level,
        'datastream_source_category': datastream_source_category,
        'datastream_classifier': datastream_classifier,
    }
    result = db.query(con, 'sampling_feature_timeseries_datastreams', data)
    return [SamplingFeatureTimeseriesDatastreams(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampling_feature_timeseries_datastreams_by_id(con: db.Connection, datastream_id: int) -> Optional[SamplingFeatureTimeseriesDatastreams]:
    result = db.query_one(con, 'sampling_feature_timeseries_datastreams', {'datastream_id': datastream_id})
    if result is None:
        return None
    return SamplingFeatureTimeseriesDatastreams(**result)

@beartype.beartype
def delete_sampling_feature_timeseries_datastreams_by_id(con: db.Connection, datastream_id: int):
    db.delete(con, 'sampling_feature_timeseries_datastreams', {'datastream_id': datastream_id})
# Associate the functions with the class
SamplingFeatureTimeseriesDatastreams.create_from_json_dict = create_sampling_feature_timeseries_datastreams_from_json_dict
SamplingFeatureTimeseriesDatastreams.write = write_sampling_feature_timeseries_datastreams
SamplingFeatureTimeseriesDatastreams.update = update_sampling_feature_timeseries_datastreams
SamplingFeatureTimeseriesDatastreams.write_many = write_sampling_feature_timeseries_datastreams_many
SamplingFeatureTimeseriesDatastreams.read = read_sampling_feature_timeseries_datastreams
SamplingFeatureTimeseriesDatastreams.read_fuzzy = read_sampling_feature_timeseries_datastreams_fuzzy
SamplingFeatureTimeseriesDatastreams.read_any = read_sampling_feature_timeseries_datastreams_any
SamplingFeatureTimeseriesDatastreams.read_one = read_sampling_feature_timeseries_datastreams_one
SamplingFeatureTimeseriesDatastreams.read_one_or_none = read_sampling_feature_timeseries_datastreams_one_or_none
SamplingFeatureTimeseriesDatastreams.read_all = read_sampling_feature_timeseries_datastreams_all
SamplingFeatureTimeseriesDatastreams.delete = delete_sampling_feature_timeseries_datastreams_by_id
SamplingFeatureTimeseriesDatastreams.read_by_id = read_sampling_feature_timeseries_datastreams_by_id
SamplingFeatureTimeseriesDatastreams.delete_by_id = delete_sampling_feature_timeseries_datastreams_by_id



@beartype_wrap_init
@dataclasses.dataclass
class DatastreamProvenance:
    """
    A table which provides information on the provenance associated with a datastream

    @param datastream_provenance_id 
    @param datastream_provenance_type 
    @param datastream_provenance_description 
    @param datastream_id 

    This is an automatically generated class
    """
    datastream_id: int # datastream_id integer (default: )
    datastream_provenance_id: Optional[int] = None # datastream_provenance_id integer (default: )
    datastream_provenance_type: Optional[str] = None # datastream_provenance_type character varying (default: )
    datastream_provenance_description: Optional[str] = None # datastream_provenance_description character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'datastream_provenance_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_datastream(self, con: db.Connection) -> Optional['SamplingFeatureTimeseriesDatastreams']:
        return read_sampling_feature_timeseries_datastreams_one_or_none(con, datastream_id=self.datastream_id)

@beartype.beartype
def create_datastream_provenance_from_json_dict(json_obj: dict):
        """
        Create a DatastreamProvenance from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return DatastreamProvenance(**json_obj)


@beartype.beartype
def write_datastream_provenance_obj(con: db.Connection, obj: DatastreamProvenance) -> int:
    """
    Write a DatastreamProvenance object to the database
    @param con: database connection
    @param obj: DatastreamProvenance object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'datastream_provenance', dataclasses.asdict(obj))

@beartype.beartype
def write_datastream_provenance(
            con: db.Connection,
            datastream_id: int,
            datastream_provenance_id: Optional[int] = None,
            datastream_provenance_type: Optional[str] = None,
            datastream_provenance_description: Optional[str] = None) -> int:
    """
    Write to the datastream_provenance table in the database
    @param con: database connection
    @param datastream_provenance_id 
    @param datastream_provenance_type 
    @param datastream_provenance_description 
    @param datastream_id 
    @return id of the inserted/updated row
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    return db.upsert(con, 'datastream_provenance', data)

@beartype.beartype
def write_datastream_provenance_many(con: db.Connection, objs: List[DatastreamProvenance], upsert: bool = False) -> int:
    """
    Write a list of DatastreamProvenance objects to the database
    @param con: database connection
    @param objs: list of DatastreamProvenance objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'datastream_provenance', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_datastream_provenance(con: db.Connection, datastream_provenance_id: int,
            datastream_id: Optional[int] = None,
            datastream_provenance_type: Optional[str] = None,
            datastream_provenance_description: Optional[str] = None) -> int:
    """
    Update a row in the datastream_provenance table in the database
    @param con: database connection
    @param datastream_provenance_id 
    @param datastream_provenance_type 
    @param datastream_provenance_description 
    @param datastream_id 
    @return The number of rows updated
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    return db.update(con, 'datastream_provenance', data)

@beartype.beartype
def read_datastream_provenance(
            con: db.Connection,
            datastream_id: Optional[int] = None,
             datastream_provenance_id: Optional[int] = None,
             datastream_provenance_type: Optional[str] = None,
             datastream_provenance_description: Optional[str] = None) -> Generator[DatastreamProvenance, None, None]:
    """
    Read from the datastream_provenance table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_provenance_id 
    @param datastream_provenance_type 
    @param datastream_provenance_description 
    @param datastream_id 
    @return generator of DatastreamProvenance objects
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    result = db.query(con, 'datastream_provenance', data)
    for row in result:
        yield DatastreamProvenance(**row.as_dict())

@beartype.beartype
def read_datastream_provenance_fuzzy(con: db.Connection, datastream_id: Optional[int] = None,
             datastream_provenance_id: Optional[int] = None,
             datastream_provenance_type: Optional[str] = None,
             datastream_provenance_description: Optional[str] = None) -> Generator[DatastreamProvenance, None, None]:
    """
    Read from the datastream_provenance table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_provenance_id 
    @param datastream_provenance_type 
    @param datastream_provenance_description 
    @param datastream_id 
    @return generator of DatastreamProvenance objects
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    result = db.query_fuzzy(con, 'datastream_provenance', data)
    for row in result:
        yield DatastreamProvenance(**row.as_dict())

@beartype.beartype
def read_datastream_provenance_any(con: db.Connection, datastream_id: Optional[List[int]] = None,
             datastream_provenance_id: Optional[List[int]] = None,
             datastream_provenance_type: Optional[List[str]] = None,
             datastream_provenance_description: Optional[List[str]] = None) -> Generator[DatastreamProvenance, None, None]:
    """
    Read from the datastream_provenance table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param datastream_provenance_id 
    @param datastream_provenance_type 
    @param datastream_provenance_description 
    @param datastream_id 
    @return generator of DatastreamProvenance objects
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    result = db.query_any(con, 'datastream_provenance', data)
    for row in result:
        yield DatastreamProvenance(**row.as_dict())

@beartype.beartype
def read_datastream_provenance_one_or_none(con: db.Connection, datastream_id: Optional[int] = None,
             datastream_provenance_id: Optional[int] = None,
             datastream_provenance_type: Optional[str] = None,
             datastream_provenance_description: Optional[str] = None) -> Optional[DatastreamProvenance]:
    """
    Read from the datastream_provenance table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    result = db.query_one_or_none(con, 'datastream_provenance', data)
    if result is None:
        return None
    return DatastreamProvenance(**result)

@beartype.beartype
def read_datastream_provenance_one(con: db.Connection, datastream_id: Optional[int] = None,
             datastream_provenance_id: Optional[int] = None,
             datastream_provenance_type: Optional[str] = None,
             datastream_provenance_description: Optional[str] = None) -> DatastreamProvenance:
    """
    Read from the datastream_provenance table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    result = db.query_one(con, 'datastream_provenance', data)
    return DatastreamProvenance(**result)

@beartype.beartype
def read_datastream_provenance_all(con: db.Connection, datastream_id: Optional[int] = None,
             datastream_provenance_id: Optional[int] = None,
             datastream_provenance_type: Optional[str] = None,
             datastream_provenance_description: Optional[str] = None) -> List[DatastreamProvenance]:
    """
    Read from the datastream_provenance table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'datastream_provenance_id': datastream_provenance_id,
        'datastream_provenance_type': datastream_provenance_type,
        'datastream_provenance_description': datastream_provenance_description,
        'datastream_id': datastream_id,
    }
    result = db.query(con, 'datastream_provenance', data)
    return [DatastreamProvenance(**row.as_dict()) for row in result]

@beartype.beartype
def read_datastream_provenance_by_id(con: db.Connection, datastream_provenance_id: int) -> Optional[DatastreamProvenance]:
    result = db.query_one(con, 'datastream_provenance', {'datastream_provenance_id': datastream_provenance_id})
    if result is None:
        return None
    return DatastreamProvenance(**result)

@beartype.beartype
def delete_datastream_provenance_by_id(con: db.Connection, datastream_provenance_id: int):
    db.delete(con, 'datastream_provenance', {'datastream_provenance_id': datastream_provenance_id})
# Associate the functions with the class
DatastreamProvenance.create_from_json_dict = create_datastream_provenance_from_json_dict
DatastreamProvenance.write = write_datastream_provenance
DatastreamProvenance.update = update_datastream_provenance
DatastreamProvenance.write_many = write_datastream_provenance_many
DatastreamProvenance.read = read_datastream_provenance
DatastreamProvenance.read_fuzzy = read_datastream_provenance_fuzzy
DatastreamProvenance.read_any = read_datastream_provenance_any
DatastreamProvenance.read_one = read_datastream_provenance_one
DatastreamProvenance.read_one_or_none = read_datastream_provenance_one_or_none
DatastreamProvenance.read_all = read_datastream_provenance_all
DatastreamProvenance.delete = delete_datastream_provenance_by_id
DatastreamProvenance.read_by_id = read_datastream_provenance_by_id
DatastreamProvenance.delete_by_id = delete_datastream_provenance_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PhenocamData:
    """
    @param phenocam_dataset_id 
    @param paf_project_id 
    @param sampling_feature_id 
    @param deployment_year 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param images_in_dataset 
    @param google_drive_folder_id 
    @param location_description 
    @param camera_direction_angle 
    @param camera_elevation_angle 
    @param camera_height 
    @param top_left_corner_image_lat 
    @param top_left_corner_image_long 
    @param top_right_corner_image_lat 
    @param top_right_corner_image_long 
    @param bottom_left_corner_image_lat 
    @param bottom_left_corner_image_long 
    @param bottom_right_corner_image_lat 
    @param bottom_right_corner_image_long 
    @param center_point_image_lat 
    @param center_point_image_long 

    This is an automatically generated class
    """
    paf_project_id: int # paf_project_id integer (default: )
    sampling_feature_id: int # sampling_feature_id integer (default: )
    deployment_year: int # deployment_year integer (default: )
    first_image_datetime_utc: datetime.datetime # first_image_datetime_utc timestamp without time zone (default: )
    last_image_datetime_utc: datetime.datetime # last_image_datetime_utc timestamp without time zone (default: )
    images_in_dataset: int # images_in_dataset integer (default: )
    google_drive_folder_id: str # google_drive_folder_id character varying (default: )
    camera_direction_angle: float # camera_direction_angle double precision (default: )
    phenocam_dataset_id: Optional[int] = None # phenocam_dataset_id integer (default: )
    location_description: Optional[str] = None # location_description character varying (default: )
    camera_elevation_angle: Optional[float] = None # camera_elevation_angle double precision (default: )
    camera_height: Optional[float] = None # camera_height double precision (default: )
    top_left_corner_image_lat: Optional[float] = None # top_left_corner_image_lat double precision (default: )
    top_left_corner_image_long: Optional[float] = None # top_left_corner_image_long double precision (default: )
    top_right_corner_image_lat: Optional[float] = None # top_right_corner_image_lat double precision (default: )
    top_right_corner_image_long: Optional[float] = None # top_right_corner_image_long double precision (default: )
    bottom_left_corner_image_lat: Optional[float] = None # bottom_left_corner_image_lat double precision (default: )
    bottom_left_corner_image_long: Optional[float] = None # bottom_left_corner_image_long double precision (default: )
    bottom_right_corner_image_lat: Optional[float] = None # bottom_right_corner_image_lat double precision (default: )
    bottom_right_corner_image_long: Optional[float] = None # bottom_right_corner_image_long double precision (default: )
    center_point_image_lat: Optional[float] = None # center_point_image_lat double precision (default: )
    center_point_image_long: Optional[float] = None # center_point_image_long double precision (default: )
    PRIMARY_KEY: ClassVar[str] = 'phenocam_dataset_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['first_image_datetime_utc'] = self.first_image_datetime_utc.isoformat()
        obj['last_image_datetime_utc'] = self.last_image_datetime_utc.isoformat()
        return obj

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_phenocam_data_from_json_dict(json_obj: dict):
        """
        Create a PhenocamData from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['first_image_datetime_utc'] = datetime.datetime.fromisoformat(json_obj['first_image_datetime_utc'])
        json_obj['last_image_datetime_utc'] = datetime.datetime.fromisoformat(json_obj['last_image_datetime_utc'])
        return PhenocamData(**json_obj)


@beartype.beartype
def write_phenocam_data_obj(con: db.Connection, obj: PhenocamData) -> int:
    """
    Write a PhenocamData object to the database
    @param con: database connection
    @param obj: PhenocamData object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'phenocam_data', dataclasses.asdict(obj))

@beartype.beartype
def write_phenocam_data(
            con: db.Connection,
            paf_project_id: int,
            sampling_feature_id: int,
            deployment_year: int,
            first_image_datetime_utc: datetime.datetime,
            last_image_datetime_utc: datetime.datetime,
            images_in_dataset: int,
            google_drive_folder_id: str,
            camera_direction_angle: float,
            phenocam_dataset_id: Optional[int] = None,
            location_description: Optional[str] = None,
            camera_elevation_angle: Optional[float] = None,
            camera_height: Optional[float] = None,
            top_left_corner_image_lat: Optional[float] = None,
            top_left_corner_image_long: Optional[float] = None,
            top_right_corner_image_lat: Optional[float] = None,
            top_right_corner_image_long: Optional[float] = None,
            bottom_left_corner_image_lat: Optional[float] = None,
            bottom_left_corner_image_long: Optional[float] = None,
            bottom_right_corner_image_lat: Optional[float] = None,
            bottom_right_corner_image_long: Optional[float] = None,
            center_point_image_lat: Optional[float] = None,
            center_point_image_long: Optional[float] = None) -> int:
    """
    Write to the phenocam_data table in the database
    @param con: database connection
    @param phenocam_dataset_id 
    @param paf_project_id 
    @param sampling_feature_id 
    @param deployment_year 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param images_in_dataset 
    @param google_drive_folder_id 
    @param location_description 
    @param camera_direction_angle 
    @param camera_elevation_angle 
    @param camera_height 
    @param top_left_corner_image_lat 
    @param top_left_corner_image_long 
    @param top_right_corner_image_lat 
    @param top_right_corner_image_long 
    @param bottom_left_corner_image_lat 
    @param bottom_left_corner_image_long 
    @param bottom_right_corner_image_lat 
    @param bottom_right_corner_image_long 
    @param center_point_image_lat 
    @param center_point_image_long 
    @return id of the inserted/updated row
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    return db.upsert(con, 'phenocam_data', data)

@beartype.beartype
def write_phenocam_data_many(con: db.Connection, objs: List[PhenocamData], upsert: bool = False) -> int:
    """
    Write a list of PhenocamData objects to the database
    @param con: database connection
    @param objs: list of PhenocamData objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'phenocam_data', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_phenocam_data(con: db.Connection, phenocam_dataset_id: int,
            paf_project_id: Optional[int] = None,
            sampling_feature_id: Optional[int] = None,
            deployment_year: Optional[int] = None,
            first_image_datetime_utc: Optional[datetime.datetime] = None,
            last_image_datetime_utc: Optional[datetime.datetime] = None,
            images_in_dataset: Optional[int] = None,
            google_drive_folder_id: Optional[str] = None,
            camera_direction_angle: Optional[float] = None,
            location_description: Optional[str] = None,
            camera_elevation_angle: Optional[float] = None,
            camera_height: Optional[float] = None,
            top_left_corner_image_lat: Optional[float] = None,
            top_left_corner_image_long: Optional[float] = None,
            top_right_corner_image_lat: Optional[float] = None,
            top_right_corner_image_long: Optional[float] = None,
            bottom_left_corner_image_lat: Optional[float] = None,
            bottom_left_corner_image_long: Optional[float] = None,
            bottom_right_corner_image_lat: Optional[float] = None,
            bottom_right_corner_image_long: Optional[float] = None,
            center_point_image_lat: Optional[float] = None,
            center_point_image_long: Optional[float] = None) -> int:
    """
    Update a row in the phenocam_data table in the database
    @param con: database connection
    @param phenocam_dataset_id 
    @param paf_project_id 
    @param sampling_feature_id 
    @param deployment_year 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param images_in_dataset 
    @param google_drive_folder_id 
    @param location_description 
    @param camera_direction_angle 
    @param camera_elevation_angle 
    @param camera_height 
    @param top_left_corner_image_lat 
    @param top_left_corner_image_long 
    @param top_right_corner_image_lat 
    @param top_right_corner_image_long 
    @param bottom_left_corner_image_lat 
    @param bottom_left_corner_image_long 
    @param bottom_right_corner_image_lat 
    @param bottom_right_corner_image_long 
    @param center_point_image_lat 
    @param center_point_image_long 
    @return The number of rows updated
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    return db.update(con, 'phenocam_data', data)

@beartype.beartype
def read_phenocam_data(
            con: db.Connection,
            paf_project_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             deployment_year: Optional[int] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             images_in_dataset: Optional[int] = None,
             google_drive_folder_id: Optional[str] = None,
             camera_direction_angle: Optional[float] = None,
             phenocam_dataset_id: Optional[int] = None,
             location_description: Optional[str] = None,
             camera_elevation_angle: Optional[float] = None,
             camera_height: Optional[float] = None,
             top_left_corner_image_lat: Optional[float] = None,
             top_left_corner_image_long: Optional[float] = None,
             top_right_corner_image_lat: Optional[float] = None,
             top_right_corner_image_long: Optional[float] = None,
             bottom_left_corner_image_lat: Optional[float] = None,
             bottom_left_corner_image_long: Optional[float] = None,
             bottom_right_corner_image_lat: Optional[float] = None,
             bottom_right_corner_image_long: Optional[float] = None,
             center_point_image_lat: Optional[float] = None,
             center_point_image_long: Optional[float] = None) -> Generator[PhenocamData, None, None]:
    """
    Read from the phenocam_data table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_dataset_id 
    @param paf_project_id 
    @param sampling_feature_id 
    @param deployment_year 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param images_in_dataset 
    @param google_drive_folder_id 
    @param location_description 
    @param camera_direction_angle 
    @param camera_elevation_angle 
    @param camera_height 
    @param top_left_corner_image_lat 
    @param top_left_corner_image_long 
    @param top_right_corner_image_lat 
    @param top_right_corner_image_long 
    @param bottom_left_corner_image_lat 
    @param bottom_left_corner_image_long 
    @param bottom_right_corner_image_lat 
    @param bottom_right_corner_image_long 
    @param center_point_image_lat 
    @param center_point_image_long 
    @return generator of PhenocamData objects
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    result = db.query(con, 'phenocam_data', data)
    for row in result:
        yield PhenocamData(**row.as_dict())

@beartype.beartype
def read_phenocam_data_fuzzy(con: db.Connection, paf_project_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             deployment_year: Optional[int] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             images_in_dataset: Optional[int] = None,
             google_drive_folder_id: Optional[str] = None,
             camera_direction_angle: Optional[float] = None,
             phenocam_dataset_id: Optional[int] = None,
             location_description: Optional[str] = None,
             camera_elevation_angle: Optional[float] = None,
             camera_height: Optional[float] = None,
             top_left_corner_image_lat: Optional[float] = None,
             top_left_corner_image_long: Optional[float] = None,
             top_right_corner_image_lat: Optional[float] = None,
             top_right_corner_image_long: Optional[float] = None,
             bottom_left_corner_image_lat: Optional[float] = None,
             bottom_left_corner_image_long: Optional[float] = None,
             bottom_right_corner_image_lat: Optional[float] = None,
             bottom_right_corner_image_long: Optional[float] = None,
             center_point_image_lat: Optional[float] = None,
             center_point_image_long: Optional[float] = None) -> Generator[PhenocamData, None, None]:
    """
    Read from the phenocam_data table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_dataset_id 
    @param paf_project_id 
    @param sampling_feature_id 
    @param deployment_year 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param images_in_dataset 
    @param google_drive_folder_id 
    @param location_description 
    @param camera_direction_angle 
    @param camera_elevation_angle 
    @param camera_height 
    @param top_left_corner_image_lat 
    @param top_left_corner_image_long 
    @param top_right_corner_image_lat 
    @param top_right_corner_image_long 
    @param bottom_left_corner_image_lat 
    @param bottom_left_corner_image_long 
    @param bottom_right_corner_image_lat 
    @param bottom_right_corner_image_long 
    @param center_point_image_lat 
    @param center_point_image_long 
    @return generator of PhenocamData objects
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    result = db.query_fuzzy(con, 'phenocam_data', data)
    for row in result:
        yield PhenocamData(**row.as_dict())

@beartype.beartype
def read_phenocam_data_any(con: db.Connection, paf_project_id: Optional[List[int]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             deployment_year: Optional[List[int]] = None,
             first_image_datetime_utc: Optional[List[datetime.datetime]] = None,
             last_image_datetime_utc: Optional[List[datetime.datetime]] = None,
             images_in_dataset: Optional[List[int]] = None,
             google_drive_folder_id: Optional[List[str]] = None,
             camera_direction_angle: Optional[List[float]] = None,
             phenocam_dataset_id: Optional[List[int]] = None,
             location_description: Optional[List[str]] = None,
             camera_elevation_angle: Optional[List[float]] = None,
             camera_height: Optional[List[float]] = None,
             top_left_corner_image_lat: Optional[List[float]] = None,
             top_left_corner_image_long: Optional[List[float]] = None,
             top_right_corner_image_lat: Optional[List[float]] = None,
             top_right_corner_image_long: Optional[List[float]] = None,
             bottom_left_corner_image_lat: Optional[List[float]] = None,
             bottom_left_corner_image_long: Optional[List[float]] = None,
             bottom_right_corner_image_lat: Optional[List[float]] = None,
             bottom_right_corner_image_long: Optional[List[float]] = None,
             center_point_image_lat: Optional[List[float]] = None,
             center_point_image_long: Optional[List[float]] = None) -> Generator[PhenocamData, None, None]:
    """
    Read from the phenocam_data table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_dataset_id 
    @param paf_project_id 
    @param sampling_feature_id 
    @param deployment_year 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param images_in_dataset 
    @param google_drive_folder_id 
    @param location_description 
    @param camera_direction_angle 
    @param camera_elevation_angle 
    @param camera_height 
    @param top_left_corner_image_lat 
    @param top_left_corner_image_long 
    @param top_right_corner_image_lat 
    @param top_right_corner_image_long 
    @param bottom_left_corner_image_lat 
    @param bottom_left_corner_image_long 
    @param bottom_right_corner_image_lat 
    @param bottom_right_corner_image_long 
    @param center_point_image_lat 
    @param center_point_image_long 
    @return generator of PhenocamData objects
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    result = db.query_any(con, 'phenocam_data', data)
    for row in result:
        yield PhenocamData(**row.as_dict())

@beartype.beartype
def read_phenocam_data_one_or_none(con: db.Connection, paf_project_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             deployment_year: Optional[int] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             images_in_dataset: Optional[int] = None,
             google_drive_folder_id: Optional[str] = None,
             camera_direction_angle: Optional[float] = None,
             phenocam_dataset_id: Optional[int] = None,
             location_description: Optional[str] = None,
             camera_elevation_angle: Optional[float] = None,
             camera_height: Optional[float] = None,
             top_left_corner_image_lat: Optional[float] = None,
             top_left_corner_image_long: Optional[float] = None,
             top_right_corner_image_lat: Optional[float] = None,
             top_right_corner_image_long: Optional[float] = None,
             bottom_left_corner_image_lat: Optional[float] = None,
             bottom_left_corner_image_long: Optional[float] = None,
             bottom_right_corner_image_lat: Optional[float] = None,
             bottom_right_corner_image_long: Optional[float] = None,
             center_point_image_lat: Optional[float] = None,
             center_point_image_long: Optional[float] = None) -> Optional[PhenocamData]:
    """
    Read from the phenocam_data table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    result = db.query_one_or_none(con, 'phenocam_data', data)
    if result is None:
        return None
    return PhenocamData(**result)

@beartype.beartype
def read_phenocam_data_one(con: db.Connection, paf_project_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             deployment_year: Optional[int] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             images_in_dataset: Optional[int] = None,
             google_drive_folder_id: Optional[str] = None,
             camera_direction_angle: Optional[float] = None,
             phenocam_dataset_id: Optional[int] = None,
             location_description: Optional[str] = None,
             camera_elevation_angle: Optional[float] = None,
             camera_height: Optional[float] = None,
             top_left_corner_image_lat: Optional[float] = None,
             top_left_corner_image_long: Optional[float] = None,
             top_right_corner_image_lat: Optional[float] = None,
             top_right_corner_image_long: Optional[float] = None,
             bottom_left_corner_image_lat: Optional[float] = None,
             bottom_left_corner_image_long: Optional[float] = None,
             bottom_right_corner_image_lat: Optional[float] = None,
             bottom_right_corner_image_long: Optional[float] = None,
             center_point_image_lat: Optional[float] = None,
             center_point_image_long: Optional[float] = None) -> PhenocamData:
    """
    Read from the phenocam_data table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    result = db.query_one(con, 'phenocam_data', data)
    return PhenocamData(**result)

@beartype.beartype
def read_phenocam_data_all(con: db.Connection, paf_project_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             deployment_year: Optional[int] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             images_in_dataset: Optional[int] = None,
             google_drive_folder_id: Optional[str] = None,
             camera_direction_angle: Optional[float] = None,
             phenocam_dataset_id: Optional[int] = None,
             location_description: Optional[str] = None,
             camera_elevation_angle: Optional[float] = None,
             camera_height: Optional[float] = None,
             top_left_corner_image_lat: Optional[float] = None,
             top_left_corner_image_long: Optional[float] = None,
             top_right_corner_image_lat: Optional[float] = None,
             top_right_corner_image_long: Optional[float] = None,
             bottom_left_corner_image_lat: Optional[float] = None,
             bottom_left_corner_image_long: Optional[float] = None,
             bottom_right_corner_image_lat: Optional[float] = None,
             bottom_right_corner_image_long: Optional[float] = None,
             center_point_image_lat: Optional[float] = None,
             center_point_image_long: Optional[float] = None) -> List[PhenocamData]:
    """
    Read from the phenocam_data table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'phenocam_dataset_id': phenocam_dataset_id,
        'paf_project_id': paf_project_id,
        'sampling_feature_id': sampling_feature_id,
        'deployment_year': deployment_year,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'images_in_dataset': images_in_dataset,
        'google_drive_folder_id': google_drive_folder_id,
        'location_description': location_description,
        'camera_direction_angle': camera_direction_angle,
        'camera_elevation_angle': camera_elevation_angle,
        'camera_height': camera_height,
        'top_left_corner_image_lat': top_left_corner_image_lat,
        'top_left_corner_image_long': top_left_corner_image_long,
        'top_right_corner_image_lat': top_right_corner_image_lat,
        'top_right_corner_image_long': top_right_corner_image_long,
        'bottom_left_corner_image_lat': bottom_left_corner_image_lat,
        'bottom_left_corner_image_long': bottom_left_corner_image_long,
        'bottom_right_corner_image_lat': bottom_right_corner_image_lat,
        'bottom_right_corner_image_long': bottom_right_corner_image_long,
        'center_point_image_lat': center_point_image_lat,
        'center_point_image_long': center_point_image_long,
    }
    result = db.query(con, 'phenocam_data', data)
    return [PhenocamData(**row.as_dict()) for row in result]

@beartype.beartype
def read_phenocam_data_by_id(con: db.Connection, phenocam_dataset_id: int) -> Optional[PhenocamData]:
    result = db.query_one(con, 'phenocam_data', {'phenocam_dataset_id': phenocam_dataset_id})
    if result is None:
        return None
    return PhenocamData(**result)

@beartype.beartype
def delete_phenocam_data_by_id(con: db.Connection, phenocam_dataset_id: int):
    db.delete(con, 'phenocam_data', {'phenocam_dataset_id': phenocam_dataset_id})
# Associate the functions with the class
PhenocamData.create_from_json_dict = create_phenocam_data_from_json_dict
PhenocamData.write = write_phenocam_data
PhenocamData.update = update_phenocam_data
PhenocamData.write_many = write_phenocam_data_many
PhenocamData.read = read_phenocam_data
PhenocamData.read_fuzzy = read_phenocam_data_fuzzy
PhenocamData.read_any = read_phenocam_data_any
PhenocamData.read_one = read_phenocam_data_one
PhenocamData.read_one_or_none = read_phenocam_data_one_or_none
PhenocamData.read_all = read_phenocam_data_all
PhenocamData.delete = delete_phenocam_data_by_id
PhenocamData.read_by_id = read_phenocam_data_by_id
PhenocamData.delete_by_id = delete_phenocam_data_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpatialOffsets:
    """
    An explicit spatial relationship between a sampling feature relative to it's parent.

    @param spatial_offset_id 
    @param spatial_offset_type_cv 
    @param offset1_value 
    @param offset1_unit_id 
    @param offset2_value 
    @param offset2_unit_id 
    @param offset3_value 
    @param offset3_unit_id 

    This is an automatically generated class
    """
    spatial_offset_type_cv: str # spatial_offset_type_cv character varying (default: )
    offset1_value: float # offset1_value double precision (default: )
    offset1_unit_id: int # offset1_unit_id integer (default: )
    spatial_offset_id: Optional[int] = None # spatial_offset_id integer (default: )
    offset2_value: Optional[float] = None # offset2_value double precision (default: )
    offset2_unit_id: Optional[int] = None # offset2_unit_id integer (default: )
    offset3_value: Optional[float] = None # offset3_value double precision (default: )
    offset3_unit_id: Optional[int] = None # offset3_unit_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'spatial_offset_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_spatial_offset_type_cv(self, con: db.Connection) -> Optional['CvSpatialOffsetType']:
        return read_cv_spatial_offset_type_one_or_none(con, term=self.spatial_offset_type_cv)

@beartype.beartype
def create_spatial_offsets_from_json_dict(json_obj: dict):
        """
        Create a SpatialOffsets from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpatialOffsets(**json_obj)


@beartype.beartype
def write_spatial_offsets_obj(con: db.Connection, obj: SpatialOffsets) -> int:
    """
    Write a SpatialOffsets object to the database
    @param con: database connection
    @param obj: SpatialOffsets object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'spatial_offsets', dataclasses.asdict(obj))

@beartype.beartype
def write_spatial_offsets(
            con: db.Connection,
            spatial_offset_type_cv: str,
            offset1_value: float,
            offset1_unit_id: int,
            spatial_offset_id: Optional[int] = None,
            offset2_value: Optional[float] = None,
            offset2_unit_id: Optional[int] = None,
            offset3_value: Optional[float] = None,
            offset3_unit_id: Optional[int] = None) -> int:
    """
    Write to the spatial_offsets table in the database
    @param con: database connection
    @param spatial_offset_id 
    @param spatial_offset_type_cv 
    @param offset1_value 
    @param offset1_unit_id 
    @param offset2_value 
    @param offset2_unit_id 
    @param offset3_value 
    @param offset3_unit_id 
    @return id of the inserted/updated row
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    return db.upsert(con, 'spatial_offsets', data)

@beartype.beartype
def write_spatial_offsets_many(con: db.Connection, objs: List[SpatialOffsets], upsert: bool = False) -> int:
    """
    Write a list of SpatialOffsets objects to the database
    @param con: database connection
    @param objs: list of SpatialOffsets objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'spatial_offsets', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_spatial_offsets(con: db.Connection, spatial_offset_id: int,
            spatial_offset_type_cv: Optional[str] = None,
            offset1_value: Optional[float] = None,
            offset1_unit_id: Optional[int] = None,
            offset2_value: Optional[float] = None,
            offset2_unit_id: Optional[int] = None,
            offset3_value: Optional[float] = None,
            offset3_unit_id: Optional[int] = None) -> int:
    """
    Update a row in the spatial_offsets table in the database
    @param con: database connection
    @param spatial_offset_id 
    @param spatial_offset_type_cv 
    @param offset1_value 
    @param offset1_unit_id 
    @param offset2_value 
    @param offset2_unit_id 
    @param offset3_value 
    @param offset3_unit_id 
    @return The number of rows updated
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    return db.update(con, 'spatial_offsets', data)

@beartype.beartype
def read_spatial_offsets(
            con: db.Connection,
            spatial_offset_type_cv: Optional[str] = None,
             offset1_value: Optional[float] = None,
             offset1_unit_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None,
             offset2_value: Optional[float] = None,
             offset2_unit_id: Optional[int] = None,
             offset3_value: Optional[float] = None,
             offset3_unit_id: Optional[int] = None) -> Generator[SpatialOffsets, None, None]:
    """
    Read from the spatial_offsets table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param spatial_offset_id 
    @param spatial_offset_type_cv 
    @param offset1_value 
    @param offset1_unit_id 
    @param offset2_value 
    @param offset2_unit_id 
    @param offset3_value 
    @param offset3_unit_id 
    @return generator of SpatialOffsets objects
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    result = db.query(con, 'spatial_offsets', data)
    for row in result:
        yield SpatialOffsets(**row.as_dict())

@beartype.beartype
def read_spatial_offsets_fuzzy(con: db.Connection, spatial_offset_type_cv: Optional[str] = None,
             offset1_value: Optional[float] = None,
             offset1_unit_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None,
             offset2_value: Optional[float] = None,
             offset2_unit_id: Optional[int] = None,
             offset3_value: Optional[float] = None,
             offset3_unit_id: Optional[int] = None) -> Generator[SpatialOffsets, None, None]:
    """
    Read from the spatial_offsets table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param spatial_offset_id 
    @param spatial_offset_type_cv 
    @param offset1_value 
    @param offset1_unit_id 
    @param offset2_value 
    @param offset2_unit_id 
    @param offset3_value 
    @param offset3_unit_id 
    @return generator of SpatialOffsets objects
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    result = db.query_fuzzy(con, 'spatial_offsets', data)
    for row in result:
        yield SpatialOffsets(**row.as_dict())

@beartype.beartype
def read_spatial_offsets_any(con: db.Connection, spatial_offset_type_cv: Optional[List[str]] = None,
             offset1_value: Optional[List[float]] = None,
             offset1_unit_id: Optional[List[int]] = None,
             spatial_offset_id: Optional[List[int]] = None,
             offset2_value: Optional[List[float]] = None,
             offset2_unit_id: Optional[List[int]] = None,
             offset3_value: Optional[List[float]] = None,
             offset3_unit_id: Optional[List[int]] = None) -> Generator[SpatialOffsets, None, None]:
    """
    Read from the spatial_offsets table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param spatial_offset_id 
    @param spatial_offset_type_cv 
    @param offset1_value 
    @param offset1_unit_id 
    @param offset2_value 
    @param offset2_unit_id 
    @param offset3_value 
    @param offset3_unit_id 
    @return generator of SpatialOffsets objects
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    result = db.query_any(con, 'spatial_offsets', data)
    for row in result:
        yield SpatialOffsets(**row.as_dict())

@beartype.beartype
def read_spatial_offsets_one_or_none(con: db.Connection, spatial_offset_type_cv: Optional[str] = None,
             offset1_value: Optional[float] = None,
             offset1_unit_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None,
             offset2_value: Optional[float] = None,
             offset2_unit_id: Optional[int] = None,
             offset3_value: Optional[float] = None,
             offset3_unit_id: Optional[int] = None) -> Optional[SpatialOffsets]:
    """
    Read from the spatial_offsets table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    result = db.query_one_or_none(con, 'spatial_offsets', data)
    if result is None:
        return None
    return SpatialOffsets(**result)

@beartype.beartype
def read_spatial_offsets_one(con: db.Connection, spatial_offset_type_cv: Optional[str] = None,
             offset1_value: Optional[float] = None,
             offset1_unit_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None,
             offset2_value: Optional[float] = None,
             offset2_unit_id: Optional[int] = None,
             offset3_value: Optional[float] = None,
             offset3_unit_id: Optional[int] = None) -> SpatialOffsets:
    """
    Read from the spatial_offsets table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    result = db.query_one(con, 'spatial_offsets', data)
    return SpatialOffsets(**result)

@beartype.beartype
def read_spatial_offsets_all(con: db.Connection, spatial_offset_type_cv: Optional[str] = None,
             offset1_value: Optional[float] = None,
             offset1_unit_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None,
             offset2_value: Optional[float] = None,
             offset2_unit_id: Optional[int] = None,
             offset3_value: Optional[float] = None,
             offset3_unit_id: Optional[int] = None) -> List[SpatialOffsets]:
    """
    Read from the spatial_offsets table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'spatial_offset_id': spatial_offset_id,
        'spatial_offset_type_cv': spatial_offset_type_cv,
        'offset1_value': offset1_value,
        'offset1_unit_id': offset1_unit_id,
        'offset2_value': offset2_value,
        'offset2_unit_id': offset2_unit_id,
        'offset3_value': offset3_value,
        'offset3_unit_id': offset3_unit_id,
    }
    result = db.query(con, 'spatial_offsets', data)
    return [SpatialOffsets(**row.as_dict()) for row in result]

@beartype.beartype
def read_spatial_offsets_by_id(con: db.Connection, spatial_offset_id: int) -> Optional[SpatialOffsets]:
    result = db.query_one(con, 'spatial_offsets', {'spatial_offset_id': spatial_offset_id})
    if result is None:
        return None
    return SpatialOffsets(**result)

@beartype.beartype
def delete_spatial_offsets_by_id(con: db.Connection, spatial_offset_id: int):
    db.delete(con, 'spatial_offsets', {'spatial_offset_id': spatial_offset_id})
# Associate the functions with the class
SpatialOffsets.create_from_json_dict = create_spatial_offsets_from_json_dict
SpatialOffsets.write = write_spatial_offsets
SpatialOffsets.update = update_spatial_offsets
SpatialOffsets.write_many = write_spatial_offsets_many
SpatialOffsets.read = read_spatial_offsets
SpatialOffsets.read_fuzzy = read_spatial_offsets_fuzzy
SpatialOffsets.read_any = read_spatial_offsets_any
SpatialOffsets.read_one = read_spatial_offsets_one
SpatialOffsets.read_one_or_none = read_spatial_offsets_one_or_none
SpatialOffsets.read_all = read_spatial_offsets_all
SpatialOffsets.delete = delete_spatial_offsets_by_id
SpatialOffsets.read_by_id = read_spatial_offsets_by_id
SpatialOffsets.delete_by_id = delete_spatial_offsets_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpatialReferences:
    """
    Describes spatial reference systems used to reference the coordinates for sites

    @param spatial_reference_id 
    @param srs_code 
    @param srs_name 
    @param srs_description 
    @param srs_link 

    This is an automatically generated class
    """
    srs_name: str # srs_name character varying (default: )
    spatial_reference_id: Optional[int] = None # spatial_reference_id integer (default: )
    srs_code: Optional[str] = None # srs_code character varying (default: )
    srs_description: Optional[str] = None # srs_description character varying (default: )
    srs_link: Optional[str] = None # srs_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'spatial_reference_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_spatial_references_from_json_dict(json_obj: dict):
        """
        Create a SpatialReferences from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpatialReferences(**json_obj)


@beartype.beartype
def write_spatial_references_obj(con: db.Connection, obj: SpatialReferences) -> int:
    """
    Write a SpatialReferences object to the database
    @param con: database connection
    @param obj: SpatialReferences object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'spatial_references', dataclasses.asdict(obj))

@beartype.beartype
def write_spatial_references(
            con: db.Connection,
            srs_name: str,
            spatial_reference_id: Optional[int] = None,
            srs_code: Optional[str] = None,
            srs_description: Optional[str] = None,
            srs_link: Optional[str] = None) -> int:
    """
    Write to the spatial_references table in the database
    @param con: database connection
    @param spatial_reference_id 
    @param srs_code 
    @param srs_name 
    @param srs_description 
    @param srs_link 
    @return id of the inserted/updated row
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    return db.upsert(con, 'spatial_references', data)

@beartype.beartype
def write_spatial_references_many(con: db.Connection, objs: List[SpatialReferences], upsert: bool = False) -> int:
    """
    Write a list of SpatialReferences objects to the database
    @param con: database connection
    @param objs: list of SpatialReferences objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'spatial_references', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_spatial_references(con: db.Connection, spatial_reference_id: int,
            srs_name: Optional[str] = None,
            srs_code: Optional[str] = None,
            srs_description: Optional[str] = None,
            srs_link: Optional[str] = None) -> int:
    """
    Update a row in the spatial_references table in the database
    @param con: database connection
    @param spatial_reference_id 
    @param srs_code 
    @param srs_name 
    @param srs_description 
    @param srs_link 
    @return The number of rows updated
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    return db.update(con, 'spatial_references', data)

@beartype.beartype
def read_spatial_references(
            con: db.Connection,
            srs_name: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             srs_code: Optional[str] = None,
             srs_description: Optional[str] = None,
             srs_link: Optional[str] = None) -> Generator[SpatialReferences, None, None]:
    """
    Read from the spatial_references table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param spatial_reference_id 
    @param srs_code 
    @param srs_name 
    @param srs_description 
    @param srs_link 
    @return generator of SpatialReferences objects
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    result = db.query(con, 'spatial_references', data)
    for row in result:
        yield SpatialReferences(**row.as_dict())

@beartype.beartype
def read_spatial_references_fuzzy(con: db.Connection, srs_name: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             srs_code: Optional[str] = None,
             srs_description: Optional[str] = None,
             srs_link: Optional[str] = None) -> Generator[SpatialReferences, None, None]:
    """
    Read from the spatial_references table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param spatial_reference_id 
    @param srs_code 
    @param srs_name 
    @param srs_description 
    @param srs_link 
    @return generator of SpatialReferences objects
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    result = db.query_fuzzy(con, 'spatial_references', data)
    for row in result:
        yield SpatialReferences(**row.as_dict())

@beartype.beartype
def read_spatial_references_any(con: db.Connection, srs_name: Optional[List[str]] = None,
             spatial_reference_id: Optional[List[int]] = None,
             srs_code: Optional[List[str]] = None,
             srs_description: Optional[List[str]] = None,
             srs_link: Optional[List[str]] = None) -> Generator[SpatialReferences, None, None]:
    """
    Read from the spatial_references table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param spatial_reference_id 
    @param srs_code 
    @param srs_name 
    @param srs_description 
    @param srs_link 
    @return generator of SpatialReferences objects
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    result = db.query_any(con, 'spatial_references', data)
    for row in result:
        yield SpatialReferences(**row.as_dict())

@beartype.beartype
def read_spatial_references_one_or_none(con: db.Connection, srs_name: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             srs_code: Optional[str] = None,
             srs_description: Optional[str] = None,
             srs_link: Optional[str] = None) -> Optional[SpatialReferences]:
    """
    Read from the spatial_references table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    result = db.query_one_or_none(con, 'spatial_references', data)
    if result is None:
        return None
    return SpatialReferences(**result)

@beartype.beartype
def read_spatial_references_one(con: db.Connection, srs_name: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             srs_code: Optional[str] = None,
             srs_description: Optional[str] = None,
             srs_link: Optional[str] = None) -> SpatialReferences:
    """
    Read from the spatial_references table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    result = db.query_one(con, 'spatial_references', data)
    return SpatialReferences(**result)

@beartype.beartype
def read_spatial_references_all(con: db.Connection, srs_name: Optional[str] = None,
             spatial_reference_id: Optional[int] = None,
             srs_code: Optional[str] = None,
             srs_description: Optional[str] = None,
             srs_link: Optional[str] = None) -> List[SpatialReferences]:
    """
    Read from the spatial_references table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'spatial_reference_id': spatial_reference_id,
        'srs_code': srs_code,
        'srs_name': srs_name,
        'srs_description': srs_description,
        'srs_link': srs_link,
    }
    result = db.query(con, 'spatial_references', data)
    return [SpatialReferences(**row.as_dict()) for row in result]

@beartype.beartype
def read_spatial_references_by_id(con: db.Connection, spatial_reference_id: int) -> Optional[SpatialReferences]:
    result = db.query_one(con, 'spatial_references', {'spatial_reference_id': spatial_reference_id})
    if result is None:
        return None
    return SpatialReferences(**result)

@beartype.beartype
def delete_spatial_references_by_id(con: db.Connection, spatial_reference_id: int):
    db.delete(con, 'spatial_references', {'spatial_reference_id': spatial_reference_id})
# Associate the functions with the class
SpatialReferences.create_from_json_dict = create_spatial_references_from_json_dict
SpatialReferences.write = write_spatial_references
SpatialReferences.update = update_spatial_references
SpatialReferences.write_many = write_spatial_references_many
SpatialReferences.read = read_spatial_references
SpatialReferences.read_fuzzy = read_spatial_references_fuzzy
SpatialReferences.read_any = read_spatial_references_any
SpatialReferences.read_one = read_spatial_references_one
SpatialReferences.read_one_or_none = read_spatial_references_one_or_none
SpatialReferences.read_all = read_spatial_references_all
SpatialReferences.delete = delete_spatial_references_by_id
SpatialReferences.read_by_id = read_spatial_references_by_id
SpatialReferences.delete_by_id = delete_spatial_references_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpecimenCollection:
    """
    This has the specimen collection information

    @param specimen_collection_id 
    @param specimen_collection_cv 
    @param specimen_collection_file 
    @param specimen_collection_name 
    @param specimen_collection_note 
    @param parent_specimen_collection_id 

    This is an automatically generated class
    """
    specimen_collection_cv: str # specimen_collection_cv character varying (default: )
    specimen_collection_id: Optional[int] = None # specimen_collection_id integer (default: )
    specimen_collection_file: Optional[str] = None # specimen_collection_file character varying (default: )
    specimen_collection_name: Optional[str] = None # specimen_collection_name character varying (default: )
    specimen_collection_note: Optional[str] = None # specimen_collection_note character varying (default: )
    parent_specimen_collection_id: Optional[int] = None # parent_specimen_collection_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'specimen_collection_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_specimen_collection_cv(self, con: db.Connection) -> Optional['CvSpecimenCollection']:
        return read_cv_specimen_collection_one_or_none(con, term=self.specimen_collection_cv)

    @beartype.beartype
    def get_parent_specimen_collection(self, con: db.Connection) -> Optional['SpecimenCollection']:
        return read_specimen_collection_one_or_none(con, specimen_collection_id=self.parent_specimen_collection_id)

@beartype.beartype
def create_specimen_collection_from_json_dict(json_obj: dict):
        """
        Create a SpecimenCollection from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpecimenCollection(**json_obj)


@beartype.beartype
def write_specimen_collection_obj(con: db.Connection, obj: SpecimenCollection) -> int:
    """
    Write a SpecimenCollection object to the database
    @param con: database connection
    @param obj: SpecimenCollection object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'specimen_collection', dataclasses.asdict(obj))

@beartype.beartype
def write_specimen_collection(
            con: db.Connection,
            specimen_collection_cv: str,
            specimen_collection_id: Optional[int] = None,
            specimen_collection_file: Optional[str] = None,
            specimen_collection_name: Optional[str] = None,
            specimen_collection_note: Optional[str] = None,
            parent_specimen_collection_id: Optional[int] = None) -> int:
    """
    Write to the specimen_collection table in the database
    @param con: database connection
    @param specimen_collection_id 
    @param specimen_collection_cv 
    @param specimen_collection_file 
    @param specimen_collection_name 
    @param specimen_collection_note 
    @param parent_specimen_collection_id 
    @return id of the inserted/updated row
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    return db.upsert(con, 'specimen_collection', data)

@beartype.beartype
def write_specimen_collection_many(con: db.Connection, objs: List[SpecimenCollection], upsert: bool = False) -> int:
    """
    Write a list of SpecimenCollection objects to the database
    @param con: database connection
    @param objs: list of SpecimenCollection objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'specimen_collection', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_specimen_collection(con: db.Connection, specimen_collection_id: int,
            specimen_collection_cv: Optional[str] = None,
            specimen_collection_file: Optional[str] = None,
            specimen_collection_name: Optional[str] = None,
            specimen_collection_note: Optional[str] = None,
            parent_specimen_collection_id: Optional[int] = None) -> int:
    """
    Update a row in the specimen_collection table in the database
    @param con: database connection
    @param specimen_collection_id 
    @param specimen_collection_cv 
    @param specimen_collection_file 
    @param specimen_collection_name 
    @param specimen_collection_note 
    @param parent_specimen_collection_id 
    @return The number of rows updated
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    return db.update(con, 'specimen_collection', data)

@beartype.beartype
def read_specimen_collection(
            con: db.Connection,
            specimen_collection_cv: Optional[str] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_collection_file: Optional[str] = None,
             specimen_collection_name: Optional[str] = None,
             specimen_collection_note: Optional[str] = None,
             parent_specimen_collection_id: Optional[int] = None) -> Generator[SpecimenCollection, None, None]:
    """
    Read from the specimen_collection table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param specimen_collection_id 
    @param specimen_collection_cv 
    @param specimen_collection_file 
    @param specimen_collection_name 
    @param specimen_collection_note 
    @param parent_specimen_collection_id 
    @return generator of SpecimenCollection objects
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    result = db.query(con, 'specimen_collection', data)
    for row in result:
        yield SpecimenCollection(**row.as_dict())

@beartype.beartype
def read_specimen_collection_fuzzy(con: db.Connection, specimen_collection_cv: Optional[str] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_collection_file: Optional[str] = None,
             specimen_collection_name: Optional[str] = None,
             specimen_collection_note: Optional[str] = None,
             parent_specimen_collection_id: Optional[int] = None) -> Generator[SpecimenCollection, None, None]:
    """
    Read from the specimen_collection table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param specimen_collection_id 
    @param specimen_collection_cv 
    @param specimen_collection_file 
    @param specimen_collection_name 
    @param specimen_collection_note 
    @param parent_specimen_collection_id 
    @return generator of SpecimenCollection objects
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    result = db.query_fuzzy(con, 'specimen_collection', data)
    for row in result:
        yield SpecimenCollection(**row.as_dict())

@beartype.beartype
def read_specimen_collection_any(con: db.Connection, specimen_collection_cv: Optional[List[str]] = None,
             specimen_collection_id: Optional[List[int]] = None,
             specimen_collection_file: Optional[List[str]] = None,
             specimen_collection_name: Optional[List[str]] = None,
             specimen_collection_note: Optional[List[str]] = None,
             parent_specimen_collection_id: Optional[List[int]] = None) -> Generator[SpecimenCollection, None, None]:
    """
    Read from the specimen_collection table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param specimen_collection_id 
    @param specimen_collection_cv 
    @param specimen_collection_file 
    @param specimen_collection_name 
    @param specimen_collection_note 
    @param parent_specimen_collection_id 
    @return generator of SpecimenCollection objects
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    result = db.query_any(con, 'specimen_collection', data)
    for row in result:
        yield SpecimenCollection(**row.as_dict())

@beartype.beartype
def read_specimen_collection_one_or_none(con: db.Connection, specimen_collection_cv: Optional[str] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_collection_file: Optional[str] = None,
             specimen_collection_name: Optional[str] = None,
             specimen_collection_note: Optional[str] = None,
             parent_specimen_collection_id: Optional[int] = None) -> Optional[SpecimenCollection]:
    """
    Read from the specimen_collection table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    result = db.query_one_or_none(con, 'specimen_collection', data)
    if result is None:
        return None
    return SpecimenCollection(**result)

@beartype.beartype
def read_specimen_collection_one(con: db.Connection, specimen_collection_cv: Optional[str] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_collection_file: Optional[str] = None,
             specimen_collection_name: Optional[str] = None,
             specimen_collection_note: Optional[str] = None,
             parent_specimen_collection_id: Optional[int] = None) -> SpecimenCollection:
    """
    Read from the specimen_collection table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    result = db.query_one(con, 'specimen_collection', data)
    return SpecimenCollection(**result)

@beartype.beartype
def read_specimen_collection_all(con: db.Connection, specimen_collection_cv: Optional[str] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_collection_file: Optional[str] = None,
             specimen_collection_name: Optional[str] = None,
             specimen_collection_note: Optional[str] = None,
             parent_specimen_collection_id: Optional[int] = None) -> List[SpecimenCollection]:
    """
    Read from the specimen_collection table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'specimen_collection_id': specimen_collection_id,
        'specimen_collection_cv': specimen_collection_cv,
        'specimen_collection_file': specimen_collection_file,
        'specimen_collection_name': specimen_collection_name,
        'specimen_collection_note': specimen_collection_note,
        'parent_specimen_collection_id': parent_specimen_collection_id,
    }
    result = db.query(con, 'specimen_collection', data)
    return [SpecimenCollection(**row.as_dict()) for row in result]

@beartype.beartype
def read_specimen_collection_by_id(con: db.Connection, specimen_collection_id: int) -> Optional[SpecimenCollection]:
    result = db.query_one(con, 'specimen_collection', {'specimen_collection_id': specimen_collection_id})
    if result is None:
        return None
    return SpecimenCollection(**result)

@beartype.beartype
def delete_specimen_collection_by_id(con: db.Connection, specimen_collection_id: int):
    db.delete(con, 'specimen_collection', {'specimen_collection_id': specimen_collection_id})
# Associate the functions with the class
SpecimenCollection.create_from_json_dict = create_specimen_collection_from_json_dict
SpecimenCollection.write = write_specimen_collection
SpecimenCollection.update = update_specimen_collection
SpecimenCollection.write_many = write_specimen_collection_many
SpecimenCollection.read = read_specimen_collection
SpecimenCollection.read_fuzzy = read_specimen_collection_fuzzy
SpecimenCollection.read_any = read_specimen_collection_any
SpecimenCollection.read_one = read_specimen_collection_one
SpecimenCollection.read_one_or_none = read_specimen_collection_one_or_none
SpecimenCollection.read_all = read_specimen_collection_all
SpecimenCollection.delete = delete_specimen_collection_by_id
SpecimenCollection.read_by_id = read_specimen_collection_by_id
SpecimenCollection.delete_by_id = delete_specimen_collection_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SampledFeatures:
    """
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param feature_of_interest_id 

    This is an automatically generated class
    """
    relation_id: int # relation_id integer (default: )
    sampling_feature_id: int # sampling_feature_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    feature_of_interest_id: int # feature_of_interest_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_feature_of_interest(self, con: db.Connection) -> Optional['FeaturesOfInterest']:
        return read_features_of_interest_one_or_none(con, features_of_interest_id=self.feature_of_interest_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_sampled_features_from_json_dict(json_obj: dict):
        """
        Create a SampledFeatures from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SampledFeatures(**json_obj)


@beartype.beartype
def write_sampled_features_obj(con: db.Connection, obj: SampledFeatures) -> int:
    """
    Write a SampledFeatures object to the database
    @param con: database connection
    @param obj: SampledFeatures object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'sampled_features', dataclasses.asdict(obj))

@beartype.beartype
def write_sampled_features(
            con: db.Connection,
            relation_id: int,
            sampling_feature_id: int,
            relationship_type_cv: str,
            feature_of_interest_id: int) -> int:
    """
    Write to the sampled_features table in the database
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param feature_of_interest_id 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    return db.upsert(con, 'sampled_features', data)

@beartype.beartype
def write_sampled_features_many(con: db.Connection, objs: List[SampledFeatures], upsert: bool = False) -> int:
    """
    Write a list of SampledFeatures objects to the database
    @param con: database connection
    @param objs: list of SampledFeatures objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'sampled_features', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_sampled_features(con: db.Connection, relation_id: int,
            sampling_feature_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            feature_of_interest_id: Optional[int] = None) -> int:
    """
    Update a row in the sampled_features table in the database
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param feature_of_interest_id 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    return db.update(con, 'sampled_features', data)

@beartype.beartype
def read_sampled_features(
            con: db.Connection,
            relation_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             feature_of_interest_id: Optional[int] = None) -> Generator[SampledFeatures, None, None]:
    """
    Read from the sampled_features table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param feature_of_interest_id 
    @return generator of SampledFeatures objects
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    result = db.query(con, 'sampled_features', data)
    for row in result:
        yield SampledFeatures(**row.as_dict())

@beartype.beartype
def read_sampled_features_fuzzy(con: db.Connection, relation_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             feature_of_interest_id: Optional[int] = None) -> Generator[SampledFeatures, None, None]:
    """
    Read from the sampled_features table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param feature_of_interest_id 
    @return generator of SampledFeatures objects
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    result = db.query_fuzzy(con, 'sampled_features', data)
    for row in result:
        yield SampledFeatures(**row.as_dict())

@beartype.beartype
def read_sampled_features_any(con: db.Connection, relation_id: Optional[List[int]] = None,
             sampling_feature_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             feature_of_interest_id: Optional[List[int]] = None) -> Generator[SampledFeatures, None, None]:
    """
    Read from the sampled_features table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param feature_of_interest_id 
    @return generator of SampledFeatures objects
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    result = db.query_any(con, 'sampled_features', data)
    for row in result:
        yield SampledFeatures(**row.as_dict())

@beartype.beartype
def read_sampled_features_one_or_none(con: db.Connection, relation_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             feature_of_interest_id: Optional[int] = None) -> Optional[SampledFeatures]:
    """
    Read from the sampled_features table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    result = db.query_one_or_none(con, 'sampled_features', data)
    if result is None:
        return None
    return SampledFeatures(**result)

@beartype.beartype
def read_sampled_features_one(con: db.Connection, relation_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             feature_of_interest_id: Optional[int] = None) -> SampledFeatures:
    """
    Read from the sampled_features table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    result = db.query_one(con, 'sampled_features', data)
    return SampledFeatures(**result)

@beartype.beartype
def read_sampled_features_all(con: db.Connection, relation_id: Optional[int] = None,
             sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             feature_of_interest_id: Optional[int] = None) -> List[SampledFeatures]:
    """
    Read from the sampled_features table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'feature_of_interest_id': feature_of_interest_id,
    }
    result = db.query(con, 'sampled_features', data)
    return [SampledFeatures(**row.as_dict()) for row in result]

@beartype.beartype
def read_sampled_features_by_id(con: db.Connection, relation_id: int) -> Optional[SampledFeatures]:
    result = db.query_one(con, 'sampled_features', {'relation_id': relation_id})
    if result is None:
        return None
    return SampledFeatures(**result)

@beartype.beartype
def delete_sampled_features_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'sampled_features', {'relation_id': relation_id})
# Associate the functions with the class
SampledFeatures.create_from_json_dict = create_sampled_features_from_json_dict
SampledFeatures.write = write_sampled_features
SampledFeatures.update = update_sampled_features
SampledFeatures.write_many = write_sampled_features_many
SampledFeatures.read = read_sampled_features
SampledFeatures.read_fuzzy = read_sampled_features_fuzzy
SampledFeatures.read_any = read_sampled_features_any
SampledFeatures.read_one = read_sampled_features_one
SampledFeatures.read_one_or_none = read_sampled_features_one_or_none
SampledFeatures.read_all = read_sampled_features_all
SampledFeatures.delete = delete_sampled_features_by_id
SampledFeatures.read_by_id = read_sampled_features_by_id
SampledFeatures.delete_by_id = delete_sampled_features_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Specimens:
    """
    Equivalent to O&M Sampling Feature Type specimen.  Describes physical samples or specimens.

    @param sampling_feature_id 
    @param specimen_type_cv 
    @param specimen_medium_cv 
    @param is_field_specimen 
    @param specimen_collection_date_time 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    specimen_type_cv: str # specimen_type_cv character varying (default: )
    specimen_medium_cv: str # specimen_medium_cv character varying (default: )
    is_field_specimen: bool # is_field_specimen boolean (default: )
    specimen_collection_date_time: Optional[datetime.datetime] = None # specimen_collection_date_time timestamp without time zone (default: )
    PRIMARY_KEY: ClassVar[str] = 'sampling_feature_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        if self.specimen_collection_date_time is not None:
            obj['specimen_collection_date_time'] = self.specimen_collection_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_specimen_medium_cv(self, con: db.Connection) -> Optional['CvMedium']:
        return read_cv_medium_one_or_none(con, term=self.specimen_medium_cv)

    @beartype.beartype
    def get_specimen_type_cv(self, con: db.Connection) -> Optional['CvSpecimenType']:
        return read_cv_specimen_type_one_or_none(con, term=self.specimen_type_cv)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_specimens_from_json_dict(json_obj: dict):
        """
        Create a Specimens from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        if 'specimen_collection_date_time' in json_obj and json_obj['specimen_collection_date_time'] is not None:
            json_obj['specimen_collection_date_time'] = datetime.datetime.fromisoformat(json_obj['specimen_collection_date_time'])
        return Specimens(**json_obj)


@beartype.beartype
def write_specimens_obj(con: db.Connection, obj: Specimens) -> int:
    """
    Write a Specimens object to the database
    @param con: database connection
    @param obj: Specimens object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'specimens', dataclasses.asdict(obj))

@beartype.beartype
def write_specimens(
            con: db.Connection,
            sampling_feature_id: int,
            specimen_type_cv: str,
            specimen_medium_cv: str,
            is_field_specimen: bool,
            specimen_collection_date_time: Optional[datetime.datetime] = None) -> int:
    """
    Write to the specimens table in the database
    @param con: database connection
    @param sampling_feature_id 
    @param specimen_type_cv 
    @param specimen_medium_cv 
    @param is_field_specimen 
    @param specimen_collection_date_time 
    @return id of the inserted/updated row
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    return db.upsert(con, 'specimens', data)

@beartype.beartype
def write_specimens_many(con: db.Connection, objs: List[Specimens], upsert: bool = False) -> int:
    """
    Write a list of Specimens objects to the database
    @param con: database connection
    @param objs: list of Specimens objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'specimens', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_specimens(con: db.Connection, sampling_feature_id: int,
            specimen_type_cv: Optional[str] = None,
            specimen_medium_cv: Optional[str] = None,
            is_field_specimen: Optional[bool] = None,
            specimen_collection_date_time: Optional[datetime.datetime] = None) -> int:
    """
    Update a row in the specimens table in the database
    @param con: database connection
    @param sampling_feature_id 
    @param specimen_type_cv 
    @param specimen_medium_cv 
    @param is_field_specimen 
    @param specimen_collection_date_time 
    @return The number of rows updated
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    return db.update(con, 'specimens', data)

@beartype.beartype
def read_specimens(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             specimen_type_cv: Optional[str] = None,
             specimen_medium_cv: Optional[str] = None,
             is_field_specimen: Optional[bool] = None,
             specimen_collection_date_time: Optional[datetime.datetime] = None) -> Generator[Specimens, None, None]:
    """
    Read from the specimens table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_feature_id 
    @param specimen_type_cv 
    @param specimen_medium_cv 
    @param is_field_specimen 
    @param specimen_collection_date_time 
    @return generator of Specimens objects
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    result = db.query(con, 'specimens', data)
    for row in result:
        yield Specimens(**row.as_dict())

@beartype.beartype
def read_specimens_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_type_cv: Optional[str] = None,
             specimen_medium_cv: Optional[str] = None,
             is_field_specimen: Optional[bool] = None,
             specimen_collection_date_time: Optional[datetime.datetime] = None) -> Generator[Specimens, None, None]:
    """
    Read from the specimens table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_feature_id 
    @param specimen_type_cv 
    @param specimen_medium_cv 
    @param is_field_specimen 
    @param specimen_collection_date_time 
    @return generator of Specimens objects
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    result = db.query_fuzzy(con, 'specimens', data)
    for row in result:
        yield Specimens(**row.as_dict())

@beartype.beartype
def read_specimens_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             specimen_type_cv: Optional[List[str]] = None,
             specimen_medium_cv: Optional[List[str]] = None,
             is_field_specimen: Optional[List[bool]] = None,
             specimen_collection_date_time: Optional[List[datetime.datetime]] = None) -> Generator[Specimens, None, None]:
    """
    Read from the specimens table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param sampling_feature_id 
    @param specimen_type_cv 
    @param specimen_medium_cv 
    @param is_field_specimen 
    @param specimen_collection_date_time 
    @return generator of Specimens objects
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    result = db.query_any(con, 'specimens', data)
    for row in result:
        yield Specimens(**row.as_dict())

@beartype.beartype
def read_specimens_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_type_cv: Optional[str] = None,
             specimen_medium_cv: Optional[str] = None,
             is_field_specimen: Optional[bool] = None,
             specimen_collection_date_time: Optional[datetime.datetime] = None) -> Optional[Specimens]:
    """
    Read from the specimens table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    result = db.query_one_or_none(con, 'specimens', data)
    if result is None:
        return None
    return Specimens(**result)

@beartype.beartype
def read_specimens_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_type_cv: Optional[str] = None,
             specimen_medium_cv: Optional[str] = None,
             is_field_specimen: Optional[bool] = None,
             specimen_collection_date_time: Optional[datetime.datetime] = None) -> Specimens:
    """
    Read from the specimens table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    result = db.query_one(con, 'specimens', data)
    return Specimens(**result)

@beartype.beartype
def read_specimens_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_type_cv: Optional[str] = None,
             specimen_medium_cv: Optional[str] = None,
             is_field_specimen: Optional[bool] = None,
             specimen_collection_date_time: Optional[datetime.datetime] = None) -> List[Specimens]:
    """
    Read from the specimens table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'sampling_feature_id': sampling_feature_id,
        'specimen_type_cv': specimen_type_cv,
        'specimen_medium_cv': specimen_medium_cv,
        'is_field_specimen': is_field_specimen,
        'specimen_collection_date_time': specimen_collection_date_time,
    }
    result = db.query(con, 'specimens', data)
    return [Specimens(**row.as_dict()) for row in result]

@beartype.beartype
def read_specimens_by_id(con: db.Connection, sampling_feature_id: int) -> Optional[Specimens]:
    result = db.query_one(con, 'specimens', {'sampling_feature_id': sampling_feature_id})
    if result is None:
        return None
    return Specimens(**result)

@beartype.beartype
def delete_specimens_by_id(con: db.Connection, sampling_feature_id: int):
    db.delete(con, 'specimens', {'sampling_feature_id': sampling_feature_id})
# Associate the functions with the class
Specimens.create_from_json_dict = create_specimens_from_json_dict
Specimens.write = write_specimens
Specimens.update = update_specimens
Specimens.write_many = write_specimens_many
Specimens.read = read_specimens
Specimens.read_fuzzy = read_specimens_fuzzy
Specimens.read_any = read_specimens_any
Specimens.read_one = read_specimens_one
Specimens.read_one_or_none = read_specimens_one_or_none
Specimens.read_all = read_specimens_all
Specimens.delete = delete_specimens_by_id
Specimens.read_by_id = read_specimens_by_id
Specimens.delete_by_id = delete_specimens_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpecimenTaxonomicClassifiers:
    """
    This cross-reference table allows Taxonomic Classification of Specimens as an annotation, rather than as a Result.

    @param bridge_id 
    @param sampling_feature_id 
    @param taxonomic_classifier_id 
    @param citation_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    taxonomic_classifier_id: int # taxonomic_classifier_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    citation_id: Optional[int] = None # citation_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_citation(self, con: db.Connection) -> Optional['Citations']:
        return read_citations_one_or_none(con, citation_id=self.citation_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['Specimens']:
        return read_specimens_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

    @beartype.beartype
    def get_taxonomic_classifier(self, con: db.Connection) -> Optional['TaxonomicClassifiers']:
        return read_taxonomic_classifiers_one_or_none(con, taxonomic_classifier_id=self.taxonomic_classifier_id)

@beartype.beartype
def create_specimen_taxonomic_classifiers_from_json_dict(json_obj: dict):
        """
        Create a SpecimenTaxonomicClassifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpecimenTaxonomicClassifiers(**json_obj)


@beartype.beartype
def write_specimen_taxonomic_classifiers_obj(con: db.Connection, obj: SpecimenTaxonomicClassifiers) -> int:
    """
    Write a SpecimenTaxonomicClassifiers object to the database
    @param con: database connection
    @param obj: SpecimenTaxonomicClassifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'specimen_taxonomic_classifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_specimen_taxonomic_classifiers(
            con: db.Connection,
            sampling_feature_id: int,
            taxonomic_classifier_id: int,
            bridge_id: Optional[int] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Write to the specimen_taxonomic_classifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param taxonomic_classifier_id 
    @param citation_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    return db.upsert(con, 'specimen_taxonomic_classifiers', data)

@beartype.beartype
def write_specimen_taxonomic_classifiers_many(con: db.Connection, objs: List[SpecimenTaxonomicClassifiers], upsert: bool = False) -> int:
    """
    Write a list of SpecimenTaxonomicClassifiers objects to the database
    @param con: database connection
    @param objs: list of SpecimenTaxonomicClassifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'specimen_taxonomic_classifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_specimen_taxonomic_classifiers(con: db.Connection, bridge_id: int,
            sampling_feature_id: Optional[int] = None,
            taxonomic_classifier_id: Optional[int] = None,
            citation_id: Optional[int] = None) -> int:
    """
    Update a row in the specimen_taxonomic_classifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param taxonomic_classifier_id 
    @param citation_id 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    return db.update(con, 'specimen_taxonomic_classifiers', data)

@beartype.beartype
def read_specimen_taxonomic_classifiers(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             taxonomic_classifier_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Generator[SpecimenTaxonomicClassifiers, None, None]:
    """
    Read from the specimen_taxonomic_classifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param taxonomic_classifier_id 
    @param citation_id 
    @return generator of SpecimenTaxonomicClassifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    result = db.query(con, 'specimen_taxonomic_classifiers', data)
    for row in result:
        yield SpecimenTaxonomicClassifiers(**row.as_dict())

@beartype.beartype
def read_specimen_taxonomic_classifiers_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             taxonomic_classifier_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Generator[SpecimenTaxonomicClassifiers, None, None]:
    """
    Read from the specimen_taxonomic_classifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param taxonomic_classifier_id 
    @param citation_id 
    @return generator of SpecimenTaxonomicClassifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    result = db.query_fuzzy(con, 'specimen_taxonomic_classifiers', data)
    for row in result:
        yield SpecimenTaxonomicClassifiers(**row.as_dict())

@beartype.beartype
def read_specimen_taxonomic_classifiers_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             taxonomic_classifier_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None,
             citation_id: Optional[List[int]] = None) -> Generator[SpecimenTaxonomicClassifiers, None, None]:
    """
    Read from the specimen_taxonomic_classifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param sampling_feature_id 
    @param taxonomic_classifier_id 
    @param citation_id 
    @return generator of SpecimenTaxonomicClassifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    result = db.query_any(con, 'specimen_taxonomic_classifiers', data)
    for row in result:
        yield SpecimenTaxonomicClassifiers(**row.as_dict())

@beartype.beartype
def read_specimen_taxonomic_classifiers_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             taxonomic_classifier_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> Optional[SpecimenTaxonomicClassifiers]:
    """
    Read from the specimen_taxonomic_classifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    result = db.query_one_or_none(con, 'specimen_taxonomic_classifiers', data)
    if result is None:
        return None
    return SpecimenTaxonomicClassifiers(**result)

@beartype.beartype
def read_specimen_taxonomic_classifiers_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             taxonomic_classifier_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> SpecimenTaxonomicClassifiers:
    """
    Read from the specimen_taxonomic_classifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    result = db.query_one(con, 'specimen_taxonomic_classifiers', data)
    return SpecimenTaxonomicClassifiers(**result)

@beartype.beartype
def read_specimen_taxonomic_classifiers_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             taxonomic_classifier_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             citation_id: Optional[int] = None) -> List[SpecimenTaxonomicClassifiers]:
    """
    Read from the specimen_taxonomic_classifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'taxonomic_classifier_id': taxonomic_classifier_id,
        'citation_id': citation_id,
    }
    result = db.query(con, 'specimen_taxonomic_classifiers', data)
    return [SpecimenTaxonomicClassifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_specimen_taxonomic_classifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[SpecimenTaxonomicClassifiers]:
    result = db.query_one(con, 'specimen_taxonomic_classifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return SpecimenTaxonomicClassifiers(**result)

@beartype.beartype
def delete_specimen_taxonomic_classifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'specimen_taxonomic_classifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
SpecimenTaxonomicClassifiers.create_from_json_dict = create_specimen_taxonomic_classifiers_from_json_dict
SpecimenTaxonomicClassifiers.write = write_specimen_taxonomic_classifiers
SpecimenTaxonomicClassifiers.update = update_specimen_taxonomic_classifiers
SpecimenTaxonomicClassifiers.write_many = write_specimen_taxonomic_classifiers_many
SpecimenTaxonomicClassifiers.read = read_specimen_taxonomic_classifiers
SpecimenTaxonomicClassifiers.read_fuzzy = read_specimen_taxonomic_classifiers_fuzzy
SpecimenTaxonomicClassifiers.read_any = read_specimen_taxonomic_classifiers_any
SpecimenTaxonomicClassifiers.read_one = read_specimen_taxonomic_classifiers_one
SpecimenTaxonomicClassifiers.read_one_or_none = read_specimen_taxonomic_classifiers_one_or_none
SpecimenTaxonomicClassifiers.read_all = read_specimen_taxonomic_classifiers_all
SpecimenTaxonomicClassifiers.delete = delete_specimen_taxonomic_classifiers_by_id
SpecimenTaxonomicClassifiers.read_by_id = read_specimen_taxonomic_classifiers_by_id
SpecimenTaxonomicClassifiers.delete_by_id = delete_specimen_taxonomic_classifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SoilprobeMonitoring:
    """
    this table keeps track of monitoring surveys

    @param soilprobe_monitoring_id 
    @param sampling_feature_id 
    @param monitoring_survey_name 
    @param first_measurement_date 
    @param last_measurement_date 
    @param ert_system_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    monitoring_survey_name: str # monitoring_survey_name character varying (default: )
    first_measurement_date: datetime.datetime # first_measurement_date timestamp without time zone (default: )
    last_measurement_date: datetime.datetime # last_measurement_date timestamp without time zone (default: )
    ert_system_id: str # ert_system_id character varying (default: )
    soilprobe_monitoring_id: Optional[int] = None # soilprobe_monitoring_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'soilprobe_monitoring_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['first_measurement_date'] = self.first_measurement_date.isoformat()
        obj['last_measurement_date'] = self.last_measurement_date.isoformat()
        return obj

@beartype.beartype
def create_soilprobe_monitoring_from_json_dict(json_obj: dict):
        """
        Create a SoilprobeMonitoring from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['first_measurement_date'] = datetime.datetime.fromisoformat(json_obj['first_measurement_date'])
        json_obj['last_measurement_date'] = datetime.datetime.fromisoformat(json_obj['last_measurement_date'])
        return SoilprobeMonitoring(**json_obj)


@beartype.beartype
def write_soilprobe_monitoring_obj(con: db.Connection, obj: SoilprobeMonitoring) -> int:
    """
    Write a SoilprobeMonitoring object to the database
    @param con: database connection
    @param obj: SoilprobeMonitoring object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'soilprobe_monitoring', dataclasses.asdict(obj))

@beartype.beartype
def write_soilprobe_monitoring(
            con: db.Connection,
            sampling_feature_id: int,
            monitoring_survey_name: str,
            first_measurement_date: datetime.datetime,
            last_measurement_date: datetime.datetime,
            ert_system_id: str,
            soilprobe_monitoring_id: Optional[int] = None) -> int:
    """
    Write to the soilprobe_monitoring table in the database
    @param con: database connection
    @param soilprobe_monitoring_id 
    @param sampling_feature_id 
    @param monitoring_survey_name 
    @param first_measurement_date 
    @param last_measurement_date 
    @param ert_system_id 
    @return id of the inserted/updated row
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    return db.upsert(con, 'soilprobe_monitoring', data)

@beartype.beartype
def write_soilprobe_monitoring_many(con: db.Connection, objs: List[SoilprobeMonitoring], upsert: bool = False) -> int:
    """
    Write a list of SoilprobeMonitoring objects to the database
    @param con: database connection
    @param objs: list of SoilprobeMonitoring objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'soilprobe_monitoring', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_soilprobe_monitoring(con: db.Connection, soilprobe_monitoring_id: int,
            sampling_feature_id: Optional[int] = None,
            monitoring_survey_name: Optional[str] = None,
            first_measurement_date: Optional[datetime.datetime] = None,
            last_measurement_date: Optional[datetime.datetime] = None,
            ert_system_id: Optional[str] = None) -> int:
    """
    Update a row in the soilprobe_monitoring table in the database
    @param con: database connection
    @param soilprobe_monitoring_id 
    @param sampling_feature_id 
    @param monitoring_survey_name 
    @param first_measurement_date 
    @param last_measurement_date 
    @param ert_system_id 
    @return The number of rows updated
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    return db.update(con, 'soilprobe_monitoring', data)

@beartype.beartype
def read_soilprobe_monitoring(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             monitoring_survey_name: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             ert_system_id: Optional[str] = None,
             soilprobe_monitoring_id: Optional[int] = None) -> Generator[SoilprobeMonitoring, None, None]:
    """
    Read from the soilprobe_monitoring table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_id 
    @param sampling_feature_id 
    @param monitoring_survey_name 
    @param first_measurement_date 
    @param last_measurement_date 
    @param ert_system_id 
    @return generator of SoilprobeMonitoring objects
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    result = db.query(con, 'soilprobe_monitoring', data)
    for row in result:
        yield SoilprobeMonitoring(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             monitoring_survey_name: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             ert_system_id: Optional[str] = None,
             soilprobe_monitoring_id: Optional[int] = None) -> Generator[SoilprobeMonitoring, None, None]:
    """
    Read from the soilprobe_monitoring table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_id 
    @param sampling_feature_id 
    @param monitoring_survey_name 
    @param first_measurement_date 
    @param last_measurement_date 
    @param ert_system_id 
    @return generator of SoilprobeMonitoring objects
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    result = db.query_fuzzy(con, 'soilprobe_monitoring', data)
    for row in result:
        yield SoilprobeMonitoring(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             monitoring_survey_name: Optional[List[str]] = None,
             first_measurement_date: Optional[List[datetime.datetime]] = None,
             last_measurement_date: Optional[List[datetime.datetime]] = None,
             ert_system_id: Optional[List[str]] = None,
             soilprobe_monitoring_id: Optional[List[int]] = None) -> Generator[SoilprobeMonitoring, None, None]:
    """
    Read from the soilprobe_monitoring table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_id 
    @param sampling_feature_id 
    @param monitoring_survey_name 
    @param first_measurement_date 
    @param last_measurement_date 
    @param ert_system_id 
    @return generator of SoilprobeMonitoring objects
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    result = db.query_any(con, 'soilprobe_monitoring', data)
    for row in result:
        yield SoilprobeMonitoring(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             monitoring_survey_name: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             ert_system_id: Optional[str] = None,
             soilprobe_monitoring_id: Optional[int] = None) -> Optional[SoilprobeMonitoring]:
    """
    Read from the soilprobe_monitoring table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    result = db.query_one_or_none(con, 'soilprobe_monitoring', data)
    if result is None:
        return None
    return SoilprobeMonitoring(**result)

@beartype.beartype
def read_soilprobe_monitoring_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             monitoring_survey_name: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             ert_system_id: Optional[str] = None,
             soilprobe_monitoring_id: Optional[int] = None) -> SoilprobeMonitoring:
    """
    Read from the soilprobe_monitoring table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    result = db.query_one(con, 'soilprobe_monitoring', data)
    return SoilprobeMonitoring(**result)

@beartype.beartype
def read_soilprobe_monitoring_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             monitoring_survey_name: Optional[str] = None,
             first_measurement_date: Optional[datetime.datetime] = None,
             last_measurement_date: Optional[datetime.datetime] = None,
             ert_system_id: Optional[str] = None,
             soilprobe_monitoring_id: Optional[int] = None) -> List[SoilprobeMonitoring]:
    """
    Read from the soilprobe_monitoring table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'sampling_feature_id': sampling_feature_id,
        'monitoring_survey_name': monitoring_survey_name,
        'first_measurement_date': first_measurement_date,
        'last_measurement_date': last_measurement_date,
        'ert_system_id': ert_system_id,
    }
    result = db.query(con, 'soilprobe_monitoring', data)
    return [SoilprobeMonitoring(**row.as_dict()) for row in result]

@beartype.beartype
def read_soilprobe_monitoring_by_id(con: db.Connection, soilprobe_monitoring_id: int) -> Optional[SoilprobeMonitoring]:
    result = db.query_one(con, 'soilprobe_monitoring', {'soilprobe_monitoring_id': soilprobe_monitoring_id})
    if result is None:
        return None
    return SoilprobeMonitoring(**result)

@beartype.beartype
def delete_soilprobe_monitoring_by_id(con: db.Connection, soilprobe_monitoring_id: int):
    db.delete(con, 'soilprobe_monitoring', {'soilprobe_monitoring_id': soilprobe_monitoring_id})
# Associate the functions with the class
SoilprobeMonitoring.create_from_json_dict = create_soilprobe_monitoring_from_json_dict
SoilprobeMonitoring.write = write_soilprobe_monitoring
SoilprobeMonitoring.update = update_soilprobe_monitoring
SoilprobeMonitoring.write_many = write_soilprobe_monitoring_many
SoilprobeMonitoring.read = read_soilprobe_monitoring
SoilprobeMonitoring.read_fuzzy = read_soilprobe_monitoring_fuzzy
SoilprobeMonitoring.read_any = read_soilprobe_monitoring_any
SoilprobeMonitoring.read_one = read_soilprobe_monitoring_one
SoilprobeMonitoring.read_one_or_none = read_soilprobe_monitoring_one_or_none
SoilprobeMonitoring.read_all = read_soilprobe_monitoring_all
SoilprobeMonitoring.delete = delete_soilprobe_monitoring_by_id
SoilprobeMonitoring.read_by_id = read_soilprobe_monitoring_by_id
SoilprobeMonitoring.delete_by_id = delete_soilprobe_monitoring_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedFeatures:
    """
    Describes parrent/child relationships among Sampling Features

    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param related_feature_id 
    @param spatial_offset_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_feature_id: int # related_feature_id integer (default: )
    relation_id: Optional[int] = None # relation_id integer (default: )
    spatial_offset_id: Optional[int] = None # spatial_offset_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'relation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

    @beartype.beartype
    def get_spatial_offset(self, con: db.Connection) -> Optional['SpatialOffsets']:
        return read_spatial_offsets_one_or_none(con, spatial_offset_id=self.spatial_offset_id)

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_related_feature(self, con: db.Connection) -> Optional['SamplingFeatures']:
        return read_sampling_features_one_or_none(con, sampling_feature_id=self.related_feature_id)

@beartype.beartype
def create_related_features_from_json_dict(json_obj: dict):
        """
        Create a RelatedFeatures from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedFeatures(**json_obj)


@beartype.beartype
def write_related_features_obj(con: db.Connection, obj: RelatedFeatures) -> int:
    """
    Write a RelatedFeatures object to the database
    @param con: database connection
    @param obj: RelatedFeatures object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_features', dataclasses.asdict(obj))

@beartype.beartype
def write_related_features(
            con: db.Connection,
            sampling_feature_id: int,
            relationship_type_cv: str,
            related_feature_id: int,
            relation_id: Optional[int] = None,
            spatial_offset_id: Optional[int] = None) -> int:
    """
    Write to the related_features table in the database
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param related_feature_id 
    @param spatial_offset_id 
    @return id of the inserted/updated row
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    return db.upsert(con, 'related_features', data)

@beartype.beartype
def write_related_features_many(con: db.Connection, objs: List[RelatedFeatures], upsert: bool = False) -> int:
    """
    Write a list of RelatedFeatures objects to the database
    @param con: database connection
    @param objs: list of RelatedFeatures objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_features', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_features(con: db.Connection, relation_id: int,
            sampling_feature_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_feature_id: Optional[int] = None,
            spatial_offset_id: Optional[int] = None) -> int:
    """
    Update a row in the related_features table in the database
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param related_feature_id 
    @param spatial_offset_id 
    @return The number of rows updated
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    return db.update(con, 'related_features', data)

@beartype.beartype
def read_related_features(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_feature_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None) -> Generator[RelatedFeatures, None, None]:
    """
    Read from the related_features table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param related_feature_id 
    @param spatial_offset_id 
    @return generator of RelatedFeatures objects
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    result = db.query(con, 'related_features', data)
    for row in result:
        yield RelatedFeatures(**row.as_dict())

@beartype.beartype
def read_related_features_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_feature_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None) -> Generator[RelatedFeatures, None, None]:
    """
    Read from the related_features table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param related_feature_id 
    @param spatial_offset_id 
    @return generator of RelatedFeatures objects
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    result = db.query_fuzzy(con, 'related_features', data)
    for row in result:
        yield RelatedFeatures(**row.as_dict())

@beartype.beartype
def read_related_features_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_feature_id: Optional[List[int]] = None,
             relation_id: Optional[List[int]] = None,
             spatial_offset_id: Optional[List[int]] = None) -> Generator[RelatedFeatures, None, None]:
    """
    Read from the related_features table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param relation_id 
    @param sampling_feature_id 
    @param relationship_type_cv 
    @param related_feature_id 
    @param spatial_offset_id 
    @return generator of RelatedFeatures objects
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    result = db.query_any(con, 'related_features', data)
    for row in result:
        yield RelatedFeatures(**row.as_dict())

@beartype.beartype
def read_related_features_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_feature_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None) -> Optional[RelatedFeatures]:
    """
    Read from the related_features table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    result = db.query_one_or_none(con, 'related_features', data)
    if result is None:
        return None
    return RelatedFeatures(**result)

@beartype.beartype
def read_related_features_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_feature_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None) -> RelatedFeatures:
    """
    Read from the related_features table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    result = db.query_one(con, 'related_features', data)
    return RelatedFeatures(**result)

@beartype.beartype
def read_related_features_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_feature_id: Optional[int] = None,
             relation_id: Optional[int] = None,
             spatial_offset_id: Optional[int] = None) -> List[RelatedFeatures]:
    """
    Read from the related_features table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'relation_id': relation_id,
        'sampling_feature_id': sampling_feature_id,
        'relationship_type_cv': relationship_type_cv,
        'related_feature_id': related_feature_id,
        'spatial_offset_id': spatial_offset_id,
    }
    result = db.query(con, 'related_features', data)
    return [RelatedFeatures(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_features_by_id(con: db.Connection, relation_id: int) -> Optional[RelatedFeatures]:
    result = db.query_one(con, 'related_features', {'relation_id': relation_id})
    if result is None:
        return None
    return RelatedFeatures(**result)

@beartype.beartype
def delete_related_features_by_id(con: db.Connection, relation_id: int):
    db.delete(con, 'related_features', {'relation_id': relation_id})
# Associate the functions with the class
RelatedFeatures.create_from_json_dict = create_related_features_from_json_dict
RelatedFeatures.write = write_related_features
RelatedFeatures.update = update_related_features
RelatedFeatures.write_many = write_related_features_many
RelatedFeatures.read = read_related_features
RelatedFeatures.read_fuzzy = read_related_features_fuzzy
RelatedFeatures.read_any = read_related_features_any
RelatedFeatures.read_one = read_related_features_one
RelatedFeatures.read_one_or_none = read_related_features_one_or_none
RelatedFeatures.read_all = read_related_features_all
RelatedFeatures.delete = delete_related_features_by_id
RelatedFeatures.read_by_id = read_related_features_by_id
RelatedFeatures.delete_by_id = delete_related_features_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SoilprobeMonitoringTemperatureDatastream:
    """
    @param soilprobe_monitoring_temperature_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param sensor_depth_meters 

    This is an automatically generated class
    """
    soilprobe_monitoring_id: int # soilprobe_monitoring_id integer (default: )
    datastream_id: int # datastream_id integer (default: )
    sensor_depth_meters: float # sensor_depth_meters double precision (default: )
    soilprobe_monitoring_temperature_datastream_id: Optional[int] = None # soilprobe_monitoring_temperature_datastream_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'soilprobe_monitoring_temperature_datastream_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_soilprobe_monitoring(self, con: db.Connection) -> Optional['SoilprobeMonitoring']:
        return read_soilprobe_monitoring_one_or_none(con, soilprobe_monitoring_id=self.soilprobe_monitoring_id)

@beartype.beartype
def create_soilprobe_monitoring_temperature_datastream_from_json_dict(json_obj: dict):
        """
        Create a SoilprobeMonitoringTemperatureDatastream from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SoilprobeMonitoringTemperatureDatastream(**json_obj)


@beartype.beartype
def write_soilprobe_monitoring_temperature_datastream_obj(con: db.Connection, obj: SoilprobeMonitoringTemperatureDatastream) -> int:
    """
    Write a SoilprobeMonitoringTemperatureDatastream object to the database
    @param con: database connection
    @param obj: SoilprobeMonitoringTemperatureDatastream object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'soilprobe_monitoring_temperature_datastream', dataclasses.asdict(obj))

@beartype.beartype
def write_soilprobe_monitoring_temperature_datastream(
            con: db.Connection,
            soilprobe_monitoring_id: int,
            datastream_id: int,
            sensor_depth_meters: float,
            soilprobe_monitoring_temperature_datastream_id: Optional[int] = None) -> int:
    """
    Write to the soilprobe_monitoring_temperature_datastream table in the database
    @param con: database connection
    @param soilprobe_monitoring_temperature_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param sensor_depth_meters 
    @return id of the inserted/updated row
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    return db.upsert(con, 'soilprobe_monitoring_temperature_datastream', data)

@beartype.beartype
def write_soilprobe_monitoring_temperature_datastream_many(con: db.Connection, objs: List[SoilprobeMonitoringTemperatureDatastream], upsert: bool = False) -> int:
    """
    Write a list of SoilprobeMonitoringTemperatureDatastream objects to the database
    @param con: database connection
    @param objs: list of SoilprobeMonitoringTemperatureDatastream objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'soilprobe_monitoring_temperature_datastream', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_soilprobe_monitoring_temperature_datastream(con: db.Connection, soilprobe_monitoring_temperature_datastream_id: int,
            soilprobe_monitoring_id: Optional[int] = None,
            datastream_id: Optional[int] = None,
            sensor_depth_meters: Optional[float] = None) -> int:
    """
    Update a row in the soilprobe_monitoring_temperature_datastream table in the database
    @param con: database connection
    @param soilprobe_monitoring_temperature_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param sensor_depth_meters 
    @return The number of rows updated
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    return db.update(con, 'soilprobe_monitoring_temperature_datastream', data)

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream(
            con: db.Connection,
            soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             sensor_depth_meters: Optional[float] = None,
             soilprobe_monitoring_temperature_datastream_id: Optional[int] = None) -> Generator[SoilprobeMonitoringTemperatureDatastream, None, None]:
    """
    Read from the soilprobe_monitoring_temperature_datastream table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_temperature_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param sensor_depth_meters 
    @return generator of SoilprobeMonitoringTemperatureDatastream objects
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    result = db.query(con, 'soilprobe_monitoring_temperature_datastream', data)
    for row in result:
        yield SoilprobeMonitoringTemperatureDatastream(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream_fuzzy(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             sensor_depth_meters: Optional[float] = None,
             soilprobe_monitoring_temperature_datastream_id: Optional[int] = None) -> Generator[SoilprobeMonitoringTemperatureDatastream, None, None]:
    """
    Read from the soilprobe_monitoring_temperature_datastream table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_temperature_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param sensor_depth_meters 
    @return generator of SoilprobeMonitoringTemperatureDatastream objects
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    result = db.query_fuzzy(con, 'soilprobe_monitoring_temperature_datastream', data)
    for row in result:
        yield SoilprobeMonitoringTemperatureDatastream(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream_any(con: db.Connection, soilprobe_monitoring_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             sensor_depth_meters: Optional[List[float]] = None,
             soilprobe_monitoring_temperature_datastream_id: Optional[List[int]] = None) -> Generator[SoilprobeMonitoringTemperatureDatastream, None, None]:
    """
    Read from the soilprobe_monitoring_temperature_datastream table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_temperature_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param sensor_depth_meters 
    @return generator of SoilprobeMonitoringTemperatureDatastream objects
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    result = db.query_any(con, 'soilprobe_monitoring_temperature_datastream', data)
    for row in result:
        yield SoilprobeMonitoringTemperatureDatastream(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream_one_or_none(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             sensor_depth_meters: Optional[float] = None,
             soilprobe_monitoring_temperature_datastream_id: Optional[int] = None) -> Optional[SoilprobeMonitoringTemperatureDatastream]:
    """
    Read from the soilprobe_monitoring_temperature_datastream table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    result = db.query_one_or_none(con, 'soilprobe_monitoring_temperature_datastream', data)
    if result is None:
        return None
    return SoilprobeMonitoringTemperatureDatastream(**result)

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream_one(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             sensor_depth_meters: Optional[float] = None,
             soilprobe_monitoring_temperature_datastream_id: Optional[int] = None) -> SoilprobeMonitoringTemperatureDatastream:
    """
    Read from the soilprobe_monitoring_temperature_datastream table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    result = db.query_one(con, 'soilprobe_monitoring_temperature_datastream', data)
    return SoilprobeMonitoringTemperatureDatastream(**result)

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream_all(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             sensor_depth_meters: Optional[float] = None,
             soilprobe_monitoring_temperature_datastream_id: Optional[int] = None) -> List[SoilprobeMonitoringTemperatureDatastream]:
    """
    Read from the soilprobe_monitoring_temperature_datastream table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'sensor_depth_meters': sensor_depth_meters,
    }
    result = db.query(con, 'soilprobe_monitoring_temperature_datastream', data)
    return [SoilprobeMonitoringTemperatureDatastream(**row.as_dict()) for row in result]

@beartype.beartype
def read_soilprobe_monitoring_temperature_datastream_by_id(con: db.Connection, soilprobe_monitoring_temperature_datastream_id: int) -> Optional[SoilprobeMonitoringTemperatureDatastream]:
    result = db.query_one(con, 'soilprobe_monitoring_temperature_datastream', {'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id})
    if result is None:
        return None
    return SoilprobeMonitoringTemperatureDatastream(**result)

@beartype.beartype
def delete_soilprobe_monitoring_temperature_datastream_by_id(con: db.Connection, soilprobe_monitoring_temperature_datastream_id: int):
    db.delete(con, 'soilprobe_monitoring_temperature_datastream', {'soilprobe_monitoring_temperature_datastream_id': soilprobe_monitoring_temperature_datastream_id})
# Associate the functions with the class
SoilprobeMonitoringTemperatureDatastream.create_from_json_dict = create_soilprobe_monitoring_temperature_datastream_from_json_dict
SoilprobeMonitoringTemperatureDatastream.write = write_soilprobe_monitoring_temperature_datastream
SoilprobeMonitoringTemperatureDatastream.update = update_soilprobe_monitoring_temperature_datastream
SoilprobeMonitoringTemperatureDatastream.write_many = write_soilprobe_monitoring_temperature_datastream_many
SoilprobeMonitoringTemperatureDatastream.read = read_soilprobe_monitoring_temperature_datastream
SoilprobeMonitoringTemperatureDatastream.read_fuzzy = read_soilprobe_monitoring_temperature_datastream_fuzzy
SoilprobeMonitoringTemperatureDatastream.read_any = read_soilprobe_monitoring_temperature_datastream_any
SoilprobeMonitoringTemperatureDatastream.read_one = read_soilprobe_monitoring_temperature_datastream_one
SoilprobeMonitoringTemperatureDatastream.read_one_or_none = read_soilprobe_monitoring_temperature_datastream_one_or_none
SoilprobeMonitoringTemperatureDatastream.read_all = read_soilprobe_monitoring_temperature_datastream_all
SoilprobeMonitoringTemperatureDatastream.delete = delete_soilprobe_monitoring_temperature_datastream_by_id
SoilprobeMonitoringTemperatureDatastream.read_by_id = read_soilprobe_monitoring_temperature_datastream_by_id
SoilprobeMonitoringTemperatureDatastream.delete_by_id = delete_soilprobe_monitoring_temperature_datastream_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SurveyElectrodeGeometry:
    """
    @param survey_electrode_geometry_id 
    @param soilprobe_monitoring_id 
    @param electrode_well 
    @param electrode_number 
    @param x_coordinate_meters 
    @param y_coordinate_meters 
    @param z_coordinate_meters 

    This is an automatically generated class
    """
    soilprobe_monitoring_id: int # soilprobe_monitoring_id integer (default: )
    electrode_well: int # electrode_well integer (default: )
    electrode_number: int # electrode_number integer (default: )
    x_coordinate_meters: float # x_coordinate_meters double precision (default: )
    y_coordinate_meters: float # y_coordinate_meters double precision (default: )
    z_coordinate_meters: float # z_coordinate_meters double precision (default: )
    survey_electrode_geometry_id: Optional[int] = None # survey_electrode_geometry_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'survey_electrode_geometry_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_soilprobe_monitoring(self, con: db.Connection) -> Optional['SoilprobeMonitoring']:
        return read_soilprobe_monitoring_one_or_none(con, soilprobe_monitoring_id=self.soilprobe_monitoring_id)

@beartype.beartype
def create_survey_electrode_geometry_from_json_dict(json_obj: dict):
        """
        Create a SurveyElectrodeGeometry from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SurveyElectrodeGeometry(**json_obj)


@beartype.beartype
def write_survey_electrode_geometry_obj(con: db.Connection, obj: SurveyElectrodeGeometry) -> int:
    """
    Write a SurveyElectrodeGeometry object to the database
    @param con: database connection
    @param obj: SurveyElectrodeGeometry object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'survey_electrode_geometry', dataclasses.asdict(obj))

@beartype.beartype
def write_survey_electrode_geometry(
            con: db.Connection,
            soilprobe_monitoring_id: int,
            electrode_well: int,
            electrode_number: int,
            x_coordinate_meters: float,
            y_coordinate_meters: float,
            z_coordinate_meters: float,
            survey_electrode_geometry_id: Optional[int] = None) -> int:
    """
    Write to the survey_electrode_geometry table in the database
    @param con: database connection
    @param survey_electrode_geometry_id 
    @param soilprobe_monitoring_id 
    @param electrode_well 
    @param electrode_number 
    @param x_coordinate_meters 
    @param y_coordinate_meters 
    @param z_coordinate_meters 
    @return id of the inserted/updated row
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    return db.upsert(con, 'survey_electrode_geometry', data)

@beartype.beartype
def write_survey_electrode_geometry_many(con: db.Connection, objs: List[SurveyElectrodeGeometry], upsert: bool = False) -> int:
    """
    Write a list of SurveyElectrodeGeometry objects to the database
    @param con: database connection
    @param objs: list of SurveyElectrodeGeometry objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'survey_electrode_geometry', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_survey_electrode_geometry(con: db.Connection, survey_electrode_geometry_id: int,
            soilprobe_monitoring_id: Optional[int] = None,
            electrode_well: Optional[int] = None,
            electrode_number: Optional[int] = None,
            x_coordinate_meters: Optional[float] = None,
            y_coordinate_meters: Optional[float] = None,
            z_coordinate_meters: Optional[float] = None) -> int:
    """
    Update a row in the survey_electrode_geometry table in the database
    @param con: database connection
    @param survey_electrode_geometry_id 
    @param soilprobe_monitoring_id 
    @param electrode_well 
    @param electrode_number 
    @param x_coordinate_meters 
    @param y_coordinate_meters 
    @param z_coordinate_meters 
    @return The number of rows updated
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    return db.update(con, 'survey_electrode_geometry', data)

@beartype.beartype
def read_survey_electrode_geometry(
            con: db.Connection,
            soilprobe_monitoring_id: Optional[int] = None,
             electrode_well: Optional[int] = None,
             electrode_number: Optional[int] = None,
             x_coordinate_meters: Optional[float] = None,
             y_coordinate_meters: Optional[float] = None,
             z_coordinate_meters: Optional[float] = None,
             survey_electrode_geometry_id: Optional[int] = None) -> Generator[SurveyElectrodeGeometry, None, None]:
    """
    Read from the survey_electrode_geometry table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param survey_electrode_geometry_id 
    @param soilprobe_monitoring_id 
    @param electrode_well 
    @param electrode_number 
    @param x_coordinate_meters 
    @param y_coordinate_meters 
    @param z_coordinate_meters 
    @return generator of SurveyElectrodeGeometry objects
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    result = db.query(con, 'survey_electrode_geometry', data)
    for row in result:
        yield SurveyElectrodeGeometry(**row.as_dict())

@beartype.beartype
def read_survey_electrode_geometry_fuzzy(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             electrode_well: Optional[int] = None,
             electrode_number: Optional[int] = None,
             x_coordinate_meters: Optional[float] = None,
             y_coordinate_meters: Optional[float] = None,
             z_coordinate_meters: Optional[float] = None,
             survey_electrode_geometry_id: Optional[int] = None) -> Generator[SurveyElectrodeGeometry, None, None]:
    """
    Read from the survey_electrode_geometry table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param survey_electrode_geometry_id 
    @param soilprobe_monitoring_id 
    @param electrode_well 
    @param electrode_number 
    @param x_coordinate_meters 
    @param y_coordinate_meters 
    @param z_coordinate_meters 
    @return generator of SurveyElectrodeGeometry objects
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    result = db.query_fuzzy(con, 'survey_electrode_geometry', data)
    for row in result:
        yield SurveyElectrodeGeometry(**row.as_dict())

@beartype.beartype
def read_survey_electrode_geometry_any(con: db.Connection, soilprobe_monitoring_id: Optional[List[int]] = None,
             electrode_well: Optional[List[int]] = None,
             electrode_number: Optional[List[int]] = None,
             x_coordinate_meters: Optional[List[float]] = None,
             y_coordinate_meters: Optional[List[float]] = None,
             z_coordinate_meters: Optional[List[float]] = None,
             survey_electrode_geometry_id: Optional[List[int]] = None) -> Generator[SurveyElectrodeGeometry, None, None]:
    """
    Read from the survey_electrode_geometry table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param survey_electrode_geometry_id 
    @param soilprobe_monitoring_id 
    @param electrode_well 
    @param electrode_number 
    @param x_coordinate_meters 
    @param y_coordinate_meters 
    @param z_coordinate_meters 
    @return generator of SurveyElectrodeGeometry objects
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    result = db.query_any(con, 'survey_electrode_geometry', data)
    for row in result:
        yield SurveyElectrodeGeometry(**row.as_dict())

@beartype.beartype
def read_survey_electrode_geometry_one_or_none(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             electrode_well: Optional[int] = None,
             electrode_number: Optional[int] = None,
             x_coordinate_meters: Optional[float] = None,
             y_coordinate_meters: Optional[float] = None,
             z_coordinate_meters: Optional[float] = None,
             survey_electrode_geometry_id: Optional[int] = None) -> Optional[SurveyElectrodeGeometry]:
    """
    Read from the survey_electrode_geometry table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    result = db.query_one_or_none(con, 'survey_electrode_geometry', data)
    if result is None:
        return None
    return SurveyElectrodeGeometry(**result)

@beartype.beartype
def read_survey_electrode_geometry_one(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             electrode_well: Optional[int] = None,
             electrode_number: Optional[int] = None,
             x_coordinate_meters: Optional[float] = None,
             y_coordinate_meters: Optional[float] = None,
             z_coordinate_meters: Optional[float] = None,
             survey_electrode_geometry_id: Optional[int] = None) -> SurveyElectrodeGeometry:
    """
    Read from the survey_electrode_geometry table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    result = db.query_one(con, 'survey_electrode_geometry', data)
    return SurveyElectrodeGeometry(**result)

@beartype.beartype
def read_survey_electrode_geometry_all(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             electrode_well: Optional[int] = None,
             electrode_number: Optional[int] = None,
             x_coordinate_meters: Optional[float] = None,
             y_coordinate_meters: Optional[float] = None,
             z_coordinate_meters: Optional[float] = None,
             survey_electrode_geometry_id: Optional[int] = None) -> List[SurveyElectrodeGeometry]:
    """
    Read from the survey_electrode_geometry table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'survey_electrode_geometry_id': survey_electrode_geometry_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'electrode_well': electrode_well,
        'electrode_number': electrode_number,
        'x_coordinate_meters': x_coordinate_meters,
        'y_coordinate_meters': y_coordinate_meters,
        'z_coordinate_meters': z_coordinate_meters,
    }
    result = db.query(con, 'survey_electrode_geometry', data)
    return [SurveyElectrodeGeometry(**row.as_dict()) for row in result]

@beartype.beartype
def read_survey_electrode_geometry_by_id(con: db.Connection, survey_electrode_geometry_id: int) -> Optional[SurveyElectrodeGeometry]:
    result = db.query_one(con, 'survey_electrode_geometry', {'survey_electrode_geometry_id': survey_electrode_geometry_id})
    if result is None:
        return None
    return SurveyElectrodeGeometry(**result)

@beartype.beartype
def delete_survey_electrode_geometry_by_id(con: db.Connection, survey_electrode_geometry_id: int):
    db.delete(con, 'survey_electrode_geometry', {'survey_electrode_geometry_id': survey_electrode_geometry_id})
# Associate the functions with the class
SurveyElectrodeGeometry.create_from_json_dict = create_survey_electrode_geometry_from_json_dict
SurveyElectrodeGeometry.write = write_survey_electrode_geometry
SurveyElectrodeGeometry.update = update_survey_electrode_geometry
SurveyElectrodeGeometry.write_many = write_survey_electrode_geometry_many
SurveyElectrodeGeometry.read = read_survey_electrode_geometry
SurveyElectrodeGeometry.read_fuzzy = read_survey_electrode_geometry_fuzzy
SurveyElectrodeGeometry.read_any = read_survey_electrode_geometry_any
SurveyElectrodeGeometry.read_one = read_survey_electrode_geometry_one
SurveyElectrodeGeometry.read_one_or_none = read_survey_electrode_geometry_one_or_none
SurveyElectrodeGeometry.read_all = read_survey_electrode_geometry_all
SurveyElectrodeGeometry.delete = delete_survey_electrode_geometry_by_id
SurveyElectrodeGeometry.read_by_id = read_survey_electrode_geometry_by_id
SurveyElectrodeGeometry.delete_by_id = delete_survey_electrode_geometry_by_id



@beartype_wrap_init
@dataclasses.dataclass
class FeaturesOfInterest:
    """
    @param features_of_interest_id 
    @param features_of_interest_type_cv 
    @param features_of_interest_name 
    @param features_of_interest_description 

    This is an automatically generated class
    """
    features_of_interest_type_cv: str # features_of_interest_type_cv character varying (default: )
    features_of_interest_name: str # features_of_interest_name character varying (default: )
    features_of_interest_id: Optional[int] = None # features_of_interest_id integer (default: )
    features_of_interest_description: Optional[str] = None # features_of_interest_description character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'features_of_interest_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_features_of_interest_type_cv(self, con: db.Connection) -> Optional['CvFeaturesOfInterestType']:
        return read_cv_features_of_interest_type_one_or_none(con, term=self.features_of_interest_type_cv)

@beartype.beartype
def create_features_of_interest_from_json_dict(json_obj: dict):
        """
        Create a FeaturesOfInterest from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return FeaturesOfInterest(**json_obj)


@beartype.beartype
def write_features_of_interest_obj(con: db.Connection, obj: FeaturesOfInterest) -> int:
    """
    Write a FeaturesOfInterest object to the database
    @param con: database connection
    @param obj: FeaturesOfInterest object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'features_of_interest', dataclasses.asdict(obj))

@beartype.beartype
def write_features_of_interest(
            con: db.Connection,
            features_of_interest_type_cv: str,
            features_of_interest_name: str,
            features_of_interest_id: Optional[int] = None,
            features_of_interest_description: Optional[str] = None) -> int:
    """
    Write to the features_of_interest table in the database
    @param con: database connection
    @param features_of_interest_id 
    @param features_of_interest_type_cv 
    @param features_of_interest_name 
    @param features_of_interest_description 
    @return id of the inserted/updated row
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    return db.upsert(con, 'features_of_interest', data)

@beartype.beartype
def write_features_of_interest_many(con: db.Connection, objs: List[FeaturesOfInterest], upsert: bool = False) -> int:
    """
    Write a list of FeaturesOfInterest objects to the database
    @param con: database connection
    @param objs: list of FeaturesOfInterest objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'features_of_interest', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_features_of_interest(con: db.Connection, features_of_interest_id: int,
            features_of_interest_type_cv: Optional[str] = None,
            features_of_interest_name: Optional[str] = None,
            features_of_interest_description: Optional[str] = None) -> int:
    """
    Update a row in the features_of_interest table in the database
    @param con: database connection
    @param features_of_interest_id 
    @param features_of_interest_type_cv 
    @param features_of_interest_name 
    @param features_of_interest_description 
    @return The number of rows updated
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    return db.update(con, 'features_of_interest', data)

@beartype.beartype
def read_features_of_interest(
            con: db.Connection,
            features_of_interest_type_cv: Optional[str] = None,
             features_of_interest_name: Optional[str] = None,
             features_of_interest_id: Optional[int] = None,
             features_of_interest_description: Optional[str] = None) -> Generator[FeaturesOfInterest, None, None]:
    """
    Read from the features_of_interest table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param features_of_interest_id 
    @param features_of_interest_type_cv 
    @param features_of_interest_name 
    @param features_of_interest_description 
    @return generator of FeaturesOfInterest objects
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    result = db.query(con, 'features_of_interest', data)
    for row in result:
        yield FeaturesOfInterest(**row.as_dict())

@beartype.beartype
def read_features_of_interest_fuzzy(con: db.Connection, features_of_interest_type_cv: Optional[str] = None,
             features_of_interest_name: Optional[str] = None,
             features_of_interest_id: Optional[int] = None,
             features_of_interest_description: Optional[str] = None) -> Generator[FeaturesOfInterest, None, None]:
    """
    Read from the features_of_interest table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param features_of_interest_id 
    @param features_of_interest_type_cv 
    @param features_of_interest_name 
    @param features_of_interest_description 
    @return generator of FeaturesOfInterest objects
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    result = db.query_fuzzy(con, 'features_of_interest', data)
    for row in result:
        yield FeaturesOfInterest(**row.as_dict())

@beartype.beartype
def read_features_of_interest_any(con: db.Connection, features_of_interest_type_cv: Optional[List[str]] = None,
             features_of_interest_name: Optional[List[str]] = None,
             features_of_interest_id: Optional[List[int]] = None,
             features_of_interest_description: Optional[List[str]] = None) -> Generator[FeaturesOfInterest, None, None]:
    """
    Read from the features_of_interest table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param features_of_interest_id 
    @param features_of_interest_type_cv 
    @param features_of_interest_name 
    @param features_of_interest_description 
    @return generator of FeaturesOfInterest objects
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    result = db.query_any(con, 'features_of_interest', data)
    for row in result:
        yield FeaturesOfInterest(**row.as_dict())

@beartype.beartype
def read_features_of_interest_one_or_none(con: db.Connection, features_of_interest_type_cv: Optional[str] = None,
             features_of_interest_name: Optional[str] = None,
             features_of_interest_id: Optional[int] = None,
             features_of_interest_description: Optional[str] = None) -> Optional[FeaturesOfInterest]:
    """
    Read from the features_of_interest table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    result = db.query_one_or_none(con, 'features_of_interest', data)
    if result is None:
        return None
    return FeaturesOfInterest(**result)

@beartype.beartype
def read_features_of_interest_one(con: db.Connection, features_of_interest_type_cv: Optional[str] = None,
             features_of_interest_name: Optional[str] = None,
             features_of_interest_id: Optional[int] = None,
             features_of_interest_description: Optional[str] = None) -> FeaturesOfInterest:
    """
    Read from the features_of_interest table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    result = db.query_one(con, 'features_of_interest', data)
    return FeaturesOfInterest(**result)

@beartype.beartype
def read_features_of_interest_all(con: db.Connection, features_of_interest_type_cv: Optional[str] = None,
             features_of_interest_name: Optional[str] = None,
             features_of_interest_id: Optional[int] = None,
             features_of_interest_description: Optional[str] = None) -> List[FeaturesOfInterest]:
    """
    Read from the features_of_interest table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'features_of_interest_id': features_of_interest_id,
        'features_of_interest_type_cv': features_of_interest_type_cv,
        'features_of_interest_name': features_of_interest_name,
        'features_of_interest_description': features_of_interest_description,
    }
    result = db.query(con, 'features_of_interest', data)
    return [FeaturesOfInterest(**row.as_dict()) for row in result]

@beartype.beartype
def read_features_of_interest_by_id(con: db.Connection, features_of_interest_id: int) -> Optional[FeaturesOfInterest]:
    result = db.query_one(con, 'features_of_interest', {'features_of_interest_id': features_of_interest_id})
    if result is None:
        return None
    return FeaturesOfInterest(**result)

@beartype.beartype
def delete_features_of_interest_by_id(con: db.Connection, features_of_interest_id: int):
    db.delete(con, 'features_of_interest', {'features_of_interest_id': features_of_interest_id})
# Associate the functions with the class
FeaturesOfInterest.create_from_json_dict = create_features_of_interest_from_json_dict
FeaturesOfInterest.write = write_features_of_interest
FeaturesOfInterest.update = update_features_of_interest
FeaturesOfInterest.write_many = write_features_of_interest_many
FeaturesOfInterest.read = read_features_of_interest
FeaturesOfInterest.read_fuzzy = read_features_of_interest_fuzzy
FeaturesOfInterest.read_any = read_features_of_interest_any
FeaturesOfInterest.read_one = read_features_of_interest_one
FeaturesOfInterest.read_one_or_none = read_features_of_interest_one_or_none
FeaturesOfInterest.read_all = read_features_of_interest_all
FeaturesOfInterest.delete = delete_features_of_interest_by_id
FeaturesOfInterest.read_by_id = read_features_of_interest_by_id
FeaturesOfInterest.delete_by_id = delete_features_of_interest_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SpecimenToSpecimenCollectionBridge:
    """
    this is a bridge between specimens and specimencollections

    @param specimen_to_specimen_collection_bridge_id 
    @param sampling_feature_id 
    @param specimen_collection_id 

    This is an automatically generated class
    """
    sampling_feature_id: int # sampling_feature_id integer (default: )
    specimen_collection_id: int # specimen_collection_id integer (default: )
    specimen_to_specimen_collection_bridge_id: Optional[int] = None # specimen_to_specimen_collection_bridge_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'specimen_to_specimen_collection_bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_specimen_collection(self, con: db.Connection) -> Optional['SpecimenCollection']:
        return read_specimen_collection_one_or_none(con, specimen_collection_id=self.specimen_collection_id)

    @beartype.beartype
    def get_sampling_feature(self, con: db.Connection) -> Optional['Specimens']:
        return read_specimens_one_or_none(con, sampling_feature_id=self.sampling_feature_id)

@beartype.beartype
def create_specimen_to_specimen_collection_bridge_from_json_dict(json_obj: dict):
        """
        Create a SpecimenToSpecimenCollectionBridge from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SpecimenToSpecimenCollectionBridge(**json_obj)


@beartype.beartype
def write_specimen_to_specimen_collection_bridge_obj(con: db.Connection, obj: SpecimenToSpecimenCollectionBridge) -> int:
    """
    Write a SpecimenToSpecimenCollectionBridge object to the database
    @param con: database connection
    @param obj: SpecimenToSpecimenCollectionBridge object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'specimen_to_specimen_collection_bridge', dataclasses.asdict(obj))

@beartype.beartype
def write_specimen_to_specimen_collection_bridge(
            con: db.Connection,
            sampling_feature_id: int,
            specimen_collection_id: int,
            specimen_to_specimen_collection_bridge_id: Optional[int] = None) -> int:
    """
    Write to the specimen_to_specimen_collection_bridge table in the database
    @param con: database connection
    @param specimen_to_specimen_collection_bridge_id 
    @param sampling_feature_id 
    @param specimen_collection_id 
    @return id of the inserted/updated row
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    return db.upsert(con, 'specimen_to_specimen_collection_bridge', data)

@beartype.beartype
def write_specimen_to_specimen_collection_bridge_many(con: db.Connection, objs: List[SpecimenToSpecimenCollectionBridge], upsert: bool = False) -> int:
    """
    Write a list of SpecimenToSpecimenCollectionBridge objects to the database
    @param con: database connection
    @param objs: list of SpecimenToSpecimenCollectionBridge objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'specimen_to_specimen_collection_bridge', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_specimen_to_specimen_collection_bridge(con: db.Connection, specimen_to_specimen_collection_bridge_id: int,
            sampling_feature_id: Optional[int] = None,
            specimen_collection_id: Optional[int] = None) -> int:
    """
    Update a row in the specimen_to_specimen_collection_bridge table in the database
    @param con: database connection
    @param specimen_to_specimen_collection_bridge_id 
    @param sampling_feature_id 
    @param specimen_collection_id 
    @return The number of rows updated
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    return db.update(con, 'specimen_to_specimen_collection_bridge', data)

@beartype.beartype
def read_specimen_to_specimen_collection_bridge(
            con: db.Connection,
            sampling_feature_id: Optional[int] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_to_specimen_collection_bridge_id: Optional[int] = None) -> Generator[SpecimenToSpecimenCollectionBridge, None, None]:
    """
    Read from the specimen_to_specimen_collection_bridge table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param specimen_to_specimen_collection_bridge_id 
    @param sampling_feature_id 
    @param specimen_collection_id 
    @return generator of SpecimenToSpecimenCollectionBridge objects
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    result = db.query(con, 'specimen_to_specimen_collection_bridge', data)
    for row in result:
        yield SpecimenToSpecimenCollectionBridge(**row.as_dict())

@beartype.beartype
def read_specimen_to_specimen_collection_bridge_fuzzy(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_to_specimen_collection_bridge_id: Optional[int] = None) -> Generator[SpecimenToSpecimenCollectionBridge, None, None]:
    """
    Read from the specimen_to_specimen_collection_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param specimen_to_specimen_collection_bridge_id 
    @param sampling_feature_id 
    @param specimen_collection_id 
    @return generator of SpecimenToSpecimenCollectionBridge objects
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    result = db.query_fuzzy(con, 'specimen_to_specimen_collection_bridge', data)
    for row in result:
        yield SpecimenToSpecimenCollectionBridge(**row.as_dict())

@beartype.beartype
def read_specimen_to_specimen_collection_bridge_any(con: db.Connection, sampling_feature_id: Optional[List[int]] = None,
             specimen_collection_id: Optional[List[int]] = None,
             specimen_to_specimen_collection_bridge_id: Optional[List[int]] = None) -> Generator[SpecimenToSpecimenCollectionBridge, None, None]:
    """
    Read from the specimen_to_specimen_collection_bridge table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param specimen_to_specimen_collection_bridge_id 
    @param sampling_feature_id 
    @param specimen_collection_id 
    @return generator of SpecimenToSpecimenCollectionBridge objects
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    result = db.query_any(con, 'specimen_to_specimen_collection_bridge', data)
    for row in result:
        yield SpecimenToSpecimenCollectionBridge(**row.as_dict())

@beartype.beartype
def read_specimen_to_specimen_collection_bridge_one_or_none(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_to_specimen_collection_bridge_id: Optional[int] = None) -> Optional[SpecimenToSpecimenCollectionBridge]:
    """
    Read from the specimen_to_specimen_collection_bridge table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    result = db.query_one_or_none(con, 'specimen_to_specimen_collection_bridge', data)
    if result is None:
        return None
    return SpecimenToSpecimenCollectionBridge(**result)

@beartype.beartype
def read_specimen_to_specimen_collection_bridge_one(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_to_specimen_collection_bridge_id: Optional[int] = None) -> SpecimenToSpecimenCollectionBridge:
    """
    Read from the specimen_to_specimen_collection_bridge table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    result = db.query_one(con, 'specimen_to_specimen_collection_bridge', data)
    return SpecimenToSpecimenCollectionBridge(**result)

@beartype.beartype
def read_specimen_to_specimen_collection_bridge_all(con: db.Connection, sampling_feature_id: Optional[int] = None,
             specimen_collection_id: Optional[int] = None,
             specimen_to_specimen_collection_bridge_id: Optional[int] = None) -> List[SpecimenToSpecimenCollectionBridge]:
    """
    Read from the specimen_to_specimen_collection_bridge table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id,
        'sampling_feature_id': sampling_feature_id,
        'specimen_collection_id': specimen_collection_id,
    }
    result = db.query(con, 'specimen_to_specimen_collection_bridge', data)
    return [SpecimenToSpecimenCollectionBridge(**row.as_dict()) for row in result]

@beartype.beartype
def read_specimen_to_specimen_collection_bridge_by_id(con: db.Connection, specimen_to_specimen_collection_bridge_id: int) -> Optional[SpecimenToSpecimenCollectionBridge]:
    result = db.query_one(con, 'specimen_to_specimen_collection_bridge', {'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id})
    if result is None:
        return None
    return SpecimenToSpecimenCollectionBridge(**result)

@beartype.beartype
def delete_specimen_to_specimen_collection_bridge_by_id(con: db.Connection, specimen_to_specimen_collection_bridge_id: int):
    db.delete(con, 'specimen_to_specimen_collection_bridge', {'specimen_to_specimen_collection_bridge_id': specimen_to_specimen_collection_bridge_id})
# Associate the functions with the class
SpecimenToSpecimenCollectionBridge.create_from_json_dict = create_specimen_to_specimen_collection_bridge_from_json_dict
SpecimenToSpecimenCollectionBridge.write = write_specimen_to_specimen_collection_bridge
SpecimenToSpecimenCollectionBridge.update = update_specimen_to_specimen_collection_bridge
SpecimenToSpecimenCollectionBridge.write_many = write_specimen_to_specimen_collection_bridge_many
SpecimenToSpecimenCollectionBridge.read = read_specimen_to_specimen_collection_bridge
SpecimenToSpecimenCollectionBridge.read_fuzzy = read_specimen_to_specimen_collection_bridge_fuzzy
SpecimenToSpecimenCollectionBridge.read_any = read_specimen_to_specimen_collection_bridge_any
SpecimenToSpecimenCollectionBridge.read_one = read_specimen_to_specimen_collection_bridge_one
SpecimenToSpecimenCollectionBridge.read_one_or_none = read_specimen_to_specimen_collection_bridge_one_or_none
SpecimenToSpecimenCollectionBridge.read_all = read_specimen_to_specimen_collection_bridge_all
SpecimenToSpecimenCollectionBridge.delete = delete_specimen_to_specimen_collection_bridge_by_id
SpecimenToSpecimenCollectionBridge.read_by_id = read_specimen_to_specimen_collection_bridge_by_id
SpecimenToSpecimenCollectionBridge.delete_by_id = delete_specimen_to_specimen_collection_bridge_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ModelAffiliations:
    """
    @param bridge_id 
    @param model_id 
    @param affiliation_id 
    @param is_primary 
    @param role_description 

    This is an automatically generated class
    """
    model_id: int # model_id integer (default: )
    affiliation_id: int # affiliation_id integer (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    is_primary: Optional[bool] = None # is_primary boolean (default: )
    role_description: Optional[str] = None # role_description character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_affiliation(self, con: db.Connection) -> Optional['Affiliations']:
        return read_affiliations_one_or_none(con, affiliation_id=self.affiliation_id)

    @beartype.beartype
    def get_model(self, con: db.Connection) -> Optional['Models']:
        return read_models_one_or_none(con, model_id=self.model_id)

@beartype.beartype
def create_model_affiliations_from_json_dict(json_obj: dict):
        """
        Create a ModelAffiliations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ModelAffiliations(**json_obj)


@beartype.beartype
def write_model_affiliations_obj(con: db.Connection, obj: ModelAffiliations) -> int:
    """
    Write a ModelAffiliations object to the database
    @param con: database connection
    @param obj: ModelAffiliations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'model_affiliations', dataclasses.asdict(obj))

@beartype.beartype
def write_model_affiliations(
            con: db.Connection,
            model_id: int,
            affiliation_id: int,
            bridge_id: Optional[int] = None,
            is_primary: Optional[bool] = None,
            role_description: Optional[str] = None) -> int:
    """
    Write to the model_affiliations table in the database
    @param con: database connection
    @param bridge_id 
    @param model_id 
    @param affiliation_id 
    @param is_primary 
    @param role_description 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    return db.upsert(con, 'model_affiliations', data)

@beartype.beartype
def write_model_affiliations_many(con: db.Connection, objs: List[ModelAffiliations], upsert: bool = False) -> int:
    """
    Write a list of ModelAffiliations objects to the database
    @param con: database connection
    @param objs: list of ModelAffiliations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'model_affiliations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_model_affiliations(con: db.Connection, bridge_id: int,
            model_id: Optional[int] = None,
            affiliation_id: Optional[int] = None,
            is_primary: Optional[bool] = None,
            role_description: Optional[str] = None) -> int:
    """
    Update a row in the model_affiliations table in the database
    @param con: database connection
    @param bridge_id 
    @param model_id 
    @param affiliation_id 
    @param is_primary 
    @param role_description 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    return db.update(con, 'model_affiliations', data)

@beartype.beartype
def read_model_affiliations(
            con: db.Connection,
            model_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             is_primary: Optional[bool] = None,
             role_description: Optional[str] = None) -> Generator[ModelAffiliations, None, None]:
    """
    Read from the model_affiliations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param model_id 
    @param affiliation_id 
    @param is_primary 
    @param role_description 
    @return generator of ModelAffiliations objects
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    result = db.query(con, 'model_affiliations', data)
    for row in result:
        yield ModelAffiliations(**row.as_dict())

@beartype.beartype
def read_model_affiliations_fuzzy(con: db.Connection, model_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             is_primary: Optional[bool] = None,
             role_description: Optional[str] = None) -> Generator[ModelAffiliations, None, None]:
    """
    Read from the model_affiliations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param model_id 
    @param affiliation_id 
    @param is_primary 
    @param role_description 
    @return generator of ModelAffiliations objects
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    result = db.query_fuzzy(con, 'model_affiliations', data)
    for row in result:
        yield ModelAffiliations(**row.as_dict())

@beartype.beartype
def read_model_affiliations_any(con: db.Connection, model_id: Optional[List[int]] = None,
             affiliation_id: Optional[List[int]] = None,
             bridge_id: Optional[List[int]] = None,
             is_primary: Optional[List[bool]] = None,
             role_description: Optional[List[str]] = None) -> Generator[ModelAffiliations, None, None]:
    """
    Read from the model_affiliations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param model_id 
    @param affiliation_id 
    @param is_primary 
    @param role_description 
    @return generator of ModelAffiliations objects
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    result = db.query_any(con, 'model_affiliations', data)
    for row in result:
        yield ModelAffiliations(**row.as_dict())

@beartype.beartype
def read_model_affiliations_one_or_none(con: db.Connection, model_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             is_primary: Optional[bool] = None,
             role_description: Optional[str] = None) -> Optional[ModelAffiliations]:
    """
    Read from the model_affiliations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    result = db.query_one_or_none(con, 'model_affiliations', data)
    if result is None:
        return None
    return ModelAffiliations(**result)

@beartype.beartype
def read_model_affiliations_one(con: db.Connection, model_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             is_primary: Optional[bool] = None,
             role_description: Optional[str] = None) -> ModelAffiliations:
    """
    Read from the model_affiliations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    result = db.query_one(con, 'model_affiliations', data)
    return ModelAffiliations(**result)

@beartype.beartype
def read_model_affiliations_all(con: db.Connection, model_id: Optional[int] = None,
             affiliation_id: Optional[int] = None,
             bridge_id: Optional[int] = None,
             is_primary: Optional[bool] = None,
             role_description: Optional[str] = None) -> List[ModelAffiliations]:
    """
    Read from the model_affiliations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'model_id': model_id,
        'affiliation_id': affiliation_id,
        'is_primary': is_primary,
        'role_description': role_description,
    }
    result = db.query(con, 'model_affiliations', data)
    return [ModelAffiliations(**row.as_dict()) for row in result]

@beartype.beartype
def read_model_affiliations_by_id(con: db.Connection, bridge_id: int) -> Optional[ModelAffiliations]:
    result = db.query_one(con, 'model_affiliations', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ModelAffiliations(**result)

@beartype.beartype
def delete_model_affiliations_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'model_affiliations', {'bridge_id': bridge_id})
# Associate the functions with the class
ModelAffiliations.create_from_json_dict = create_model_affiliations_from_json_dict
ModelAffiliations.write = write_model_affiliations
ModelAffiliations.update = update_model_affiliations
ModelAffiliations.write_many = write_model_affiliations_many
ModelAffiliations.read = read_model_affiliations
ModelAffiliations.read_fuzzy = read_model_affiliations_fuzzy
ModelAffiliations.read_any = read_model_affiliations_any
ModelAffiliations.read_one = read_model_affiliations_one
ModelAffiliations.read_one_or_none = read_model_affiliations_one_or_none
ModelAffiliations.read_all = read_model_affiliations_all
ModelAffiliations.delete = delete_model_affiliations_by_id
ModelAffiliations.read_by_id = read_model_affiliations_by_id
ModelAffiliations.delete_by_id = delete_model_affiliations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Citations:
    """
    Information about Citations

    @param citation_id 
    @param title 
    @param publisher 
    @param publication_year 
    @param citation_link 

    This is an automatically generated class
    """
    title: str # title character varying (default: )
    publisher: str # publisher character varying (default: )
    publication_year: int # publication_year integer (default: )
    citation_id: Optional[int] = None # citation_id integer (default: )
    citation_link: Optional[str] = None # citation_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'citation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_citations_from_json_dict(json_obj: dict):
        """
        Create a Citations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Citations(**json_obj)


@beartype.beartype
def write_citations_obj(con: db.Connection, obj: Citations) -> int:
    """
    Write a Citations object to the database
    @param con: database connection
    @param obj: Citations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'citations', dataclasses.asdict(obj))

@beartype.beartype
def write_citations(
            con: db.Connection,
            title: str,
            publisher: str,
            publication_year: int,
            citation_id: Optional[int] = None,
            citation_link: Optional[str] = None) -> int:
    """
    Write to the citations table in the database
    @param con: database connection
    @param citation_id 
    @param title 
    @param publisher 
    @param publication_year 
    @param citation_link 
    @return id of the inserted/updated row
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    return db.upsert(con, 'citations', data)

@beartype.beartype
def write_citations_many(con: db.Connection, objs: List[Citations], upsert: bool = False) -> int:
    """
    Write a list of Citations objects to the database
    @param con: database connection
    @param objs: list of Citations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'citations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_citations(con: db.Connection, citation_id: int,
            title: Optional[str] = None,
            publisher: Optional[str] = None,
            publication_year: Optional[int] = None,
            citation_link: Optional[str] = None) -> int:
    """
    Update a row in the citations table in the database
    @param con: database connection
    @param citation_id 
    @param title 
    @param publisher 
    @param publication_year 
    @param citation_link 
    @return The number of rows updated
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    return db.update(con, 'citations', data)

@beartype.beartype
def read_citations(
            con: db.Connection,
            title: Optional[str] = None,
             publisher: Optional[str] = None,
             publication_year: Optional[int] = None,
             citation_id: Optional[int] = None,
             citation_link: Optional[str] = None) -> Generator[Citations, None, None]:
    """
    Read from the citations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param citation_id 
    @param title 
    @param publisher 
    @param publication_year 
    @param citation_link 
    @return generator of Citations objects
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    result = db.query(con, 'citations', data)
    for row in result:
        yield Citations(**row.as_dict())

@beartype.beartype
def read_citations_fuzzy(con: db.Connection, title: Optional[str] = None,
             publisher: Optional[str] = None,
             publication_year: Optional[int] = None,
             citation_id: Optional[int] = None,
             citation_link: Optional[str] = None) -> Generator[Citations, None, None]:
    """
    Read from the citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param citation_id 
    @param title 
    @param publisher 
    @param publication_year 
    @param citation_link 
    @return generator of Citations objects
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    result = db.query_fuzzy(con, 'citations', data)
    for row in result:
        yield Citations(**row.as_dict())

@beartype.beartype
def read_citations_any(con: db.Connection, title: Optional[List[str]] = None,
             publisher: Optional[List[str]] = None,
             publication_year: Optional[List[int]] = None,
             citation_id: Optional[List[int]] = None,
             citation_link: Optional[List[str]] = None) -> Generator[Citations, None, None]:
    """
    Read from the citations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param citation_id 
    @param title 
    @param publisher 
    @param publication_year 
    @param citation_link 
    @return generator of Citations objects
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    result = db.query_any(con, 'citations', data)
    for row in result:
        yield Citations(**row.as_dict())

@beartype.beartype
def read_citations_one_or_none(con: db.Connection, title: Optional[str] = None,
             publisher: Optional[str] = None,
             publication_year: Optional[int] = None,
             citation_id: Optional[int] = None,
             citation_link: Optional[str] = None) -> Optional[Citations]:
    """
    Read from the citations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    result = db.query_one_or_none(con, 'citations', data)
    if result is None:
        return None
    return Citations(**result)

@beartype.beartype
def read_citations_one(con: db.Connection, title: Optional[str] = None,
             publisher: Optional[str] = None,
             publication_year: Optional[int] = None,
             citation_id: Optional[int] = None,
             citation_link: Optional[str] = None) -> Citations:
    """
    Read from the citations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    result = db.query_one(con, 'citations', data)
    return Citations(**result)

@beartype.beartype
def read_citations_all(con: db.Connection, title: Optional[str] = None,
             publisher: Optional[str] = None,
             publication_year: Optional[int] = None,
             citation_id: Optional[int] = None,
             citation_link: Optional[str] = None) -> List[Citations]:
    """
    Read from the citations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'citation_id': citation_id,
        'title': title,
        'publisher': publisher,
        'publication_year': publication_year,
        'citation_link': citation_link,
    }
    result = db.query(con, 'citations', data)
    return [Citations(**row.as_dict()) for row in result]

@beartype.beartype
def read_citations_by_id(con: db.Connection, citation_id: int) -> Optional[Citations]:
    result = db.query_one(con, 'citations', {'citation_id': citation_id})
    if result is None:
        return None
    return Citations(**result)

@beartype.beartype
def delete_citations_by_id(con: db.Connection, citation_id: int):
    db.delete(con, 'citations', {'citation_id': citation_id})
# Associate the functions with the class
Citations.create_from_json_dict = create_citations_from_json_dict
Citations.write = write_citations
Citations.update = update_citations
Citations.write_many = write_citations_many
Citations.read = read_citations
Citations.read_fuzzy = read_citations_fuzzy
Citations.read_any = read_citations_any
Citations.read_one = read_citations_one
Citations.read_one_or_none = read_citations_one_or_none
Citations.read_all = read_citations_all
Citations.delete = delete_citations_by_id
Citations.read_by_id = read_citations_by_id
Citations.delete_by_id = delete_citations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Variables:
    """
    Stores information about measured properties.

    @param variable_id 
    @param variable_term 
    @param variable_name 
    @param variable_definition 
    @param variable_domain_cv 
    @param sampled_medium_cv 
    @param quantity_kind_cv 
    @param variable_source_uri 

    This is an automatically generated class
    """
    variable_term: str # variable_term character varying (default: )
    variable_name: str # variable_name character varying (default: )
    variable_definition: str # variable_definition character varying (default: )
    variable_id: Optional[int] = None # variable_id integer (default: )
    variable_domain_cv: Optional[str] = None # variable_domain_cv character varying (default: )
    sampled_medium_cv: Optional[str] = None # sampled_medium_cv character varying (default: )
    quantity_kind_cv: Optional[str] = None # quantity_kind_cv character varying (default: )
    variable_source_uri: Optional[str] = None # variable_source_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'variable_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_sampled_medium_cv(self, con: db.Connection) -> Optional['CvMedium']:
        return read_cv_medium_one_or_none(con, term=self.sampled_medium_cv)

    @beartype.beartype
    def get_quantity_kind_cv(self, con: db.Connection) -> Optional['CvQuantityKind']:
        return read_cv_quantity_kind_one_or_none(con, term=self.quantity_kind_cv)

    @beartype.beartype
    def get_variable_domain_cv(self, con: db.Connection) -> Optional['CvVariableDomain']:
        return read_cv_variable_domain_one_or_none(con, term=self.variable_domain_cv)

@beartype.beartype
def create_variables_from_json_dict(json_obj: dict):
        """
        Create a Variables from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Variables(**json_obj)


@beartype.beartype
def write_variables_obj(con: db.Connection, obj: Variables) -> int:
    """
    Write a Variables object to the database
    @param con: database connection
    @param obj: Variables object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'variables', dataclasses.asdict(obj))

@beartype.beartype
def write_variables(
            con: db.Connection,
            variable_term: str,
            variable_name: str,
            variable_definition: str,
            variable_id: Optional[int] = None,
            variable_domain_cv: Optional[str] = None,
            sampled_medium_cv: Optional[str] = None,
            quantity_kind_cv: Optional[str] = None,
            variable_source_uri: Optional[str] = None) -> int:
    """
    Write to the variables table in the database
    @param con: database connection
    @param variable_id 
    @param variable_term 
    @param variable_name 
    @param variable_definition 
    @param variable_domain_cv 
    @param sampled_medium_cv 
    @param quantity_kind_cv 
    @param variable_source_uri 
    @return id of the inserted/updated row
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    return db.upsert(con, 'variables', data)

@beartype.beartype
def write_variables_many(con: db.Connection, objs: List[Variables], upsert: bool = False) -> int:
    """
    Write a list of Variables objects to the database
    @param con: database connection
    @param objs: list of Variables objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'variables', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_variables(con: db.Connection, variable_id: int,
            variable_term: Optional[str] = None,
            variable_name: Optional[str] = None,
            variable_definition: Optional[str] = None,
            variable_domain_cv: Optional[str] = None,
            sampled_medium_cv: Optional[str] = None,
            quantity_kind_cv: Optional[str] = None,
            variable_source_uri: Optional[str] = None) -> int:
    """
    Update a row in the variables table in the database
    @param con: database connection
    @param variable_id 
    @param variable_term 
    @param variable_name 
    @param variable_definition 
    @param variable_domain_cv 
    @param sampled_medium_cv 
    @param quantity_kind_cv 
    @param variable_source_uri 
    @return The number of rows updated
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    return db.update(con, 'variables', data)

@beartype.beartype
def read_variables(
            con: db.Connection,
            variable_term: Optional[str] = None,
             variable_name: Optional[str] = None,
             variable_definition: Optional[str] = None,
             variable_id: Optional[int] = None,
             variable_domain_cv: Optional[str] = None,
             sampled_medium_cv: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             variable_source_uri: Optional[str] = None) -> Generator[Variables, None, None]:
    """
    Read from the variables table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_id 
    @param variable_term 
    @param variable_name 
    @param variable_definition 
    @param variable_domain_cv 
    @param sampled_medium_cv 
    @param quantity_kind_cv 
    @param variable_source_uri 
    @return generator of Variables objects
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    result = db.query(con, 'variables', data)
    for row in result:
        yield Variables(**row.as_dict())

@beartype.beartype
def read_variables_fuzzy(con: db.Connection, variable_term: Optional[str] = None,
             variable_name: Optional[str] = None,
             variable_definition: Optional[str] = None,
             variable_id: Optional[int] = None,
             variable_domain_cv: Optional[str] = None,
             sampled_medium_cv: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             variable_source_uri: Optional[str] = None) -> Generator[Variables, None, None]:
    """
    Read from the variables table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_id 
    @param variable_term 
    @param variable_name 
    @param variable_definition 
    @param variable_domain_cv 
    @param sampled_medium_cv 
    @param quantity_kind_cv 
    @param variable_source_uri 
    @return generator of Variables objects
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    result = db.query_fuzzy(con, 'variables', data)
    for row in result:
        yield Variables(**row.as_dict())

@beartype.beartype
def read_variables_any(con: db.Connection, variable_term: Optional[List[str]] = None,
             variable_name: Optional[List[str]] = None,
             variable_definition: Optional[List[str]] = None,
             variable_id: Optional[List[int]] = None,
             variable_domain_cv: Optional[List[str]] = None,
             sampled_medium_cv: Optional[List[str]] = None,
             quantity_kind_cv: Optional[List[str]] = None,
             variable_source_uri: Optional[List[str]] = None) -> Generator[Variables, None, None]:
    """
    Read from the variables table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param variable_id 
    @param variable_term 
    @param variable_name 
    @param variable_definition 
    @param variable_domain_cv 
    @param sampled_medium_cv 
    @param quantity_kind_cv 
    @param variable_source_uri 
    @return generator of Variables objects
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    result = db.query_any(con, 'variables', data)
    for row in result:
        yield Variables(**row.as_dict())

@beartype.beartype
def read_variables_one_or_none(con: db.Connection, variable_term: Optional[str] = None,
             variable_name: Optional[str] = None,
             variable_definition: Optional[str] = None,
             variable_id: Optional[int] = None,
             variable_domain_cv: Optional[str] = None,
             sampled_medium_cv: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             variable_source_uri: Optional[str] = None) -> Optional[Variables]:
    """
    Read from the variables table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    result = db.query_one_or_none(con, 'variables', data)
    if result is None:
        return None
    return Variables(**result)

@beartype.beartype
def read_variables_one(con: db.Connection, variable_term: Optional[str] = None,
             variable_name: Optional[str] = None,
             variable_definition: Optional[str] = None,
             variable_id: Optional[int] = None,
             variable_domain_cv: Optional[str] = None,
             sampled_medium_cv: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             variable_source_uri: Optional[str] = None) -> Variables:
    """
    Read from the variables table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    result = db.query_one(con, 'variables', data)
    return Variables(**result)

@beartype.beartype
def read_variables_all(con: db.Connection, variable_term: Optional[str] = None,
             variable_name: Optional[str] = None,
             variable_definition: Optional[str] = None,
             variable_id: Optional[int] = None,
             variable_domain_cv: Optional[str] = None,
             sampled_medium_cv: Optional[str] = None,
             quantity_kind_cv: Optional[str] = None,
             variable_source_uri: Optional[str] = None) -> List[Variables]:
    """
    Read from the variables table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'variable_id': variable_id,
        'variable_term': variable_term,
        'variable_name': variable_name,
        'variable_definition': variable_definition,
        'variable_domain_cv': variable_domain_cv,
        'sampled_medium_cv': sampled_medium_cv,
        'quantity_kind_cv': quantity_kind_cv,
        'variable_source_uri': variable_source_uri,
    }
    result = db.query(con, 'variables', data)
    return [Variables(**row.as_dict()) for row in result]

@beartype.beartype
def read_variables_by_id(con: db.Connection, variable_id: int) -> Optional[Variables]:
    result = db.query_one(con, 'variables', {'variable_id': variable_id})
    if result is None:
        return None
    return Variables(**result)

@beartype.beartype
def delete_variables_by_id(con: db.Connection, variable_id: int):
    db.delete(con, 'variables', {'variable_id': variable_id})
# Associate the functions with the class
Variables.create_from_json_dict = create_variables_from_json_dict
Variables.write = write_variables
Variables.update = update_variables
Variables.write_many = write_variables_many
Variables.read = read_variables
Variables.read_fuzzy = read_variables_fuzzy
Variables.read_any = read_variables_any
Variables.read_one = read_variables_one
Variables.read_one_or_none = read_variables_one_or_none
Variables.read_all = read_variables_all
Variables.delete = delete_variables_by_id
Variables.read_by_id = read_variables_by_id
Variables.delete_by_id = delete_variables_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ReferenceMaterialExternalIdentifiers:
    """
    @param bridge_id 
    @param reference_material_id 
    @param external_identifier_system_id 
    @param reference_material_external_identifier 
    @param reference_material_external_identifier_uri 

    This is an automatically generated class
    """
    reference_material_id: int # reference_material_id integer (default: )
    external_identifier_system_id: int # external_identifier_system_id integer (default: )
    reference_material_external_identifier: str # reference_material_external_identifier character varying (default: )
    bridge_id: Optional[int] = None # bridge_id integer (default: )
    reference_material_external_identifier_uri: Optional[str] = None # reference_material_external_identifier_uri character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_external_identifier_system(self, con: db.Connection) -> Optional['ExternalIdentifierSystems']:
        return read_external_identifier_systems_one_or_none(con, external_identifier_system_id=self.external_identifier_system_id)

    @beartype.beartype
    def get_reference_material(self, con: db.Connection) -> Optional['ReferenceMaterials']:
        return read_reference_materials_one_or_none(con, reference_material_id=self.reference_material_id)

@beartype.beartype
def create_reference_material_external_identifiers_from_json_dict(json_obj: dict):
        """
        Create a ReferenceMaterialExternalIdentifiers from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ReferenceMaterialExternalIdentifiers(**json_obj)


@beartype.beartype
def write_reference_material_external_identifiers_obj(con: db.Connection, obj: ReferenceMaterialExternalIdentifiers) -> int:
    """
    Write a ReferenceMaterialExternalIdentifiers object to the database
    @param con: database connection
    @param obj: ReferenceMaterialExternalIdentifiers object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'reference_material_external_identifiers', dataclasses.asdict(obj))

@beartype.beartype
def write_reference_material_external_identifiers(
            con: db.Connection,
            reference_material_id: int,
            external_identifier_system_id: int,
            reference_material_external_identifier: str,
            bridge_id: Optional[int] = None,
            reference_material_external_identifier_uri: Optional[str] = None) -> int:
    """
    Write to the reference_material_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param reference_material_id 
    @param external_identifier_system_id 
    @param reference_material_external_identifier 
    @param reference_material_external_identifier_uri 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    return db.upsert(con, 'reference_material_external_identifiers', data)

@beartype.beartype
def write_reference_material_external_identifiers_many(con: db.Connection, objs: List[ReferenceMaterialExternalIdentifiers], upsert: bool = False) -> int:
    """
    Write a list of ReferenceMaterialExternalIdentifiers objects to the database
    @param con: database connection
    @param objs: list of ReferenceMaterialExternalIdentifiers objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'reference_material_external_identifiers', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_reference_material_external_identifiers(con: db.Connection, bridge_id: int,
            reference_material_id: Optional[int] = None,
            external_identifier_system_id: Optional[int] = None,
            reference_material_external_identifier: Optional[str] = None,
            reference_material_external_identifier_uri: Optional[str] = None) -> int:
    """
    Update a row in the reference_material_external_identifiers table in the database
    @param con: database connection
    @param bridge_id 
    @param reference_material_id 
    @param external_identifier_system_id 
    @param reference_material_external_identifier 
    @param reference_material_external_identifier_uri 
    @return The number of rows updated
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    return db.update(con, 'reference_material_external_identifiers', data)

@beartype.beartype
def read_reference_material_external_identifiers(
            con: db.Connection,
            reference_material_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             reference_material_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             reference_material_external_identifier_uri: Optional[str] = None) -> Generator[ReferenceMaterialExternalIdentifiers, None, None]:
    """
    Read from the reference_material_external_identifiers table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param reference_material_id 
    @param external_identifier_system_id 
    @param reference_material_external_identifier 
    @param reference_material_external_identifier_uri 
    @return generator of ReferenceMaterialExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    result = db.query(con, 'reference_material_external_identifiers', data)
    for row in result:
        yield ReferenceMaterialExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_reference_material_external_identifiers_fuzzy(con: db.Connection, reference_material_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             reference_material_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             reference_material_external_identifier_uri: Optional[str] = None) -> Generator[ReferenceMaterialExternalIdentifiers, None, None]:
    """
    Read from the reference_material_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param reference_material_id 
    @param external_identifier_system_id 
    @param reference_material_external_identifier 
    @param reference_material_external_identifier_uri 
    @return generator of ReferenceMaterialExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    result = db.query_fuzzy(con, 'reference_material_external_identifiers', data)
    for row in result:
        yield ReferenceMaterialExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_reference_material_external_identifiers_any(con: db.Connection, reference_material_id: Optional[List[int]] = None,
             external_identifier_system_id: Optional[List[int]] = None,
             reference_material_external_identifier: Optional[List[str]] = None,
             bridge_id: Optional[List[int]] = None,
             reference_material_external_identifier_uri: Optional[List[str]] = None) -> Generator[ReferenceMaterialExternalIdentifiers, None, None]:
    """
    Read from the reference_material_external_identifiers table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_id 
    @param reference_material_id 
    @param external_identifier_system_id 
    @param reference_material_external_identifier 
    @param reference_material_external_identifier_uri 
    @return generator of ReferenceMaterialExternalIdentifiers objects
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    result = db.query_any(con, 'reference_material_external_identifiers', data)
    for row in result:
        yield ReferenceMaterialExternalIdentifiers(**row.as_dict())

@beartype.beartype
def read_reference_material_external_identifiers_one_or_none(con: db.Connection, reference_material_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             reference_material_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             reference_material_external_identifier_uri: Optional[str] = None) -> Optional[ReferenceMaterialExternalIdentifiers]:
    """
    Read from the reference_material_external_identifiers table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    result = db.query_one_or_none(con, 'reference_material_external_identifiers', data)
    if result is None:
        return None
    return ReferenceMaterialExternalIdentifiers(**result)

@beartype.beartype
def read_reference_material_external_identifiers_one(con: db.Connection, reference_material_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             reference_material_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             reference_material_external_identifier_uri: Optional[str] = None) -> ReferenceMaterialExternalIdentifiers:
    """
    Read from the reference_material_external_identifiers table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    result = db.query_one(con, 'reference_material_external_identifiers', data)
    return ReferenceMaterialExternalIdentifiers(**result)

@beartype.beartype
def read_reference_material_external_identifiers_all(con: db.Connection, reference_material_id: Optional[int] = None,
             external_identifier_system_id: Optional[int] = None,
             reference_material_external_identifier: Optional[str] = None,
             bridge_id: Optional[int] = None,
             reference_material_external_identifier_uri: Optional[str] = None) -> List[ReferenceMaterialExternalIdentifiers]:
    """
    Read from the reference_material_external_identifiers table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_id': bridge_id,
        'reference_material_id': reference_material_id,
        'external_identifier_system_id': external_identifier_system_id,
        'reference_material_external_identifier': reference_material_external_identifier,
        'reference_material_external_identifier_uri': reference_material_external_identifier_uri,
    }
    result = db.query(con, 'reference_material_external_identifiers', data)
    return [ReferenceMaterialExternalIdentifiers(**row.as_dict()) for row in result]

@beartype.beartype
def read_reference_material_external_identifiers_by_id(con: db.Connection, bridge_id: int) -> Optional[ReferenceMaterialExternalIdentifiers]:
    result = db.query_one(con, 'reference_material_external_identifiers', {'bridge_id': bridge_id})
    if result is None:
        return None
    return ReferenceMaterialExternalIdentifiers(**result)

@beartype.beartype
def delete_reference_material_external_identifiers_by_id(con: db.Connection, bridge_id: int):
    db.delete(con, 'reference_material_external_identifiers', {'bridge_id': bridge_id})
# Associate the functions with the class
ReferenceMaterialExternalIdentifiers.create_from_json_dict = create_reference_material_external_identifiers_from_json_dict
ReferenceMaterialExternalIdentifiers.write = write_reference_material_external_identifiers
ReferenceMaterialExternalIdentifiers.update = update_reference_material_external_identifiers
ReferenceMaterialExternalIdentifiers.write_many = write_reference_material_external_identifiers_many
ReferenceMaterialExternalIdentifiers.read = read_reference_material_external_identifiers
ReferenceMaterialExternalIdentifiers.read_fuzzy = read_reference_material_external_identifiers_fuzzy
ReferenceMaterialExternalIdentifiers.read_any = read_reference_material_external_identifiers_any
ReferenceMaterialExternalIdentifiers.read_one = read_reference_material_external_identifiers_one
ReferenceMaterialExternalIdentifiers.read_one_or_none = read_reference_material_external_identifiers_one_or_none
ReferenceMaterialExternalIdentifiers.read_all = read_reference_material_external_identifiers_all
ReferenceMaterialExternalIdentifiers.delete = delete_reference_material_external_identifiers_by_id
ReferenceMaterialExternalIdentifiers.read_by_id = read_reference_material_external_identifiers_by_id
ReferenceMaterialExternalIdentifiers.delete_by_id = delete_reference_material_external_identifiers_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Assembly:
    """
    @param assembled_contigs_id 
    @param number_of_contigs 
    @param qcd_reads_id 
    @param total_assembled_length 
    @param n50 
    @param assembly_event_id 

    This is an automatically generated class
    """
    assembled_contigs_id: Optional[int] = None # assembled_contigs_id integer (default: )
    number_of_contigs: Optional[int] = None # number_of_contigs integer (default: )
    qcd_reads_id: Optional[int] = None # qcd_reads_id integer (default: )
    total_assembled_length: Optional[int] = None # total_assembled_length integer (default: )
    n50: Optional[str] = None # n50 character varying (default: )
    assembly_event_id: Optional[int] = None # assembly_event_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'assembled_contigs_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_assembly_event(self, con: db.Connection) -> Optional['AssemblyEvent']:
        return read_assembly_event_one_or_none(con, assembly_event_id=self.assembly_event_id)

@beartype.beartype
def create_assembly_from_json_dict(json_obj: dict):
        """
        Create a Assembly from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Assembly(**json_obj)


@beartype.beartype
def write_assembly_obj(con: db.Connection, obj: Assembly) -> int:
    """
    Write a Assembly object to the database
    @param con: database connection
    @param obj: Assembly object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'assembly', dataclasses.asdict(obj))

@beartype.beartype
def write_assembly(
            con: db.Connection,
            assembled_contigs_id: Optional[int] = None,
            number_of_contigs: Optional[int] = None,
            qcd_reads_id: Optional[int] = None,
            total_assembled_length: Optional[int] = None,
            n50: Optional[str] = None,
            assembly_event_id: Optional[int] = None) -> int:
    """
    Write to the assembly table in the database
    @param con: database connection
    @param assembled_contigs_id 
    @param number_of_contigs 
    @param qcd_reads_id 
    @param total_assembled_length 
    @param n50 
    @param assembly_event_id 
    @return id of the inserted/updated row
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    return db.upsert(con, 'assembly', data)

@beartype.beartype
def write_assembly_many(con: db.Connection, objs: List[Assembly], upsert: bool = False) -> int:
    """
    Write a list of Assembly objects to the database
    @param con: database connection
    @param objs: list of Assembly objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'assembly', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_assembly(con: db.Connection, assembled_contigs_id: int,
            number_of_contigs: Optional[int] = None,
            qcd_reads_id: Optional[int] = None,
            total_assembled_length: Optional[int] = None,
            n50: Optional[str] = None,
            assembly_event_id: Optional[int] = None) -> int:
    """
    Update a row in the assembly table in the database
    @param con: database connection
    @param assembled_contigs_id 
    @param number_of_contigs 
    @param qcd_reads_id 
    @param total_assembled_length 
    @param n50 
    @param assembly_event_id 
    @return The number of rows updated
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    return db.update(con, 'assembly', data)

@beartype.beartype
def read_assembly(
            con: db.Connection,
            assembled_contigs_id: Optional[int] = None,
             number_of_contigs: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             total_assembled_length: Optional[int] = None,
             n50: Optional[str] = None,
             assembly_event_id: Optional[int] = None) -> Generator[Assembly, None, None]:
    """
    Read from the assembly table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param assembled_contigs_id 
    @param number_of_contigs 
    @param qcd_reads_id 
    @param total_assembled_length 
    @param n50 
    @param assembly_event_id 
    @return generator of Assembly objects
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query(con, 'assembly', data)
    for row in result:
        yield Assembly(**row.as_dict())

@beartype.beartype
def read_assembly_fuzzy(con: db.Connection, assembled_contigs_id: Optional[int] = None,
             number_of_contigs: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             total_assembled_length: Optional[int] = None,
             n50: Optional[str] = None,
             assembly_event_id: Optional[int] = None) -> Generator[Assembly, None, None]:
    """
    Read from the assembly table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param assembled_contigs_id 
    @param number_of_contigs 
    @param qcd_reads_id 
    @param total_assembled_length 
    @param n50 
    @param assembly_event_id 
    @return generator of Assembly objects
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_fuzzy(con, 'assembly', data)
    for row in result:
        yield Assembly(**row.as_dict())

@beartype.beartype
def read_assembly_any(con: db.Connection, assembled_contigs_id: Optional[List[int]] = None,
             number_of_contigs: Optional[List[int]] = None,
             qcd_reads_id: Optional[List[int]] = None,
             total_assembled_length: Optional[List[int]] = None,
             n50: Optional[List[str]] = None,
             assembly_event_id: Optional[List[int]] = None) -> Generator[Assembly, None, None]:
    """
    Read from the assembly table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param assembled_contigs_id 
    @param number_of_contigs 
    @param qcd_reads_id 
    @param total_assembled_length 
    @param n50 
    @param assembly_event_id 
    @return generator of Assembly objects
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_any(con, 'assembly', data)
    for row in result:
        yield Assembly(**row.as_dict())

@beartype.beartype
def read_assembly_one_or_none(con: db.Connection, assembled_contigs_id: Optional[int] = None,
             number_of_contigs: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             total_assembled_length: Optional[int] = None,
             n50: Optional[str] = None,
             assembly_event_id: Optional[int] = None) -> Optional[Assembly]:
    """
    Read from the assembly table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_one_or_none(con, 'assembly', data)
    if result is None:
        return None
    return Assembly(**result)

@beartype.beartype
def read_assembly_one(con: db.Connection, assembled_contigs_id: Optional[int] = None,
             number_of_contigs: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             total_assembled_length: Optional[int] = None,
             n50: Optional[str] = None,
             assembly_event_id: Optional[int] = None) -> Assembly:
    """
    Read from the assembly table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query_one(con, 'assembly', data)
    return Assembly(**result)

@beartype.beartype
def read_assembly_all(con: db.Connection, assembled_contigs_id: Optional[int] = None,
             number_of_contigs: Optional[int] = None,
             qcd_reads_id: Optional[int] = None,
             total_assembled_length: Optional[int] = None,
             n50: Optional[str] = None,
             assembly_event_id: Optional[int] = None) -> List[Assembly]:
    """
    Read from the assembly table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'assembled_contigs_id': assembled_contigs_id,
        'number_of_contigs': number_of_contigs,
        'qcd_reads_id': qcd_reads_id,
        'total_assembled_length': total_assembled_length,
        'n50': n50,
        'assembly_event_id': assembly_event_id,
    }
    result = db.query(con, 'assembly', data)
    return [Assembly(**row.as_dict()) for row in result]

@beartype.beartype
def read_assembly_by_id(con: db.Connection, assembled_contigs_id: int) -> Optional[Assembly]:
    result = db.query_one(con, 'assembly', {'assembled_contigs_id': assembled_contigs_id})
    if result is None:
        return None
    return Assembly(**result)

@beartype.beartype
def delete_assembly_by_id(con: db.Connection, assembled_contigs_id: int):
    db.delete(con, 'assembly', {'assembled_contigs_id': assembled_contigs_id})
# Associate the functions with the class
Assembly.create_from_json_dict = create_assembly_from_json_dict
Assembly.write = write_assembly
Assembly.update = update_assembly
Assembly.write_many = write_assembly_many
Assembly.read = read_assembly
Assembly.read_fuzzy = read_assembly_fuzzy
Assembly.read_any = read_assembly_any
Assembly.read_one = read_assembly_one
Assembly.read_one_or_none = read_assembly_one_or_none
Assembly.read_all = read_assembly_all
Assembly.delete = delete_assembly_by_id
Assembly.read_by_id = read_assembly_by_id
Assembly.delete_by_id = delete_assembly_by_id



@beartype_wrap_init
@dataclasses.dataclass
class BridgeMagsMagCollections:
    """
    @param bridge_mags_mag_collections_id 
    @param mag_collections_id 
    @param mags_id 

    This is an automatically generated class
    """
    mag_collections_id: int # mag_collections_id integer (default: )
    mags_id: int # mags_id integer (default: )
    bridge_mags_mag_collections_id: Optional[int] = None # bridge_mags_mag_collections_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'bridge_mags_mag_collections_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_mag_collections(self, con: db.Connection) -> Optional['MagCollections']:
        return read_mag_collections_one_or_none(con, mag_collections_id=self.mag_collections_id)

    @beartype.beartype
    def get_mags(self, con: db.Connection) -> Optional['Mags']:
        return read_mags_one_or_none(con, mags_id=self.mags_id)

@beartype.beartype
def create_bridge_mags_mag_collections_from_json_dict(json_obj: dict):
        """
        Create a BridgeMagsMagCollections from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return BridgeMagsMagCollections(**json_obj)


@beartype.beartype
def write_bridge_mags_mag_collections_obj(con: db.Connection, obj: BridgeMagsMagCollections) -> int:
    """
    Write a BridgeMagsMagCollections object to the database
    @param con: database connection
    @param obj: BridgeMagsMagCollections object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'bridge_mags_mag_collections', dataclasses.asdict(obj))

@beartype.beartype
def write_bridge_mags_mag_collections(
            con: db.Connection,
            mag_collections_id: int,
            mags_id: int,
            bridge_mags_mag_collections_id: Optional[int] = None) -> int:
    """
    Write to the bridge_mags_mag_collections table in the database
    @param con: database connection
    @param bridge_mags_mag_collections_id 
    @param mag_collections_id 
    @param mags_id 
    @return id of the inserted/updated row
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    return db.upsert(con, 'bridge_mags_mag_collections', data)

@beartype.beartype
def write_bridge_mags_mag_collections_many(con: db.Connection, objs: List[BridgeMagsMagCollections], upsert: bool = False) -> int:
    """
    Write a list of BridgeMagsMagCollections objects to the database
    @param con: database connection
    @param objs: list of BridgeMagsMagCollections objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'bridge_mags_mag_collections', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_bridge_mags_mag_collections(con: db.Connection, bridge_mags_mag_collections_id: int,
            mag_collections_id: Optional[int] = None,
            mags_id: Optional[int] = None) -> int:
    """
    Update a row in the bridge_mags_mag_collections table in the database
    @param con: database connection
    @param bridge_mags_mag_collections_id 
    @param mag_collections_id 
    @param mags_id 
    @return The number of rows updated
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    return db.update(con, 'bridge_mags_mag_collections', data)

@beartype.beartype
def read_bridge_mags_mag_collections(
            con: db.Connection,
            mag_collections_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             bridge_mags_mag_collections_id: Optional[int] = None) -> Generator[BridgeMagsMagCollections, None, None]:
    """
    Read from the bridge_mags_mag_collections table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_mags_mag_collections_id 
    @param mag_collections_id 
    @param mags_id 
    @return generator of BridgeMagsMagCollections objects
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    result = db.query(con, 'bridge_mags_mag_collections', data)
    for row in result:
        yield BridgeMagsMagCollections(**row.as_dict())

@beartype.beartype
def read_bridge_mags_mag_collections_fuzzy(con: db.Connection, mag_collections_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             bridge_mags_mag_collections_id: Optional[int] = None) -> Generator[BridgeMagsMagCollections, None, None]:
    """
    Read from the bridge_mags_mag_collections table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_mags_mag_collections_id 
    @param mag_collections_id 
    @param mags_id 
    @return generator of BridgeMagsMagCollections objects
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    result = db.query_fuzzy(con, 'bridge_mags_mag_collections', data)
    for row in result:
        yield BridgeMagsMagCollections(**row.as_dict())

@beartype.beartype
def read_bridge_mags_mag_collections_any(con: db.Connection, mag_collections_id: Optional[List[int]] = None,
             mags_id: Optional[List[int]] = None,
             bridge_mags_mag_collections_id: Optional[List[int]] = None) -> Generator[BridgeMagsMagCollections, None, None]:
    """
    Read from the bridge_mags_mag_collections table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param bridge_mags_mag_collections_id 
    @param mag_collections_id 
    @param mags_id 
    @return generator of BridgeMagsMagCollections objects
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    result = db.query_any(con, 'bridge_mags_mag_collections', data)
    for row in result:
        yield BridgeMagsMagCollections(**row.as_dict())

@beartype.beartype
def read_bridge_mags_mag_collections_one_or_none(con: db.Connection, mag_collections_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             bridge_mags_mag_collections_id: Optional[int] = None) -> Optional[BridgeMagsMagCollections]:
    """
    Read from the bridge_mags_mag_collections table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    result = db.query_one_or_none(con, 'bridge_mags_mag_collections', data)
    if result is None:
        return None
    return BridgeMagsMagCollections(**result)

@beartype.beartype
def read_bridge_mags_mag_collections_one(con: db.Connection, mag_collections_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             bridge_mags_mag_collections_id: Optional[int] = None) -> BridgeMagsMagCollections:
    """
    Read from the bridge_mags_mag_collections table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    result = db.query_one(con, 'bridge_mags_mag_collections', data)
    return BridgeMagsMagCollections(**result)

@beartype.beartype
def read_bridge_mags_mag_collections_all(con: db.Connection, mag_collections_id: Optional[int] = None,
             mags_id: Optional[int] = None,
             bridge_mags_mag_collections_id: Optional[int] = None) -> List[BridgeMagsMagCollections]:
    """
    Read from the bridge_mags_mag_collections table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id,
        'mag_collections_id': mag_collections_id,
        'mags_id': mags_id,
    }
    result = db.query(con, 'bridge_mags_mag_collections', data)
    return [BridgeMagsMagCollections(**row.as_dict()) for row in result]

@beartype.beartype
def read_bridge_mags_mag_collections_by_id(con: db.Connection, bridge_mags_mag_collections_id: int) -> Optional[BridgeMagsMagCollections]:
    result = db.query_one(con, 'bridge_mags_mag_collections', {'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id})
    if result is None:
        return None
    return BridgeMagsMagCollections(**result)

@beartype.beartype
def delete_bridge_mags_mag_collections_by_id(con: db.Connection, bridge_mags_mag_collections_id: int):
    db.delete(con, 'bridge_mags_mag_collections', {'bridge_mags_mag_collections_id': bridge_mags_mag_collections_id})
# Associate the functions with the class
BridgeMagsMagCollections.create_from_json_dict = create_bridge_mags_mag_collections_from_json_dict
BridgeMagsMagCollections.write = write_bridge_mags_mag_collections
BridgeMagsMagCollections.update = update_bridge_mags_mag_collections
BridgeMagsMagCollections.write_many = write_bridge_mags_mag_collections_many
BridgeMagsMagCollections.read = read_bridge_mags_mag_collections
BridgeMagsMagCollections.read_fuzzy = read_bridge_mags_mag_collections_fuzzy
BridgeMagsMagCollections.read_any = read_bridge_mags_mag_collections_any
BridgeMagsMagCollections.read_one = read_bridge_mags_mag_collections_one
BridgeMagsMagCollections.read_one_or_none = read_bridge_mags_mag_collections_one_or_none
BridgeMagsMagCollections.read_all = read_bridge_mags_mag_collections_all
BridgeMagsMagCollections.delete = delete_bridge_mags_mag_collections_by_id
BridgeMagsMagCollections.read_by_id = read_bridge_mags_mag_collections_by_id
BridgeMagsMagCollections.delete_by_id = delete_bridge_mags_mag_collections_by_id



@beartype_wrap_init
@dataclasses.dataclass
class ResultDerivationEquations:
    """
    Relationship between Results and Equations used to derive them

    @param result_derivation_equations_id 
    @param derivation_equation_id 
    @param result_id 

    This is an automatically generated class
    """
    derivation_equation_id: int # derivation_equation_id integer (default: )
    result_id: int # result_id bigint (default: )
    result_derivation_equations_id: Optional[int] = None # result_derivation_equations_id bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'result_derivation_equations_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_derivation_equation(self, con: db.Connection) -> Optional['DerivationEquations']:
        return read_derivation_equations_one_or_none(con, derivation_equation_id=self.derivation_equation_id)

    @beartype.beartype
    def get_result(self, con: db.Connection) -> Optional['Results']:
        return read_results_one_or_none(con, result_id=self.result_id)

@beartype.beartype
def create_result_derivation_equations_from_json_dict(json_obj: dict):
        """
        Create a ResultDerivationEquations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return ResultDerivationEquations(**json_obj)


@beartype.beartype
def write_result_derivation_equations_obj(con: db.Connection, obj: ResultDerivationEquations) -> int:
    """
    Write a ResultDerivationEquations object to the database
    @param con: database connection
    @param obj: ResultDerivationEquations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'result_derivation_equations', dataclasses.asdict(obj))

@beartype.beartype
def write_result_derivation_equations(
            con: db.Connection,
            derivation_equation_id: int,
            result_id: int,
            result_derivation_equations_id: Optional[int] = None) -> int:
    """
    Write to the result_derivation_equations table in the database
    @param con: database connection
    @param result_derivation_equations_id 
    @param derivation_equation_id 
    @param result_id 
    @return id of the inserted/updated row
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    return db.upsert(con, 'result_derivation_equations', data)

@beartype.beartype
def write_result_derivation_equations_many(con: db.Connection, objs: List[ResultDerivationEquations], upsert: bool = False) -> int:
    """
    Write a list of ResultDerivationEquations objects to the database
    @param con: database connection
    @param objs: list of ResultDerivationEquations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'result_derivation_equations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_result_derivation_equations(con: db.Connection, result_derivation_equations_id: int,
            derivation_equation_id: Optional[int] = None,
            result_id: Optional[int] = None) -> int:
    """
    Update a row in the result_derivation_equations table in the database
    @param con: database connection
    @param result_derivation_equations_id 
    @param derivation_equation_id 
    @param result_id 
    @return The number of rows updated
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    return db.update(con, 'result_derivation_equations', data)

@beartype.beartype
def read_result_derivation_equations(
            con: db.Connection,
            derivation_equation_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_derivation_equations_id: Optional[int] = None) -> Generator[ResultDerivationEquations, None, None]:
    """
    Read from the result_derivation_equations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_derivation_equations_id 
    @param derivation_equation_id 
    @param result_id 
    @return generator of ResultDerivationEquations objects
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    result = db.query(con, 'result_derivation_equations', data)
    for row in result:
        yield ResultDerivationEquations(**row.as_dict())

@beartype.beartype
def read_result_derivation_equations_fuzzy(con: db.Connection, derivation_equation_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_derivation_equations_id: Optional[int] = None) -> Generator[ResultDerivationEquations, None, None]:
    """
    Read from the result_derivation_equations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_derivation_equations_id 
    @param derivation_equation_id 
    @param result_id 
    @return generator of ResultDerivationEquations objects
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    result = db.query_fuzzy(con, 'result_derivation_equations', data)
    for row in result:
        yield ResultDerivationEquations(**row.as_dict())

@beartype.beartype
def read_result_derivation_equations_any(con: db.Connection, derivation_equation_id: Optional[List[int]] = None,
             result_id: Optional[List[int]] = None,
             result_derivation_equations_id: Optional[List[int]] = None) -> Generator[ResultDerivationEquations, None, None]:
    """
    Read from the result_derivation_equations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param result_derivation_equations_id 
    @param derivation_equation_id 
    @param result_id 
    @return generator of ResultDerivationEquations objects
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    result = db.query_any(con, 'result_derivation_equations', data)
    for row in result:
        yield ResultDerivationEquations(**row.as_dict())

@beartype.beartype
def read_result_derivation_equations_one_or_none(con: db.Connection, derivation_equation_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_derivation_equations_id: Optional[int] = None) -> Optional[ResultDerivationEquations]:
    """
    Read from the result_derivation_equations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    result = db.query_one_or_none(con, 'result_derivation_equations', data)
    if result is None:
        return None
    return ResultDerivationEquations(**result)

@beartype.beartype
def read_result_derivation_equations_one(con: db.Connection, derivation_equation_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_derivation_equations_id: Optional[int] = None) -> ResultDerivationEquations:
    """
    Read from the result_derivation_equations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    result = db.query_one(con, 'result_derivation_equations', data)
    return ResultDerivationEquations(**result)

@beartype.beartype
def read_result_derivation_equations_all(con: db.Connection, derivation_equation_id: Optional[int] = None,
             result_id: Optional[int] = None,
             result_derivation_equations_id: Optional[int] = None) -> List[ResultDerivationEquations]:
    """
    Read from the result_derivation_equations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'result_derivation_equations_id': result_derivation_equations_id,
        'derivation_equation_id': derivation_equation_id,
        'result_id': result_id,
    }
    result = db.query(con, 'result_derivation_equations', data)
    return [ResultDerivationEquations(**row.as_dict()) for row in result]

@beartype.beartype
def read_result_derivation_equations_by_id(con: db.Connection, result_derivation_equations_id: int) -> Optional[ResultDerivationEquations]:
    result = db.query_one(con, 'result_derivation_equations', {'result_derivation_equations_id': result_derivation_equations_id})
    if result is None:
        return None
    return ResultDerivationEquations(**result)

@beartype.beartype
def delete_result_derivation_equations_by_id(con: db.Connection, result_derivation_equations_id: int):
    db.delete(con, 'result_derivation_equations', {'result_derivation_equations_id': result_derivation_equations_id})
# Associate the functions with the class
ResultDerivationEquations.create_from_json_dict = create_result_derivation_equations_from_json_dict
ResultDerivationEquations.write = write_result_derivation_equations
ResultDerivationEquations.update = update_result_derivation_equations
ResultDerivationEquations.write_many = write_result_derivation_equations_many
ResultDerivationEquations.read = read_result_derivation_equations
ResultDerivationEquations.read_fuzzy = read_result_derivation_equations_fuzzy
ResultDerivationEquations.read_any = read_result_derivation_equations_any
ResultDerivationEquations.read_one = read_result_derivation_equations_one
ResultDerivationEquations.read_one_or_none = read_result_derivation_equations_one_or_none
ResultDerivationEquations.read_all = read_result_derivation_equations_all
ResultDerivationEquations.delete = delete_result_derivation_equations_by_id
ResultDerivationEquations.read_by_id = read_result_derivation_equations_by_id
ResultDerivationEquations.delete_by_id = delete_result_derivation_equations_by_id



@beartype_wrap_init
@dataclasses.dataclass
class PhenocamCubes:
    """
    @param phenocam_cube_id 
    @param phenocam_dataset_id 
    @param filter_setting1 
    @param filter_setting2 
    @param filter_setting3 
    @param cubefile_directory_on_server 
    @param phenocam_cube_file_name_on_server 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param number_images_in_cube 

    This is an automatically generated class
    """
    phenocam_dataset_id: int # phenocam_dataset_id integer (default: )
    cubefile_directory_on_server: str # cubefile_directory_on_server character varying (default: )
    phenocam_cube_file_name_on_server: str # phenocam_cube_file_name_on_server character varying (default: )
    first_image_datetime_utc: datetime.datetime # first_image_datetime_utc timestamp without time zone (default: )
    last_image_datetime_utc: datetime.datetime # last_image_datetime_utc timestamp without time zone (default: )
    number_images_in_cube: int # number_images_in_cube integer (default: )
    phenocam_cube_id: Optional[int] = None # phenocam_cube_id integer (default: )
    filter_setting1: Optional[str] = None # filter_setting1 character varying (default: )
    filter_setting2: Optional[str] = None # filter_setting2 character varying (default: )
    filter_setting3: Optional[int] = None # filter_setting3 bigint (default: )
    PRIMARY_KEY: ClassVar[str] = 'phenocam_cube_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['first_image_datetime_utc'] = self.first_image_datetime_utc.isoformat()
        obj['last_image_datetime_utc'] = self.last_image_datetime_utc.isoformat()
        return obj

    @beartype.beartype
    def get_phenocam_dataset(self, con: db.Connection) -> Optional['PhenocamData']:
        return read_phenocam_data_one_or_none(con, phenocam_dataset_id=self.phenocam_dataset_id)

@beartype.beartype
def create_phenocam_cubes_from_json_dict(json_obj: dict):
        """
        Create a PhenocamCubes from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['first_image_datetime_utc'] = datetime.datetime.fromisoformat(json_obj['first_image_datetime_utc'])
        json_obj['last_image_datetime_utc'] = datetime.datetime.fromisoformat(json_obj['last_image_datetime_utc'])
        return PhenocamCubes(**json_obj)


@beartype.beartype
def write_phenocam_cubes_obj(con: db.Connection, obj: PhenocamCubes) -> int:
    """
    Write a PhenocamCubes object to the database
    @param con: database connection
    @param obj: PhenocamCubes object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'phenocam_cubes', dataclasses.asdict(obj))

@beartype.beartype
def write_phenocam_cubes(
            con: db.Connection,
            phenocam_dataset_id: int,
            cubefile_directory_on_server: str,
            phenocam_cube_file_name_on_server: str,
            first_image_datetime_utc: datetime.datetime,
            last_image_datetime_utc: datetime.datetime,
            number_images_in_cube: int,
            phenocam_cube_id: Optional[int] = None,
            filter_setting1: Optional[str] = None,
            filter_setting2: Optional[str] = None,
            filter_setting3: Optional[int] = None) -> int:
    """
    Write to the phenocam_cubes table in the database
    @param con: database connection
    @param phenocam_cube_id 
    @param phenocam_dataset_id 
    @param filter_setting1 
    @param filter_setting2 
    @param filter_setting3 
    @param cubefile_directory_on_server 
    @param phenocam_cube_file_name_on_server 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param number_images_in_cube 
    @return id of the inserted/updated row
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    return db.upsert(con, 'phenocam_cubes', data)

@beartype.beartype
def write_phenocam_cubes_many(con: db.Connection, objs: List[PhenocamCubes], upsert: bool = False) -> int:
    """
    Write a list of PhenocamCubes objects to the database
    @param con: database connection
    @param objs: list of PhenocamCubes objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'phenocam_cubes', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_phenocam_cubes(con: db.Connection, phenocam_cube_id: int,
            phenocam_dataset_id: Optional[int] = None,
            cubefile_directory_on_server: Optional[str] = None,
            phenocam_cube_file_name_on_server: Optional[str] = None,
            first_image_datetime_utc: Optional[datetime.datetime] = None,
            last_image_datetime_utc: Optional[datetime.datetime] = None,
            number_images_in_cube: Optional[int] = None,
            filter_setting1: Optional[str] = None,
            filter_setting2: Optional[str] = None,
            filter_setting3: Optional[int] = None) -> int:
    """
    Update a row in the phenocam_cubes table in the database
    @param con: database connection
    @param phenocam_cube_id 
    @param phenocam_dataset_id 
    @param filter_setting1 
    @param filter_setting2 
    @param filter_setting3 
    @param cubefile_directory_on_server 
    @param phenocam_cube_file_name_on_server 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param number_images_in_cube 
    @return The number of rows updated
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    return db.update(con, 'phenocam_cubes', data)

@beartype.beartype
def read_phenocam_cubes(
            con: db.Connection,
            phenocam_dataset_id: Optional[int] = None,
             cubefile_directory_on_server: Optional[str] = None,
             phenocam_cube_file_name_on_server: Optional[str] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             number_images_in_cube: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             filter_setting1: Optional[str] = None,
             filter_setting2: Optional[str] = None,
             filter_setting3: Optional[int] = None) -> Generator[PhenocamCubes, None, None]:
    """
    Read from the phenocam_cubes table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_cube_id 
    @param phenocam_dataset_id 
    @param filter_setting1 
    @param filter_setting2 
    @param filter_setting3 
    @param cubefile_directory_on_server 
    @param phenocam_cube_file_name_on_server 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param number_images_in_cube 
    @return generator of PhenocamCubes objects
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    result = db.query(con, 'phenocam_cubes', data)
    for row in result:
        yield PhenocamCubes(**row.as_dict())

@beartype.beartype
def read_phenocam_cubes_fuzzy(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             cubefile_directory_on_server: Optional[str] = None,
             phenocam_cube_file_name_on_server: Optional[str] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             number_images_in_cube: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             filter_setting1: Optional[str] = None,
             filter_setting2: Optional[str] = None,
             filter_setting3: Optional[int] = None) -> Generator[PhenocamCubes, None, None]:
    """
    Read from the phenocam_cubes table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_cube_id 
    @param phenocam_dataset_id 
    @param filter_setting1 
    @param filter_setting2 
    @param filter_setting3 
    @param cubefile_directory_on_server 
    @param phenocam_cube_file_name_on_server 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param number_images_in_cube 
    @return generator of PhenocamCubes objects
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    result = db.query_fuzzy(con, 'phenocam_cubes', data)
    for row in result:
        yield PhenocamCubes(**row.as_dict())

@beartype.beartype
def read_phenocam_cubes_any(con: db.Connection, phenocam_dataset_id: Optional[List[int]] = None,
             cubefile_directory_on_server: Optional[List[str]] = None,
             phenocam_cube_file_name_on_server: Optional[List[str]] = None,
             first_image_datetime_utc: Optional[List[datetime.datetime]] = None,
             last_image_datetime_utc: Optional[List[datetime.datetime]] = None,
             number_images_in_cube: Optional[List[int]] = None,
             phenocam_cube_id: Optional[List[int]] = None,
             filter_setting1: Optional[List[str]] = None,
             filter_setting2: Optional[List[str]] = None,
             filter_setting3: Optional[List[int]] = None) -> Generator[PhenocamCubes, None, None]:
    """
    Read from the phenocam_cubes table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param phenocam_cube_id 
    @param phenocam_dataset_id 
    @param filter_setting1 
    @param filter_setting2 
    @param filter_setting3 
    @param cubefile_directory_on_server 
    @param phenocam_cube_file_name_on_server 
    @param first_image_datetime_utc 
    @param last_image_datetime_utc 
    @param number_images_in_cube 
    @return generator of PhenocamCubes objects
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    result = db.query_any(con, 'phenocam_cubes', data)
    for row in result:
        yield PhenocamCubes(**row.as_dict())

@beartype.beartype
def read_phenocam_cubes_one_or_none(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             cubefile_directory_on_server: Optional[str] = None,
             phenocam_cube_file_name_on_server: Optional[str] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             number_images_in_cube: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             filter_setting1: Optional[str] = None,
             filter_setting2: Optional[str] = None,
             filter_setting3: Optional[int] = None) -> Optional[PhenocamCubes]:
    """
    Read from the phenocam_cubes table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    result = db.query_one_or_none(con, 'phenocam_cubes', data)
    if result is None:
        return None
    return PhenocamCubes(**result)

@beartype.beartype
def read_phenocam_cubes_one(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             cubefile_directory_on_server: Optional[str] = None,
             phenocam_cube_file_name_on_server: Optional[str] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             number_images_in_cube: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             filter_setting1: Optional[str] = None,
             filter_setting2: Optional[str] = None,
             filter_setting3: Optional[int] = None) -> PhenocamCubes:
    """
    Read from the phenocam_cubes table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    result = db.query_one(con, 'phenocam_cubes', data)
    return PhenocamCubes(**result)

@beartype.beartype
def read_phenocam_cubes_all(con: db.Connection, phenocam_dataset_id: Optional[int] = None,
             cubefile_directory_on_server: Optional[str] = None,
             phenocam_cube_file_name_on_server: Optional[str] = None,
             first_image_datetime_utc: Optional[datetime.datetime] = None,
             last_image_datetime_utc: Optional[datetime.datetime] = None,
             number_images_in_cube: Optional[int] = None,
             phenocam_cube_id: Optional[int] = None,
             filter_setting1: Optional[str] = None,
             filter_setting2: Optional[str] = None,
             filter_setting3: Optional[int] = None) -> List[PhenocamCubes]:
    """
    Read from the phenocam_cubes table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'phenocam_cube_id': phenocam_cube_id,
        'phenocam_dataset_id': phenocam_dataset_id,
        'filter_setting1': filter_setting1,
        'filter_setting2': filter_setting2,
        'filter_setting3': filter_setting3,
        'cubefile_directory_on_server': cubefile_directory_on_server,
        'phenocam_cube_file_name_on_server': phenocam_cube_file_name_on_server,
        'first_image_datetime_utc': first_image_datetime_utc,
        'last_image_datetime_utc': last_image_datetime_utc,
        'number_images_in_cube': number_images_in_cube,
    }
    result = db.query(con, 'phenocam_cubes', data)
    return [PhenocamCubes(**row.as_dict()) for row in result]

@beartype.beartype
def read_phenocam_cubes_by_id(con: db.Connection, phenocam_cube_id: int) -> Optional[PhenocamCubes]:
    result = db.query_one(con, 'phenocam_cubes', {'phenocam_cube_id': phenocam_cube_id})
    if result is None:
        return None
    return PhenocamCubes(**result)

@beartype.beartype
def delete_phenocam_cubes_by_id(con: db.Connection, phenocam_cube_id: int):
    db.delete(con, 'phenocam_cubes', {'phenocam_cube_id': phenocam_cube_id})
# Associate the functions with the class
PhenocamCubes.create_from_json_dict = create_phenocam_cubes_from_json_dict
PhenocamCubes.write = write_phenocam_cubes
PhenocamCubes.update = update_phenocam_cubes
PhenocamCubes.write_many = write_phenocam_cubes_many
PhenocamCubes.read = read_phenocam_cubes
PhenocamCubes.read_fuzzy = read_phenocam_cubes_fuzzy
PhenocamCubes.read_any = read_phenocam_cubes_any
PhenocamCubes.read_one = read_phenocam_cubes_one
PhenocamCubes.read_one_or_none = read_phenocam_cubes_one_or_none
PhenocamCubes.read_all = read_phenocam_cubes_all
PhenocamCubes.delete = delete_phenocam_cubes_by_id
PhenocamCubes.read_by_id = read_phenocam_cubes_by_id
PhenocamCubes.delete_by_id = delete_phenocam_cubes_by_id



@beartype_wrap_init
@dataclasses.dataclass
class SoilprobeMonitoringErtDatastream:
    """
    @param soilprobe_monitoring_ert_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param a_well 
    @param a_electrode 
    @param b_well 
    @param b_electrode 
    @param m_well 
    @param m_electrode 
    @param n_well 
    @param n_electrode 

    This is an automatically generated class
    """
    soilprobe_monitoring_id: int # soilprobe_monitoring_id integer (default: )
    datastream_id: int # datastream_id integer (default: )
    a_well: int # a_well integer (default: )
    a_electrode: int # a_electrode integer (default: )
    b_well: int # b_well integer (default: )
    b_electrode: int # b_electrode integer (default: )
    m_well: int # m_well integer (default: )
    m_electrode: int # m_electrode integer (default: )
    n_well: int # n_well integer (default: )
    n_electrode: int # n_electrode integer (default: )
    soilprobe_monitoring_ert_datastream_id: Optional[int] = None # soilprobe_monitoring_ert_datastream_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'soilprobe_monitoring_ert_datastream_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_soilprobe_monitoring(self, con: db.Connection) -> Optional['SoilprobeMonitoring']:
        return read_soilprobe_monitoring_one_or_none(con, soilprobe_monitoring_id=self.soilprobe_monitoring_id)

@beartype.beartype
def create_soilprobe_monitoring_ert_datastream_from_json_dict(json_obj: dict):
        """
        Create a SoilprobeMonitoringErtDatastream from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return SoilprobeMonitoringErtDatastream(**json_obj)


@beartype.beartype
def write_soilprobe_monitoring_ert_datastream_obj(con: db.Connection, obj: SoilprobeMonitoringErtDatastream) -> int:
    """
    Write a SoilprobeMonitoringErtDatastream object to the database
    @param con: database connection
    @param obj: SoilprobeMonitoringErtDatastream object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'soilprobe_monitoring_ert_datastream', dataclasses.asdict(obj))

@beartype.beartype
def write_soilprobe_monitoring_ert_datastream(
            con: db.Connection,
            soilprobe_monitoring_id: int,
            datastream_id: int,
            a_well: int,
            a_electrode: int,
            b_well: int,
            b_electrode: int,
            m_well: int,
            m_electrode: int,
            n_well: int,
            n_electrode: int,
            soilprobe_monitoring_ert_datastream_id: Optional[int] = None) -> int:
    """
    Write to the soilprobe_monitoring_ert_datastream table in the database
    @param con: database connection
    @param soilprobe_monitoring_ert_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param a_well 
    @param a_electrode 
    @param b_well 
    @param b_electrode 
    @param m_well 
    @param m_electrode 
    @param n_well 
    @param n_electrode 
    @return id of the inserted/updated row
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    return db.upsert(con, 'soilprobe_monitoring_ert_datastream', data)

@beartype.beartype
def write_soilprobe_monitoring_ert_datastream_many(con: db.Connection, objs: List[SoilprobeMonitoringErtDatastream], upsert: bool = False) -> int:
    """
    Write a list of SoilprobeMonitoringErtDatastream objects to the database
    @param con: database connection
    @param objs: list of SoilprobeMonitoringErtDatastream objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'soilprobe_monitoring_ert_datastream', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_soilprobe_monitoring_ert_datastream(con: db.Connection, soilprobe_monitoring_ert_datastream_id: int,
            soilprobe_monitoring_id: Optional[int] = None,
            datastream_id: Optional[int] = None,
            a_well: Optional[int] = None,
            a_electrode: Optional[int] = None,
            b_well: Optional[int] = None,
            b_electrode: Optional[int] = None,
            m_well: Optional[int] = None,
            m_electrode: Optional[int] = None,
            n_well: Optional[int] = None,
            n_electrode: Optional[int] = None) -> int:
    """
    Update a row in the soilprobe_monitoring_ert_datastream table in the database
    @param con: database connection
    @param soilprobe_monitoring_ert_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param a_well 
    @param a_electrode 
    @param b_well 
    @param b_electrode 
    @param m_well 
    @param m_electrode 
    @param n_well 
    @param n_electrode 
    @return The number of rows updated
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    return db.update(con, 'soilprobe_monitoring_ert_datastream', data)

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream(
            con: db.Connection,
            soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             a_well: Optional[int] = None,
             a_electrode: Optional[int] = None,
             b_well: Optional[int] = None,
             b_electrode: Optional[int] = None,
             m_well: Optional[int] = None,
             m_electrode: Optional[int] = None,
             n_well: Optional[int] = None,
             n_electrode: Optional[int] = None,
             soilprobe_monitoring_ert_datastream_id: Optional[int] = None) -> Generator[SoilprobeMonitoringErtDatastream, None, None]:
    """
    Read from the soilprobe_monitoring_ert_datastream table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_ert_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param a_well 
    @param a_electrode 
    @param b_well 
    @param b_electrode 
    @param m_well 
    @param m_electrode 
    @param n_well 
    @param n_electrode 
    @return generator of SoilprobeMonitoringErtDatastream objects
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    result = db.query(con, 'soilprobe_monitoring_ert_datastream', data)
    for row in result:
        yield SoilprobeMonitoringErtDatastream(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream_fuzzy(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             a_well: Optional[int] = None,
             a_electrode: Optional[int] = None,
             b_well: Optional[int] = None,
             b_electrode: Optional[int] = None,
             m_well: Optional[int] = None,
             m_electrode: Optional[int] = None,
             n_well: Optional[int] = None,
             n_electrode: Optional[int] = None,
             soilprobe_monitoring_ert_datastream_id: Optional[int] = None) -> Generator[SoilprobeMonitoringErtDatastream, None, None]:
    """
    Read from the soilprobe_monitoring_ert_datastream table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_ert_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param a_well 
    @param a_electrode 
    @param b_well 
    @param b_electrode 
    @param m_well 
    @param m_electrode 
    @param n_well 
    @param n_electrode 
    @return generator of SoilprobeMonitoringErtDatastream objects
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    result = db.query_fuzzy(con, 'soilprobe_monitoring_ert_datastream', data)
    for row in result:
        yield SoilprobeMonitoringErtDatastream(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream_any(con: db.Connection, soilprobe_monitoring_id: Optional[List[int]] = None,
             datastream_id: Optional[List[int]] = None,
             a_well: Optional[List[int]] = None,
             a_electrode: Optional[List[int]] = None,
             b_well: Optional[List[int]] = None,
             b_electrode: Optional[List[int]] = None,
             m_well: Optional[List[int]] = None,
             m_electrode: Optional[List[int]] = None,
             n_well: Optional[List[int]] = None,
             n_electrode: Optional[List[int]] = None,
             soilprobe_monitoring_ert_datastream_id: Optional[List[int]] = None) -> Generator[SoilprobeMonitoringErtDatastream, None, None]:
    """
    Read from the soilprobe_monitoring_ert_datastream table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param soilprobe_monitoring_ert_datastream_id 
    @param soilprobe_monitoring_id 
    @param datastream_id 
    @param a_well 
    @param a_electrode 
    @param b_well 
    @param b_electrode 
    @param m_well 
    @param m_electrode 
    @param n_well 
    @param n_electrode 
    @return generator of SoilprobeMonitoringErtDatastream objects
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    result = db.query_any(con, 'soilprobe_monitoring_ert_datastream', data)
    for row in result:
        yield SoilprobeMonitoringErtDatastream(**row.as_dict())

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream_one_or_none(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             a_well: Optional[int] = None,
             a_electrode: Optional[int] = None,
             b_well: Optional[int] = None,
             b_electrode: Optional[int] = None,
             m_well: Optional[int] = None,
             m_electrode: Optional[int] = None,
             n_well: Optional[int] = None,
             n_electrode: Optional[int] = None,
             soilprobe_monitoring_ert_datastream_id: Optional[int] = None) -> Optional[SoilprobeMonitoringErtDatastream]:
    """
    Read from the soilprobe_monitoring_ert_datastream table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    result = db.query_one_or_none(con, 'soilprobe_monitoring_ert_datastream', data)
    if result is None:
        return None
    return SoilprobeMonitoringErtDatastream(**result)

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream_one(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             a_well: Optional[int] = None,
             a_electrode: Optional[int] = None,
             b_well: Optional[int] = None,
             b_electrode: Optional[int] = None,
             m_well: Optional[int] = None,
             m_electrode: Optional[int] = None,
             n_well: Optional[int] = None,
             n_electrode: Optional[int] = None,
             soilprobe_monitoring_ert_datastream_id: Optional[int] = None) -> SoilprobeMonitoringErtDatastream:
    """
    Read from the soilprobe_monitoring_ert_datastream table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    result = db.query_one(con, 'soilprobe_monitoring_ert_datastream', data)
    return SoilprobeMonitoringErtDatastream(**result)

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream_all(con: db.Connection, soilprobe_monitoring_id: Optional[int] = None,
             datastream_id: Optional[int] = None,
             a_well: Optional[int] = None,
             a_electrode: Optional[int] = None,
             b_well: Optional[int] = None,
             b_electrode: Optional[int] = None,
             m_well: Optional[int] = None,
             m_electrode: Optional[int] = None,
             n_well: Optional[int] = None,
             n_electrode: Optional[int] = None,
             soilprobe_monitoring_ert_datastream_id: Optional[int] = None) -> List[SoilprobeMonitoringErtDatastream]:
    """
    Read from the soilprobe_monitoring_ert_datastream table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id,
        'soilprobe_monitoring_id': soilprobe_monitoring_id,
        'datastream_id': datastream_id,
        'a_well': a_well,
        'a_electrode': a_electrode,
        'b_well': b_well,
        'b_electrode': b_electrode,
        'm_well': m_well,
        'm_electrode': m_electrode,
        'n_well': n_well,
        'n_electrode': n_electrode,
    }
    result = db.query(con, 'soilprobe_monitoring_ert_datastream', data)
    return [SoilprobeMonitoringErtDatastream(**row.as_dict()) for row in result]

@beartype.beartype
def read_soilprobe_monitoring_ert_datastream_by_id(con: db.Connection, soilprobe_monitoring_ert_datastream_id: int) -> Optional[SoilprobeMonitoringErtDatastream]:
    result = db.query_one(con, 'soilprobe_monitoring_ert_datastream', {'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id})
    if result is None:
        return None
    return SoilprobeMonitoringErtDatastream(**result)

@beartype.beartype
def delete_soilprobe_monitoring_ert_datastream_by_id(con: db.Connection, soilprobe_monitoring_ert_datastream_id: int):
    db.delete(con, 'soilprobe_monitoring_ert_datastream', {'soilprobe_monitoring_ert_datastream_id': soilprobe_monitoring_ert_datastream_id})
# Associate the functions with the class
SoilprobeMonitoringErtDatastream.create_from_json_dict = create_soilprobe_monitoring_ert_datastream_from_json_dict
SoilprobeMonitoringErtDatastream.write = write_soilprobe_monitoring_ert_datastream
SoilprobeMonitoringErtDatastream.update = update_soilprobe_monitoring_ert_datastream
SoilprobeMonitoringErtDatastream.write_many = write_soilprobe_monitoring_ert_datastream_many
SoilprobeMonitoringErtDatastream.read = read_soilprobe_monitoring_ert_datastream
SoilprobeMonitoringErtDatastream.read_fuzzy = read_soilprobe_monitoring_ert_datastream_fuzzy
SoilprobeMonitoringErtDatastream.read_any = read_soilprobe_monitoring_ert_datastream_any
SoilprobeMonitoringErtDatastream.read_one = read_soilprobe_monitoring_ert_datastream_one
SoilprobeMonitoringErtDatastream.read_one_or_none = read_soilprobe_monitoring_ert_datastream_one_or_none
SoilprobeMonitoringErtDatastream.read_all = read_soilprobe_monitoring_ert_datastream_all
SoilprobeMonitoringErtDatastream.delete = delete_soilprobe_monitoring_ert_datastream_by_id
SoilprobeMonitoringErtDatastream.read_by_id = read_soilprobe_monitoring_ert_datastream_by_id
SoilprobeMonitoringErtDatastream.delete_by_id = delete_soilprobe_monitoring_ert_datastream_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Models:
    """
    @param model_id 
    @param model_code 
    @param model_name 
    @param model_description 
    @param version 
    @param model_link 

    This is an automatically generated class
    """
    model_code: str # model_code character varying (default: )
    model_name: str # model_name character varying (default: )
    model_id: Optional[int] = None # model_id integer (default: )
    model_description: Optional[str] = None # model_description character varying (default: )
    version: Optional[str] = None # version character varying (default: )
    model_link: Optional[str] = None # model_link character varying (default: )
    PRIMARY_KEY: ClassVar[str] = 'model_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

@beartype.beartype
def create_models_from_json_dict(json_obj: dict):
        """
        Create a Models from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return Models(**json_obj)


@beartype.beartype
def write_models_obj(con: db.Connection, obj: Models) -> int:
    """
    Write a Models object to the database
    @param con: database connection
    @param obj: Models object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'models', dataclasses.asdict(obj))

@beartype.beartype
def write_models(
            con: db.Connection,
            model_code: str,
            model_name: str,
            model_id: Optional[int] = None,
            model_description: Optional[str] = None,
            version: Optional[str] = None,
            model_link: Optional[str] = None) -> int:
    """
    Write to the models table in the database
    @param con: database connection
    @param model_id 
    @param model_code 
    @param model_name 
    @param model_description 
    @param version 
    @param model_link 
    @return id of the inserted/updated row
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    return db.upsert(con, 'models', data)

@beartype.beartype
def write_models_many(con: db.Connection, objs: List[Models], upsert: bool = False) -> int:
    """
    Write a list of Models objects to the database
    @param con: database connection
    @param objs: list of Models objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'models', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_models(con: db.Connection, model_id: int,
            model_code: Optional[str] = None,
            model_name: Optional[str] = None,
            model_description: Optional[str] = None,
            version: Optional[str] = None,
            model_link: Optional[str] = None) -> int:
    """
    Update a row in the models table in the database
    @param con: database connection
    @param model_id 
    @param model_code 
    @param model_name 
    @param model_description 
    @param version 
    @param model_link 
    @return The number of rows updated
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    return db.update(con, 'models', data)

@beartype.beartype
def read_models(
            con: db.Connection,
            model_code: Optional[str] = None,
             model_name: Optional[str] = None,
             model_id: Optional[int] = None,
             model_description: Optional[str] = None,
             version: Optional[str] = None,
             model_link: Optional[str] = None) -> Generator[Models, None, None]:
    """
    Read from the models table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param model_id 
    @param model_code 
    @param model_name 
    @param model_description 
    @param version 
    @param model_link 
    @return generator of Models objects
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    result = db.query(con, 'models', data)
    for row in result:
        yield Models(**row.as_dict())

@beartype.beartype
def read_models_fuzzy(con: db.Connection, model_code: Optional[str] = None,
             model_name: Optional[str] = None,
             model_id: Optional[int] = None,
             model_description: Optional[str] = None,
             version: Optional[str] = None,
             model_link: Optional[str] = None) -> Generator[Models, None, None]:
    """
    Read from the models table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param model_id 
    @param model_code 
    @param model_name 
    @param model_description 
    @param version 
    @param model_link 
    @return generator of Models objects
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    result = db.query_fuzzy(con, 'models', data)
    for row in result:
        yield Models(**row.as_dict())

@beartype.beartype
def read_models_any(con: db.Connection, model_code: Optional[List[str]] = None,
             model_name: Optional[List[str]] = None,
             model_id: Optional[List[int]] = None,
             model_description: Optional[List[str]] = None,
             version: Optional[List[str]] = None,
             model_link: Optional[List[str]] = None) -> Generator[Models, None, None]:
    """
    Read from the models table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param model_id 
    @param model_code 
    @param model_name 
    @param model_description 
    @param version 
    @param model_link 
    @return generator of Models objects
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    result = db.query_any(con, 'models', data)
    for row in result:
        yield Models(**row.as_dict())

@beartype.beartype
def read_models_one_or_none(con: db.Connection, model_code: Optional[str] = None,
             model_name: Optional[str] = None,
             model_id: Optional[int] = None,
             model_description: Optional[str] = None,
             version: Optional[str] = None,
             model_link: Optional[str] = None) -> Optional[Models]:
    """
    Read from the models table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    result = db.query_one_or_none(con, 'models', data)
    if result is None:
        return None
    return Models(**result)

@beartype.beartype
def read_models_one(con: db.Connection, model_code: Optional[str] = None,
             model_name: Optional[str] = None,
             model_id: Optional[int] = None,
             model_description: Optional[str] = None,
             version: Optional[str] = None,
             model_link: Optional[str] = None) -> Models:
    """
    Read from the models table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    result = db.query_one(con, 'models', data)
    return Models(**result)

@beartype.beartype
def read_models_all(con: db.Connection, model_code: Optional[str] = None,
             model_name: Optional[str] = None,
             model_id: Optional[int] = None,
             model_description: Optional[str] = None,
             version: Optional[str] = None,
             model_link: Optional[str] = None) -> List[Models]:
    """
    Read from the models table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'model_id': model_id,
        'model_code': model_code,
        'model_name': model_name,
        'model_description': model_description,
        'version': version,
        'model_link': model_link,
    }
    result = db.query(con, 'models', data)
    return [Models(**row.as_dict()) for row in result]

@beartype.beartype
def read_models_by_id(con: db.Connection, model_id: int) -> Optional[Models]:
    result = db.query_one(con, 'models', {'model_id': model_id})
    if result is None:
        return None
    return Models(**result)

@beartype.beartype
def delete_models_by_id(con: db.Connection, model_id: int):
    db.delete(con, 'models', {'model_id': model_id})
# Associate the functions with the class
Models.create_from_json_dict = create_models_from_json_dict
Models.write = write_models
Models.update = update_models
Models.write_many = write_models_many
Models.read = read_models
Models.read_fuzzy = read_models_fuzzy
Models.read_any = read_models_any
Models.read_one = read_models_one
Models.read_one_or_none = read_models_one_or_none
Models.read_all = read_models_all
Models.delete = delete_models_by_id
Models.read_by_id = read_models_by_id
Models.delete_by_id = delete_models_by_id



@beartype_wrap_init
@dataclasses.dataclass
class RelatedModels:
    """
    @param related_id 
    @param model_id 
    @param relationship_type_cv 
    @param related_model_id 

    This is an automatically generated class
    """
    model_id: int # model_id integer (default: )
    relationship_type_cv: str # relationship_type_cv character varying (default: )
    related_model_id: int # related_model_id integer (default: )
    related_id: Optional[int] = None # related_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'related_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        return obj

    @beartype.beartype
    def get_relationship_type_cv(self, con: db.Connection) -> Optional['CvRelationshipType']:
        return read_cv_relationship_type_one_or_none(con, term=self.relationship_type_cv)

    @beartype.beartype
    def get_model(self, con: db.Connection) -> Optional['Models']:
        return read_models_one_or_none(con, model_id=self.model_id)

@beartype.beartype
def create_related_models_from_json_dict(json_obj: dict):
        """
        Create a RelatedModels from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        return RelatedModels(**json_obj)


@beartype.beartype
def write_related_models_obj(con: db.Connection, obj: RelatedModels) -> int:
    """
    Write a RelatedModels object to the database
    @param con: database connection
    @param obj: RelatedModels object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'related_models', dataclasses.asdict(obj))

@beartype.beartype
def write_related_models(
            con: db.Connection,
            model_id: int,
            relationship_type_cv: str,
            related_model_id: int,
            related_id: Optional[int] = None) -> int:
    """
    Write to the related_models table in the database
    @param con: database connection
    @param related_id 
    @param model_id 
    @param relationship_type_cv 
    @param related_model_id 
    @return id of the inserted/updated row
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    return db.upsert(con, 'related_models', data)

@beartype.beartype
def write_related_models_many(con: db.Connection, objs: List[RelatedModels], upsert: bool = False) -> int:
    """
    Write a list of RelatedModels objects to the database
    @param con: database connection
    @param objs: list of RelatedModels objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'related_models', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_related_models(con: db.Connection, related_id: int,
            model_id: Optional[int] = None,
            relationship_type_cv: Optional[str] = None,
            related_model_id: Optional[int] = None) -> int:
    """
    Update a row in the related_models table in the database
    @param con: database connection
    @param related_id 
    @param model_id 
    @param relationship_type_cv 
    @param related_model_id 
    @return The number of rows updated
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    return db.update(con, 'related_models', data)

@beartype.beartype
def read_related_models(
            con: db.Connection,
            model_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_model_id: Optional[int] = None,
             related_id: Optional[int] = None) -> Generator[RelatedModels, None, None]:
    """
    Read from the related_models table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param related_id 
    @param model_id 
    @param relationship_type_cv 
    @param related_model_id 
    @return generator of RelatedModels objects
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    result = db.query(con, 'related_models', data)
    for row in result:
        yield RelatedModels(**row.as_dict())

@beartype.beartype
def read_related_models_fuzzy(con: db.Connection, model_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_model_id: Optional[int] = None,
             related_id: Optional[int] = None) -> Generator[RelatedModels, None, None]:
    """
    Read from the related_models table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param related_id 
    @param model_id 
    @param relationship_type_cv 
    @param related_model_id 
    @return generator of RelatedModels objects
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    result = db.query_fuzzy(con, 'related_models', data)
    for row in result:
        yield RelatedModels(**row.as_dict())

@beartype.beartype
def read_related_models_any(con: db.Connection, model_id: Optional[List[int]] = None,
             relationship_type_cv: Optional[List[str]] = None,
             related_model_id: Optional[List[int]] = None,
             related_id: Optional[List[int]] = None) -> Generator[RelatedModels, None, None]:
    """
    Read from the related_models table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param related_id 
    @param model_id 
    @param relationship_type_cv 
    @param related_model_id 
    @return generator of RelatedModels objects
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    result = db.query_any(con, 'related_models', data)
    for row in result:
        yield RelatedModels(**row.as_dict())

@beartype.beartype
def read_related_models_one_or_none(con: db.Connection, model_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_model_id: Optional[int] = None,
             related_id: Optional[int] = None) -> Optional[RelatedModels]:
    """
    Read from the related_models table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    result = db.query_one_or_none(con, 'related_models', data)
    if result is None:
        return None
    return RelatedModels(**result)

@beartype.beartype
def read_related_models_one(con: db.Connection, model_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_model_id: Optional[int] = None,
             related_id: Optional[int] = None) -> RelatedModels:
    """
    Read from the related_models table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    result = db.query_one(con, 'related_models', data)
    return RelatedModels(**result)

@beartype.beartype
def read_related_models_all(con: db.Connection, model_id: Optional[int] = None,
             relationship_type_cv: Optional[str] = None,
             related_model_id: Optional[int] = None,
             related_id: Optional[int] = None) -> List[RelatedModels]:
    """
    Read from the related_models table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'related_id': related_id,
        'model_id': model_id,
        'relationship_type_cv': relationship_type_cv,
        'related_model_id': related_model_id,
    }
    result = db.query(con, 'related_models', data)
    return [RelatedModels(**row.as_dict()) for row in result]

@beartype.beartype
def read_related_models_by_id(con: db.Connection, related_id: int) -> Optional[RelatedModels]:
    result = db.query_one(con, 'related_models', {'related_id': related_id})
    if result is None:
        return None
    return RelatedModels(**result)

@beartype.beartype
def delete_related_models_by_id(con: db.Connection, related_id: int):
    db.delete(con, 'related_models', {'related_id': related_id})
# Associate the functions with the class
RelatedModels.create_from_json_dict = create_related_models_from_json_dict
RelatedModels.write = write_related_models
RelatedModels.update = update_related_models
RelatedModels.write_many = write_related_models_many
RelatedModels.read = read_related_models
RelatedModels.read_fuzzy = read_related_models_fuzzy
RelatedModels.read_any = read_related_models_any
RelatedModels.read_one = read_related_models_one
RelatedModels.read_one_or_none = read_related_models_one_or_none
RelatedModels.read_all = read_related_models_all
RelatedModels.delete = delete_related_models_by_id
RelatedModels.read_by_id = read_related_models_by_id
RelatedModels.delete_by_id = delete_related_models_by_id



@beartype_wrap_init
@dataclasses.dataclass
class Simulations:
    """
    @param simulation_id 
    @param action_id 
    @param simulation_name 
    @param simulation_description 
    @param simulation_start_date_time 
    @param simulation_start_date_time_utc_offset 
    @param simulation_end_date_time 
    @param simulation_end_date_time_utc_offset 
    @param time_step_value 
    @param time_step_units_id 
    @param input_data_set_id 
    @param model_id 

    This is an automatically generated class
    """
    action_id: int # action_id integer (default: )
    simulation_name: str # simulation_name character varying (default: )
    simulation_start_date_time: datetime.datetime # simulation_start_date_time timestamp without time zone (default: )
    simulation_start_date_time_utc_offset: int # simulation_start_date_time_utc_offset integer (default: )
    simulation_end_date_time: datetime.datetime # simulation_end_date_time timestamp without time zone (default: )
    simulation_end_date_time_utc_offset: int # simulation_end_date_time_utc_offset integer (default: )
    time_step_value: float # time_step_value double precision (default: )
    time_step_units_id: int # time_step_units_id integer (default: )
    model_id: int # model_id integer (default: )
    simulation_id: Optional[int] = None # simulation_id integer (default: )
    simulation_description: Optional[str] = None # simulation_description character varying (default: )
    input_data_set_id: Optional[int] = None # input_data_set_id integer (default: )
    PRIMARY_KEY: ClassVar[str] = 'simulation_id'

    def to_json_dict(self) -> Dict[str, Any]:
        obj = dataclasses.asdict(self)
        obj['simulation_start_date_time'] = self.simulation_start_date_time.isoformat()
        obj['simulation_end_date_time'] = self.simulation_end_date_time.isoformat()
        return obj

    @beartype.beartype
    def get_action(self, con: db.Connection) -> Optional['Actions']:
        return read_actions_one_or_none(con, action_id=self.action_id)

    @beartype.beartype
    def get_model(self, con: db.Connection) -> Optional['Models']:
        return read_models_one_or_none(con, model_id=self.model_id)

@beartype.beartype
def create_simulations_from_json_dict(json_obj: dict):
        """
        Create a Simulations from a json object dict
        doing type conversions (IE, datetime str) as necessary
        """
        json_obj['simulation_start_date_time'] = datetime.datetime.fromisoformat(json_obj['simulation_start_date_time'])
        json_obj['simulation_end_date_time'] = datetime.datetime.fromisoformat(json_obj['simulation_end_date_time'])
        return Simulations(**json_obj)


@beartype.beartype
def write_simulations_obj(con: db.Connection, obj: Simulations) -> int:
    """
    Write a Simulations object to the database
    @param con: database connection
    @param obj: Simulations object
    @return id of the inserted/updated row
    """
    return db.upsert(con, 'simulations', dataclasses.asdict(obj))

@beartype.beartype
def write_simulations(
            con: db.Connection,
            action_id: int,
            simulation_name: str,
            simulation_start_date_time: datetime.datetime,
            simulation_start_date_time_utc_offset: int,
            simulation_end_date_time: datetime.datetime,
            simulation_end_date_time_utc_offset: int,
            time_step_value: float,
            time_step_units_id: int,
            model_id: int,
            simulation_id: Optional[int] = None,
            simulation_description: Optional[str] = None,
            input_data_set_id: Optional[int] = None) -> int:
    """
    Write to the simulations table in the database
    @param con: database connection
    @param simulation_id 
    @param action_id 
    @param simulation_name 
    @param simulation_description 
    @param simulation_start_date_time 
    @param simulation_start_date_time_utc_offset 
    @param simulation_end_date_time 
    @param simulation_end_date_time_utc_offset 
    @param time_step_value 
    @param time_step_units_id 
    @param input_data_set_id 
    @param model_id 
    @return id of the inserted/updated row
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    return db.upsert(con, 'simulations', data)

@beartype.beartype
def write_simulations_many(con: db.Connection, objs: List[Simulations], upsert: bool = False) -> int:
    """
    Write a list of Simulations objects to the database
    @param con: database connection
    @param objs: list of Simulations objects
    @param upsert: if True, update existing rows based on ID
    @return The number of rows inserted
    """
    return db.insert_many(con, 'simulations', [dataclasses.asdict(obj) for obj in objs], upsert=upsert)

@beartype.beartype
def update_simulations(con: db.Connection, simulation_id: int,
            action_id: Optional[int] = None,
            simulation_name: Optional[str] = None,
            simulation_start_date_time: Optional[datetime.datetime] = None,
            simulation_start_date_time_utc_offset: Optional[int] = None,
            simulation_end_date_time: Optional[datetime.datetime] = None,
            simulation_end_date_time_utc_offset: Optional[int] = None,
            time_step_value: Optional[float] = None,
            time_step_units_id: Optional[int] = None,
            model_id: Optional[int] = None,
            simulation_description: Optional[str] = None,
            input_data_set_id: Optional[int] = None) -> int:
    """
    Update a row in the simulations table in the database
    @param con: database connection
    @param simulation_id 
    @param action_id 
    @param simulation_name 
    @param simulation_description 
    @param simulation_start_date_time 
    @param simulation_start_date_time_utc_offset 
    @param simulation_end_date_time 
    @param simulation_end_date_time_utc_offset 
    @param time_step_value 
    @param time_step_units_id 
    @param input_data_set_id 
    @param model_id 
    @return The number of rows updated
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    return db.update(con, 'simulations', data)

@beartype.beartype
def read_simulations(
            con: db.Connection,
            action_id: Optional[int] = None,
             simulation_name: Optional[str] = None,
             simulation_start_date_time: Optional[datetime.datetime] = None,
             simulation_start_date_time_utc_offset: Optional[int] = None,
             simulation_end_date_time: Optional[datetime.datetime] = None,
             simulation_end_date_time_utc_offset: Optional[int] = None,
             time_step_value: Optional[float] = None,
             time_step_units_id: Optional[int] = None,
             model_id: Optional[int] = None,
             simulation_id: Optional[int] = None,
             simulation_description: Optional[str] = None,
             input_data_set_id: Optional[int] = None) -> Generator[Simulations, None, None]:
    """
    Read from the simulations table in the database, optionally filtered by a parameter
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param simulation_id 
    @param action_id 
    @param simulation_name 
    @param simulation_description 
    @param simulation_start_date_time 
    @param simulation_start_date_time_utc_offset 
    @param simulation_end_date_time 
    @param simulation_end_date_time_utc_offset 
    @param time_step_value 
    @param time_step_units_id 
    @param input_data_set_id 
    @param model_id 
    @return generator of Simulations objects
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    result = db.query(con, 'simulations', data)
    for row in result:
        yield Simulations(**row.as_dict())

@beartype.beartype
def read_simulations_fuzzy(con: db.Connection, action_id: Optional[int] = None,
             simulation_name: Optional[str] = None,
             simulation_start_date_time: Optional[datetime.datetime] = None,
             simulation_start_date_time_utc_offset: Optional[int] = None,
             simulation_end_date_time: Optional[datetime.datetime] = None,
             simulation_end_date_time_utc_offset: Optional[int] = None,
             time_step_value: Optional[float] = None,
             time_step_units_id: Optional[int] = None,
             model_id: Optional[int] = None,
             simulation_id: Optional[int] = None,
             simulation_description: Optional[str] = None,
             input_data_set_id: Optional[int] = None) -> Generator[Simulations, None, None]:
    """
    Read from the simulations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param simulation_id 
    @param action_id 
    @param simulation_name 
    @param simulation_description 
    @param simulation_start_date_time 
    @param simulation_start_date_time_utc_offset 
    @param simulation_end_date_time 
    @param simulation_end_date_time_utc_offset 
    @param time_step_value 
    @param time_step_units_id 
    @param input_data_set_id 
    @param model_id 
    @return generator of Simulations objects
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    result = db.query_fuzzy(con, 'simulations', data)
    for row in result:
        yield Simulations(**row.as_dict())

@beartype.beartype
def read_simulations_any(con: db.Connection, action_id: Optional[List[int]] = None,
             simulation_name: Optional[List[str]] = None,
             simulation_start_date_time: Optional[List[datetime.datetime]] = None,
             simulation_start_date_time_utc_offset: Optional[List[int]] = None,
             simulation_end_date_time: Optional[List[datetime.datetime]] = None,
             simulation_end_date_time_utc_offset: Optional[List[int]] = None,
             time_step_value: Optional[List[float]] = None,
             time_step_units_id: Optional[List[int]] = None,
             model_id: Optional[List[int]] = None,
             simulation_id: Optional[List[int]] = None,
             simulation_description: Optional[List[str]] = None,
             input_data_set_id: Optional[List[int]] = None) -> Generator[Simulations, None, None]:
    """
    Read from the simulations table in the database, optionally filtered by fuzzy parameter matching
    Returns a generator so that not all rows are fetched in memory at once
    @param con: database connection
    @param simulation_id 
    @param action_id 
    @param simulation_name 
    @param simulation_description 
    @param simulation_start_date_time 
    @param simulation_start_date_time_utc_offset 
    @param simulation_end_date_time 
    @param simulation_end_date_time_utc_offset 
    @param time_step_value 
    @param time_step_units_id 
    @param input_data_set_id 
    @param model_id 
    @return generator of Simulations objects
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    result = db.query_any(con, 'simulations', data)
    for row in result:
        yield Simulations(**row.as_dict())

@beartype.beartype
def read_simulations_one_or_none(con: db.Connection, action_id: Optional[int] = None,
             simulation_name: Optional[str] = None,
             simulation_start_date_time: Optional[datetime.datetime] = None,
             simulation_start_date_time_utc_offset: Optional[int] = None,
             simulation_end_date_time: Optional[datetime.datetime] = None,
             simulation_end_date_time_utc_offset: Optional[int] = None,
             time_step_value: Optional[float] = None,
             time_step_units_id: Optional[int] = None,
             model_id: Optional[int] = None,
             simulation_id: Optional[int] = None,
             simulation_description: Optional[str] = None,
             input_data_set_id: Optional[int] = None) -> Optional[Simulations]:
    """
    Read from the simulations table in the database, filtered by a required parameter.
    Returns None if no row is found.
    Raises MultipleResultsFound if more than one ro/w matches
    @param con: database connection
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    result = db.query_one_or_none(con, 'simulations', data)
    if result is None:
        return None
    return Simulations(**result)

@beartype.beartype
def read_simulations_one(con: db.Connection, action_id: Optional[int] = None,
             simulation_name: Optional[str] = None,
             simulation_start_date_time: Optional[datetime.datetime] = None,
             simulation_start_date_time_utc_offset: Optional[int] = None,
             simulation_end_date_time: Optional[datetime.datetime] = None,
             simulation_end_date_time_utc_offset: Optional[int] = None,
             time_step_value: Optional[float] = None,
             time_step_units_id: Optional[int] = None,
             model_id: Optional[int] = None,
             simulation_id: Optional[int] = None,
             simulation_description: Optional[str] = None,
             input_data_set_id: Optional[int] = None) -> Simulations:
    """
    Read from the simulations table in the database, filtered by a required parameter.
    Raises MultipleResultsFound if more than one row matches
    Raises NoResultsFound if no row matches
    @param con: database connection
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    result = db.query_one(con, 'simulations', data)
    return Simulations(**result)

@beartype.beartype
def read_simulations_all(con: db.Connection, action_id: Optional[int] = None,
             simulation_name: Optional[str] = None,
             simulation_start_date_time: Optional[datetime.datetime] = None,
             simulation_start_date_time_utc_offset: Optional[int] = None,
             simulation_end_date_time: Optional[datetime.datetime] = None,
             simulation_end_date_time_utc_offset: Optional[int] = None,
             time_step_value: Optional[float] = None,
             time_step_units_id: Optional[int] = None,
             model_id: Optional[int] = None,
             simulation_id: Optional[int] = None,
             simulation_description: Optional[str] = None,
             input_data_set_id: Optional[int] = None) -> List[Simulations]:
    """
    Read from the simulations table in the database, 
    optionally filtered by parameters
    @param con: database connection
    """
    data = {
        'simulation_id': simulation_id,
        'action_id': action_id,
        'simulation_name': simulation_name,
        'simulation_description': simulation_description,
        'simulation_start_date_time': simulation_start_date_time,
        'simulation_start_date_time_utc_offset': simulation_start_date_time_utc_offset,
        'simulation_end_date_time': simulation_end_date_time,
        'simulation_end_date_time_utc_offset': simulation_end_date_time_utc_offset,
        'time_step_value': time_step_value,
        'time_step_units_id': time_step_units_id,
        'input_data_set_id': input_data_set_id,
        'model_id': model_id,
    }
    result = db.query(con, 'simulations', data)
    return [Simulations(**row.as_dict()) for row in result]

@beartype.beartype
def read_simulations_by_id(con: db.Connection, simulation_id: int) -> Optional[Simulations]:
    result = db.query_one(con, 'simulations', {'simulation_id': simulation_id})
    if result is None:
        return None
    return Simulations(**result)

@beartype.beartype
def delete_simulations_by_id(con: db.Connection, simulation_id: int):
    db.delete(con, 'simulations', {'simulation_id': simulation_id})
# Associate the functions with the class
Simulations.create_from_json_dict = create_simulations_from_json_dict
Simulations.write = write_simulations
Simulations.update = update_simulations
Simulations.write_many = write_simulations_many
Simulations.read = read_simulations
Simulations.read_fuzzy = read_simulations_fuzzy
Simulations.read_any = read_simulations_any
Simulations.read_one = read_simulations_one
Simulations.read_one_or_none = read_simulations_one_or_none
Simulations.read_all = read_simulations_all
Simulations.delete = delete_simulations_by_id
Simulations.read_by_id = read_simulations_by_id
Simulations.delete_by_id = delete_simulations_by_id



_table_classes_by_name = {
    'categorical_result_value_annotations': CategoricalResultValueAnnotations,
    'action_annotations': ActionAnnotations,
    'annotations': Annotations,
    'equipment_annotations': EquipmentAnnotations,
    'measurement_result_value_annotations': MeasurementResultValueAnnotations,
    'method_annotations': MethodAnnotations,
    'point_coverage_result_value_annotations': PointCoverageResultValueAnnotations,
    'profile_result_value_annotations': ProfileResultValueAnnotations,
    'result_annotations': ResultAnnotations,
    'sampling_feature_annotations': SamplingFeatureAnnotations,
    'section_result_value_annotations': SectionResultValueAnnotations,
    'spectra_result_value_annotations': SpectraResultValueAnnotations,
    'timeseries_result_value_annotations': TimeseriesResultValueAnnotations,
    'trajectory_result_value_annotations': TrajectoryResultValueAnnotations,
    'transect_result_value_annotations': TransectResultValueAnnotations,
    'cv_censor_code': CvCensorCode,
    'cv_annotation_source': CvAnnotationSource,
    'cv_action_type': CvActionType,
    'cv_datastream_access_level': CvDatastreamAccessLevel,
    'cv_aggregation_statistic': CvAggregationStatistic,
    'cv_data_quality_type': CvDataQualityType,
    'cv_datastream_classifier': CvDatastreamClassifier,
    'cv_datastream_source_category': CvDatastreamSourceCategory,
    'cv_datastream_type': CvDatastreamType,
    'cv_annotation_type': CvAnnotationType,
    'cv_dataset_type': CvDatasetType,
    'cv_medium': CvMedium,
    'cv_property_data_type': CvPropertyDataType,
    'cv_persons_role': CvPersonsRole,
    'cv_image_channel': CvImageChannel,
    'cv_equipment_type': CvEquipmentType,
    'cv_organization_type': CvOrganizationType,
    'cv_elevation_datum': CvElevationDatum,
    'cv_equipment_status': CvEquipmentStatus,
    'cv_directive_type': CvDirectiveType,
    'cv_method_type': CvMethodType,
    'cv_features_of_interest_type': CvFeaturesOfInterestType,
    'cv_relationship_type': CvRelationshipType,
    'cv_result_type': CvResultType,
    'cv_status': CvStatus,
    'cv_sampling_feature_type': CvSamplingFeatureType,
    'cv_taxonomic_classifier_domain': CvTaxonomicClassifierDomain,
    'cv_specimen_collection': CvSpecimenCollection,
    'cv_specimen_type': CvSpecimenType,
    'cv_sampling_feature_geo_type': CvSamplingFeatureGeoType,
    'cv_quality_code': CvQualityCode,
    'cv_quantity_kind': CvQuantityKind,
    'cv_spatial_offset_type': CvSpatialOffsetType,
    'cv_units': CvUnits,
    'affiliations': Affiliations,
    'units_quantity_kind_bridge': UnitsQuantityKindBridge,
    'datasets': Datasets,
    'datasets_results': DatasetsResults,
    'feature_actions': FeatureActions,
    'actions': Actions,
    'action_by': ActionBy,
    'external_connection': ExternalConnection,
    'image_equipment_bridge': ImageEquipmentBridge,
    'image_persons_bridge': ImagePersonsBridge,
    'image_sampling_feature_bridge': ImageSamplingFeatureBridge,
    'cv_variable_domain': CvVariableDomain,
    'results': Results,
    'images': Images,
    'methods': Methods,
    'sampling_features_aliases': SamplingFeaturesAliases,
    'processing_levels': ProcessingLevels,
    'sampling_features': SamplingFeatures,
    'organizations': Organizations,
    'persons': Persons,
    'instrument_actions': InstrumentActions,
    'organization_sampling_feature_bridge': OrganizationSamplingFeatureBridge,
    'related_actions': RelatedActions,
    'variables_taxonomic_classifiers_bridge': VariablesTaxonomicClassifiersBridge,
    'taxonomic_classifiers': TaxonomicClassifiers,
    'data_quality': DataQuality,
    'reference_material_values': ReferenceMaterialValues,
    'result_normalization_values': ResultNormalizationValues,
    'calibration_reference_equipment': CalibrationReferenceEquipment,
    'variable_mapping': VariableMapping,
    'reference_materials': ReferenceMaterials,
    'results_data_quality': ResultsDataQuality,
    'calibration_actions': CalibrationActions,
    'calibration_standards': CalibrationStandards,
    'datalogger_file_columns': DataloggerFileColumns,
    'datalogger_program_files': DataloggerProgramFiles,
    'equipment_models': EquipmentModels,
    'instrument_output_quantity_kind': InstrumentOutputQuantityKind,
    'equipment_persons_bridge': EquipmentPersonsBridge,
    'equipment_position': EquipmentPosition,
    'equipment_used': EquipmentUsed,
    'maintenance_actions': MaintenanceActions,
    'datalogger_files': DataloggerFiles,
    'related_equipment': RelatedEquipment,
    'equipment': Equipment,
    'heartbeat': Heartbeat,
    'method_extension_property_values': MethodExtensionPropertyValues,
    'citation_extension_property_values': CitationExtensionPropertyValues,
    'result_extension_property_values': ResultExtensionPropertyValues,
    'sampling_feature_extension_property_values': SamplingFeatureExtensionPropertyValues,
    'variable_extension_property_values': VariableExtensionPropertyValues,
    'citation_external_identifiers': CitationExternalIdentifiers,
    'external_identifier_systems': ExternalIdentifierSystems,
    'method_external_identifiers': MethodExternalIdentifiers,
    'person_external_identifiers': PersonExternalIdentifiers,
    'action_extension_property_values': ActionExtensionPropertyValues,
    'extension_properties': ExtensionProperties,
    'spatial_reference_external_identifiers': SpatialReferenceExternalIdentifiers,
    'taxonomic_classifier_external_identifiers': TaxonomicClassifierExternalIdentifiers,
    'variable_external_identifiers': VariableExternalIdentifiers,
    'action_directives': ActionDirectives,
    'specimen_batch_positions': SpecimenBatchPositions,
    'assembly_event': AssemblyEvent,
    'binning_event': BinningEvent,
    'bridge_contigs_mags': BridgeContigsMags,
    'bridge_genes_gene_annotations': BridgeGenesGeneAnnotations,
    'sampling_feature_external_identifiers': SamplingFeatureExternalIdentifiers,
    'directives': Directives,
    'mags': Mags,
    'raw_reads': RawReads,
    'genes': Genes,
    'bridge_mag_annotation_event_gene_annotation': BridgeMagAnnotationEventGeneAnnotation,
    'mag_collections': MagCollections,
    'bridge_qcd_reads_assembly_event': BridgeQcdReadsAssemblyEvent,
    'gene_annotations': GeneAnnotations,
    'coverage': Coverage,
    'contigs': Contigs,
    'mag_annotation_event': MagAnnotationEvent,
    'qcd_reads': QcdReads,
    'extracted_dna': ExtractedDna,
    'categorical_result_values': CategoricalResultValues,
    'method_citations': MethodCitations,
    'related_annotations': RelatedAnnotations,
    'related_citations': RelatedCitations,
    'related_datasets': RelatedDatasets,
    'related_results': RelatedResults,
    'derivation_equations': DerivationEquations,
    'sequencing_facility': SequencingFacility,
    'author_lists': AuthorLists,
    'dataset_citations': DatasetCitations,
    'measurement_results': MeasurementResults,
    'point_coverage_result_values': PointCoverageResultValues,
    'profile_result_values': ProfileResultValues,
    'profile_results': ProfileResults,
    'section_result_values': SectionResultValues,
    'section_results': SectionResults,
    'spectra_result_values': SpectraResultValues,
    'categorical_results': CategoricalResults,
    'measurement_result_values': MeasurementResultValues,
    'point_coverage_results': PointCoverageResults,
    'trajectory_result_values': TrajectoryResultValues,
    'trajectory_results': TrajectoryResults,
    'transect_result_values': TransectResultValues,
    'transect_results': TransectResults,
    'spectra_results': SpectraResults,
    'calculated_datastream_expression': CalculatedDatastreamExpression,
    'datasource_description': DatasourceDescription,
    'calibration_multiplier_offset': CalibrationMultiplierOffset,
    'conversion_multiplier_offset': ConversionMultiplierOffset,
    'data_channel': DataChannel,
    'timeseries_result_values': TimeseriesResultValues,
    'timeseries_results': TimeseriesResults,
    'datastream_provenance_files': DatastreamProvenanceFiles,
    'phenocam_calculated_channel': PhenocamCalculatedChannel,
    'phenocam_imgs': PhenocamImgs,
    'qaqc_log': QaqcLog,
    'qaqc_detail': QaqcDetail,
    'variable_qa_min_max': VariableQaMinMax,
    'datastream_person_bridge': DatastreamPersonBridge,
    'timeseries_datastream_template': TimeseriesDatastreamTemplate,
    'sampling_feature_timeseries_datastreams': SamplingFeatureTimeseriesDatastreams,
    'datastream_provenance': DatastreamProvenance,
    'phenocam_data': PhenocamData,
    'spatial_offsets': SpatialOffsets,
    'spatial_references': SpatialReferences,
    'specimen_collection': SpecimenCollection,
    'sampled_features': SampledFeatures,
    'specimens': Specimens,
    'specimen_taxonomic_classifiers': SpecimenTaxonomicClassifiers,
    'soilprobe_monitoring': SoilprobeMonitoring,
    'related_features': RelatedFeatures,
    'soilprobe_monitoring_temperature_datastream': SoilprobeMonitoringTemperatureDatastream,
    'survey_electrode_geometry': SurveyElectrodeGeometry,
    'features_of_interest': FeaturesOfInterest,
    'specimen_to_specimen_collection_bridge': SpecimenToSpecimenCollectionBridge,
    'model_affiliations': ModelAffiliations,
    'citations': Citations,
    'variables': Variables,
    'reference_material_external_identifiers': ReferenceMaterialExternalIdentifiers,
    'assembly': Assembly,
    'bridge_mags_mag_collections': BridgeMagsMagCollections,
    'result_derivation_equations': ResultDerivationEquations,
    'phenocam_cubes': PhenocamCubes,
    'soilprobe_monitoring_ert_datastream': SoilprobeMonitoringErtDatastream,
    'models': Models,
    'related_models': RelatedModels,
    'simulations': Simulations,
}

def get_table_class(table_name: str) -> Optional[Type]:
    return _table_classes_by_name.get(table_name)

